{
 "cells": [
  {
   "cell_type": "raw",
   "id": "12a1fd37",
   "metadata": {},
   "source": [
    "---\n",
    "author: Nipun Batra\n",
    "badges: true\n",
    "categories:\n",
    "- ML\n",
    "date: '2023-12-18'\n",
    "output-file: transcript.html\n",
    "title: YouTube video to transcript using openAI whisper\n",
    "toc: true\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90499d25",
   "metadata": {},
   "source": [
    "Based on:\n",
    "https://blog.devgenius.io/transcribing-youtube-videos-using-openais-whisper-%EF%B8%8F-%EF%B8%8F-a29d264d6fb1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c576bebd",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f41ca63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8793dd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(video_id: str) -> str:\n",
    "    video_url = f'https://www.youtube.com/watch?v={video_id}'\n",
    "    ydl_opts = {\n",
    "        'format': 'm4a/bestaudio/best',\n",
    "        'paths': {'home': 'audio/'},\n",
    "        'outtmpl': {'default': '%(id)s.%(ext)s'},\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'm4a',\n",
    "        }]\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        error_code = ydl.download([video_url])\n",
    "        if error_code != 0:\n",
    "            raise Exception('Failed to download video')\n",
    "\n",
    "    return f'audio/{video_id}.m4a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de0e3377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=CuBzyh4Xmvk\n",
      "[youtube] CuBzyh4Xmvk: Downloading webpage\n",
      "[youtube] CuBzyh4Xmvk: Downloading ios player API JSON\n",
      "[youtube] CuBzyh4Xmvk: Downloading android player API JSON\n",
      "[youtube] CuBzyh4Xmvk: Downloading player d23221b6\n",
      "[youtube] CuBzyh4Xmvk: Downloading m3u8 information\n",
      "[info] CuBzyh4Xmvk: Downloading 1 format(s): 140\n",
      "[download] Destination: audio/CuBzyh4Xmvk.m4a\n",
      "[download] 100% of   72.31MiB in 00:00:41 at 1.75MiB/s     \n",
      "[FixupM4a] Correcting container of \"audio/CuBzyh4Xmvk.m4a\"\n",
      "[ExtractAudio] Not converting audio audio/CuBzyh4Xmvk.m4a; file is already in target format m4a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'audio/CuBzyh4Xmvk.m4a'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download('CuBzyh4Xmvk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46b2e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30b1aa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:03<00:00, 46.6MiB/s]\n"
     ]
    }
   ],
   "source": [
    "whisper_model = whisper.load_model(\"base.en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "933b2158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:05.400]  Please look at the code mentioned above and please sign up on the Google Cloud.\n",
      "[00:05.400 --> 00:08.520]  We've already started making some announcements.\n",
      "[00:08.520 --> 00:14.240]  You will likely end up missing the announcements and you'll have no one else to play with.\n",
      "[00:14.240 --> 00:20.080]  The second quick logistical announcement is that we'll have an extra lecture on Saturday,\n",
      "[00:20.080 --> 00:23.800]  11th Jan at 11am in 1.101.\n",
      "[00:23.800 --> 00:26.240]  So a lot of ones over there.\n",
      "[00:26.240 --> 00:32.000]  And I think one or two people still have conflict, but in the larger, in the larger\n",
      "[00:32.000 --> 00:36.240]  phone we will have almost everyone available, so we'll have to stick with this.\n",
      "[00:36.240 --> 00:43.960]  FAQ and the projects which were earlier shared on Google Docs, I'll give all of you a comment\n",
      "[00:43.960 --> 00:48.960]  access on it so that if you have any questions, queries, things like what should be the,\n",
      "[00:48.960 --> 00:54.160]  what are the maps, what are the main group size you can ask situations if they're already\n",
      "[00:54.160 --> 00:55.160]  not there.\n",
      "[00:55.520 --> 01:00.480]  Also about projects, if you have any questions, like what is the expectation if it's something\n",
      "[01:00.480 --> 01:06.600]  is not mentioned clearly, you can please comment on the Google Doc and we'll get back to you soon.\n",
      "[01:08.560 --> 01:13.160]  Also the video and the slides from the first lecture, in order to actually, actually\n",
      "[01:13.160 --> 01:18.600]  haven't put up on code translate, which is at the entrance, as mentioned in the slide\n",
      "[01:18.600 --> 01:19.600]  above.\n",
      "[01:20.600 --> 01:23.440]  This course website has also been now put on Google Cloud.\n",
      "[01:23.440 --> 01:26.120]  So you can also get to that.\n",
      "[01:28.600 --> 01:33.520]  Before we go forward, we should quickly revise what we started last time.\n",
      "[01:34.280 --> 01:37.800]  And someone tell you what is machine learning based on what we learned last time.\n",
      "[01:38.960 --> 01:40.520]  We looked at a couple of definitions.\n",
      "[01:40.520 --> 01:46.880]  One was from Arthur Sandler, who by the way was the first person to point with the machine learning\n",
      "[01:46.880 --> 01:48.440]  and he did that in 1959.\n",
      "[01:49.440 --> 01:50.720]  So a long long time back.\n",
      "[01:51.720 --> 01:53.720]  Anyone for this machine learning?\n",
      "[02:05.720 --> 02:12.720]  The ability to learn without explicitly being to add others, any definition you want to get?\n",
      "[02:14.720 --> 02:16.720]  There's a more technical definition also.\n",
      "[02:16.720 --> 02:18.720]  But we'll get to that later.\n",
      "[02:18.720 --> 02:23.720]  Let's first start with again this same study, same definition of the learning code.\n",
      "[02:23.720 --> 02:29.720]  It's a period of study and get computers, they are ready to learn without being explicitly programming.\n",
      "[02:29.720 --> 02:33.720]  Okay, anyone tell you what does being explicitly programming here?\n",
      "[02:37.720 --> 02:40.720]  Does a need a machine learning involves low programming?\n",
      "[02:40.720 --> 02:43.720]  So all programming, assignments are just the ways of learning.\n",
      "[02:44.720 --> 02:46.720]  Program itself.\n",
      "[02:46.720 --> 02:47.720]  Program itself.\n",
      "[02:47.720 --> 02:48.720]  Program itself.\n",
      "[02:48.720 --> 02:53.720]  So is it some, some oracle which ends up writing the code?\n",
      "[02:53.720 --> 02:55.720]  It's a whole writing program.\n",
      "[02:56.720 --> 03:02.720]  Of course there's one area, there's something on the computer architecture, so we're not going into that.\n",
      "[03:02.720 --> 03:04.720]  But who I'd say is the machine learning program.\n",
      "[03:05.720 --> 03:07.720]  So today's legislative program.\n",
      "[03:07.720 --> 03:12.720]  What is the exact meaning of adopting the executive program?\n",
      "[03:14.720 --> 03:16.720]  You don't have to replace this.\n",
      "[03:16.720 --> 03:18.720]  Okay, can you explain what does mean?\n",
      "[03:26.720 --> 03:28.720]  But he's on the right track.\n",
      "[03:28.720 --> 03:32.720]  Let's take an example to get this concept even better.\n",
      "[03:34.720 --> 03:36.720]  Can you see these model digits?\n",
      "[03:36.720 --> 03:39.720]  These are digits from 0 to 9.\n",
      "[03:40.720 --> 03:42.720]  And these are from the dataset for in this.\n",
      "[03:42.720 --> 03:45.720]  One of the most popular machine learning datasets.\n",
      "[03:45.720 --> 03:54.720]  Now the first task for all of us is we want to now write a program to recognize the digits.\n",
      "[03:54.720 --> 03:56.720]  And we'll start with code.\n",
      "[03:56.720 --> 04:01.720]  Can someone tell me how they'll recognize if a digit is 4 or not?\n",
      "[04:01.720 --> 04:03.720]  We're looking at these specific rules.\n",
      "[04:03.720 --> 04:07.720]  What does how we add to the code that we need?\n",
      "[04:08.720 --> 04:17.720]  Can we start off as 4 can be quantified as a vertical line, a horizontal line, a vertical line.\n",
      "[04:17.720 --> 04:19.720]  All of them are jointed.\n",
      "[04:19.720 --> 04:24.720]  And then another vertical line going down from the first, from the last vertical line.\n",
      "[04:24.720 --> 04:32.720]  Everything of that is that all that is there to 4 or if there are any models.\n",
      "[04:33.720 --> 04:41.720]  What about the fact that the height of each of the vertical lines need to be very similar?\n",
      "[04:41.720 --> 04:44.720]  Can you write this kind of a rule?\n",
      "[04:44.720 --> 04:50.720]  Or do you see a force where one of the lines is very, very long compared to the other?\n",
      "[04:50.720 --> 04:52.720]  Generally not.\n",
      "[04:52.720 --> 04:56.720]  So you have to report some of these constraints.\n",
      "[04:56.720 --> 04:58.720]  But are you done with it anything more?\n",
      "[04:59.720 --> 05:05.720]  Just look through the example for do you see any force which would violate the difference\n",
      "[05:05.720 --> 05:08.720]  that we've seen it, specify the thought.\n",
      "[05:08.720 --> 05:13.720]  And a thought will look that.\n",
      "[05:13.720 --> 05:16.720]  Okay, the second last is one case.\n",
      "[05:16.720 --> 05:21.720]  What about this one?\n",
      "[05:21.720 --> 05:27.720]  Okay, so each of the vertical lines would be a little smaller.\n",
      "[05:28.720 --> 05:32.720]  In many cases it would be a, and if I were to write, you will not understand it,\n",
      "[05:32.720 --> 05:34.720]  or you will get it.\n",
      "[05:34.720 --> 05:37.720]  So because people write different things.\n",
      "[05:37.720 --> 05:39.720]  So that's another rule that I like.\n",
      "[05:39.720 --> 05:41.720]  Now what do you mean by slides?\n",
      "[05:41.720 --> 05:47.720]  Well, it doesn't mean that it can have an inclination of some 10 degrees, 20 degrees, 30 degrees,\n",
      "[05:47.720 --> 05:49.720]  very excited, none of them.\n",
      "[05:49.720 --> 05:54.720]  So let's say you come up with some number, based on your experience, based on some rules of time.\n",
      "[05:55.720 --> 05:56.720]  But is that all?\n",
      "[05:56.720 --> 06:00.720]  No, some people write 4 with a star, right?\n",
      "[06:00.720 --> 06:07.720]  If you look at this, 1, 2, 3, 4, 5, 4, you have this particular line, we have to join\n",
      "[06:07.720 --> 06:10.720]  like this before piloting the end, right?\n",
      "[06:10.720 --> 06:13.720]  So that is now another rule that I've written.\n",
      "[06:13.720 --> 06:19.720]  You have already come up with 5, 6 of such rules, but that's not all.\n",
      "[06:19.720 --> 06:21.720]  Anything else you can think of?\n",
      "[06:21.720 --> 06:26.720]  That's why we have not talked about the bits of the lines.\n",
      "[06:26.720 --> 06:29.720]  What can we think about that?\n",
      "[06:29.720 --> 06:31.720]  Can we cover some rules?\n",
      "[06:31.720 --> 06:39.720]  Let's say if I'm writing the different mark or if I'm using the pen in different fashion,\n",
      "[06:39.720 --> 06:44.720]  where some of my strokes we fired will be thicker, right?\n",
      "[06:44.720 --> 06:47.720]  Maybe that's another particular rule, right?\n",
      "[06:47.720 --> 06:52.720]  There can be some cases where the width of each of the stroke is a little different.\n",
      "[06:52.720 --> 06:58.720]  You'll have to again capture some of these characteristics, while writing some rules or\n",
      "[06:58.720 --> 07:02.720]  writing a program to recognize 4.\n",
      "[07:02.720 --> 07:11.720]  So what we have done thus far is explicitly programmed to classify order, right?\n",
      "[07:11.720 --> 07:17.720]  So now we understand what is explicit programming, what we know is completely different from this.\n",
      "[07:17.720 --> 07:21.720]  So what if thus far does is we had data?\n",
      "[07:21.720 --> 07:26.720]  Data was these examples that we already had.\n",
      "[07:26.720 --> 07:28.720]  We came up with some rules.\n",
      "[07:28.720 --> 07:33.720]  So these were rules which we as experts suggested.\n",
      "[07:33.720 --> 07:38.720]  And in traditional programming we have some kind of a pattern, some programming line would be right,\n",
      "[07:38.720 --> 07:41.720]  which would recognize all of these.\n",
      "[07:41.720 --> 07:45.720]  Of course, what is presented as a vertical line or horizontal line?\n",
      "[07:45.720 --> 07:48.720]  Are still higher constructs?\n",
      "[07:48.720 --> 07:53.720]  For example, vertical line a program computer does not know what is a vertical line.\n",
      "[07:53.720 --> 07:56.720]  So you have to again boil it down to the computer.\n",
      "[07:56.720 --> 08:00.720]  What do you think the vertical line to the middle means?\n",
      "[08:00.720 --> 08:02.720]  Same.\n",
      "[08:02.720 --> 08:03.720]  Same.\n",
      "[08:03.720 --> 08:04.720]  Same.\n",
      "[08:04.720 --> 08:05.720]  Same.\n",
      "[08:05.720 --> 08:06.720]  Ex-axis.\n",
      "[08:06.720 --> 08:16.720]  So think of it as pixels and all of the pixels would be of similar shape, like vertically going on.\n",
      "[08:16.720 --> 08:21.720]  So we have data rules and traditional programming that gives us the answers.\n",
      "[08:21.720 --> 08:24.720]  Now let's go back to the definition.\n",
      "[08:24.720 --> 08:27.720]  The genome is a period of study as computers.\n",
      "[08:27.720 --> 08:32.720]  We have computers a little bit to learn without being explicit in the program.\n",
      "[08:32.720 --> 08:38.720]  And now to make this particular program, to tell me what, if you have to be able to\n",
      "[08:38.720 --> 08:43.720]  use traditional programming with machine learning, what do we need to do?\n",
      "[08:43.720 --> 08:45.720]  So we are not explicitly programming.\n",
      "[08:45.720 --> 08:46.720]  What changes?\n",
      "[08:46.720 --> 08:51.720]  The Romans are gone there.\n",
      "[08:51.720 --> 09:00.720]  So what we are saying is, I am going to learn with the only explicitly- describe program.\n",
      "[09:00.720 --> 09:02.720]  So we don't need the data.\n",
      "[09:02.720 --> 09:04.720]  We don't need the answers.\n",
      "[09:04.720 --> 09:11.720]  And what we end up with is automatically some function of rules that are being run.\n",
      "[09:11.720 --> 09:14.720]  So this is how traditional programming is.\n",
      "[09:14.720 --> 09:17.720]  The bad line of the system program is very different from machine learning.\n",
      "[09:17.720 --> 09:21.720]  Which I have still done this, done this in a very abstract sense.\n",
      "[09:21.720 --> 09:24.720]  We are slowly going to go deeper from this.\n",
      "[09:24.720 --> 09:30.720]  We also looked at another definition which was a more formal definition of machine learning,\n",
      "[09:30.720 --> 09:33.720]  which was given by Tom, which I like.\n",
      "[09:33.720 --> 09:36.720]  Tom is learning from experience E.\n",
      "[09:36.720 --> 09:43.720]  If you look at the experience E, tasks, P, and a performance measure, P,\n",
      "[09:43.720 --> 09:50.720]  if the performance is improving in the particular task, as to measure by the performance measure.\n",
      "[09:50.720 --> 09:53.720]  And it is improving with experience.\n",
      "[09:54.720 --> 09:58.720]  Let's say in this particular case, the task is what?\n",
      "[09:58.720 --> 10:00.720]  For machine learning.\n",
      "[10:00.720 --> 10:02.720]  To classify digits.\n",
      "[10:02.720 --> 10:05.720]  And what is the input that is typically given?\n",
      "[10:05.720 --> 10:10.720]  You have some, so you said that you have some experience.\n",
      "[10:10.720 --> 10:16.720]  The experience can be you have some images along with the true label.\n",
      "[10:16.720 --> 10:22.720]  So you have elements like this 0 along with that label that is actually 0.\n",
      "[10:22.720 --> 10:26.720]  But you have various different examples.\n",
      "[10:26.720 --> 10:31.720]  And the performance measure P, what do you think is the performance measure P?\n",
      "[10:31.720 --> 10:34.720]  What do you want to optimize on?\n",
      "[10:34.720 --> 10:37.720]  How correctly you are given to classify digits?\n",
      "[10:37.720 --> 10:43.720]  So, could you come up with a more scientific sub-centum for correctness?\n",
      "[10:43.720 --> 10:44.720]  I can see.\n",
      "[10:44.720 --> 10:45.720]  Or similar sub-centum.\n",
      "[10:45.720 --> 10:49.720]  So we look at some of these metrics in today.\n",
      "[10:49.720 --> 10:54.720]  So we will start of place lecture after having revised what is machine learning.\n",
      "[10:54.720 --> 10:58.720]  We will start, we are now starting a company, all of us are starting a company.\n",
      "[10:58.720 --> 11:04.720]  And we want to be the basket of those words or some similar words we saw.\n",
      "[11:04.720 --> 11:05.720]  We want to scale.\n",
      "[11:05.720 --> 11:10.720]  So if you remember one of the keywords which we use a lot in the previous lecture was scaled.\n",
      "[11:10.720 --> 11:15.720]  The problem statement is that you want to predict the quality or condition for computer.\n",
      "[11:15.720 --> 11:17.720]  Given its visual features.\n",
      "[11:18.720 --> 11:25.720]  So we say that our business use cases that growth rates are similar such grocery stores,\n",
      "[11:25.720 --> 11:29.720]  they have some human in the loop who looks at each of the tomatoes.\n",
      "[11:29.720 --> 11:33.720]  And that is in let's say a per minute per tomato.\n",
      "[11:33.720 --> 11:39.720]  So there is a lot of human input involved which is making the whole process look.\n",
      "[11:39.720 --> 11:44.720]  We plan to scale it by using computer vision with your features between the data.\n",
      "[11:44.720 --> 11:47.720]  So what we are going to do is we have now an assembly line.\n",
      "[11:47.720 --> 11:52.720]  You put the tomatoes in the assembly line as the pass of snapshots are taken.\n",
      "[11:52.720 --> 11:56.720]  And you automatically classify whether it is a good tomato or bad tomato.\n",
      "[11:56.720 --> 11:58.720]  And back of the tomatoes are from away.\n",
      "[11:58.720 --> 11:59.720]  Right?\n",
      "[11:59.720 --> 12:00.720]  So you are saying that you are saying that you are saying that you are saying that you are\n",
      "[12:00.720 --> 12:01.720]  using a huge amount of human effort.\n",
      "[12:01.720 --> 12:03.720]  And what are you making your process greater?\n",
      "[12:03.720 --> 12:09.720]  So you are saying that why this process we are able to make the living spirit.\n",
      "[12:09.720 --> 12:10.720]  Right?\n",
      "[12:10.720 --> 12:15.720]  So let's now do one of the machine learning aspects of this problem spirit.\n",
      "[12:15.720 --> 12:21.720]  So if you remember, that's why I just spoken that there is an enerity of data.\n",
      "[12:21.720 --> 12:22.720]  Right?\n",
      "[12:22.720 --> 12:24.720]  There is an enerity of experience and data.\n",
      "[12:24.720 --> 12:29.720]  So let's say that we have some pass data on the quality of tomatoes.\n",
      "[12:29.720 --> 12:35.720]  We have collected thousands of tomatoes and for each of the tomatoes some human expert\n",
      "[12:35.720 --> 12:38.720]  can identify whether it is a good tomato or bad tomato.\n",
      "[12:38.720 --> 12:43.720]  For now it is just if you are good or bad and not on the scale of all the tomatoes.\n",
      "[12:43.720 --> 12:44.720]  Right?\n",
      "[12:44.720 --> 12:45.720]  There are two classes.\n",
      "[12:45.720 --> 12:50.720]  What visual features do you think would be useful to characterize the tomato?\n",
      "[12:50.720 --> 12:51.720]  Color?\n",
      "[12:51.720 --> 12:55.720]  Any...so what...what if you could be a good tomato?\n",
      "[12:55.720 --> 12:56.720]  You just...\n",
      "[12:56.720 --> 12:59.720]  Which is more red or more...\n",
      "[12:59.720 --> 13:01.720]  There is something on the shades of red.\n",
      "[13:01.720 --> 13:03.720]  What is the data made of?\n",
      "[13:04.720 --> 13:10.720]  Something which is either showing some greenish shade, it may be an anvil.\n",
      "[13:10.720 --> 13:16.720]  Black definitely or if it has some fungus or some other attributes.\n",
      "[13:16.720 --> 13:19.720]  What is the other attributes which make it a little bit of bad?\n",
      "[13:19.720 --> 13:21.720]  It is a shade.\n",
      "[13:21.720 --> 13:22.720]  It is a shade.\n",
      "[13:22.720 --> 13:24.720]  Is there a text?\n",
      "[13:24.720 --> 13:27.720]  It is a perfect circle.\n",
      "[13:27.720 --> 13:32.720]  So the...okay some...some...so the size is another attribute.\n",
      "[13:32.720 --> 13:39.720]  Let's say that we have seen for now that all tomatoes are roughly over and smaller tomatoes\n",
      "[13:39.720 --> 13:42.720]  are bad, very big tomatoes are also bad.\n",
      "[13:42.720 --> 13:47.720]  They are very injected with some growth...growth chemicals.\n",
      "[13:47.720 --> 13:52.720]  Size, whether we have seen, what are the other things you would typically do?\n",
      "[13:52.720 --> 13:53.720]  Fine.\n",
      "[13:53.720 --> 13:56.720]  Yeah, but visual features will not look at the people.\n",
      "[13:56.720 --> 13:58.720]  So you'll have to get some proxy for that.\n",
      "[13:59.720 --> 14:02.720]  So that is another thing which I want all of us to take from the machine learning course.\n",
      "[14:02.720 --> 14:05.720]  What are some of the proxy features we could take from?\n",
      "[14:05.720 --> 14:06.720]  Yes, texture.\n",
      "[14:06.720 --> 14:11.720]  So texture will tell us something about the field of the community.\n",
      "[14:11.720 --> 14:15.720]  Whether it's very rough, very smooth, very light and etc.\n",
      "[14:15.720 --> 14:18.720]  So we looked at these three specific features.\n",
      "[14:18.720 --> 14:19.720]  Would there be others?\n",
      "[14:19.720 --> 14:22.720]  Yes, there might be thousands of other features.\n",
      "[14:22.720 --> 14:25.720]  But for the purposes of this example, it's only these three.\n",
      "[14:26.720 --> 14:31.720]  So we were talking about some vast data or some vast experience that we already have.\n",
      "[14:31.720 --> 14:35.720]  Maybe it exists in a form of potato like this.\n",
      "[14:35.720 --> 14:40.720]  You have some sample of the...you have the color, size, texture and you have the condition.\n",
      "[14:40.720 --> 14:45.720]  So this condition has been manually and a data written down by a human expert.\n",
      "[14:45.720 --> 14:57.720]  So in this particular table, you think sample number could be a useful attribute of feature\n",
      "[14:57.720 --> 14:59.720]  to predict the condition?\n",
      "[14:59.720 --> 15:02.720]  How many think yes?\n",
      "[15:02.720 --> 15:05.720]  How many think no?\n",
      "[15:05.720 --> 15:06.720]  Okay.\n",
      "[15:06.720 --> 15:09.720]  Now tell me that it could be a useful feature.\n",
      "[15:09.720 --> 15:11.720]  Now think more and more.\n",
      "[15:11.720 --> 15:16.720]  How could the sample number be useful?\n",
      "[15:16.720 --> 15:23.720]  Sorry.\n",
      "[15:23.720 --> 15:31.720]  No, also the equation is orange.\n",
      "[15:31.720 --> 15:36.720]  If the other is orange, decide the small, the texture is smooth.\n",
      "[15:36.720 --> 15:38.720]  I can roughly say the condition is good.\n",
      "[15:38.720 --> 15:45.720]  So let's say we have a sample number that is equal to 1, 10 because the parameters will be equal to 1.\n",
      "[15:45.720 --> 15:46.720]  Yes.\n",
      "[15:46.720 --> 15:49.720]  1 and 2 are equal to 0.\n",
      "[15:49.720 --> 15:52.720]  It sequentially arrives to 1 and 2.\n",
      "[15:52.720 --> 15:58.720]  So why do you think the sample number could be useful?\n",
      "[15:58.720 --> 16:03.720]  So some of you get it to the point that let's say we sequentially arrange, then we will get something.\n",
      "[16:03.720 --> 16:05.720]  But are we getting something?\n",
      "[16:05.720 --> 16:06.720]  Yes.\n",
      "[16:06.720 --> 16:11.720]  So you can just write the same thing and then get qualified for the same time.\n",
      "[16:11.720 --> 16:12.720]  Okay.\n",
      "[16:12.720 --> 16:19.720]  So he is answering that maybe there is a notion of time associated with samples, very likely they could be.\n",
      "[16:19.720 --> 16:26.720]  And imagine a scenario where there is one specific time of the year, maybe when all of the variables are bad.\n",
      "[16:26.720 --> 16:33.720]  Maybe if we produce a band, maybe the leader, which is bringing the tomatoes was hard, had gone wrong, something would have happened.\n",
      "[16:33.720 --> 16:37.720]  So in some very limited cases, the sample number could be used for the future.\n",
      "[16:37.720 --> 16:46.720]  But it's more likely that it's probably better to include more features, which are capturing the types of things we are looking at.\n",
      "[16:46.720 --> 16:48.720]  For example, what was its vehicle condition?\n",
      "[16:48.720 --> 16:52.720]  How many hours have passed through the way it was made?\n",
      "[16:52.720 --> 16:54.720]  Things like that.\n",
      "[16:54.720 --> 16:57.720]  The sample number might be giving them this up.\n",
      "[16:57.720 --> 17:01.720]  But then this could be the same example as we saw in the last lecture.\n",
      "[17:01.720 --> 17:05.720]  Where more ice beams means more sharp attacks.\n",
      "[17:05.720 --> 17:08.720]  There was some correlation, but there was no correlation.\n",
      "[17:08.720 --> 17:20.720]  So we have thus discussed that the sample number is likely or unlikely to be a good feature depending on how we model the phone process.\n",
      "[17:20.720 --> 17:23.720]  So for now, let's ignore the sample number.\n",
      "[17:23.720 --> 17:26.720]  Imagine it does not provide any useful information.\n",
      "[17:26.720 --> 17:30.720]  So then we have some data table, which looks like the problem.\n",
      "[17:30.720 --> 17:36.720]  We will call this entire table the training set.\n",
      "[17:36.720 --> 17:41.720]  And if you've noted, I have labeled them in different columns.\n",
      "[17:41.720 --> 17:44.720]  Anyone wants to tell why they are different?\n",
      "[17:44.720 --> 17:49.720]  Okay, and put an output as a very technical term.\n",
      "[17:49.720 --> 17:55.720]  Any other term you could talk about these two paths of a so far way.\n",
      "[17:55.720 --> 17:58.720]  So this looks like a matrix with real matrix.\n",
      "[17:58.720 --> 18:00.720]  I think they get that performance.\n",
      "[18:00.720 --> 18:01.720]  Experience and performance.\n",
      "[18:01.720 --> 18:04.720]  So the condition is not very good performance.\n",
      "[18:04.720 --> 18:11.720]  The condition is the annotation or the label or the output assigned to this particular item.\n",
      "[18:11.720 --> 18:14.720]  So this is one parameter.\n",
      "[18:14.720 --> 18:16.720]  The extra is one parameter.\n",
      "[18:16.720 --> 18:18.720]  It's not very good performance.\n",
      "[18:19.720 --> 18:25.720]  We call these things as features, items, and code areas.\n",
      "[18:25.720 --> 18:29.720]  If we go back, let's look at the equation which I was asking.\n",
      "[18:29.720 --> 18:32.720]  What features do you think will be used?\n",
      "[18:32.720 --> 18:33.720]  Make sense?\n",
      "[18:33.720 --> 18:35.720]  These things are called features.\n",
      "[18:35.720 --> 18:39.720]  The first three columns in this table are called features.\n",
      "[18:39.720 --> 18:42.720]  They are telling us something useful about the parameter.\n",
      "[18:42.720 --> 18:45.720]  What are the four features that are going on?\n",
      "[18:46.720 --> 18:51.720]  Those also equals, by the features that we have over here, they are all used anonymously.\n",
      "[18:51.720 --> 18:54.720]  But you will generally use features that are handy.\n",
      "[18:54.720 --> 18:57.720]  Obviates is generally used in some of the features.\n",
      "[18:57.720 --> 19:03.720]  And the output of the condition in this case is called the output of the response wave\n",
      "[19:03.720 --> 19:07.720]  and what is the response once you've observed some features.\n",
      "[19:07.720 --> 19:08.720]  Right?\n",
      "[19:08.720 --> 19:12.720]  Everyone, here to now.\n",
      "[19:13.720 --> 19:16.720]  Now, we call this a training set.\n",
      "[19:16.720 --> 19:19.720]  And let's for now introduce a bit of populism.\n",
      "[19:19.720 --> 19:23.720]  We call this entire matrix as D.\n",
      "[19:23.720 --> 19:24.720]  Right?\n",
      "[19:24.720 --> 19:28.720]  We call this feature matrix.\n",
      "[19:28.720 --> 19:31.720]  It contains N samples.\n",
      "[19:31.720 --> 19:33.720]  What is N?\n",
      "[19:33.720 --> 19:35.720]  N equals four samples.\n",
      "[19:35.720 --> 19:41.720]  And what is the features in this?\n",
      "[19:41.720 --> 19:45.720]  The number of features is color, size, and texture, which is three features.\n",
      "[19:45.720 --> 19:46.720]  Right?\n",
      "[19:46.720 --> 19:55.720]  So the matrix X shown in the shader pane is a four rows three columns matrix.\n",
      "[19:55.720 --> 19:59.720]  It contains N samples, which are P and M. Right?\n",
      "[19:59.720 --> 20:06.720]  We can write an individual sample as something like this.\n",
      "[20:06.720 --> 20:10.720]  Like X1, we can write as orange, small, smooth.\n",
      "[20:10.720 --> 20:12.720]  Orange, small, smooth.\n",
      "[20:12.720 --> 20:13.720]  Right?\n",
      "[20:13.720 --> 20:19.720]  Does anyone want to tell you why X1 is written in a column format where in this particular\n",
      "[20:19.720 --> 20:23.720]  matrix X1 appears in a row?\n",
      "[20:23.720 --> 20:24.720]  Why?\n",
      "[20:24.720 --> 20:26.720]  That is the operation.\n",
      "[20:26.720 --> 20:27.720]  Yes.\n",
      "[20:27.720 --> 20:33.720]  So typically when you consider the features or you consider a particular sample, you consider\n",
      "[20:33.720 --> 20:35.720]  that to be a form vector.\n",
      "[20:35.720 --> 20:40.720]  So this is where now we started to produce a little bit of annotations.\n",
      "[20:40.720 --> 20:46.720]  Eight sample is a column vector, which is what I am interested on.\n",
      "[20:46.720 --> 20:48.720]  What is the dimension of this?\n",
      "[20:48.720 --> 20:51.720]  P dot N equal to P in this case.\n",
      "[20:51.720 --> 20:52.720]  Orange, small, smooth.\n",
      "[20:52.720 --> 20:53.720]  P. Right?\n",
      "[20:53.720 --> 21:00.720]  Does camera X as XI transpose where I is from month to month.\n",
      "[21:00.720 --> 21:01.720]  Right?\n",
      "[21:01.720 --> 21:02.720]  This is X1 transpose.\n",
      "[21:02.720 --> 21:04.720]  This is X2 transpose with our row.\n",
      "[21:04.720 --> 21:11.720]  This is, in fact, the third row is X3 transpose and X4 transpose.\n",
      "[21:11.720 --> 21:12.720]  Right?\n",
      "[21:12.720 --> 21:19.720]  So we are able to now write the matrix X in terms of the individual elements.\n",
      "[21:19.720 --> 21:28.960]  So when we have an output vector Y, now this is going to be Y non-\n",
      "[21:28.960 --> 21:29.960]  output, we have a single output.\n",
      "[21:29.960 --> 21:36.960]  Single output variable or response variable, which is going to be R N. Right?\n",
      "[21:36.960 --> 21:38.960]  Because we have any examples.\n",
      "[21:38.960 --> 21:49.960]  Can we thus write this training set D as a set where we have XI transpose from a YI and\n",
      "[21:49.960 --> 21:51.960]  I release from month to month.\n",
      "[21:51.960 --> 21:52.960]  Right?\n",
      "[21:52.960 --> 21:56.960]  So this way we are able to be able to create this entire training set.\n",
      "[21:56.960 --> 22:00.960]  And it can size comma depending on the I X sample.\n",
      "[22:00.960 --> 22:01.960]  Right?\n",
      "[22:01.960 --> 22:08.960]  So again, XI belongs to, is a B M integral vector and Y is an N M integral vector.\n",
      "[22:08.960 --> 22:12.960]  Everyone clear this part?\n",
      "[22:12.960 --> 22:19.960]  Now, the prediction tasks, this is where machine learning lengths usually.\n",
      "[22:19.960 --> 22:20.960]  Right?\n",
      "[22:20.960 --> 22:24.960]  If you only have trained set, there is no access used for it.\n",
      "[22:24.960 --> 22:30.960]  What you wanted to do was for unseen samples of course for these samples for which a human\n",
      "[22:30.960 --> 22:33.960]  has not yet annotated as a good commit or a bad commit.\n",
      "[22:33.960 --> 22:40.960]  You want them to be fast in the seminary and compute the vision approach which there is\n",
      "[22:40.960 --> 22:44.960]  on camera, which is looking at these, the videos you want to play in the policy condition for\n",
      "[22:44.960 --> 22:45.960]  it.\n",
      "[22:45.960 --> 22:46.960]  Right?\n",
      "[22:46.960 --> 22:48.960]  This is a goal clear to everyone.\n",
      "[22:49.960 --> 22:55.960]  So for future unseen tomatoes of which you don't have a human annotated answer, you want\n",
      "[22:55.960 --> 23:00.960]  to tell whether the condition is better bad and then you want to call it a process.\n",
      "[23:00.960 --> 23:07.960]  So we have for these unseen samples that I would draw a line to separate these out.\n",
      "[23:07.960 --> 23:10.960]  For these unseen samples we still observe the input features.\n",
      "[23:10.960 --> 23:16.960]  We still observe the color, size and texture as given by the computer vision system.\n",
      "[23:16.960 --> 23:17.960]  Right?\n",
      "[23:17.960 --> 23:23.960]  But we don't know the condition and that is what we're trying to do.\n",
      "[23:23.960 --> 23:24.960]  Yeah?\n",
      "[23:24.960 --> 23:28.960]  We now break this whole matrix into two subsets.\n",
      "[23:28.960 --> 23:36.960]  The first we've already discussed is the training set which we set as the matrix D.\n",
      "[23:36.960 --> 23:42.960]  And now we have the test set where we have these specific entries on the condition as\n",
      "[23:42.960 --> 23:44.960]  unknown which we're trying to estimate today.\n",
      "[23:44.960 --> 23:45.960]  Right?\n",
      "[23:46.960 --> 23:51.960]  So the testing set will be very similar to the training set but it does not mean any\n",
      "[23:51.960 --> 23:53.960]  levels for the output variable.\n",
      "[23:53.960 --> 23:54.960]  Right?\n",
      "[23:54.960 --> 23:56.960]  Everyone clear the distinction between training and testing?\n",
      "[23:56.960 --> 23:57.960]  Right?\n",
      "[23:57.960 --> 23:58.960]  Okay.\n",
      "[23:58.960 --> 24:05.960]  So given the background that we have thus far, could we now tell what we're trying to do\n",
      "[24:05.960 --> 24:10.960]  from this example in a more succinct fashion?\n",
      "[24:10.960 --> 24:16.960]  What do we hope to do given the training set, given the test set?\n",
      "[24:16.960 --> 24:19.960]  And we have to have some learning component.\n",
      "[24:19.960 --> 24:25.960]  It's the relating point of output.\n",
      "[24:25.960 --> 24:30.960]  How do you relate the input to the output?\n",
      "[24:30.960 --> 24:33.960]  I don't need a precise answer but you can relate.\n",
      "[24:33.960 --> 24:39.960]  You can write the output as some function of the input.\n",
      "[24:39.960 --> 24:42.960]  Thus far we don't know what kind of function is this.\n",
      "[24:42.960 --> 24:47.960]  And if we do the volumes we have a different functions relating the output to the input.\n",
      "[24:47.960 --> 24:54.960]  But we want to be able to predict the output using some functional complex set for now.\n",
      "[24:54.960 --> 24:57.960]  And where do we learn this F from?\n",
      "[24:57.960 --> 24:58.960]  This function F from?\n",
      "[24:58.960 --> 24:59.960]  It is.\n",
      "[24:59.960 --> 25:01.960]  From the training set.\n",
      "[25:01.960 --> 25:05.960]  And where do we apply this function F on?\n",
      "[25:05.960 --> 25:07.960]  On the testing set.\n",
      "[25:07.960 --> 25:14.960]  So that given this for this particular sample, given the inputs red, red and red, you want\n",
      "[25:14.960 --> 25:15.960]  to predict the condition.\n",
      "[25:15.960 --> 25:16.960]  Right?\n",
      "[25:16.960 --> 25:20.960]  And the general rule would be that we're able to do this accurately otherwise it does not\n",
      "[25:20.960 --> 25:21.960]  make any sense.\n",
      "[25:21.960 --> 25:22.960]  Right?\n",
      "[25:22.960 --> 25:23.960]  Okay.\n",
      "[25:23.960 --> 25:26.960]  Now a big question.\n",
      "[25:26.960 --> 25:33.960]  Is predicting on the test set enough to say that the model is invalidating?\n",
      "[25:34.960 --> 25:37.960]  Why or why not?\n",
      "[25:37.960 --> 25:43.960]  The test set now is missing out the outliers.\n",
      "[25:43.960 --> 25:45.960]  Missing out the outliers.\n",
      "[25:45.960 --> 25:46.960]  Okay.\n",
      "[25:46.960 --> 25:49.960]  So we will say that if test set, why do you missing out the outliers?\n",
      "[25:49.960 --> 25:52.960]  So we can add a little more weight rate.\n",
      "[25:52.960 --> 25:53.960]  Okay.\n",
      "[25:53.960 --> 25:54.960]  Okay.\n",
      "[25:54.960 --> 25:55.960]  Okay.\n",
      "[25:55.960 --> 25:56.960]  Okay.\n",
      "[25:56.960 --> 25:57.960]  Okay.\n",
      "[25:57.960 --> 26:01.960]  So the answer is the answer that he is giving is that they could be some exceptions.\n",
      "[26:01.960 --> 26:03.960]  They could be some outliers.\n",
      "[26:03.960 --> 26:06.960]  But that is getting to the right answer.\n",
      "[26:06.960 --> 26:09.960]  But you need to make a movement.\n",
      "[26:09.960 --> 26:12.960]  The case that the contour is not a rotation.\n",
      "[26:12.960 --> 26:15.960]  The case that it does not have annotations.\n",
      "[26:15.960 --> 26:17.960]  So what will it be?\n",
      "[26:17.960 --> 26:19.960]  How will it be?\n",
      "[26:19.960 --> 26:20.960]  How will it be?\n",
      "[26:20.960 --> 26:21.960]  How will it be?\n",
      "[26:21.960 --> 26:22.960]  How will it be?\n",
      "[26:22.960 --> 26:24.960]  So we come to the specific question of how we do it.\n",
      "[26:24.960 --> 26:25.960]  We take the accuracy.\n",
      "[26:25.960 --> 26:26.960]  Yeah.\n",
      "[26:26.960 --> 26:27.960]  So we come to that.\n",
      "[26:27.960 --> 26:28.960]  But yes.\n",
      "[26:28.960 --> 26:29.960]  Okay.\n",
      "[26:29.960 --> 26:30.960]  Okay.\n",
      "[26:30.960 --> 26:38.960]  The test set may be a subset of the brain set.\n",
      "[26:38.960 --> 26:41.960]  And your answer was that the test set might have some outliers.\n",
      "[26:41.960 --> 26:44.960]  Both of you are really there.\n",
      "[26:44.960 --> 26:45.960]  Come with us on.\n",
      "[26:45.960 --> 26:46.960]  Oh, yes.\n",
      "[26:46.960 --> 26:47.960]  Overthinking.\n",
      "[26:47.960 --> 26:48.960]  That's good.\n",
      "[26:48.960 --> 26:51.960]  So we have not thus introduced it on that over period.\n",
      "[26:51.960 --> 26:56.960]  Can you use some simpler numbers we have seen thus far?\n",
      "[26:56.960 --> 27:12.960]  Think of sometimes you might have covered in some probability code.\n",
      "[27:12.960 --> 27:18.960]  So the ideal thing that we want to do is to be creating well of all possible inputs.\n",
      "[27:18.960 --> 27:19.960]  Right?\n",
      "[27:19.960 --> 27:22.960]  The emphasis on all possible inputs.\n",
      "[27:23.960 --> 27:25.960]  But can you test that?\n",
      "[27:25.960 --> 27:28.960]  Can the test set be all possible inputs?\n",
      "[27:28.960 --> 27:30.960]  Maybe an ideal case.\n",
      "[27:30.960 --> 27:31.960]  Yes.\n",
      "[27:31.960 --> 27:37.960]  But in a more practical case, you know, you will never be able to enumerate all possible test\n",
      "[27:37.960 --> 27:38.960]  cases.\n",
      "[27:38.960 --> 27:44.960]  And now relating to the answer which some of you have already given.\n",
      "[27:44.960 --> 27:50.960]  So one way to put it would be that the test set is only a sample from all possible inputs.\n",
      "[27:50.960 --> 27:51.960]  Right?\n",
      "[27:51.960 --> 27:56.960]  So this now relates to the answer we are talking about outliers.\n",
      "[27:56.960 --> 28:02.960]  You could end up choosing a test set which is a very expensive test set.\n",
      "[28:02.960 --> 28:03.960]  It's a lot of outlier.\n",
      "[28:03.960 --> 28:07.960]  But there's a lot of internal outliers which might be present in all possible inputs.\n",
      "[28:07.960 --> 28:12.960]  And also the next to your specific answer that the test set would be a part of the brain set\n",
      "[28:12.960 --> 28:16.960]  because it's now a sample from all possible inputs.\n",
      "[28:17.960 --> 28:23.960]  More generally we have to think, let's think of it as there is some origin or there is\n",
      "[28:23.960 --> 28:30.960]  some generating process which generates the brain data which I am calling there as the\n",
      "[28:30.960 --> 28:31.960]  empirical data sample.\n",
      "[28:31.960 --> 28:34.960]  And I've written it in a little bit on where I do.\n",
      "[28:34.960 --> 28:37.960]  So this is identity and independence distributed.\n",
      "[28:37.960 --> 28:42.960]  If I would recommend that if you don't know this term again, go back and study some of\n",
      "[28:42.960 --> 28:45.960]  the three records mentioned.\n",
      "[28:46.960 --> 28:52.960]  You sample from the hidden proof or you generate data from the queue process.\n",
      "[28:52.960 --> 28:56.960]  You are able to get some free data which you learn.\n",
      "[28:56.960 --> 29:02.960]  You get a model which in a previous case was some function S that we will learn in.\n",
      "[29:02.960 --> 29:08.960]  Once you've learned by function you predict using unseen data, you predict another sample.\n",
      "[29:08.960 --> 29:14.960]  So that sample is again also coming from the same data set, from the same underlying\n",
      "[29:14.960 --> 29:19.960]  distributed or the same generating process by all the way.\n",
      "[29:19.960 --> 29:24.960]  So what now we get is that the training set and the test set of samples are from the\n",
      "[29:24.960 --> 29:26.960]  hidden proof distribution.\n",
      "[29:26.960 --> 29:29.960]  Sometimes it is also known as population.\n",
      "[29:29.960 --> 29:32.960]  You get some samples from the population.\n",
      "[29:32.960 --> 29:36.960]  So the test set will not contain all the samples.\n",
      "[29:36.960 --> 29:42.960]  In order to say that our model generalizes perfectly, we would have had to see the entire\n",
      "[29:42.960 --> 29:47.960]  population which is never the same.\n",
      "[29:47.960 --> 29:54.960]  And you have much more deeper differences between the test set and the group population.\n",
      "[29:54.960 --> 30:01.960]  Once we study bias in various terms, hopefully it will come from the next lecture.\n",
      "[30:02.960 --> 30:04.960]  Everyone clear the line?\n",
      "[30:07.960 --> 30:12.960]  Okay, so we have last part seen one particular type of machine learning task where you will\n",
      "[30:12.960 --> 30:17.960]  try to classify whether the object or whether the particular the meters would have had.\n",
      "[30:17.960 --> 30:20.960]  But now we can have a very different example.\n",
      "[30:20.960 --> 30:24.960]  We want to predict the energy consumption of IT on the other campus.\n",
      "[30:24.960 --> 30:27.960]  Okay, so again the same exercise.\n",
      "[30:27.960 --> 30:31.960]  For more factors, you will think the energy consumption should depend on.\n",
      "[30:31.960 --> 30:34.960]  Can you quantify that?\n",
      "[30:34.960 --> 30:38.960]  Because whether it is again one specific aspect of IT.\n",
      "[30:38.960 --> 30:40.960]  You may need temperature, okay.\n",
      "[30:40.960 --> 30:43.960]  What do you expect the humidity is more?\n",
      "[30:43.960 --> 30:46.960]  Do you think they will do more of it?\n",
      "[30:46.960 --> 30:47.960]  More?\n",
      "[30:47.960 --> 30:50.960]  Okay, more of the temperature.\n",
      "[30:50.960 --> 30:54.960]  Temperature is more, what energy do you want?\n",
      "[30:54.960 --> 30:55.960]  Five.\n",
      "[30:55.960 --> 30:57.960]  More energy is less.\n",
      "[30:57.960 --> 31:02.960]  Okay, what are the other factors in the application?\n",
      "[31:02.960 --> 31:04.960]  Elic, okay.\n",
      "[31:04.960 --> 31:09.960]  Then, okay, number of people, number of occupants.\n",
      "[31:09.960 --> 31:12.960]  And if there are more occupants, do you expect more energy will happen?\n",
      "[31:12.960 --> 31:14.960]  Generally yes.\n",
      "[31:14.960 --> 31:16.960]  Any other factor?\n",
      "[31:16.960 --> 31:17.960]  Sorry.\n",
      "[31:18.960 --> 31:26.960]  Okay, one of the things I have to say is that there are some other aspects of a campus\n",
      "[31:26.960 --> 31:31.960]  energy they don't manage, they are going to call this a quality term, some of the energy.\n",
      "[31:31.960 --> 31:34.960]  What are the assets?\n",
      "[31:34.960 --> 31:37.960]  This level is less.\n",
      "[31:37.960 --> 31:39.960]  Lab switches, this level.\n",
      "[31:39.960 --> 31:44.960]  Lab usage, let's say, machinery or let's say IT.\n",
      "[31:44.960 --> 31:47.960]  So, we think number of computers could be one of the examples.\n",
      "[31:47.960 --> 31:52.960]  The more the computers, the more the servers will generate strength more energy.\n",
      "[31:52.960 --> 31:55.960]  Any other factor we could think about?\n",
      "[31:55.960 --> 32:00.960]  We can make them a status in some sense captured by the number of occupants.\n",
      "[32:00.960 --> 32:01.960]  Right?\n",
      "[32:01.960 --> 32:06.960]  So, we don't have to explicitly write whether it's a big or a big thing.\n",
      "[32:06.960 --> 32:09.960]  That is a big factor.\n",
      "[32:09.960 --> 32:10.960]  Sorry?\n",
      "[32:11.960 --> 32:16.960]  Okay, so the question is how does weekend or week to relate to the population?\n",
      "[32:16.960 --> 32:31.960]  So, I am saying that in some sense, when it's a weekend, you would assume that many of the people are, let's say, not in the\n",
      "[32:31.960 --> 32:38.960]  future, that would be lesser than the weekend.\n",
      "[32:38.960 --> 32:41.960]  Yes, why are you there?\n",
      "[32:41.960 --> 32:44.960]  So, you could always come up with some counter-events.\n",
      "[32:44.960 --> 32:45.960]  Yes.\n",
      "[32:45.960 --> 32:50.960]  But there may be some people who would be leaving, some people who would be coming.\n",
      "[32:50.960 --> 32:54.960]  They and I, we can all meet different people.\n",
      "[32:55.960 --> 32:59.960]  Okay, so he is saying that the hour of the day is also an important factor.\n",
      "[32:59.960 --> 33:04.960]  How can you gain tellers which are expected more energy consumption?\n",
      "[33:04.960 --> 33:08.960]  So, in the night we got 15, we can all get 20, 20, 20, 20.\n",
      "[33:08.960 --> 33:12.960]  Yes, in the night I assume, but we not have a fine.\n",
      "[33:12.960 --> 33:16.960]  For now, let's assume that, 24, 20, 9 people have to 3, 10, so it's a lot harder.\n",
      "[33:16.960 --> 33:19.960]  So, in the night I mean, 10, 20, see the lot to be low.\n",
      "[33:19.960 --> 33:22.960]  At least in the right, 10, 20, 20, 20, 20.\n",
      "[33:23.960 --> 33:30.960]  So, more people with generally poor energy, higher temperature, generally higher energy.\n",
      "[33:30.960 --> 33:33.960]  Again, it can be constructed here like this now.\n",
      "[33:33.960 --> 33:37.960]  We have people temperature and this, well the purpose of the relationship is to be in people\n",
      "[33:37.960 --> 33:42.960]  and people and temperature and energy, you know, for now, I mean some of the people are\n",
      "[33:42.960 --> 33:43.960]  doing it also.\n",
      "[33:43.960 --> 33:47.960]  You could use jewels, but, you know, rather, more generally, I am certain, certain level.\n",
      "[33:47.960 --> 33:49.960]  Now, what is the training center?\n",
      "[33:49.960 --> 33:56.960]  The first three rows and they consider them as pre-made side because they have the labels,\n",
      "[33:56.960 --> 34:00.960]  also mentioned the output variable or response variable also maintenance.\n",
      "[34:00.960 --> 34:05.960]  Where as the set shown below of the last two samples, becomes a test set.\n",
      "[34:05.960 --> 34:11.960]  Where the labels or the response variable or the target rate of the application have not been mentioned.\n",
      "[34:11.960 --> 34:14.960]  And this is what you're trying to say, right?\n",
      "[34:15.960 --> 34:20.960]  So, you have thus far seen two different kinds of examples.\n",
      "[34:20.960 --> 34:27.960]  Let's try and make a little more abstractly because of two specific classes of problems.\n",
      "[34:27.960 --> 34:32.960]  I am going to write the first class of problems as classification.\n",
      "[34:32.960 --> 34:37.960]  Here the output variable of concern is discrete in nature, right?\n",
      "[34:37.960 --> 34:40.960]  There is a number here, I understand what is discrete.\n",
      "[34:41.960 --> 34:44.960]  So, discrete means it could be one of few classes.\n",
      "[34:44.960 --> 34:50.960]  It could either be any, so this one of the examples of discrete is binary, whether it's on or off.\n",
      "[34:50.960 --> 34:53.960]  It could also be done to be one of three classes.\n",
      "[34:53.960 --> 34:55.960]  It could also be binary.\n",
      "[34:55.960 --> 35:03.960]  Both formerly they say that why I belong to a set from one to C where we have C classes.\n",
      "[35:03.960 --> 35:09.960]  We have seen one example can even tell you more examples of classification tasks in my new version.\n",
      "[35:09.960 --> 35:30.960]  So, in the example that is given is given is you want to predict Google when, right?\n",
      "[35:30.960 --> 35:34.960]  So, in fact this reminds me of some very interesting simulation.\n",
      "[35:34.960 --> 35:38.960]  I think there is a very nice log by a data server.\n",
      "[35:38.960 --> 35:45.960]  Those of you who follow sports as well as data, should be really looking into that.\n",
      "[35:45.960 --> 35:51.960]  And some of these log is fact greatly winners of the football champions team and the NBA, et cetera.\n",
      "[35:51.960 --> 35:53.960]  You look over the masses now.\n",
      "[35:53.960 --> 36:00.960]  And they have some, they have some confidence with the same group in the league, et cetera.\n",
      "[36:00.960 --> 36:02.960]  So, what are the kinds of numbers you have?\n",
      "[36:02.960 --> 36:05.960]  Let's focus on how or something like this.\n",
      "[36:05.960 --> 36:10.960]  When you also have tie your top, or particular cases.\n",
      "[36:10.960 --> 36:12.960]  So, this is not full class.\n",
      "[36:12.960 --> 36:16.960]  And what kind of input features do you think you have to get?\n",
      "[36:18.960 --> 36:21.960]  And everyone else can also take this one out.\n",
      "[36:21.960 --> 36:27.960]  So, if you want to predict whether India and Sri Lanka are playing, like, we do 20, who will win.\n",
      "[36:28.960 --> 36:30.960]  So, how would you find that?\n",
      "[36:30.960 --> 36:32.960]  We need to ask you to ask them.\n",
      "[36:32.960 --> 36:33.960]  Playing 11th.\n",
      "[36:33.960 --> 36:36.960]  Playing 11th, so playing 11th, fine.\n",
      "[36:36.960 --> 36:39.960]  So, you know, by playing 11th, you mean the names?\n",
      "[36:39.960 --> 36:40.960]  20th.\n",
      "[36:40.960 --> 36:41.960]  Probably not.\n",
      "[36:41.960 --> 36:43.960]  So, some notion of their ratings, right?\n",
      "[36:43.960 --> 36:48.960]  All that having said that, only yesterday I read about the very interesting article.\n",
      "[36:48.960 --> 36:53.960]  So, there was some research paper which mentioned that some of those really chess playing\n",
      "[36:53.960 --> 36:58.960]  are the clear of the natural language process, natural language processing game.\n",
      "[36:58.960 --> 37:02.960]  And not looking at the inherent notion of what both means.\n",
      "[37:02.960 --> 37:05.960]  So, they just gave it a specific easy code, et cetera.\n",
      "[37:05.960 --> 37:08.960]  And that was also a little bit of a comedy level test task.\n",
      "[37:08.960 --> 37:12.960]  So, those of bell words where they might find this very interesting and shocking.\n",
      "[37:12.960 --> 37:13.960]  Okay.\n",
      "[37:13.960 --> 37:16.960]  For cricket, maybe we are looking at the player ratings.\n",
      "[37:16.960 --> 37:22.960]  Maybe the player age, maybe the fitness level, something on that start.\n",
      "[37:23.960 --> 37:24.960]  Why?\n",
      "[37:24.960 --> 37:26.960]  It's not some last names.\n",
      "[37:26.960 --> 37:27.960]  Yes.\n",
      "[37:27.960 --> 37:31.960]  If there are, almost is the way.\n",
      "[37:31.960 --> 37:36.960]  And in fact, if any of you play games like T by NAR, what do you do all that?\n",
      "[37:36.960 --> 37:39.960]  They take you to the configuration menu.\n",
      "[37:39.960 --> 37:41.960]  And they are able to simulate both seasons.\n",
      "[37:41.960 --> 37:42.960]  Okay.\n",
      "[37:42.960 --> 37:45.960]  Any other task, documentation, talk you can think of.\n",
      "[37:45.960 --> 37:47.960]  And don't.\n",
      "[37:48.960 --> 37:49.960]  Okay.\n",
      "[37:49.960 --> 37:55.960]  So, how much data and image you want to classify whether it's an image or it's an university\n",
      "[37:55.960 --> 37:57.960]  or something around the thing.\n",
      "[37:57.960 --> 37:59.960]  You have not two output classes.\n",
      "[37:59.960 --> 38:04.960]  And what is the input that you're given?\n",
      "[38:04.960 --> 38:07.960]  So, the input would be an image.\n",
      "[38:07.960 --> 38:08.960]  Right?\n",
      "[38:08.960 --> 38:11.960]  Input now would be an image of some item somewhere.\n",
      "[38:11.960 --> 38:16.960]  So, what previously you look, the kinds of inputs that we had were putting into the matrix.\n",
      "[38:16.960 --> 38:23.960]  So, in sample, most corresponding to only, you know, let's say p-\n",
      "[38:23.960 --> 38:26.960]  But now you have a, let's say p cross q matrix.\n",
      "[38:26.960 --> 38:30.960]  So, again you have to figure out earlier, you will put the p cross q matrix into that particular\n",
      "[38:30.960 --> 38:32.960]  scheme which we have.\n",
      "[38:32.960 --> 38:33.960]  Okay.\n",
      "[38:33.960 --> 38:34.960]  Any other example?\n",
      "[38:34.960 --> 38:35.960]  Okay.\n",
      "[38:35.960 --> 38:45.960]  Shouldn't be, let me, let me, let me, let me, let me, let me, let me, let me, let me,\n",
      "[38:45.960 --> 38:46.960]  interrupt them.\n",
      "[38:46.960 --> 38:47.960]  Okay.\n",
      "[38:47.960 --> 38:48.960]  So, okay.\n",
      "[38:48.960 --> 38:49.960]  We have two databases based onnikENG.\n",
      "[38:49.960 --> 39:09.860]  And, you know, Ocean\n",
      "[39:09.860 --> 39:15.860]  talk about this later, there is also some notion of ordering associated with grades.\n",
      "[39:15.860 --> 39:22.860]  Sometimes you want to provide the data in order. We are not going to be able to perform.\n",
      "[39:22.860 --> 39:27.860]  The second example that we saw fits into something known as regression.\n",
      "[39:27.860 --> 39:31.860]  They output variables, continuous and nature, right? To allow the experience.\n",
      "[39:31.860 --> 39:36.860]  As you can see in that, so you can write yi is a real number.\n",
      "[39:36.860 --> 39:39.860]  Okay, give me some examples of regression.\n",
      "[39:42.860 --> 39:44.860]  You want to predict a real number.\n",
      "[39:44.860 --> 39:46.860]  The amount of grades you want to write.\n",
      "[39:46.860 --> 39:50.860]  The amount of grades you want to write all.\n",
      "[39:50.860 --> 39:55.860]  So that's the reason. I have to say that I have to write.\n",
      "[39:55.860 --> 39:56.860]  Stop market.\n",
      "[39:56.860 --> 39:58.860]  Stop market. What do you want to predict?\n",
      "[39:58.860 --> 40:03.860]  The price of a particular stock. Okay, any other example?\n",
      "[40:03.860 --> 40:05.860]  That's four times.\n",
      "[40:05.860 --> 40:06.860]  Okay.\n",
      "[40:06.860 --> 40:07.860]  How many runs of four?\n",
      "[40:07.860 --> 40:09.860]  Okay, how many runs with our teams?\n",
      "[40:09.860 --> 40:12.860]  Again, very interesting points of grades.\n",
      "[40:12.860 --> 40:17.860]  Again, if you look at all the sports, people have already come up with some rules of the family.\n",
      "[40:17.860 --> 40:21.860]  You are only three back to down, and you get half to 30, you would be double.\n",
      "[40:21.860 --> 40:26.860]  You can always verify those rules.\n",
      "[40:26.860 --> 40:30.860]  And before we get into the actual algorithms,\n",
      "[40:30.860 --> 40:35.860]  I wanted to talk about the performance measure P, which we discussed in the definition.\n",
      "[40:35.860 --> 40:40.860]  We talked about experience P, task P, and performance measure P.\n",
      "[40:40.860 --> 40:45.860]  I thought it's more important to first understand what different metrics mean,\n",
      "[40:45.860 --> 40:49.860]  and what does it mean that we have done a good job in machine learning or not?\n",
      "[40:49.860 --> 40:52.860]  We started with some metrics of graph education.\n",
      "[40:52.860 --> 40:57.860]  Let's assume that we had a ground growth y.\n",
      "[40:57.860 --> 41:00.860]  The number means the correct labels that we've got.\n",
      "[41:00.860 --> 41:05.860]  Let's say we had a particular set of two meters.\n",
      "[41:05.860 --> 41:08.860]  For the first meter, we know that it was good.\n",
      "[41:08.860 --> 41:10.860]  Some human and a different.\n",
      "[41:10.860 --> 41:13.860]  Second meter, some unsighted is good, and the other three, some unsighted.\n",
      "[41:13.860 --> 41:16.860]  Some export label that was bad.\n",
      "[41:16.860 --> 41:20.860]  And then there is some algorithms, some function F that we've learned.\n",
      "[41:20.860 --> 41:25.860]  That ends up predicting, good, good, good, good, good, and bad.\n",
      "[41:25.860 --> 41:29.860]  And we call this vector as y-act.\n",
      "[41:29.860 --> 41:33.860]  So we'll use this hat a lot in machine learning.\n",
      "[41:33.860 --> 41:36.860]  hat generally signifies an estimate.\n",
      "[41:36.860 --> 41:41.860]  What is your estimate of these labels of the parameters?\n",
      "[41:41.860 --> 41:44.860]  So it is y-act.\n",
      "[41:44.860 --> 41:47.860]  And number comes from the actual premise set.\n",
      "[41:47.860 --> 41:50.860]  For now, this is something we have somehow interpreted.\n",
      "[41:50.860 --> 41:52.860]  We know the example.\n",
      "[41:52.860 --> 41:55.860]  And the prediction is made by Vma.\n",
      "[41:55.860 --> 42:00.860]  So what are the different metrics we could use to tell the data in the data.\n",
      "[42:00.860 --> 42:01.860]  What is it?\n",
      "[42:01.860 --> 42:03.860]  We have done a good job in predicting.\n",
      "[42:03.860 --> 42:06.860]  What has been done back down?\n",
      "[42:06.860 --> 42:09.860]  It's bad job.\n",
      "[42:09.860 --> 42:12.860]  How many times you have done good?\n",
      "[42:12.860 --> 42:15.860]  Okay, why?\n",
      "[42:15.860 --> 42:17.860]  I think we're in the three-hundred.\n",
      "[42:17.860 --> 42:20.860]  Sorry.\n",
      "[42:20.860 --> 42:23.860]  Depends on the answer.\n",
      "[42:23.860 --> 42:27.860]  The answer is depends on the state of the art, which is a very valid answer because what is fine to say is that you want to\n",
      "[42:27.860 --> 42:36.860]  to externalize the accuracy of the metric that we put up on it.\n",
      "[42:36.860 --> 42:40.860]  Just say 80% accurate does not mean it.\n",
      "[42:40.860 --> 42:49.860]  Only if the best report thus far was 60% and 80% accuracy means a lot.\n",
      "[42:49.860 --> 42:57.860]  We first look at a very simple metric on the accuracy, which basically tells us that how many you look at the\n",
      "[42:57.860 --> 43:00.860]  accuracy across y-act.\n",
      "[43:00.860 --> 43:04.860]  You look at the predictions across specific rows and this.\n",
      "[43:04.860 --> 43:07.860]  And how many times is the y-act equal to y?\n",
      "[43:07.860 --> 43:10.860]  Divided by the length of y-act.\n",
      "[43:10.860 --> 43:11.860]  Right?\n",
      "[43:11.860 --> 43:16.860]  So how many times have we accurately or correctly predicted the linear?\n",
      "[43:16.860 --> 43:22.860]  The accuracy in this case is in terms of proportion is 0.6 in terms of percentage is 60%.\n",
      "[43:22.860 --> 43:23.860]  Right?\n",
      "[43:23.860 --> 43:28.860]  So it tells you one specific number, but this is often not enough.\n",
      "[43:28.860 --> 43:32.860]  And there are different cases in which we need to again contextualize with.\n",
      "[43:32.860 --> 43:38.860]  Let's look at some specific types of data to motivate our metric.\n",
      "[43:38.860 --> 43:41.860]  Let's imagine that we have one zero one samples.\n",
      "[43:41.860 --> 43:46.860]  And you're predicting something which is not a scale of either, which is either word or band.\n",
      "[43:46.860 --> 43:53.860]  And we have, and for examples where the norm of all the actual samples are good.\n",
      "[43:53.860 --> 43:54.860]  Right?\n",
      "[43:54.860 --> 44:01.860]  And one sample where the actual quality is bad.\n",
      "[44:01.860 --> 44:02.860]  Right?\n",
      "[44:02.860 --> 44:08.860]  Now, they could be multiple cases when it's such kind of a data-specific.\n",
      "[44:08.860 --> 44:18.860]  For example, the cancer strain, you would hope that in most cases, cancer strain, we will have people's health as good.\n",
      "[44:18.860 --> 44:19.860]  They don't have cancer.\n",
      "[44:19.860 --> 44:22.860]  Unfortunately, for very small, they will be cancer.\n",
      "[44:22.860 --> 44:27.860]  But in general, if we look at some data, we'll expect it to look something like this.\n",
      "[44:27.860 --> 44:31.860]  Go to good, go to good, go to good, go to cancer, go to cancer, go to cancer, go to other cancer.\n",
      "[44:31.860 --> 44:32.860]  Right?\n",
      "[44:32.860 --> 44:35.860]  So you end up with an imbalance data set.\n",
      "[44:35.860 --> 44:45.860]  And maybe even if I'm a detect, if someone is trying to detect forms of imagery or forms of speech, most of the time you shouldn't have no bad code on code on code on code on it.\n",
      "[44:45.860 --> 44:47.860]  And some plans to work.\n",
      "[44:47.860 --> 44:53.860]  Otherwise, people will be getting only twice a period of time.\n",
      "[44:53.860 --> 44:58.860]  Now, let's look at a different metric now.\n",
      "[44:58.860 --> 45:00.860]  It was part of precision.\n",
      "[45:00.860 --> 45:05.860]  Let's look at any number of the same paper as picture earlier.\n",
      "[45:05.860 --> 45:12.860]  Now, before looking at this slide, can someone tell you what you understand very strong precision?\n",
      "[45:12.860 --> 45:15.860]  In general, in this functional layman process.\n",
      "[45:15.860 --> 45:18.860]  If it's a probability of it.\n",
      "[45:18.860 --> 45:19.860]  Sorry.\n",
      "[45:19.860 --> 45:20.860]  If it's a probability of it.\n",
      "[45:20.860 --> 45:21.860]  A probability, okay.\n",
      "[45:21.860 --> 45:24.860]  What does it mean to be very precise?\n",
      "[45:24.860 --> 45:27.860]  It can be a difference.\n",
      "[45:27.860 --> 45:28.860]  It can be a difference.\n",
      "[45:28.860 --> 45:29.860]  It can be a difference.\n",
      "[45:29.860 --> 45:34.860]  Any other, what does it mean to be precise?\n",
      "[45:34.860 --> 45:44.860]  What do you mean by when someone asks, can you speak with precise?\n",
      "[45:44.860 --> 45:47.860]  Or can you write down the term of the measure?\n",
      "[45:47.860 --> 45:48.860]  Sorry.\n",
      "[45:48.860 --> 45:49.860]  To the mark.\n",
      "[45:49.860 --> 45:50.860]  To the mark.\n",
      "[45:50.860 --> 45:51.860]  Okay.\n",
      "[45:51.860 --> 45:58.860]  What do you think of precision in terms of whatever your writing or whatever you're predicting or how to that you mean?\n",
      "[45:58.860 --> 46:00.860]  How true that is.\n",
      "[46:00.860 --> 46:03.860]  Or how much sense that does mean.\n",
      "[46:03.860 --> 46:11.860]  So, more English terms in layman terms might mean that how much sense does it mean what you're writing.\n",
      "[46:11.860 --> 46:12.860]  Okay.\n",
      "[46:12.860 --> 46:20.860]  So, now, when you work on the definition, you look at the times you predicted good, right?\n",
      "[46:20.860 --> 46:22.860]  You predicted good how many times?\n",
      "[46:22.860 --> 46:24.860]  1, 2, 3 and 4.\n",
      "[46:24.860 --> 46:27.860]  Out of these, 4 times you predicted good.\n",
      "[46:27.860 --> 46:29.860]  How many times were you actually good?\n",
      "[46:29.860 --> 46:32.860]  Or was the ground truth also sense good?\n",
      "[46:32.860 --> 46:33.860]  Right?\n",
      "[46:33.860 --> 46:36.860]  So, you predicted good 4 times.\n",
      "[46:36.860 --> 46:39.860]  But you will not predict the size in predicting good.\n",
      "[46:39.860 --> 46:45.860]  Your precision was thus far, thus, 2 or 4, which is the algorithm.\n",
      "[46:45.860 --> 46:46.860]  Right?\n",
      "[46:46.860 --> 46:48.860]  Does everyone get the definition?\n",
      "[46:48.860 --> 46:52.860]  How precise are you in predicting a particular class?\n",
      "[46:52.860 --> 46:56.860]  Now, precision can be defined in terms of the specific part.\n",
      "[46:56.860 --> 46:59.860]  You could also define precision for bad.\n",
      "[46:59.860 --> 47:00.860]  Right?\n",
      "[47:00.860 --> 47:02.860]  What is the precision for bad?\n",
      "[47:02.860 --> 47:10.860]  You predicted bad once, but for that specific time it was actually not bad.\n",
      "[47:10.860 --> 47:14.860]  So, you have got 0 precision in predicting bad.\n",
      "[47:14.860 --> 47:19.860]  So, precision for bad to 10v is 0 or 1 is going to be 0, precision for bad as now 2 or 4.\n",
      "[47:19.860 --> 47:20.860]  Right?\n",
      "[47:20.860 --> 47:26.860]  Or what technically you would write in fraction of relevant expenses, amongst the retreats.\n",
      "[47:26.860 --> 47:27.860]  Right?\n",
      "[47:27.860 --> 47:36.860]  Now, we come to another method called the recon, which is of fairly similar notion.\n",
      "[47:36.860 --> 47:38.860]  Now, what is the word English?\n",
      "[47:38.860 --> 47:40.860]  What is the English word?\n",
      "[47:40.860 --> 47:47.860]  What does it mean that person X has a very good recall?\n",
      "[47:47.860 --> 47:48.860]  Right?\n",
      "[47:48.860 --> 47:49.860]  Right?\n",
      "[47:49.860 --> 47:50.860]  Right?\n",
      "[47:50.860 --> 47:51.860]  Right?\n",
      "[47:51.860 --> 47:53.860]  It is a good remember.\n",
      "[47:53.860 --> 47:54.860]  Right?\n",
      "[47:54.860 --> 47:55.860]  One thing on that mind.\n",
      "[47:55.860 --> 48:01.860]  So, the definition of recall is how many times it was actually good?\n",
      "[48:01.860 --> 48:06.860]  How much of the, how much of that you were able to recall in a prediction?\n",
      "[48:06.860 --> 48:07.860]  Right?\n",
      "[48:07.860 --> 48:10.860]  So, it was good, air, air and air.\n",
      "[48:10.860 --> 48:13.860]  I have, you showed it to the apple.\n",
      "[48:13.860 --> 48:17.860]  We have been able to recall two of these three.\n",
      "[48:17.860 --> 48:21.860]  So, three times the condition of the meter was good.\n",
      "[48:21.860 --> 48:23.860]  We have been able to recall two times.\n",
      "[48:23.860 --> 48:26.860]  That's the goal is to do with the system.\n",
      "[48:26.860 --> 48:27.860]  Right?\n",
      "[48:27.860 --> 48:30.860]  We see the difference between precision and the clock.\n",
      "[48:30.860 --> 48:34.860]  Everyone will be able to listen.\n",
      "[48:35.860 --> 48:37.860]  Apple again.\n",
      "[48:37.860 --> 48:41.860]  We are trying to predict whether tissues cancerous or not.\n",
      "[48:41.860 --> 48:53.860]  In the ground truth, we see that we have 100 samples out of which only one of them has cancer, which is the last sample, which is shown over here.\n",
      "[48:53.860 --> 49:02.860]  And when we are predicting, we predict 99 times that the person or the specific sample is not cancerous.\n",
      "[49:02.860 --> 49:06.860]  And one time, this is the first sample we predicted to be cancerous.\n",
      "[49:06.860 --> 49:07.860]  Right?\n",
      "[49:07.860 --> 49:13.860]  So, now let's try and understand the precision and recall for this set of predictions.\n",
      "[49:13.860 --> 49:18.860]  The accuracy of the system is fairly good.\n",
      "[49:18.860 --> 49:22.860]  Out of the total hundred times, we were accurate 98 times.\n",
      "[49:22.860 --> 49:25.860]  The only two times we are getting wrong is one.\n",
      "[49:25.860 --> 49:30.860]  The time, for the first sample, when we are predicting it to be cancerous, viral.\n",
      "[49:30.860 --> 49:32.860]  In ground truth, it is not cancerous.\n",
      "[49:32.860 --> 49:36.860]  And the other time we are getting it wrong is when we are predicting it to be not cancerous.\n",
      "[49:36.860 --> 49:40.860]  And the ground truth says it is cancerous, which is the last sample.\n",
      "[49:40.860 --> 49:42.860]  The accuracy is 98 times.\n",
      "[49:42.860 --> 49:44.860]  You've correctly identified it over the hundred times.\n",
      "[49:44.860 --> 49:47.860]  Now, let's look at the recall.\n",
      "[49:47.860 --> 49:53.860]  Out of the times, the ground truth was true, which is the hundred sample.\n",
      "[49:53.860 --> 49:55.860]  Only a single sample.\n",
      "[49:55.860 --> 50:01.860]  Do we predict it to be cancerous in our prediction system?\n",
      "[50:01.860 --> 50:02.860]  No.\n",
      "[50:02.860 --> 50:09.860]  So, out of one time where it was actually cancerous, we are not able to recall that prediction correctly.\n",
      "[50:09.860 --> 50:12.860]  Thus, the recall is 0 or 1, which is 0.\n",
      "[50:12.860 --> 50:15.860]  Let's look at the precision now.\n",
      "[50:15.860 --> 50:23.860]  Out of the one time, which we are predicting, the tissue to be cancerous, was it actually cancerous?\n",
      "[50:23.860 --> 50:24.860]  No.\n",
      "[50:24.860 --> 50:25.860]  In the ground truth, it was not cancerous.\n",
      "[50:25.860 --> 50:29.860]  Thus, the precision is 0 or 1, which is 0.\n",
      "[50:29.860 --> 50:38.860]  There is another way to look at the previous example, which is known as confusion matrix.\n",
      "[50:38.860 --> 50:41.860]  We have four entries in this confusion matrix.\n",
      "[50:41.860 --> 50:46.860]  The ground truth could be either yes or no, which is cancerous or not cancerous.\n",
      "[50:46.860 --> 50:52.860]  And similarly, we could predict to be either cancerous or not cancerous.\n",
      "[50:52.860 --> 51:01.860]  We saw previously that out of the 90, out of the hundred instances, 98 times when the\n",
      "[51:01.860 --> 51:04.860]  ground truth was not cancerous.\n",
      "[51:04.860 --> 51:06.860]  We were also able to predict it as not cancerous.\n",
      "[51:06.860 --> 51:14.860]  Thus, the entry corresponding to predicted equal to no and ground truth equal to no is 98.\n",
      "[51:14.860 --> 51:21.860]  For one instance, if you look at the first sample, the prediction is yes, but the ground truth was no.\n",
      "[51:21.860 --> 51:28.860]  So, the prediction is yes, the ground truth is no, which is the first row and the second column.\n",
      "[51:28.860 --> 51:35.860]  And then if we go back, we thought there was one sample where the ground truth was yes, but the prediction was no.\n",
      "[51:35.860 --> 51:42.860]  So, one sample where the ground truth was yes, the prediction was no, which is the first column and the second row.\n",
      "[51:43.860 --> 51:51.860]  Now, can you think about precision and recall in terms of these quantities or in terms of the confusion matrix?\n",
      "[51:51.860 --> 51:57.860]  But before we do that, let us make the confusion matrix more generalizable.\n",
      "[51:57.860 --> 52:01.860]  So, we now have four quantities.\n",
      "[52:01.860 --> 52:07.860]  We have four numbers which are written as true positive, false positive, false negative and true negative.\n",
      "[52:07.860 --> 52:12.860]  Let us try and understand how do we remember these four names.\n",
      "[52:12.860 --> 52:14.860]  Let us look at the first true positive.\n",
      "[52:14.860 --> 52:21.860]  The ground truth was positive and we are predicting it to be true, we are truly predicting it to be positive.\n",
      "[52:21.860 --> 52:25.860]  Thus, it is truly predicted as positive, that is true positive.\n",
      "[52:25.860 --> 52:30.860]  The first one in the second column is false positive.\n",
      "[52:30.860 --> 52:39.860]  So, the ground truth was not positive, but we are falsely predicting it to be positive, thus false positive.\n",
      "[52:39.860 --> 52:42.860]  The third element is false negative.\n",
      "[52:42.860 --> 52:49.860]  The ground truth was yes or positive, but we are falsely predicting it to be negative.\n",
      "[52:49.860 --> 52:57.860]  So, it is a false negative and the last entry is a true negative, the ground truth was a negative and the prediction was also negative.\n",
      "[52:57.860 --> 53:02.860]  So, we are truly predicting it to be negative.\n",
      "[53:02.860 --> 53:14.860]  Now, let us come back to the definitions of recall and precision and try to write them in terms of the four quantities from the confusion matrix that we have just seen.\n",
      "[53:14.860 --> 53:23.860]  So, when we talk about precision, we spoke about how correct we are when we predict it to be the positive class.\n",
      "[53:23.860 --> 53:31.860]  So, we say yes in this case, out of the total number of times we predicted it to yes, how accurate we were.\n",
      "[53:31.860 --> 53:36.860]  So, the first row corresponds to the total number of times we predicting it to yes.\n",
      "[53:36.860 --> 53:40.860]  This becomes a denominator which is true positive plus false positive.\n",
      "[53:40.860 --> 53:49.860]  And the portion where we correct is the true positive, where we were predicting it to be positive or yes, when it is actually yes.\n",
      "[53:49.860 --> 53:52.860]  Thus, the numerator becomes true positive.\n",
      "[53:52.860 --> 53:59.860]  Thus, the precision is given by true positive over true positive plus false positive.\n",
      "[53:59.860 --> 54:03.860]  Similarly, let us think about recall.\n",
      "[54:03.860 --> 54:13.860]  For recall, we said that out of the instances which were true in the ground truth, how many are we able to recall.\n",
      "[54:13.860 --> 54:25.860]  So, thus, the instances which were true in the ground truth becomes a denominator which is the first column of this matrix which corresponds to true positive plus false negative.\n",
      "[54:25.860 --> 54:33.860]  And the fraction which is identified correctly is the true positive or what we are able to recall is the true positive.\n",
      "[54:33.860 --> 54:41.860]  Thus, the recall becomes true positive over true positive plus false negative.\n",
      "[54:41.860 --> 54:48.860]  We have another metric called the F score which combines the precision and recall in the following ways.\n",
      "[54:48.860 --> 54:56.860]  So, the definition is given by the formula is given by twice precision times recall divided by precision plus recall.\n",
      "[54:56.860 --> 55:01.860]  It is sometimes useful to give a single number instead of giving a precision and a recall.\n",
      "[55:02.860 --> 55:07.860]  There is another interesting metric called Matthew's correlation coefficient.\n",
      "[55:07.860 --> 55:12.860]  The formula looks fairly complicated at this point of time if you see.\n",
      "[55:12.860 --> 55:18.860]  But there is one particular reason why this coefficient is very useful.\n",
      "[55:18.860 --> 55:24.860]  And to see that specific reason, let us try to work out a simple example now.\n",
      "[55:25.860 --> 55:34.860]  For the data that you have given below where the ground truth positive and predicted positive is the largest number 90.\n",
      "[55:34.860 --> 55:39.860]  And the other three entries are also in the field in the matrix and fusion matrix.\n",
      "[55:39.860 --> 55:43.860]  Can you calculate the precision recall F score and Matthew's coefficient?\n",
      "[55:44.860 --> 55:49.860]  Okay, let us talk about precision for now.\n",
      "[55:49.860 --> 55:54.860]  The precision is out of the times you are predicting it to be positive how correct you are.\n",
      "[55:54.860 --> 56:00.860]  For that we look at the row corresponding to predicted positive that becomes a denominator.\n",
      "[56:00.860 --> 56:04.860]  Thus the total entries are 90 plus 4 which is 94.\n",
      "[56:04.860 --> 56:08.860]  And how many of them are we correctly identifying that is 90.\n",
      "[56:09.860 --> 56:12.860]  Thus precision becomes 90 over 94.\n",
      "[56:14.860 --> 56:23.860]  Similarly, if you look for recall out of the entries which were positive in the ground truth that becomes a first column.\n",
      "[56:23.860 --> 56:26.860]  That is 90 plus 1 which is 91 entries.\n",
      "[56:26.860 --> 56:28.860]  How many are we able to recall correctly?\n",
      "[56:28.860 --> 56:30.860]  That is 90.\n",
      "[56:30.860 --> 56:33.860]  Thus recall becomes 90 over 91.\n",
      "[56:34.860 --> 56:40.860]  And we can calculate the F score by twice precision times recall divided by precision plus recall.\n",
      "[56:40.860 --> 56:47.860]  Now all of these numbers are giving an indication that we have done a very good job by identification or prediction.\n",
      "[56:47.860 --> 56:50.860]  But does this seem to be a problem?\n",
      "[56:52.860 --> 57:02.860]  Yes, so the problem is that this was a very very easy problem for classification because most of the instances were positive in the ground truth.\n",
      "[57:03.860 --> 57:10.860]  So if you predicted everything to be positive you will have a fairly high precision and recall and accuracy and F score.\n",
      "[57:10.860 --> 57:14.860]  But the Matthew's coefficient comes out to be fairly low.\n",
      "[57:14.860 --> 57:24.860]  What this is telling us is that you are not doing a substantially good job identifying or predicting in such a case because the problem itself was fairly simple.\n",
      "[57:24.860 --> 57:39.860]  So this is where we need to take all the metrics and all the results with the salt of grain because it is important to look at how easy or difficult it was when you could have predicted the most occurring class.\n",
      "[57:40.860 --> 57:47.860]  I, ground truth, has a vector of grain number and the prediction will also be a vector of grain number.\n",
      "[57:47.860 --> 57:48.860]  Right?\n",
      "[57:48.860 --> 57:52.860]  We first met with a look at the mean squared error.\n",
      "[57:52.860 --> 57:58.860]  The way to remember this is to compose the three terms mean squared error and then the good and the reverse value.\n",
      "[57:59.860 --> 58:06.860]  You first compute the error which is y i hat minus y i. Right?\n",
      "[58:06.860 --> 58:09.860]  Predicted minus ground for the i-e example.\n",
      "[58:09.860 --> 58:14.860]  You have computed the error and also shown the corresponding error.\n",
      "[58:14.860 --> 58:22.860]  And see the different colors now.\n",
      "[58:22.860 --> 58:28.860]  So y i minus y, y i minus y i is the error term.\n",
      "[58:28.860 --> 58:30.860]  Then you have a squared term.\n",
      "[58:30.860 --> 58:33.860]  So y i minus y i hat minus y i.\n",
      "[58:33.860 --> 58:35.860]  For example, you squared the error.\n",
      "[58:35.860 --> 58:36.860]  Right?\n",
      "[58:36.860 --> 58:38.860]  And then you find it is the mean over it.\n",
      "[58:38.860 --> 58:40.860]  Which is the mean over the end sample.\n",
      "[58:40.860 --> 58:41.860]  Right?\n",
      "[58:41.860 --> 58:42.860]  Means squared error.\n",
      "[58:42.860 --> 58:45.860]  First the error squared is 18 mean.\n",
      "[58:45.860 --> 58:50.860]  And a term is generally then used in the root of the root means squared error.\n",
      "[58:50.860 --> 58:53.860]  Which is the root of the mean squared error.\n",
      "[58:53.860 --> 58:54.860]  Right?\n",
      "[58:54.860 --> 58:59.860]  There are other many similar method called the mean absolute error.\n",
      "[58:59.860 --> 59:01.860]  Again, it starts with the inside.\n",
      "[59:01.860 --> 59:04.860]  You first calculate the error y i hat and y i.\n",
      "[59:04.860 --> 59:07.860]  If the absolute value is a good, then they do.\n",
      "[59:07.860 --> 59:08.860]  Right?\n",
      "[59:08.860 --> 59:11.860]  We can also come with a method called the mean error.\n",
      "[59:11.860 --> 59:14.860]  Which is first of the error and 18 mean.\n",
      "[59:14.860 --> 59:16.860]  Why is that a part right?\n",
      "[59:16.860 --> 59:17.860]  Use it as a metric.\n",
      "[59:17.860 --> 59:19.860]  Yeah, we can get the error.\n",
      "[59:19.860 --> 59:20.860]  Then we cancel each other out.\n",
      "[59:20.860 --> 59:26.860]  If you could have a prediction imagine the number of 0 0 0 0 0.\n",
      "[59:26.860 --> 59:28.860]  Or you have a code in terms of all 0.\n",
      "[59:28.860 --> 59:31.860]  And I have predicted as plus and minus and plus and minus.\n",
      "[59:31.860 --> 59:33.860]  What is the mean error in the space?\n",
      "[59:33.860 --> 59:36.860]  It means error is 0.\n",
      "[59:36.860 --> 59:39.860]  What is the mean absolute error?\n",
      "[59:39.860 --> 59:40.860]  What is the mean?\n",
      "[59:40.860 --> 59:41.860]  What is the mean?\n",
      "[59:41.860 --> 59:42.860]  What is the mean absolute error?\n",
      "[59:42.860 --> 59:46.860]  Yeah, I will see you to know what is the mean error.\n",
      "[59:46.860 --> 59:49.860]  So this is why it is also what it is known what is the metrics.\n",
      "[59:49.860 --> 59:53.860]  You are trying to optimize them.\n",
      "[59:53.860 --> 01:00:01.860]  And you know why you might want to use mean squared error or mean absolute error times.\n",
      "[01:00:01.860 --> 01:00:02.860]  Right?\n",
      "[01:00:03.860 --> 01:00:06.860]  There is something more to do with.\n",
      "[01:00:06.860 --> 01:00:08.860]  Sorry.\n",
      "[01:00:08.860 --> 01:00:10.860]  Maybe not.\n",
      "[01:00:10.860 --> 01:00:12.860]  Okay, something even bigger than that.\n",
      "[01:00:12.860 --> 01:00:17.860]  Can you just write out the mean and then write out the mean and then write it.\n",
      "[01:00:17.860 --> 01:00:21.860]  Okay, can you tell me how does the error may see?\n",
      "[01:00:21.860 --> 01:00:28.860]  So if y i hat is very far away from y i which is going to produce more error.\n",
      "[01:00:28.860 --> 01:00:29.860]  Right.\n",
      "[01:00:30.860 --> 01:00:39.860]  So can you say that squared errors tend to penalize bad predictions much more than the regular.\n",
      "[01:00:46.860 --> 01:00:51.860]  Now let's quickly get into the first algorithm for today.\n",
      "[01:00:51.860 --> 01:00:55.860]  We are going to talk about decision trees.\n",
      "[01:01:00.860 --> 01:01:07.860]  We are getting now solving a classification problem using our first algorithm for decision trees.\n",
      "[01:01:07.860 --> 01:01:13.860]  So we have some training data where we have different days from D1 to D4E.\n",
      "[01:01:13.860 --> 01:01:16.860]  Should the day be included at an accurate error path?\n",
      "[01:01:16.860 --> 01:01:19.860]  That is the new assignment from the one that we have now.\n",
      "[01:01:19.860 --> 01:01:23.860]  We have the algorithm that is funny and we want to talk a separate generation of a quad,\n",
      "[01:01:23.860 --> 01:01:25.860]  a quad, a quad, a humidity and a wind.\n",
      "[01:01:25.860 --> 01:01:27.860]  And whether or not we play it.\n",
      "[01:01:28.860 --> 01:01:35.860]  So now you try and predict whether I should or learn a function between data and some of the attributes of the function.\n",
      "[01:01:38.860 --> 01:01:44.860]  These are actually different in the computer, the four way attributes and the output variable.\n",
      "[01:01:44.860 --> 01:01:49.860]  And this is practice equation because the output variable of the function is just clear.\n",
      "[01:01:49.860 --> 01:01:51.860]  In this case it is only in the guess of the function.\n",
      "[01:01:52.860 --> 01:01:58.860]  And because I have also used decision trees to follow regression here.\n",
      "[01:01:58.860 --> 01:02:03.860]  Where we try to predict the house price given the square point of the data.\n",
      "[01:02:03.860 --> 01:02:06.860]  Let's get back to the example which we were discussing.\n",
      "[01:02:06.860 --> 01:02:11.860]  I am not going to talk about this for now.\n",
      "[01:02:11.860 --> 01:02:15.860]  So one of the reasons why I am about to put a decision tree is started to be.\n",
      "[01:02:15.860 --> 01:02:20.860]  Remember last time we put a something like over and test our captures.\n",
      "[01:02:21.860 --> 01:02:24.860]  Imagine if we are very very complicated machine learning algorithms.\n",
      "[01:02:24.860 --> 01:02:27.860]  That says some new retro technical models.\n",
      "[01:02:27.860 --> 01:02:31.860]  There is often a very, there is often a case of very hard to do,\n",
      "[01:02:31.860 --> 01:02:33.860]  readjustratively for these models.\n",
      "[01:02:34.860 --> 01:02:37.860]  It is not really to understand what the model is done.\n",
      "[01:02:37.860 --> 01:02:44.860]  But the ship trees being one of the very simple models are very very suited for such cases.\n",
      "[01:02:44.860 --> 01:02:47.860]  Where you want the model to be educated.\n",
      "[01:02:48.860 --> 01:02:50.860]  Now imagine if we go to a doctor.\n",
      "[01:02:50.860 --> 01:02:53.860]  We want to build an application.\n",
      "[01:02:53.860 --> 01:02:54.860]  We want to build a machine learning that says,\n",
      "[01:02:54.860 --> 01:02:57.860]  it adds a screening application for an author.\n",
      "[01:02:57.860 --> 01:03:04.860]  When the doctor tries that, I will find it is ignored and relo and some phalency maps.\n",
      "[01:03:04.860 --> 01:03:09.860]  And I have done some attention and 20 other technical terms in the event it works.\n",
      "[01:03:09.860 --> 01:03:12.860]  Or they will say that I have some of this set of rules.\n",
      "[01:03:12.860 --> 01:03:18.860]  If the patient has, you know, decaying cell function and the patient has some swelling etc.\n",
      "[01:03:18.860 --> 01:03:20.860]  Then the patient is like you have to ask them.\n",
      "[01:03:20.860 --> 01:03:22.860]  Which of them do you think is doctorability?\n",
      "[01:03:22.860 --> 01:03:25.860]  There is a couple of shared models.\n",
      "[01:03:25.860 --> 01:03:27.860]  Obviously it is a certain model.\n",
      "[01:03:27.860 --> 01:03:28.860]  Because that is more interpretive.\n",
      "[01:03:28.860 --> 01:03:31.860]  This is also about many of our things.\n",
      "[01:03:31.860 --> 01:03:36.860]  If we go back to this example and if you think in your life,\n",
      "[01:03:36.860 --> 01:03:40.860]  if you were to play it as what is this set of values that you play?\n",
      "[01:03:42.860 --> 01:03:44.860]  One parameter is just not written as a code.\n",
      "[01:03:44.860 --> 01:03:46.860]  They will get someone to play with.\n",
      "[01:03:46.860 --> 01:03:48.860]  They cannot play with them.\n",
      "[01:03:48.860 --> 01:03:52.860]  But then of course you will not want to play with this very hot.\n",
      "[01:03:52.860 --> 01:03:56.860]  You will not want to play with it very human.\n",
      "[01:03:56.860 --> 01:04:00.860]  Looking at this, playing it up for a specific example.\n",
      "[01:04:00.860 --> 01:04:05.860]  Can you tell me some of the times you will definitely play an operator.\n",
      "[01:04:05.860 --> 01:04:12.860]  As an operator, the overcast has always been.\n",
      "[01:04:12.860 --> 01:04:14.860]  I mean tell you something like that.\n",
      "[01:04:14.860 --> 01:04:22.860]  Okay, in fact, when it is overcast you see you are not here always playing.\n",
      "[01:04:22.860 --> 01:04:25.860]  Just look at these specific rules.\n",
      "[01:04:25.860 --> 01:04:28.860]  So can you come up with these simple kind of rules?\n",
      "[01:04:28.860 --> 01:04:30.860]  If it is overcast, I will definitely play.\n",
      "[01:04:30.860 --> 01:04:33.860]  If it is not overcast, it is semi.\n",
      "[01:04:33.860 --> 01:04:37.860]  Let us say that the temperature is mild and added also.\n",
      "[01:04:37.860 --> 01:04:41.860]  This is how we find to play it as a structure.\n",
      "[01:04:41.860 --> 01:04:44.860]  This is the output of the decision tree.\n",
      "[01:04:44.860 --> 01:04:50.860]  This is what we hope to learn from a machine learning algorithm called the decision tree.\n",
      "[01:04:50.860 --> 01:04:52.860]  This is our tree.\n",
      "[01:04:52.860 --> 01:04:54.860]  You can see you have some rules.\n",
      "[01:04:54.860 --> 01:04:57.860]  You have some branches and you have some leaves.\n",
      "[01:04:57.860 --> 01:05:00.860]  These are also telling what is different.\n",
      "[01:05:00.860 --> 01:05:02.860]  I have to be sorry previously.\n",
      "[01:05:02.860 --> 01:05:06.860]  If it is overcast, Glauvitz, Labor.\n",
      "[01:05:06.860 --> 01:05:10.860]  If it is, if the outlook is overcast, you play it in it.\n",
      "[01:05:10.860 --> 01:05:15.860]  But if the outlook is semi and the humidity is lower, it is still playing.\n",
      "[01:05:15.860 --> 01:05:22.860]  It is only when the humidity is high and the outlook is sunny, I will not only play.\n",
      "[01:05:22.860 --> 01:05:26.860]  Similarly if the outlook is raining, but the wind is really I can still play.\n",
      "[01:05:26.860 --> 01:05:30.860]  But if the wind is strong, maybe I will not be able to play.\n",
      "[01:05:30.860 --> 01:05:32.860]  Or this is a specific example.\n",
      "[01:05:32.860 --> 01:05:37.860]  This is what we hope to learn using a algorithm.\n",
      "[01:05:37.860 --> 01:05:40.860]  We have data.\n",
      "[01:05:40.860 --> 01:05:44.860]  We have some performance images, what the accuracy figures and results are.\n",
      "[01:05:44.860 --> 01:05:47.860]  And we have experience coming from this data.\n",
      "[01:05:50.860 --> 01:05:55.860]  Interestingly, what is an optimum decision tree that we can learn?\n",
      "[01:05:55.860 --> 01:05:58.860]  What is the optimum tree that we can learn?\n",
      "[01:05:58.860 --> 01:05:59.860]  We have learned one such tree.\n",
      "[01:05:59.860 --> 01:06:02.860]  Could you have learned many such trees?\n",
      "[01:06:02.860 --> 01:06:08.860]  Could you have learned tree where the environment appears, the environment appears below?\n",
      "[01:06:08.860 --> 01:06:10.860]  So there is a very old table.\n",
      "[01:06:10.860 --> 01:06:13.860]  Does everyone recognize the same?\n",
      "[01:06:13.860 --> 01:06:15.860]  Rodder and the best.\n",
      "[01:06:15.860 --> 01:06:17.860]  Where have you started?\n",
      "[01:06:17.860 --> 01:06:20.860]  Ciales, which is your algorithm's book.\n",
      "[01:06:20.860 --> 01:06:25.860]  This is by the same author of this book's published in the 19th century.\n",
      "[01:06:25.860 --> 01:06:30.860]  Where the measure of constructing optimal binding decision tree is simply concrete.\n",
      "[01:06:30.860 --> 01:06:38.860]  Which means that we can have so many different trees we don't, it is non-driven to tell which is the best decision we can learn.\n",
      "[01:06:38.860 --> 01:06:42.860]  In such cases what do you typically do?\n",
      "[01:06:42.860 --> 01:06:48.860]  When I talk about the possibility tree.\n",
      "[01:06:48.860 --> 01:06:53.860]  Do you think it is called the possibility and then the principal tree?\n",
      "[01:06:53.860 --> 01:07:00.860]  Okay, so my answer is a concern for all the possible trees, but that operation is going to be computed.\n",
      "[01:07:00.860 --> 01:07:03.860]  One after the purpose of the specific, let's say that cannot be done.\n",
      "[01:07:03.860 --> 01:07:06.860]  Or it cannot be done criminally.\n",
      "[01:07:06.860 --> 01:07:10.860]  So we need some of the solution to tell which is a good tree.\n",
      "[01:07:10.860 --> 01:07:13.860]  That is the ability to end up creating a good tree.\n",
      "[01:07:13.860 --> 01:07:18.860]  And which is what is the same as the ability to classify or it is able to predict after it.\n",
      "[01:07:18.860 --> 01:07:21.860]  But we cannot enumerate all possible trees.\n",
      "[01:07:21.860 --> 01:07:26.860]  So we end up using something called the greedy algorithm.\n",
      "[01:07:26.860 --> 01:07:28.860]  So greedy means literally greedy.\n",
      "[01:07:28.860 --> 01:07:36.860]  And the intuition is that at each level of the tree, we choose an attribute that gives us the biggest estimated performance.\n",
      "[01:07:37.860 --> 01:07:39.860]  We are looking at some performance standards.\n",
      "[01:07:39.860 --> 01:07:45.860]  We want something which is given as the best performance game, but we are only able to estimate it.\n",
      "[01:07:45.860 --> 01:07:51.860]  We are not getting the entire accurate performance game, we cannot get that.\n",
      "[01:07:51.860 --> 01:07:55.860]  But greedy algorithms can be really bad.\n",
      "[01:07:55.860 --> 01:07:58.860]  Imagine that this is you.\n",
      "[01:07:58.860 --> 01:08:01.860]  You want to now, you know, you are very impatient.\n",
      "[01:08:01.860 --> 01:08:03.860]  You want to reach them early, you are very concrete.\n",
      "[01:08:03.860 --> 01:08:06.860]  You see that there is no car over here.\n",
      "[01:08:06.860 --> 01:08:11.860]  You try and take a left.\n",
      "[01:08:11.860 --> 01:08:16.860]  And then you, because you have only seen the same spot, you are not able to see these huge tracks.\n",
      "[01:08:16.860 --> 01:08:22.860]  You take a left over here and then you perpetually caught behind these various global graphs.\n",
      "[01:08:22.860 --> 01:08:24.860]  They are moving at 30 degrees.\n",
      "[01:08:24.860 --> 01:08:27.860]  It would have been better if you were just scared at this point.\n",
      "[01:08:27.860 --> 01:08:29.860]  In the long run.\n",
      "[01:08:30.860 --> 01:08:33.860]  So what we have done here is to take a very greedy position.\n",
      "[01:08:33.860 --> 01:08:38.860]  We have not considered the global picture or we have not seen very much into the future.\n",
      "[01:08:38.860 --> 01:08:45.860]  We have just seen what is the best I can do right now, which is just take a left and then I will be caught in a slowly.\n",
      "[01:08:45.860 --> 01:08:49.860]  So this is just to show that the media is not off there.\n",
      "[01:08:51.860 --> 01:08:54.860]  Now we come up with the first algorithm.\n",
      "[01:08:54.860 --> 01:09:02.860]  This particular algorithm is called IDP of some other variations of this particular algorithm.\n",
      "[01:09:02.860 --> 01:09:05.860]  We have created three specific arguments.\n",
      "[01:09:05.860 --> 01:09:09.860]  The first is examples target attribute and attributes.\n",
      "[01:09:09.860 --> 01:09:12.860]  Can anyone tell me what you think the target attribute is?\n",
      "[01:09:15.860 --> 01:09:16.860]  Output.\n",
      "[01:09:16.860 --> 01:09:22.860]  So the target attribute is what the response variable or the output variable will actually tell us somehow.\n",
      "[01:09:23.860 --> 01:09:25.860]  What do you think are the attributes?\n",
      "[01:09:26.860 --> 01:09:32.860]  The features here which were outlook, event, humidity, etcetera are those specific features.\n",
      "[01:09:32.860 --> 01:09:33.860]  What are the examples?\n",
      "[01:09:34.860 --> 01:09:40.860]  Examples are the set of examples are basically the methods that we have,\n",
      "[01:09:40.860 --> 01:09:44.860]  which contains the target attributes and the attributes.\n",
      "[01:09:45.860 --> 01:09:48.860]  We will start this algorithm by creating root node.\n",
      "[01:09:48.860 --> 01:09:52.860]  So in the previous case, we do not know the first cause algorithm.\n",
      "[01:09:52.860 --> 01:09:56.860]  We will first of all this in Sanskrit with an empty root node.\n",
      "[01:09:57.860 --> 01:10:01.860]  So say that if all the examples are positive or negative or yes or no,\n",
      "[01:10:01.860 --> 01:10:04.860]  then return root to the label class and yes.\n",
      "[01:10:04.860 --> 01:10:05.860]  Does this make sense to you?\n",
      "[01:10:07.860 --> 01:10:08.860]  You understand what this means?\n",
      "[01:10:09.860 --> 01:10:16.860]  So if all of the examples, if all of the examples were yes or no,\n",
      "[01:10:16.860 --> 01:10:18.880]  do we need a decision to do a kind of a directly or a\n",
      "[01:10:18.880 --> 01:10:26.880]  directly or a directly or a just a\n",
      "[01:10:26.880 --> 01:10:27.880]  category to the standard?\n",
      "[01:10:27.880 --> 01:10:29.880]  You can always predict it to the yes or no.\n",
      "[01:10:29.880 --> 01:10:31.880]  There is no a decision involved.\n",
      "[01:10:31.880 --> 01:10:34.880]  There is no specific attribute to the standard attribute to the standard attribute.\n",
      "[01:10:34.880 --> 01:10:36.880]  If all the examples, if the attribute is empty,\n",
      "[01:10:36.880 --> 01:10:40.880]  then return root to the most common value of target attribute and examples.\n",
      "[01:10:40.880 --> 01:10:42.880]  We will come to this later.\n",
      "[01:10:42.880 --> 01:10:44.880]  But for now, let us look at the recursive procedure.\n",
      "[01:10:44.880 --> 01:10:49.880]  This is a very nice intuitive algorithm which can work with the recursive.\n",
      "[01:10:49.880 --> 01:10:56.880]  You first become an attribute A which best classifies the example.\n",
      "[01:10:56.880 --> 01:11:01.880]  Now if you go back to this tree, we have 50 first attributes that is output.\n",
      "[01:11:01.880 --> 01:11:08.880]  So the inclusion of an output will help us get the best estimated performance game\n",
      "[01:11:08.880 --> 01:11:16.880]  or does the best attribute for classifying the example.\n",
      "[01:11:16.880 --> 01:11:20.880]  How does the inclusion of best coming will look at the number?\n",
      "[01:11:20.880 --> 01:11:27.880]  Now the output A was chosen as the output was chosen as A.\n",
      "[01:11:27.880 --> 01:11:31.880]  What are the values that the attribute output could have taken?\n",
      "[01:11:31.880 --> 01:11:35.880]  Sunny overcast already.\n",
      "[01:11:36.880 --> 01:11:43.880]  Now for each of these attributes, can you call the same concept because of any of them?\n",
      "[01:11:43.880 --> 01:11:47.880]  That is the simple inclusion of the algorithm.\n",
      "[01:11:47.880 --> 01:11:50.880]  At each level, you keep on taking the same variable.\n",
      "[01:11:50.880 --> 01:11:53.880]  Let us...\n",
      "[01:11:53.880 --> 01:11:59.880]  So we set the root to be K and for each value of A,\n",
      "[01:11:59.880 --> 01:12:11.880]  which was sunny, overcast and rainy, you then add new pre-launch and you also reduce your\n",
      "[01:12:11.880 --> 01:12:13.880]  number of examples from now on.\n",
      "[01:12:13.880 --> 01:12:21.880]  You restrict the set of examples where the active A was the particular value of B.\n",
      "[01:12:21.880 --> 01:12:29.880]  And the examples is empty, you add to leave the level of most common value of the target.\n",
      "[01:12:29.880 --> 01:12:32.880]  Otherwise, you call the same procedure.\n",
      "[01:12:32.880 --> 01:12:38.880]  After adding the set of add-on tools, on the remaining subset of the query.\n",
      "[01:12:38.880 --> 01:12:45.880]  So this is only complicated just for now, because we will get into the details of it.\n",
      "[01:12:45.880 --> 01:12:52.880]  But before that, we had talked about giving the best estimated performance gain rate.\n",
      "[01:12:52.880 --> 01:12:54.880]  How do we quantify that?\n",
      "[01:12:54.880 --> 01:12:59.880]  So the amount of the metric of the amount of the set still measure known as entropy.\n",
      "[01:12:59.880 --> 01:13:02.880]  What do you think entropy means in general?\n",
      "[01:13:02.880 --> 01:13:05.880]  You would have started from the bottom.\n",
      "[01:13:05.880 --> 01:13:10.880]  Now randomness or some impurity in sample.\n",
      "[01:13:10.880 --> 01:13:15.880]  If you see a sample like this, can you tell me what is the entropy of this?\n",
      "[01:13:15.880 --> 01:13:37.100]  Randomness or disorder or the amount of uncar\n",
      "[01:13:37.100 --> 01:13:41.100]  that you have to find those and nine variables.\n",
      "[01:13:41.100 --> 01:13:45.100]  Imagine all of these ODEs were yes.\n",
      "[01:13:45.100 --> 01:13:48.100]  We have an disorder in the system.\n",
      "[01:13:48.100 --> 01:13:51.100]  You have anything that is conserved in.\n",
      "[01:13:51.100 --> 01:13:55.100]  So then in such cases we will say the entropy is zero.\n",
      "[01:13:55.100 --> 01:13:59.100]  If the answer was seven, the answer was seven nodes.\n",
      "[01:13:59.100 --> 01:14:01.100]  What could you think is the entropy?\n",
      "[01:14:01.100 --> 01:14:03.100]  It would be very high.\n",
      "[01:14:03.100 --> 01:14:08.100]  Because you are very unsure about whether it should be a yes or a no.\n",
      "[01:14:08.100 --> 01:14:16.100]  So if formula is given in terms of minus p log, in summation minus p log p, for the different classes,\n",
      "[01:14:16.100 --> 01:14:23.100]  we had probability of no as 5 by 14, we had 14 examples, 5 of which were no.\n",
      "[01:14:23.100 --> 01:14:28.100]  And I know that they were yes and log base two probability of no.\n",
      "[01:14:28.100 --> 01:14:32.100]  So if you do this calculation, it comes out to be 0.9.\n",
      "[01:14:32.100 --> 01:14:34.100]  This is the daily high number.\n",
      "[01:14:34.100 --> 01:14:37.100]  We also get a curve by this.\n",
      "[01:14:37.100 --> 01:14:40.100]  So the probability of yes was zero.\n",
      "[01:14:40.100 --> 01:14:42.100]  The entropy is zero.\n",
      "[01:14:42.100 --> 01:14:46.100]  This means that there is no disorder for the examples negative.\n",
      "[01:14:46.100 --> 01:14:51.100]  And if you look at the other extreme, the probability of class or yes is one.\n",
      "[01:14:51.100 --> 01:14:55.100]  There is again no entropy because there is no uncertainty.\n",
      "[01:14:55.100 --> 01:15:02.100]  The maximum uncertainty or ability happens when the probability of class is the same as probability of no.\n",
      "[01:15:02.100 --> 01:15:08.100]  So we will start with calculating an entropy of a set.\n",
      "[01:15:08.100 --> 01:15:15.100]  And we now want to choose an attitude A, which is able to give us the biggest performance gain.\n",
      "[01:15:15.100 --> 01:15:20.100]  So can you think of in terms of starting with entropy as a starting point?\n",
      "[01:15:21.100 --> 01:15:27.100]  What manipulation or what are the statistical measures we need to tell this is the best attribute?\n",
      "[01:15:27.100 --> 01:15:30.100]  Please get it.\n",
      "[01:15:30.100 --> 01:15:32.100]  It needs an attribute.\n",
      "[01:15:32.100 --> 01:15:34.100]  One is the objective.\n",
      "[01:15:34.100 --> 01:15:39.100]  Okay, but how do you calculate the entropy of an attribute?\n",
      "[01:15:39.100 --> 01:15:44.100]  For me, to think of it in terms of we have to choose an attribute.\n",
      "[01:15:44.100 --> 01:15:51.100]  So before it is started up with the elementary learning, you have several examples.\n",
      "[01:15:51.100 --> 01:15:54.100]  You can calculate the entropy of that sample.\n",
      "[01:15:54.100 --> 01:15:59.100]  Now you want to choose an attribute which will lower the entropy.\n",
      "[01:15:59.100 --> 01:16:04.100]  So basically we go at this point.\n",
      "[01:16:04.100 --> 01:16:08.100]  So we said that there was a lot of uncertainty in whether I will break into some more.\n",
      "[01:16:08.100 --> 01:16:10.100]  Which means that there is a lot of memory.\n",
      "[01:16:10.100 --> 01:16:16.100]  But if I choose output as overpass, I know that I will decorate it later.\n",
      "[01:16:16.100 --> 01:16:22.100]  So there is no element of entropy in order for those specific examples.\n",
      "[01:16:22.100 --> 01:16:27.100]  So we will now see that we are trying to choose an attribute.\n",
      "[01:16:27.100 --> 01:16:29.100]  Subject will choose an image.\n",
      "[01:16:29.100 --> 01:16:32.100]  The entropy becomes lower.\n",
      "[01:16:32.100 --> 01:16:35.100]  There is a lesser disorder in this system.\n",
      "[01:16:35.100 --> 01:16:39.100]  So that concept is known as information gain.\n",
      "[01:16:39.100 --> 01:16:48.100]  I just look at the, I just show the formula.\n",
      "[01:16:48.100 --> 01:16:55.100]  Information gain is known as the formula is given in terms of regression entropy.\n",
      "[01:16:55.100 --> 01:16:59.100]  By partitioning a set of examples, S on an attribute.\n",
      "[01:16:59.100 --> 01:17:02.100]  So an attribute A to have taken different values.\n",
      "[01:17:02.100 --> 01:17:08.100]  For example, the output wrapping is sunny, a regular overpass.\n",
      "[01:17:08.100 --> 01:17:14.980]  We can write the gain on a set of examples S subject to an attribute A as defined by the\n",
      "[01:17:14.980 --> 01:17:17.100]  entropy which is the initial system.\n",
      "[01:17:17.100 --> 01:17:23.100]  Of all the examples, minus the weighted entropy, weighted by the number of samples we have\n",
      "[01:17:23.100 --> 01:17:25.100]  for a particular value.\n",
      "[01:17:25.100 --> 01:17:29.100]  But in fact, the entropy of the subsets that we have written.\n",
      "[01:17:29.100 --> 01:17:30.100]  Right?\n",
      "[01:17:30.100 --> 01:17:35.100]  I will not go into the details but now let us assume that at this point of time we have\n",
      "[01:17:35.100 --> 01:17:36.100]  a loaded examples.\n",
      "[01:17:36.100 --> 01:17:39.100]  We choose an output as the first node.\n",
      "[01:17:39.100 --> 01:17:41.100]  The entropy of this set is zero.\n",
      "[01:17:41.100 --> 01:17:42.100]  Right?\n",
      "[01:17:42.100 --> 01:17:44.100]  The weighted entropy of this set is also zero.\n",
      "[01:17:44.100 --> 01:17:46.100]  This side will have some weighted entropy.\n",
      "[01:17:46.100 --> 01:17:49.100]  So let us stop at this point with the input.\n",
      "[01:17:49.100 --> 01:17:55.100]  We are understanding that we are trying to choose an attribute which reduces the entropy.\n",
      "[01:17:55.100 --> 01:18:00.100]  Let us see it at 11am on our target.\n",
      "[01:18:00.100 --> 01:18:05.100]  Thank you.\n"
     ]
    }
   ],
   "source": [
    "transcription = whisper_model.transcribe(\"audio/CuBzyh4Xmvk.m4a\", fp16=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "218ada6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \" Please look at the code mentioned above and please sign up on the Google Cloud. We've already started making some announcements. You will likely end up missing the announcements and you'll have no one else to play with. The second quick logistical announcement is that we'll have an extra lecture on Saturday, 11th Jan at 11am in 1.101. So a lot of ones over there. And I think one or two people still have conflict, but in the larger, in the larger phone we will have almost everyone available, so we'll have to stick with this. FAQ and the projects which were earlier shared on Google Docs, I'll give all of you a comment access on it so that if you have any questions, queries, things like what should be the, what are the maps, what are the main group size you can ask situations if they're already not there. Also about projects, if you have any questions, like what is the expectation if it's something is not mentioned clearly, you can please comment on the Google Doc and we'll get back to you soon. Also the video and the slides from the first lecture, in order to actually, actually haven't put up on code translate, which is at the entrance, as mentioned in the slide above. This course website has also been now put on Google Cloud. So you can also get to that. Before we go forward, we should quickly revise what we started last time. And someone tell you what is machine learning based on what we learned last time. We looked at a couple of definitions. One was from Arthur Sandler, who by the way was the first person to point with the machine learning and he did that in 1959. So a long long time back. Anyone for this machine learning? The ability to learn without explicitly being to add others, any definition you want to get? There's a more technical definition also. But we'll get to that later. Let's first start with again this same study, same definition of the learning code. It's a period of study and get computers, they are ready to learn without being explicitly programming. Okay, anyone tell you what does being explicitly programming here? Does a need a machine learning involves low programming? So all programming, assignments are just the ways of learning. Program itself. Program itself. Program itself. So is it some, some oracle which ends up writing the code? It's a whole writing program. Of course there's one area, there's something on the computer architecture, so we're not going into that. But who I'd say is the machine learning program. So today's legislative program. What is the exact meaning of adopting the executive program? You don't have to replace this. Okay, can you explain what does mean? But he's on the right track. Let's take an example to get this concept even better. Can you see these model digits? These are digits from 0 to 9. And these are from the dataset for in this. One of the most popular machine learning datasets. Now the first task for all of us is we want to now write a program to recognize the digits. And we'll start with code. Can someone tell me how they'll recognize if a digit is 4 or not? We're looking at these specific rules. What does how we add to the code that we need? Can we start off as 4 can be quantified as a vertical line, a horizontal line, a vertical line. All of them are jointed. And then another vertical line going down from the first, from the last vertical line. Everything of that is that all that is there to 4 or if there are any models. What about the fact that the height of each of the vertical lines need to be very similar? Can you write this kind of a rule? Or do you see a force where one of the lines is very, very long compared to the other? Generally not. So you have to report some of these constraints. But are you done with it anything more? Just look through the example for do you see any force which would violate the difference that we've seen it, specify the thought. And a thought will look that. Okay, the second last is one case. What about this one? Okay, so each of the vertical lines would be a little smaller. In many cases it would be a, and if I were to write, you will not understand it, or you will get it. So because people write different things. So that's another rule that I like. Now what do you mean by slides? Well, it doesn't mean that it can have an inclination of some 10 degrees, 20 degrees, 30 degrees, very excited, none of them. So let's say you come up with some number, based on your experience, based on some rules of time. But is that all? No, some people write 4 with a star, right? If you look at this, 1, 2, 3, 4, 5, 4, you have this particular line, we have to join like this before piloting the end, right? So that is now another rule that I've written. You have already come up with 5, 6 of such rules, but that's not all. Anything else you can think of? That's why we have not talked about the bits of the lines. What can we think about that? Can we cover some rules? Let's say if I'm writing the different mark or if I'm using the pen in different fashion, where some of my strokes we fired will be thicker, right? Maybe that's another particular rule, right? There can be some cases where the width of each of the stroke is a little different. You'll have to again capture some of these characteristics, while writing some rules or writing a program to recognize 4. So what we have done thus far is explicitly programmed to classify order, right? So now we understand what is explicit programming, what we know is completely different from this. So what if thus far does is we had data? Data was these examples that we already had. We came up with some rules. So these were rules which we as experts suggested. And in traditional programming we have some kind of a pattern, some programming line would be right, which would recognize all of these. Of course, what is presented as a vertical line or horizontal line? Are still higher constructs? For example, vertical line a program computer does not know what is a vertical line. So you have to again boil it down to the computer. What do you think the vertical line to the middle means? Same. Same. Same. Same. Ex-axis. So think of it as pixels and all of the pixels would be of similar shape, like vertically going on. So we have data rules and traditional programming that gives us the answers. Now let's go back to the definition. The genome is a period of study as computers. We have computers a little bit to learn without being explicit in the program. And now to make this particular program, to tell me what, if you have to be able to use traditional programming with machine learning, what do we need to do? So we are not explicitly programming. What changes? The Romans are gone there. So what we are saying is, I am going to learn with the only explicitly- describe program. So we don't need the data. We don't need the answers. And what we end up with is automatically some function of rules that are being run. So this is how traditional programming is. The bad line of the system program is very different from machine learning. Which I have still done this, done this in a very abstract sense. We are slowly going to go deeper from this. We also looked at another definition which was a more formal definition of machine learning, which was given by Tom, which I like. Tom is learning from experience E. If you look at the experience E, tasks, P, and a performance measure, P, if the performance is improving in the particular task, as to measure by the performance measure. And it is improving with experience. Let's say in this particular case, the task is what? For machine learning. To classify digits. And what is the input that is typically given? You have some, so you said that you have some experience. The experience can be you have some images along with the true label. So you have elements like this 0 along with that label that is actually 0. But you have various different examples. And the performance measure P, what do you think is the performance measure P? What do you want to optimize on? How correctly you are given to classify digits? So, could you come up with a more scientific sub-centum for correctness? I can see. Or similar sub-centum. So we look at some of these metrics in today. So we will start of place lecture after having revised what is machine learning. We will start, we are now starting a company, all of us are starting a company. And we want to be the basket of those words or some similar words we saw. We want to scale. So if you remember one of the keywords which we use a lot in the previous lecture was scaled. The problem statement is that you want to predict the quality or condition for computer. Given its visual features. So we say that our business use cases that growth rates are similar such grocery stores, they have some human in the loop who looks at each of the tomatoes. And that is in let's say a per minute per tomato. So there is a lot of human input involved which is making the whole process look. We plan to scale it by using computer vision with your features between the data. So what we are going to do is we have now an assembly line. You put the tomatoes in the assembly line as the pass of snapshots are taken. And you automatically classify whether it is a good tomato or bad tomato. And back of the tomatoes are from away. Right? So you are saying that you are saying that you are saying that you are saying that you are using a huge amount of human effort. And what are you making your process greater? So you are saying that why this process we are able to make the living spirit. Right? So let's now do one of the machine learning aspects of this problem spirit. So if you remember, that's why I just spoken that there is an enerity of data. Right? There is an enerity of experience and data. So let's say that we have some pass data on the quality of tomatoes. We have collected thousands of tomatoes and for each of the tomatoes some human expert can identify whether it is a good tomato or bad tomato. For now it is just if you are good or bad and not on the scale of all the tomatoes. Right? There are two classes. What visual features do you think would be useful to characterize the tomato? Color? Any...so what...what if you could be a good tomato? You just... Which is more red or more... There is something on the shades of red. What is the data made of? Something which is either showing some greenish shade, it may be an anvil. Black definitely or if it has some fungus or some other attributes. What is the other attributes which make it a little bit of bad? It is a shade. It is a shade. Is there a text? It is a perfect circle. So the...okay some...some...so the size is another attribute. Let's say that we have seen for now that all tomatoes are roughly over and smaller tomatoes are bad, very big tomatoes are also bad. They are very injected with some growth...growth chemicals. Size, whether we have seen, what are the other things you would typically do? Fine. Yeah, but visual features will not look at the people. So you'll have to get some proxy for that. So that is another thing which I want all of us to take from the machine learning course. What are some of the proxy features we could take from? Yes, texture. So texture will tell us something about the field of the community. Whether it's very rough, very smooth, very light and etc. So we looked at these three specific features. Would there be others? Yes, there might be thousands of other features. But for the purposes of this example, it's only these three. So we were talking about some vast data or some vast experience that we already have. Maybe it exists in a form of potato like this. You have some sample of the...you have the color, size, texture and you have the condition. So this condition has been manually and a data written down by a human expert. So in this particular table, you think sample number could be a useful attribute of feature to predict the condition? How many think yes? How many think no? Okay. Now tell me that it could be a useful feature. Now think more and more. How could the sample number be useful? Sorry. No, also the equation is orange. If the other is orange, decide the small, the texture is smooth. I can roughly say the condition is good. So let's say we have a sample number that is equal to 1, 10 because the parameters will be equal to 1. Yes. 1 and 2 are equal to 0. It sequentially arrives to 1 and 2. So why do you think the sample number could be useful? So some of you get it to the point that let's say we sequentially arrange, then we will get something. But are we getting something? Yes. So you can just write the same thing and then get qualified for the same time. Okay. So he is answering that maybe there is a notion of time associated with samples, very likely they could be. And imagine a scenario where there is one specific time of the year, maybe when all of the variables are bad. Maybe if we produce a band, maybe the leader, which is bringing the tomatoes was hard, had gone wrong, something would have happened. So in some very limited cases, the sample number could be used for the future. But it's more likely that it's probably better to include more features, which are capturing the types of things we are looking at. For example, what was its vehicle condition? How many hours have passed through the way it was made? Things like that. The sample number might be giving them this up. But then this could be the same example as we saw in the last lecture. Where more ice beams means more sharp attacks. There was some correlation, but there was no correlation. So we have thus discussed that the sample number is likely or unlikely to be a good feature depending on how we model the phone process. So for now, let's ignore the sample number. Imagine it does not provide any useful information. So then we have some data table, which looks like the problem. We will call this entire table the training set. And if you've noted, I have labeled them in different columns. Anyone wants to tell why they are different? Okay, and put an output as a very technical term. Any other term you could talk about these two paths of a so far way. So this looks like a matrix with real matrix. I think they get that performance. Experience and performance. So the condition is not very good performance. The condition is the annotation or the label or the output assigned to this particular item. So this is one parameter. The extra is one parameter. It's not very good performance. We call these things as features, items, and code areas. If we go back, let's look at the equation which I was asking. What features do you think will be used? Make sense? These things are called features. The first three columns in this table are called features. They are telling us something useful about the parameter. What are the four features that are going on? Those also equals, by the features that we have over here, they are all used anonymously. But you will generally use features that are handy. Obviates is generally used in some of the features. And the output of the condition in this case is called the output of the response wave and what is the response once you've observed some features. Right? Everyone, here to now. Now, we call this a training set. And let's for now introduce a bit of populism. We call this entire matrix as D. Right? We call this feature matrix. It contains N samples. What is N? N equals four samples. And what is the features in this? The number of features is color, size, and texture, which is three features. Right? So the matrix X shown in the shader pane is a four rows three columns matrix. It contains N samples, which are P and M. Right? We can write an individual sample as something like this. Like X1, we can write as orange, small, smooth. Orange, small, smooth. Right? Does anyone want to tell you why X1 is written in a column format where in this particular matrix X1 appears in a row? Why? That is the operation. Yes. So typically when you consider the features or you consider a particular sample, you consider that to be a form vector. So this is where now we started to produce a little bit of annotations. Eight sample is a column vector, which is what I am interested on. What is the dimension of this? P dot N equal to P in this case. Orange, small, smooth. P. Right? Does camera X as XI transpose where I is from month to month. Right? This is X1 transpose. This is X2 transpose with our row. This is, in fact, the third row is X3 transpose and X4 transpose. Right? So we are able to now write the matrix X in terms of the individual elements. So when we have an output vector Y, now this is going to be Y non- output, we have a single output. Single output variable or response variable, which is going to be R N. Right? Because we have any examples. Can we thus write this training set D as a set where we have XI transpose from a YI and I release from month to month. Right? So this way we are able to be able to create this entire training set. And it can size comma depending on the I X sample. Right? So again, XI belongs to, is a B M integral vector and Y is an N M integral vector. Everyone clear this part? Now, the prediction tasks, this is where machine learning lengths usually. Right? If you only have trained set, there is no access used for it. What you wanted to do was for unseen samples of course for these samples for which a human has not yet annotated as a good commit or a bad commit. You want them to be fast in the seminary and compute the vision approach which there is on camera, which is looking at these, the videos you want to play in the policy condition for it. Right? This is a goal clear to everyone. So for future unseen tomatoes of which you don't have a human annotated answer, you want to tell whether the condition is better bad and then you want to call it a process. So we have for these unseen samples that I would draw a line to separate these out. For these unseen samples we still observe the input features. We still observe the color, size and texture as given by the computer vision system. Right? But we don't know the condition and that is what we're trying to do. Yeah? We now break this whole matrix into two subsets. The first we've already discussed is the training set which we set as the matrix D. And now we have the test set where we have these specific entries on the condition as unknown which we're trying to estimate today. Right? So the testing set will be very similar to the training set but it does not mean any levels for the output variable. Right? Everyone clear the distinction between training and testing? Right? Okay. So given the background that we have thus far, could we now tell what we're trying to do from this example in a more succinct fashion? What do we hope to do given the training set, given the test set? And we have to have some learning component. It's the relating point of output. How do you relate the input to the output? I don't need a precise answer but you can relate. You can write the output as some function of the input. Thus far we don't know what kind of function is this. And if we do the volumes we have a different functions relating the output to the input. But we want to be able to predict the output using some functional complex set for now. And where do we learn this F from? This function F from? It is. From the training set. And where do we apply this function F on? On the testing set. So that given this for this particular sample, given the inputs red, red and red, you want to predict the condition. Right? And the general rule would be that we're able to do this accurately otherwise it does not make any sense. Right? Okay. Now a big question. Is predicting on the test set enough to say that the model is invalidating? Why or why not? The test set now is missing out the outliers. Missing out the outliers. Okay. So we will say that if test set, why do you missing out the outliers? So we can add a little more weight rate. Okay. Okay. Okay. Okay. Okay. So the answer is the answer that he is giving is that they could be some exceptions. They could be some outliers. But that is getting to the right answer. But you need to make a movement. The case that the contour is not a rotation. The case that it does not have annotations. So what will it be? How will it be? How will it be? How will it be? How will it be? So we come to the specific question of how we do it. We take the accuracy. Yeah. So we come to that. But yes. Okay. Okay. The test set may be a subset of the brain set. And your answer was that the test set might have some outliers. Both of you are really there. Come with us on. Oh, yes. Overthinking. That's good. So we have not thus introduced it on that over period. Can you use some simpler numbers we have seen thus far? Think of sometimes you might have covered in some probability code. So the ideal thing that we want to do is to be creating well of all possible inputs. Right? The emphasis on all possible inputs. But can you test that? Can the test set be all possible inputs? Maybe an ideal case. Yes. But in a more practical case, you know, you will never be able to enumerate all possible test cases. And now relating to the answer which some of you have already given. So one way to put it would be that the test set is only a sample from all possible inputs. Right? So this now relates to the answer we are talking about outliers. You could end up choosing a test set which is a very expensive test set. It's a lot of outlier. But there's a lot of internal outliers which might be present in all possible inputs. And also the next to your specific answer that the test set would be a part of the brain set because it's now a sample from all possible inputs. More generally we have to think, let's think of it as there is some origin or there is some generating process which generates the brain data which I am calling there as the empirical data sample. And I've written it in a little bit on where I do. So this is identity and independence distributed. If I would recommend that if you don't know this term again, go back and study some of the three records mentioned. You sample from the hidden proof or you generate data from the queue process. You are able to get some free data which you learn. You get a model which in a previous case was some function S that we will learn in. Once you've learned by function you predict using unseen data, you predict another sample. So that sample is again also coming from the same data set, from the same underlying distributed or the same generating process by all the way. So what now we get is that the training set and the test set of samples are from the hidden proof distribution. Sometimes it is also known as population. You get some samples from the population. So the test set will not contain all the samples. In order to say that our model generalizes perfectly, we would have had to see the entire population which is never the same. And you have much more deeper differences between the test set and the group population. Once we study bias in various terms, hopefully it will come from the next lecture. Everyone clear the line? Okay, so we have last part seen one particular type of machine learning task where you will try to classify whether the object or whether the particular the meters would have had. But now we can have a very different example. We want to predict the energy consumption of IT on the other campus. Okay, so again the same exercise. For more factors, you will think the energy consumption should depend on. Can you quantify that? Because whether it is again one specific aspect of IT. You may need temperature, okay. What do you expect the humidity is more? Do you think they will do more of it? More? Okay, more of the temperature. Temperature is more, what energy do you want? Five. More energy is less. Okay, what are the other factors in the application? Elic, okay. Then, okay, number of people, number of occupants. And if there are more occupants, do you expect more energy will happen? Generally yes. Any other factor? Sorry. Okay, one of the things I have to say is that there are some other aspects of a campus energy they don't manage, they are going to call this a quality term, some of the energy. What are the assets? This level is less. Lab switches, this level. Lab usage, let's say, machinery or let's say IT. So, we think number of computers could be one of the examples. The more the computers, the more the servers will generate strength more energy. Any other factor we could think about? We can make them a status in some sense captured by the number of occupants. Right? So, we don't have to explicitly write whether it's a big or a big thing. That is a big factor. Sorry? Okay, so the question is how does weekend or week to relate to the population? So, I am saying that in some sense, when it's a weekend, you would assume that many of the people are, let's say, not in the future, that would be lesser than the weekend. Yes, why are you there? So, you could always come up with some counter-events. Yes. But there may be some people who would be leaving, some people who would be coming. They and I, we can all meet different people. Okay, so he is saying that the hour of the day is also an important factor. How can you gain tellers which are expected more energy consumption? So, in the night we got 15, we can all get 20, 20, 20, 20. Yes, in the night I assume, but we not have a fine. For now, let's assume that, 24, 20, 9 people have to 3, 10, so it's a lot harder. So, in the night I mean, 10, 20, see the lot to be low. At least in the right, 10, 20, 20, 20, 20. So, more people with generally poor energy, higher temperature, generally higher energy. Again, it can be constructed here like this now. We have people temperature and this, well the purpose of the relationship is to be in people and people and temperature and energy, you know, for now, I mean some of the people are doing it also. You could use jewels, but, you know, rather, more generally, I am certain, certain level. Now, what is the training center? The first three rows and they consider them as pre-made side because they have the labels, also mentioned the output variable or response variable also maintenance. Where as the set shown below of the last two samples, becomes a test set. Where the labels or the response variable or the target rate of the application have not been mentioned. And this is what you're trying to say, right? So, you have thus far seen two different kinds of examples. Let's try and make a little more abstractly because of two specific classes of problems. I am going to write the first class of problems as classification. Here the output variable of concern is discrete in nature, right? There is a number here, I understand what is discrete. So, discrete means it could be one of few classes. It could either be any, so this one of the examples of discrete is binary, whether it's on or off. It could also be done to be one of three classes. It could also be binary. Both formerly they say that why I belong to a set from one to C where we have C classes. We have seen one example can even tell you more examples of classification tasks in my new version. So, in the example that is given is given is you want to predict Google when, right? So, in fact this reminds me of some very interesting simulation. I think there is a very nice log by a data server. Those of you who follow sports as well as data, should be really looking into that. And some of these log is fact greatly winners of the football champions team and the NBA, et cetera. You look over the masses now. And they have some, they have some confidence with the same group in the league, et cetera. So, what are the kinds of numbers you have? Let's focus on how or something like this. When you also have tie your top, or particular cases. So, this is not full class. And what kind of input features do you think you have to get? And everyone else can also take this one out. So, if you want to predict whether India and Sri Lanka are playing, like, we do 20, who will win. So, how would you find that? We need to ask you to ask them. Playing 11th. Playing 11th, so playing 11th, fine. So, you know, by playing 11th, you mean the names? 20th. Probably not. So, some notion of their ratings, right? All that having said that, only yesterday I read about the very interesting article. So, there was some research paper which mentioned that some of those really chess playing are the clear of the natural language process, natural language processing game. And not looking at the inherent notion of what both means. So, they just gave it a specific easy code, et cetera. And that was also a little bit of a comedy level test task. So, those of bell words where they might find this very interesting and shocking. Okay. For cricket, maybe we are looking at the player ratings. Maybe the player age, maybe the fitness level, something on that start. Why? It's not some last names. Yes. If there are, almost is the way. And in fact, if any of you play games like T by NAR, what do you do all that? They take you to the configuration menu. And they are able to simulate both seasons. Okay. Any other task, documentation, talk you can think of. And don't. Okay. So, how much data and image you want to classify whether it's an image or it's an university or something around the thing. You have not two output classes. And what is the input that you're given? So, the input would be an image. Right? Input now would be an image of some item somewhere. So, what previously you look, the kinds of inputs that we had were putting into the matrix. So, in sample, most corresponding to only, you know, let's say p- But now you have a, let's say p cross q matrix. So, again you have to figure out earlier, you will put the p cross q matrix into that particular scheme which we have. Okay. Any other example? Okay. Shouldn't be, let me, let me, let me, let me, let me, let me, let me, let me, let me, interrupt them. Okay. So, okay. We have two databases based onnikENG. And, you know, Ocean talk about this later, there is also some notion of ordering associated with grades. Sometimes you want to provide the data in order. We are not going to be able to perform. The second example that we saw fits into something known as regression. They output variables, continuous and nature, right? To allow the experience. As you can see in that, so you can write yi is a real number. Okay, give me some examples of regression. You want to predict a real number. The amount of grades you want to write. The amount of grades you want to write all. So that's the reason. I have to say that I have to write. Stop market. Stop market. What do you want to predict? The price of a particular stock. Okay, any other example? That's four times. Okay. How many runs of four? Okay, how many runs with our teams? Again, very interesting points of grades. Again, if you look at all the sports, people have already come up with some rules of the family. You are only three back to down, and you get half to 30, you would be double. You can always verify those rules. And before we get into the actual algorithms, I wanted to talk about the performance measure P, which we discussed in the definition. We talked about experience P, task P, and performance measure P. I thought it's more important to first understand what different metrics mean, and what does it mean that we have done a good job in machine learning or not? We started with some metrics of graph education. Let's assume that we had a ground growth y. The number means the correct labels that we've got. Let's say we had a particular set of two meters. For the first meter, we know that it was good. Some human and a different. Second meter, some unsighted is good, and the other three, some unsighted. Some export label that was bad. And then there is some algorithms, some function F that we've learned. That ends up predicting, good, good, good, good, good, and bad. And we call this vector as y-act. So we'll use this hat a lot in machine learning. hat generally signifies an estimate. What is your estimate of these labels of the parameters? So it is y-act. And number comes from the actual premise set. For now, this is something we have somehow interpreted. We know the example. And the prediction is made by Vma. So what are the different metrics we could use to tell the data in the data. What is it? We have done a good job in predicting. What has been done back down? It's bad job. How many times you have done good? Okay, why? I think we're in the three-hundred. Sorry. Depends on the answer. The answer is depends on the state of the art, which is a very valid answer because what is fine to say is that you want to to externalize the accuracy of the metric that we put up on it. Just say 80% accurate does not mean it. Only if the best report thus far was 60% and 80% accuracy means a lot. We first look at a very simple metric on the accuracy, which basically tells us that how many you look at the accuracy across y-act. You look at the predictions across specific rows and this. And how many times is the y-act equal to y? Divided by the length of y-act. Right? So how many times have we accurately or correctly predicted the linear? The accuracy in this case is in terms of proportion is 0.6 in terms of percentage is 60%. Right? So it tells you one specific number, but this is often not enough. And there are different cases in which we need to again contextualize with. Let's look at some specific types of data to motivate our metric. Let's imagine that we have one zero one samples. And you're predicting something which is not a scale of either, which is either word or band. And we have, and for examples where the norm of all the actual samples are good. Right? And one sample where the actual quality is bad. Right? Now, they could be multiple cases when it's such kind of a data-specific. For example, the cancer strain, you would hope that in most cases, cancer strain, we will have people's health as good. They don't have cancer. Unfortunately, for very small, they will be cancer. But in general, if we look at some data, we'll expect it to look something like this. Go to good, go to good, go to good, go to cancer, go to cancer, go to cancer, go to other cancer. Right? So you end up with an imbalance data set. And maybe even if I'm a detect, if someone is trying to detect forms of imagery or forms of speech, most of the time you shouldn't have no bad code on code on code on code on it. And some plans to work. Otherwise, people will be getting only twice a period of time. Now, let's look at a different metric now. It was part of precision. Let's look at any number of the same paper as picture earlier. Now, before looking at this slide, can someone tell you what you understand very strong precision? In general, in this functional layman process. If it's a probability of it. Sorry. If it's a probability of it. A probability, okay. What does it mean to be very precise? It can be a difference. It can be a difference. It can be a difference. Any other, what does it mean to be precise? What do you mean by when someone asks, can you speak with precise? Or can you write down the term of the measure? Sorry. To the mark. To the mark. Okay. What do you think of precision in terms of whatever your writing or whatever you're predicting or how to that you mean? How true that is. Or how much sense that does mean. So, more English terms in layman terms might mean that how much sense does it mean what you're writing. Okay. So, now, when you work on the definition, you look at the times you predicted good, right? You predicted good how many times? 1, 2, 3 and 4. Out of these, 4 times you predicted good. How many times were you actually good? Or was the ground truth also sense good? Right? So, you predicted good 4 times. But you will not predict the size in predicting good. Your precision was thus far, thus, 2 or 4, which is the algorithm. Right? Does everyone get the definition? How precise are you in predicting a particular class? Now, precision can be defined in terms of the specific part. You could also define precision for bad. Right? What is the precision for bad? You predicted bad once, but for that specific time it was actually not bad. So, you have got 0 precision in predicting bad. So, precision for bad to 10v is 0 or 1 is going to be 0, precision for bad as now 2 or 4. Right? Or what technically you would write in fraction of relevant expenses, amongst the retreats. Right? Now, we come to another method called the recon, which is of fairly similar notion. Now, what is the word English? What is the English word? What does it mean that person X has a very good recall? Right? Right? Right? Right? It is a good remember. Right? One thing on that mind. So, the definition of recall is how many times it was actually good? How much of the, how much of that you were able to recall in a prediction? Right? So, it was good, air, air and air. I have, you showed it to the apple. We have been able to recall two of these three. So, three times the condition of the meter was good. We have been able to recall two times. That's the goal is to do with the system. Right? We see the difference between precision and the clock. Everyone will be able to listen. Apple again. We are trying to predict whether tissues cancerous or not. In the ground truth, we see that we have 100 samples out of which only one of them has cancer, which is the last sample, which is shown over here. And when we are predicting, we predict 99 times that the person or the specific sample is not cancerous. And one time, this is the first sample we predicted to be cancerous. Right? So, now let's try and understand the precision and recall for this set of predictions. The accuracy of the system is fairly good. Out of the total hundred times, we were accurate 98 times. The only two times we are getting wrong is one. The time, for the first sample, when we are predicting it to be cancerous, viral. In ground truth, it is not cancerous. And the other time we are getting it wrong is when we are predicting it to be not cancerous. And the ground truth says it is cancerous, which is the last sample. The accuracy is 98 times. You've correctly identified it over the hundred times. Now, let's look at the recall. Out of the times, the ground truth was true, which is the hundred sample. Only a single sample. Do we predict it to be cancerous in our prediction system? No. So, out of one time where it was actually cancerous, we are not able to recall that prediction correctly. Thus, the recall is 0 or 1, which is 0. Let's look at the precision now. Out of the one time, which we are predicting, the tissue to be cancerous, was it actually cancerous? No. In the ground truth, it was not cancerous. Thus, the precision is 0 or 1, which is 0. There is another way to look at the previous example, which is known as confusion matrix. We have four entries in this confusion matrix. The ground truth could be either yes or no, which is cancerous or not cancerous. And similarly, we could predict to be either cancerous or not cancerous. We saw previously that out of the 90, out of the hundred instances, 98 times when the ground truth was not cancerous. We were also able to predict it as not cancerous. Thus, the entry corresponding to predicted equal to no and ground truth equal to no is 98. For one instance, if you look at the first sample, the prediction is yes, but the ground truth was no. So, the prediction is yes, the ground truth is no, which is the first row and the second column. And then if we go back, we thought there was one sample where the ground truth was yes, but the prediction was no. So, one sample where the ground truth was yes, the prediction was no, which is the first column and the second row. Now, can you think about precision and recall in terms of these quantities or in terms of the confusion matrix? But before we do that, let us make the confusion matrix more generalizable. So, we now have four quantities. We have four numbers which are written as true positive, false positive, false negative and true negative. Let us try and understand how do we remember these four names. Let us look at the first true positive. The ground truth was positive and we are predicting it to be true, we are truly predicting it to be positive. Thus, it is truly predicted as positive, that is true positive. The first one in the second column is false positive. So, the ground truth was not positive, but we are falsely predicting it to be positive, thus false positive. The third element is false negative. The ground truth was yes or positive, but we are falsely predicting it to be negative. So, it is a false negative and the last entry is a true negative, the ground truth was a negative and the prediction was also negative. So, we are truly predicting it to be negative. Now, let us come back to the definitions of recall and precision and try to write them in terms of the four quantities from the confusion matrix that we have just seen. So, when we talk about precision, we spoke about how correct we are when we predict it to be the positive class. So, we say yes in this case, out of the total number of times we predicted it to yes, how accurate we were. So, the first row corresponds to the total number of times we predicting it to yes. This becomes a denominator which is true positive plus false positive. And the portion where we correct is the true positive, where we were predicting it to be positive or yes, when it is actually yes. Thus, the numerator becomes true positive. Thus, the precision is given by true positive over true positive plus false positive. Similarly, let us think about recall. For recall, we said that out of the instances which were true in the ground truth, how many are we able to recall. So, thus, the instances which were true in the ground truth becomes a denominator which is the first column of this matrix which corresponds to true positive plus false negative. And the fraction which is identified correctly is the true positive or what we are able to recall is the true positive. Thus, the recall becomes true positive over true positive plus false negative. We have another metric called the F score which combines the precision and recall in the following ways. So, the definition is given by the formula is given by twice precision times recall divided by precision plus recall. It is sometimes useful to give a single number instead of giving a precision and a recall. There is another interesting metric called Matthew's correlation coefficient. The formula looks fairly complicated at this point of time if you see. But there is one particular reason why this coefficient is very useful. And to see that specific reason, let us try to work out a simple example now. For the data that you have given below where the ground truth positive and predicted positive is the largest number 90. And the other three entries are also in the field in the matrix and fusion matrix. Can you calculate the precision recall F score and Matthew's coefficient? Okay, let us talk about precision for now. The precision is out of the times you are predicting it to be positive how correct you are. For that we look at the row corresponding to predicted positive that becomes a denominator. Thus the total entries are 90 plus 4 which is 94. And how many of them are we correctly identifying that is 90. Thus precision becomes 90 over 94. Similarly, if you look for recall out of the entries which were positive in the ground truth that becomes a first column. That is 90 plus 1 which is 91 entries. How many are we able to recall correctly? That is 90. Thus recall becomes 90 over 91. And we can calculate the F score by twice precision times recall divided by precision plus recall. Now all of these numbers are giving an indication that we have done a very good job by identification or prediction. But does this seem to be a problem? Yes, so the problem is that this was a very very easy problem for classification because most of the instances were positive in the ground truth. So if you predicted everything to be positive you will have a fairly high precision and recall and accuracy and F score. But the Matthew's coefficient comes out to be fairly low. What this is telling us is that you are not doing a substantially good job identifying or predicting in such a case because the problem itself was fairly simple. So this is where we need to take all the metrics and all the results with the salt of grain because it is important to look at how easy or difficult it was when you could have predicted the most occurring class. I, ground truth, has a vector of grain number and the prediction will also be a vector of grain number. Right? We first met with a look at the mean squared error. The way to remember this is to compose the three terms mean squared error and then the good and the reverse value. You first compute the error which is y i hat minus y i. Right? Predicted minus ground for the i-e example. You have computed the error and also shown the corresponding error. And see the different colors now. So y i minus y, y i minus y i is the error term. Then you have a squared term. So y i minus y i hat minus y i. For example, you squared the error. Right? And then you find it is the mean over it. Which is the mean over the end sample. Right? Means squared error. First the error squared is 18 mean. And a term is generally then used in the root of the root means squared error. Which is the root of the mean squared error. Right? There are other many similar method called the mean absolute error. Again, it starts with the inside. You first calculate the error y i hat and y i. If the absolute value is a good, then they do. Right? We can also come with a method called the mean error. Which is first of the error and 18 mean. Why is that a part right? Use it as a metric. Yeah, we can get the error. Then we cancel each other out. If you could have a prediction imagine the number of 0 0 0 0 0. Or you have a code in terms of all 0. And I have predicted as plus and minus and plus and minus. What is the mean error in the space? It means error is 0. What is the mean absolute error? What is the mean? What is the mean? What is the mean absolute error? Yeah, I will see you to know what is the mean error. So this is why it is also what it is known what is the metrics. You are trying to optimize them. And you know why you might want to use mean squared error or mean absolute error times. Right? There is something more to do with. Sorry. Maybe not. Okay, something even bigger than that. Can you just write out the mean and then write out the mean and then write it. Okay, can you tell me how does the error may see? So if y i hat is very far away from y i which is going to produce more error. Right. So can you say that squared errors tend to penalize bad predictions much more than the regular. Now let's quickly get into the first algorithm for today. We are going to talk about decision trees. We are getting now solving a classification problem using our first algorithm for decision trees. So we have some training data where we have different days from D1 to D4E. Should the day be included at an accurate error path? That is the new assignment from the one that we have now. We have the algorithm that is funny and we want to talk a separate generation of a quad, a quad, a quad, a humidity and a wind. And whether or not we play it. So now you try and predict whether I should or learn a function between data and some of the attributes of the function. These are actually different in the computer, the four way attributes and the output variable. And this is practice equation because the output variable of the function is just clear. In this case it is only in the guess of the function. And because I have also used decision trees to follow regression here. Where we try to predict the house price given the square point of the data. Let's get back to the example which we were discussing. I am not going to talk about this for now. So one of the reasons why I am about to put a decision tree is started to be. Remember last time we put a something like over and test our captures. Imagine if we are very very complicated machine learning algorithms. That says some new retro technical models. There is often a very, there is often a case of very hard to do, readjustratively for these models. It is not really to understand what the model is done. But the ship trees being one of the very simple models are very very suited for such cases. Where you want the model to be educated. Now imagine if we go to a doctor. We want to build an application. We want to build a machine learning that says, it adds a screening application for an author. When the doctor tries that, I will find it is ignored and relo and some phalency maps. And I have done some attention and 20 other technical terms in the event it works. Or they will say that I have some of this set of rules. If the patient has, you know, decaying cell function and the patient has some swelling etc. Then the patient is like you have to ask them. Which of them do you think is doctorability? There is a couple of shared models. Obviously it is a certain model. Because that is more interpretive. This is also about many of our things. If we go back to this example and if you think in your life, if you were to play it as what is this set of values that you play? One parameter is just not written as a code. They will get someone to play with. They cannot play with them. But then of course you will not want to play with this very hot. You will not want to play with it very human. Looking at this, playing it up for a specific example. Can you tell me some of the times you will definitely play an operator. As an operator, the overcast has always been. I mean tell you something like that. Okay, in fact, when it is overcast you see you are not here always playing. Just look at these specific rules. So can you come up with these simple kind of rules? If it is overcast, I will definitely play. If it is not overcast, it is semi. Let us say that the temperature is mild and added also. This is how we find to play it as a structure. This is the output of the decision tree. This is what we hope to learn from a machine learning algorithm called the decision tree. This is our tree. You can see you have some rules. You have some branches and you have some leaves. These are also telling what is different. I have to be sorry previously. If it is overcast, Glauvitz, Labor. If it is, if the outlook is overcast, you play it in it. But if the outlook is semi and the humidity is lower, it is still playing. It is only when the humidity is high and the outlook is sunny, I will not only play. Similarly if the outlook is raining, but the wind is really I can still play. But if the wind is strong, maybe I will not be able to play. Or this is a specific example. This is what we hope to learn using a algorithm. We have data. We have some performance images, what the accuracy figures and results are. And we have experience coming from this data. Interestingly, what is an optimum decision tree that we can learn? What is the optimum tree that we can learn? We have learned one such tree. Could you have learned many such trees? Could you have learned tree where the environment appears, the environment appears below? So there is a very old table. Does everyone recognize the same? Rodder and the best. Where have you started? Ciales, which is your algorithm's book. This is by the same author of this book's published in the 19th century. Where the measure of constructing optimal binding decision tree is simply concrete. Which means that we can have so many different trees we don't, it is non-driven to tell which is the best decision we can learn. In such cases what do you typically do? When I talk about the possibility tree. Do you think it is called the possibility and then the principal tree? Okay, so my answer is a concern for all the possible trees, but that operation is going to be computed. One after the purpose of the specific, let's say that cannot be done. Or it cannot be done criminally. So we need some of the solution to tell which is a good tree. That is the ability to end up creating a good tree. And which is what is the same as the ability to classify or it is able to predict after it. But we cannot enumerate all possible trees. So we end up using something called the greedy algorithm. So greedy means literally greedy. And the intuition is that at each level of the tree, we choose an attribute that gives us the biggest estimated performance. We are looking at some performance standards. We want something which is given as the best performance game, but we are only able to estimate it. We are not getting the entire accurate performance game, we cannot get that. But greedy algorithms can be really bad. Imagine that this is you. You want to now, you know, you are very impatient. You want to reach them early, you are very concrete. You see that there is no car over here. You try and take a left. And then you, because you have only seen the same spot, you are not able to see these huge tracks. You take a left over here and then you perpetually caught behind these various global graphs. They are moving at 30 degrees. It would have been better if you were just scared at this point. In the long run. So what we have done here is to take a very greedy position. We have not considered the global picture or we have not seen very much into the future. We have just seen what is the best I can do right now, which is just take a left and then I will be caught in a slowly. So this is just to show that the media is not off there. Now we come up with the first algorithm. This particular algorithm is called IDP of some other variations of this particular algorithm. We have created three specific arguments. The first is examples target attribute and attributes. Can anyone tell me what you think the target attribute is? Output. So the target attribute is what the response variable or the output variable will actually tell us somehow. What do you think are the attributes? The features here which were outlook, event, humidity, etcetera are those specific features. What are the examples? Examples are the set of examples are basically the methods that we have, which contains the target attributes and the attributes. We will start this algorithm by creating root node. So in the previous case, we do not know the first cause algorithm. We will first of all this in Sanskrit with an empty root node. So say that if all the examples are positive or negative or yes or no, then return root to the label class and yes. Does this make sense to you? You understand what this means? So if all of the examples, if all of the examples were yes or no, do we need a decision to do a kind of a directly or a directly or a directly or a just a category to the standard? You can always predict it to the yes or no. There is no a decision involved. There is no specific attribute to the standard attribute to the standard attribute. If all the examples, if the attribute is empty, then return root to the most common value of target attribute and examples. We will come to this later. But for now, let us look at the recursive procedure. This is a very nice intuitive algorithm which can work with the recursive. You first become an attribute A which best classifies the example. Now if you go back to this tree, we have 50 first attributes that is output. So the inclusion of an output will help us get the best estimated performance game or does the best attribute for classifying the example. How does the inclusion of best coming will look at the number? Now the output A was chosen as the output was chosen as A. What are the values that the attribute output could have taken? Sunny overcast already. Now for each of these attributes, can you call the same concept because of any of them? That is the simple inclusion of the algorithm. At each level, you keep on taking the same variable. Let us... So we set the root to be K and for each value of A, which was sunny, overcast and rainy, you then add new pre-launch and you also reduce your number of examples from now on. You restrict the set of examples where the active A was the particular value of B. And the examples is empty, you add to leave the level of most common value of the target. Otherwise, you call the same procedure. After adding the set of add-on tools, on the remaining subset of the query. So this is only complicated just for now, because we will get into the details of it. But before that, we had talked about giving the best estimated performance gain rate. How do we quantify that? So the amount of the metric of the amount of the set still measure known as entropy. What do you think entropy means in general? You would have started from the bottom. Now randomness or some impurity in sample. If you see a sample like this, can you tell me what is the entropy of this? Randomness or disorder or the amount of uncar that you have to find those and nine variables. Imagine all of these ODEs were yes. We have an disorder in the system. You have anything that is conserved in. So then in such cases we will say the entropy is zero. If the answer was seven, the answer was seven nodes. What could you think is the entropy? It would be very high. Because you are very unsure about whether it should be a yes or a no. So if formula is given in terms of minus p log, in summation minus p log p, for the different classes, we had probability of no as 5 by 14, we had 14 examples, 5 of which were no. And I know that they were yes and log base two probability of no. So if you do this calculation, it comes out to be 0.9. This is the daily high number. We also get a curve by this. So the probability of yes was zero. The entropy is zero. This means that there is no disorder for the examples negative. And if you look at the other extreme, the probability of class or yes is one. There is again no entropy because there is no uncertainty. The maximum uncertainty or ability happens when the probability of class is the same as probability of no. So we will start with calculating an entropy of a set. And we now want to choose an attitude A, which is able to give us the biggest performance gain. So can you think of in terms of starting with entropy as a starting point? What manipulation or what are the statistical measures we need to tell this is the best attribute? Please get it. It needs an attribute. One is the objective. Okay, but how do you calculate the entropy of an attribute? For me, to think of it in terms of we have to choose an attribute. So before it is started up with the elementary learning, you have several examples. You can calculate the entropy of that sample. Now you want to choose an attribute which will lower the entropy. So basically we go at this point. So we said that there was a lot of uncertainty in whether I will break into some more. Which means that there is a lot of memory. But if I choose output as overpass, I know that I will decorate it later. So there is no element of entropy in order for those specific examples. So we will now see that we are trying to choose an attribute. Subject will choose an image. The entropy becomes lower. There is a lesser disorder in this system. So that concept is known as information gain. I just look at the, I just show the formula. Information gain is known as the formula is given in terms of regression entropy. By partitioning a set of examples, S on an attribute. So an attribute A to have taken different values. For example, the output wrapping is sunny, a regular overpass. We can write the gain on a set of examples S subject to an attribute A as defined by the entropy which is the initial system. Of all the examples, minus the weighted entropy, weighted by the number of samples we have for a particular value. But in fact, the entropy of the subsets that we have written. Right? I will not go into the details but now let us assume that at this point of time we have a loaded examples. We choose an output as the first node. The entropy of this set is zero. Right? The weighted entropy of this set is also zero. This side will have some weighted entropy. So let us stop at this point with the input. We are understanding that we are trying to choose an attribute which reduces the entropy. Let us see it at 11am on our target. Thank you.\",\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 5.4,\n",
       "   'text': ' Please look at the code mentioned above and please sign up on the Google Cloud.',\n",
       "   'tokens': [50363,\n",
       "    4222,\n",
       "    804,\n",
       "    379,\n",
       "    262,\n",
       "    2438,\n",
       "    4750,\n",
       "    2029,\n",
       "    290,\n",
       "    3387,\n",
       "    1051,\n",
       "    510,\n",
       "    319,\n",
       "    262,\n",
       "    3012,\n",
       "    10130,\n",
       "    13,\n",
       "    50633],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3954378625620966,\n",
       "   'compression_ratio': 1.5466101694915255,\n",
       "   'no_speech_prob': 0.08800440281629562},\n",
       "  {'id': 1,\n",
       "   'seek': 0,\n",
       "   'start': 5.4,\n",
       "   'end': 8.52,\n",
       "   'text': \" We've already started making some announcements.\",\n",
       "   'tokens': [50633, 775, 1053, 1541, 2067, 1642, 617, 24009, 13, 50789],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3954378625620966,\n",
       "   'compression_ratio': 1.5466101694915255,\n",
       "   'no_speech_prob': 0.08800440281629562},\n",
       "  {'id': 2,\n",
       "   'seek': 0,\n",
       "   'start': 8.52,\n",
       "   'end': 14.24,\n",
       "   'text': \" You will likely end up missing the announcements and you'll have no one else to play with.\",\n",
       "   'tokens': [50789,\n",
       "    921,\n",
       "    481,\n",
       "    1884,\n",
       "    886,\n",
       "    510,\n",
       "    4814,\n",
       "    262,\n",
       "    24009,\n",
       "    290,\n",
       "    345,\n",
       "    1183,\n",
       "    423,\n",
       "    645,\n",
       "    530,\n",
       "    2073,\n",
       "    284,\n",
       "    711,\n",
       "    351,\n",
       "    13,\n",
       "    51075],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3954378625620966,\n",
       "   'compression_ratio': 1.5466101694915255,\n",
       "   'no_speech_prob': 0.08800440281629562},\n",
       "  {'id': 3,\n",
       "   'seek': 0,\n",
       "   'start': 14.24,\n",
       "   'end': 20.080000000000002,\n",
       "   'text': \" The second quick logistical announcement is that we'll have an extra lecture on Saturday,\",\n",
       "   'tokens': [51075,\n",
       "    383,\n",
       "    1218,\n",
       "    2068,\n",
       "    41088,\n",
       "    8009,\n",
       "    318,\n",
       "    326,\n",
       "    356,\n",
       "    1183,\n",
       "    423,\n",
       "    281,\n",
       "    3131,\n",
       "    19143,\n",
       "    319,\n",
       "    3909,\n",
       "    11,\n",
       "    51367],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3954378625620966,\n",
       "   'compression_ratio': 1.5466101694915255,\n",
       "   'no_speech_prob': 0.08800440281629562},\n",
       "  {'id': 4,\n",
       "   'seek': 0,\n",
       "   'start': 20.080000000000002,\n",
       "   'end': 23.8,\n",
       "   'text': ' 11th Jan at 11am in 1.101.',\n",
       "   'tokens': [51367,\n",
       "    1367,\n",
       "    400,\n",
       "    2365,\n",
       "    379,\n",
       "    1367,\n",
       "    321,\n",
       "    287,\n",
       "    352,\n",
       "    13,\n",
       "    8784,\n",
       "    13,\n",
       "    51553],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3954378625620966,\n",
       "   'compression_ratio': 1.5466101694915255,\n",
       "   'no_speech_prob': 0.08800440281629562},\n",
       "  {'id': 5,\n",
       "   'seek': 0,\n",
       "   'start': 23.8,\n",
       "   'end': 26.240000000000002,\n",
       "   'text': ' So a lot of ones over there.',\n",
       "   'tokens': [51553, 1406, 257, 1256, 286, 3392, 625, 612, 13, 51675],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3954378625620966,\n",
       "   'compression_ratio': 1.5466101694915255,\n",
       "   'no_speech_prob': 0.08800440281629562},\n",
       "  {'id': 6,\n",
       "   'seek': 2624,\n",
       "   'start': 26.24,\n",
       "   'end': 32.0,\n",
       "   'text': ' And I think one or two people still have conflict, but in the larger, in the larger',\n",
       "   'tokens': [50363,\n",
       "    843,\n",
       "    314,\n",
       "    892,\n",
       "    530,\n",
       "    393,\n",
       "    734,\n",
       "    661,\n",
       "    991,\n",
       "    423,\n",
       "    5358,\n",
       "    11,\n",
       "    475,\n",
       "    287,\n",
       "    262,\n",
       "    4025,\n",
       "    11,\n",
       "    287,\n",
       "    262,\n",
       "    4025,\n",
       "    50651],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38320693294558905,\n",
       "   'compression_ratio': 1.6555555555555554,\n",
       "   'no_speech_prob': 0.2509423494338989},\n",
       "  {'id': 7,\n",
       "   'seek': 2624,\n",
       "   'start': 32.0,\n",
       "   'end': 36.239999999999995,\n",
       "   'text': \" phone we will have almost everyone available, so we'll have to stick with this.\",\n",
       "   'tokens': [50651,\n",
       "    3072,\n",
       "    356,\n",
       "    481,\n",
       "    423,\n",
       "    2048,\n",
       "    2506,\n",
       "    1695,\n",
       "    11,\n",
       "    523,\n",
       "    356,\n",
       "    1183,\n",
       "    423,\n",
       "    284,\n",
       "    4859,\n",
       "    351,\n",
       "    428,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38320693294558905,\n",
       "   'compression_ratio': 1.6555555555555554,\n",
       "   'no_speech_prob': 0.2509423494338989},\n",
       "  {'id': 8,\n",
       "   'seek': 2624,\n",
       "   'start': 36.239999999999995,\n",
       "   'end': 43.959999999999994,\n",
       "   'text': \" FAQ and the projects which were earlier shared on Google Docs, I'll give all of you a comment\",\n",
       "   'tokens': [50863,\n",
       "    18749,\n",
       "    290,\n",
       "    262,\n",
       "    4493,\n",
       "    543,\n",
       "    547,\n",
       "    2961,\n",
       "    4888,\n",
       "    319,\n",
       "    3012,\n",
       "    14432,\n",
       "    82,\n",
       "    11,\n",
       "    314,\n",
       "    1183,\n",
       "    1577,\n",
       "    477,\n",
       "    286,\n",
       "    345,\n",
       "    257,\n",
       "    2912,\n",
       "    51249],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38320693294558905,\n",
       "   'compression_ratio': 1.6555555555555554,\n",
       "   'no_speech_prob': 0.2509423494338989},\n",
       "  {'id': 9,\n",
       "   'seek': 2624,\n",
       "   'start': 43.959999999999994,\n",
       "   'end': 48.959999999999994,\n",
       "   'text': ' access on it so that if you have any questions, queries, things like what should be the,',\n",
       "   'tokens': [51249,\n",
       "    1895,\n",
       "    319,\n",
       "    340,\n",
       "    523,\n",
       "    326,\n",
       "    611,\n",
       "    345,\n",
       "    423,\n",
       "    597,\n",
       "    2683,\n",
       "    11,\n",
       "    20743,\n",
       "    11,\n",
       "    1243,\n",
       "    588,\n",
       "    644,\n",
       "    815,\n",
       "    307,\n",
       "    262,\n",
       "    11,\n",
       "    51499],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38320693294558905,\n",
       "   'compression_ratio': 1.6555555555555554,\n",
       "   'no_speech_prob': 0.2509423494338989},\n",
       "  {'id': 10,\n",
       "   'seek': 2624,\n",
       "   'start': 48.959999999999994,\n",
       "   'end': 54.16,\n",
       "   'text': \" what are the maps, what are the main group size you can ask situations if they're already\",\n",
       "   'tokens': [51499,\n",
       "    644,\n",
       "    389,\n",
       "    262,\n",
       "    8739,\n",
       "    11,\n",
       "    644,\n",
       "    389,\n",
       "    262,\n",
       "    1388,\n",
       "    1448,\n",
       "    2546,\n",
       "    345,\n",
       "    460,\n",
       "    1265,\n",
       "    7445,\n",
       "    611,\n",
       "    484,\n",
       "    821,\n",
       "    1541,\n",
       "    51759],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38320693294558905,\n",
       "   'compression_ratio': 1.6555555555555554,\n",
       "   'no_speech_prob': 0.2509423494338989},\n",
       "  {'id': 11,\n",
       "   'seek': 2624,\n",
       "   'start': 54.16,\n",
       "   'end': 55.16,\n",
       "   'text': ' not there.',\n",
       "   'tokens': [51759, 407, 612, 13, 51809],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38320693294558905,\n",
       "   'compression_ratio': 1.6555555555555554,\n",
       "   'no_speech_prob': 0.2509423494338989},\n",
       "  {'id': 12,\n",
       "   'seek': 5516,\n",
       "   'start': 55.519999999999996,\n",
       "   'end': 60.48,\n",
       "   'text': \" Also about projects, if you have any questions, like what is the expectation if it's something\",\n",
       "   'tokens': [50381,\n",
       "    4418,\n",
       "    546,\n",
       "    4493,\n",
       "    11,\n",
       "    611,\n",
       "    345,\n",
       "    423,\n",
       "    597,\n",
       "    2683,\n",
       "    11,\n",
       "    588,\n",
       "    644,\n",
       "    318,\n",
       "    262,\n",
       "    17507,\n",
       "    611,\n",
       "    340,\n",
       "    338,\n",
       "    1223,\n",
       "    50629],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5557547069731212,\n",
       "   'compression_ratio': 1.6475095785440612,\n",
       "   'no_speech_prob': 0.14653082191944122},\n",
       "  {'id': 13,\n",
       "   'seek': 5516,\n",
       "   'start': 60.48,\n",
       "   'end': 66.6,\n",
       "   'text': \" is not mentioned clearly, you can please comment on the Google Doc and we'll get back to you soon.\",\n",
       "   'tokens': [50629,\n",
       "    318,\n",
       "    407,\n",
       "    4750,\n",
       "    4084,\n",
       "    11,\n",
       "    345,\n",
       "    460,\n",
       "    3387,\n",
       "    2912,\n",
       "    319,\n",
       "    262,\n",
       "    3012,\n",
       "    14432,\n",
       "    290,\n",
       "    356,\n",
       "    1183,\n",
       "    651,\n",
       "    736,\n",
       "    284,\n",
       "    345,\n",
       "    2582,\n",
       "    13,\n",
       "    50935],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5557547069731212,\n",
       "   'compression_ratio': 1.6475095785440612,\n",
       "   'no_speech_prob': 0.14653082191944122},\n",
       "  {'id': 14,\n",
       "   'seek': 5516,\n",
       "   'start': 68.56,\n",
       "   'end': 73.16,\n",
       "   'text': ' Also the video and the slides from the first lecture, in order to actually, actually',\n",
       "   'tokens': [51033,\n",
       "    4418,\n",
       "    262,\n",
       "    2008,\n",
       "    290,\n",
       "    262,\n",
       "    19392,\n",
       "    422,\n",
       "    262,\n",
       "    717,\n",
       "    19143,\n",
       "    11,\n",
       "    287,\n",
       "    1502,\n",
       "    284,\n",
       "    1682,\n",
       "    11,\n",
       "    1682,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5557547069731212,\n",
       "   'compression_ratio': 1.6475095785440612,\n",
       "   'no_speech_prob': 0.14653082191944122},\n",
       "  {'id': 15,\n",
       "   'seek': 5516,\n",
       "   'start': 73.16,\n",
       "   'end': 78.6,\n",
       "   'text': \" haven't put up on code translate, which is at the entrance, as mentioned in the slide\",\n",
       "   'tokens': [51263,\n",
       "    4398,\n",
       "    470,\n",
       "    1234,\n",
       "    510,\n",
       "    319,\n",
       "    2438,\n",
       "    15772,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    379,\n",
       "    262,\n",
       "    10384,\n",
       "    11,\n",
       "    355,\n",
       "    4750,\n",
       "    287,\n",
       "    262,\n",
       "    10649,\n",
       "    51535],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5557547069731212,\n",
       "   'compression_ratio': 1.6475095785440612,\n",
       "   'no_speech_prob': 0.14653082191944122},\n",
       "  {'id': 16,\n",
       "   'seek': 5516,\n",
       "   'start': 78.6,\n",
       "   'end': 79.6,\n",
       "   'text': ' above.',\n",
       "   'tokens': [51535, 2029, 13, 51585],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5557547069731212,\n",
       "   'compression_ratio': 1.6475095785440612,\n",
       "   'no_speech_prob': 0.14653082191944122},\n",
       "  {'id': 17,\n",
       "   'seek': 5516,\n",
       "   'start': 80.6,\n",
       "   'end': 83.44,\n",
       "   'text': ' This course website has also been now put on Google Cloud.',\n",
       "   'tokens': [51635,\n",
       "    770,\n",
       "    1781,\n",
       "    3052,\n",
       "    468,\n",
       "    635,\n",
       "    587,\n",
       "    783,\n",
       "    1234,\n",
       "    319,\n",
       "    3012,\n",
       "    10130,\n",
       "    13,\n",
       "    51777],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5557547069731212,\n",
       "   'compression_ratio': 1.6475095785440612,\n",
       "   'no_speech_prob': 0.14653082191944122},\n",
       "  {'id': 18,\n",
       "   'seek': 8344,\n",
       "   'start': 83.44,\n",
       "   'end': 86.12,\n",
       "   'text': ' So you can also get to that.',\n",
       "   'tokens': [50363, 1406, 345, 460, 635, 651, 284, 326, 13, 50497],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4321711014728157,\n",
       "   'compression_ratio': 1.6008583690987124,\n",
       "   'no_speech_prob': 0.02126738615334034},\n",
       "  {'id': 19,\n",
       "   'seek': 8344,\n",
       "   'start': 88.6,\n",
       "   'end': 93.52,\n",
       "   'text': ' Before we go forward, we should quickly revise what we started last time.',\n",
       "   'tokens': [50621,\n",
       "    7413,\n",
       "    356,\n",
       "    467,\n",
       "    2651,\n",
       "    11,\n",
       "    356,\n",
       "    815,\n",
       "    2952,\n",
       "    32548,\n",
       "    644,\n",
       "    356,\n",
       "    2067,\n",
       "    938,\n",
       "    640,\n",
       "    13,\n",
       "    50867],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4321711014728157,\n",
       "   'compression_ratio': 1.6008583690987124,\n",
       "   'no_speech_prob': 0.02126738615334034},\n",
       "  {'id': 20,\n",
       "   'seek': 8344,\n",
       "   'start': 94.28,\n",
       "   'end': 97.8,\n",
       "   'text': ' And someone tell you what is machine learning based on what we learned last time.',\n",
       "   'tokens': [50905,\n",
       "    843,\n",
       "    2130,\n",
       "    1560,\n",
       "    345,\n",
       "    644,\n",
       "    318,\n",
       "    4572,\n",
       "    4673,\n",
       "    1912,\n",
       "    319,\n",
       "    644,\n",
       "    356,\n",
       "    4499,\n",
       "    938,\n",
       "    640,\n",
       "    13,\n",
       "    51081],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4321711014728157,\n",
       "   'compression_ratio': 1.6008583690987124,\n",
       "   'no_speech_prob': 0.02126738615334034},\n",
       "  {'id': 21,\n",
       "   'seek': 8344,\n",
       "   'start': 98.96,\n",
       "   'end': 100.52,\n",
       "   'text': ' We looked at a couple of definitions.',\n",
       "   'tokens': [51139, 775, 3114, 379, 257, 3155, 286, 17336, 13, 51217],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4321711014728157,\n",
       "   'compression_ratio': 1.6008583690987124,\n",
       "   'no_speech_prob': 0.02126738615334034},\n",
       "  {'id': 22,\n",
       "   'seek': 8344,\n",
       "   'start': 100.52,\n",
       "   'end': 106.88,\n",
       "   'text': ' One was from Arthur Sandler, who by the way was the first person to point with the machine learning',\n",
       "   'tokens': [51217,\n",
       "    1881,\n",
       "    373,\n",
       "    422,\n",
       "    13514,\n",
       "    3837,\n",
       "    1754,\n",
       "    11,\n",
       "    508,\n",
       "    416,\n",
       "    262,\n",
       "    835,\n",
       "    373,\n",
       "    262,\n",
       "    717,\n",
       "    1048,\n",
       "    284,\n",
       "    966,\n",
       "    351,\n",
       "    262,\n",
       "    4572,\n",
       "    4673,\n",
       "    51535],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4321711014728157,\n",
       "   'compression_ratio': 1.6008583690987124,\n",
       "   'no_speech_prob': 0.02126738615334034},\n",
       "  {'id': 23,\n",
       "   'seek': 8344,\n",
       "   'start': 106.88,\n",
       "   'end': 108.44,\n",
       "   'text': ' and he did that in 1959.',\n",
       "   'tokens': [51535, 290, 339, 750, 326, 287, 23859, 13, 51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4321711014728157,\n",
       "   'compression_ratio': 1.6008583690987124,\n",
       "   'no_speech_prob': 0.02126738615334034},\n",
       "  {'id': 24,\n",
       "   'seek': 8344,\n",
       "   'start': 109.44,\n",
       "   'end': 110.72,\n",
       "   'text': ' So a long long time back.',\n",
       "   'tokens': [51663, 1406, 257, 890, 890, 640, 736, 13, 51727],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4321711014728157,\n",
       "   'compression_ratio': 1.6008583690987124,\n",
       "   'no_speech_prob': 0.02126738615334034},\n",
       "  {'id': 25,\n",
       "   'seek': 11072,\n",
       "   'start': 111.72,\n",
       "   'end': 113.72,\n",
       "   'text': ' Anyone for this machine learning?',\n",
       "   'tokens': [50413, 17462, 329, 428, 4572, 4673, 30, 50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6282451152801514,\n",
       "   'compression_ratio': 1.3333333333333333,\n",
       "   'no_speech_prob': 0.054103784263134},\n",
       "  {'id': 26,\n",
       "   'seek': 11072,\n",
       "   'start': 125.72,\n",
       "   'end': 132.72,\n",
       "   'text': ' The ability to learn without explicitly being to add others, any definition you want to get?',\n",
       "   'tokens': [51113,\n",
       "    383,\n",
       "    2694,\n",
       "    284,\n",
       "    2193,\n",
       "    1231,\n",
       "    11777,\n",
       "    852,\n",
       "    284,\n",
       "    751,\n",
       "    1854,\n",
       "    11,\n",
       "    597,\n",
       "    6770,\n",
       "    345,\n",
       "    765,\n",
       "    284,\n",
       "    651,\n",
       "    30,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6282451152801514,\n",
       "   'compression_ratio': 1.3333333333333333,\n",
       "   'no_speech_prob': 0.054103784263134},\n",
       "  {'id': 27,\n",
       "   'seek': 11072,\n",
       "   'start': 134.72,\n",
       "   'end': 136.72,\n",
       "   'text': \" There's a more technical definition also.\",\n",
       "   'tokens': [51563, 1318, 338, 257, 517, 6276, 6770, 635, 13, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6282451152801514,\n",
       "   'compression_ratio': 1.3333333333333333,\n",
       "   'no_speech_prob': 0.054103784263134},\n",
       "  {'id': 28,\n",
       "   'seek': 13672,\n",
       "   'start': 136.72,\n",
       "   'end': 138.72,\n",
       "   'text': \" But we'll get to that later.\",\n",
       "   'tokens': [50363, 887, 356, 1183, 651, 284, 326, 1568, 13, 50463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4336578615250126,\n",
       "   'compression_ratio': 1.6791666666666667,\n",
       "   'no_speech_prob': 0.026327241212129593},\n",
       "  {'id': 29,\n",
       "   'seek': 13672,\n",
       "   'start': 138.72,\n",
       "   'end': 143.72,\n",
       "   'text': \" Let's first start with again this same study, same definition of the learning code.\",\n",
       "   'tokens': [50463,\n",
       "    3914,\n",
       "    338,\n",
       "    717,\n",
       "    923,\n",
       "    351,\n",
       "    757,\n",
       "    428,\n",
       "    976,\n",
       "    2050,\n",
       "    11,\n",
       "    976,\n",
       "    6770,\n",
       "    286,\n",
       "    262,\n",
       "    4673,\n",
       "    2438,\n",
       "    13,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4336578615250126,\n",
       "   'compression_ratio': 1.6791666666666667,\n",
       "   'no_speech_prob': 0.026327241212129593},\n",
       "  {'id': 30,\n",
       "   'seek': 13672,\n",
       "   'start': 143.72,\n",
       "   'end': 149.72,\n",
       "   'text': \" It's a period of study and get computers, they are ready to learn without being explicitly programming.\",\n",
       "   'tokens': [50713,\n",
       "    632,\n",
       "    338,\n",
       "    257,\n",
       "    2278,\n",
       "    286,\n",
       "    2050,\n",
       "    290,\n",
       "    651,\n",
       "    9061,\n",
       "    11,\n",
       "    484,\n",
       "    389,\n",
       "    3492,\n",
       "    284,\n",
       "    2193,\n",
       "    1231,\n",
       "    852,\n",
       "    11777,\n",
       "    8300,\n",
       "    13,\n",
       "    51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4336578615250126,\n",
       "   'compression_ratio': 1.6791666666666667,\n",
       "   'no_speech_prob': 0.026327241212129593},\n",
       "  {'id': 31,\n",
       "   'seek': 13672,\n",
       "   'start': 149.72,\n",
       "   'end': 153.72,\n",
       "   'text': ' Okay, anyone tell you what does being explicitly programming here?',\n",
       "   'tokens': [51013,\n",
       "    16805,\n",
       "    11,\n",
       "    2687,\n",
       "    1560,\n",
       "    345,\n",
       "    644,\n",
       "    857,\n",
       "    852,\n",
       "    11777,\n",
       "    8300,\n",
       "    994,\n",
       "    30,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4336578615250126,\n",
       "   'compression_ratio': 1.6791666666666667,\n",
       "   'no_speech_prob': 0.026327241212129593},\n",
       "  {'id': 32,\n",
       "   'seek': 13672,\n",
       "   'start': 157.72,\n",
       "   'end': 160.72,\n",
       "   'text': ' Does a need a machine learning involves low programming?',\n",
       "   'tokens': [51413,\n",
       "    8314,\n",
       "    257,\n",
       "    761,\n",
       "    257,\n",
       "    4572,\n",
       "    4673,\n",
       "    9018,\n",
       "    1877,\n",
       "    8300,\n",
       "    30,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4336578615250126,\n",
       "   'compression_ratio': 1.6791666666666667,\n",
       "   'no_speech_prob': 0.026327241212129593},\n",
       "  {'id': 33,\n",
       "   'seek': 13672,\n",
       "   'start': 160.72,\n",
       "   'end': 163.72,\n",
       "   'text': ' So all programming, assignments are just the ways of learning.',\n",
       "   'tokens': [51563,\n",
       "    1406,\n",
       "    477,\n",
       "    8300,\n",
       "    11,\n",
       "    25815,\n",
       "    389,\n",
       "    655,\n",
       "    262,\n",
       "    2842,\n",
       "    286,\n",
       "    4673,\n",
       "    13,\n",
       "    51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4336578615250126,\n",
       "   'compression_ratio': 1.6791666666666667,\n",
       "   'no_speech_prob': 0.026327241212129593},\n",
       "  {'id': 34,\n",
       "   'seek': 16372,\n",
       "   'start': 164.72,\n",
       "   'end': 166.72,\n",
       "   'text': ' Program itself.',\n",
       "   'tokens': [50413, 6118, 2346, 13, 50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4044962212590888,\n",
       "   'compression_ratio': 1.761467889908257,\n",
       "   'no_speech_prob': 0.02665896527469158},\n",
       "  {'id': 35,\n",
       "   'seek': 16372,\n",
       "   'start': 166.72,\n",
       "   'end': 167.72,\n",
       "   'text': ' Program itself.',\n",
       "   'tokens': [50513, 6118, 2346, 13, 50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4044962212590888,\n",
       "   'compression_ratio': 1.761467889908257,\n",
       "   'no_speech_prob': 0.02665896527469158},\n",
       "  {'id': 36,\n",
       "   'seek': 16372,\n",
       "   'start': 167.72,\n",
       "   'end': 168.72,\n",
       "   'text': ' Program itself.',\n",
       "   'tokens': [50563, 6118, 2346, 13, 50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4044962212590888,\n",
       "   'compression_ratio': 1.761467889908257,\n",
       "   'no_speech_prob': 0.02665896527469158},\n",
       "  {'id': 37,\n",
       "   'seek': 16372,\n",
       "   'start': 168.72,\n",
       "   'end': 173.72,\n",
       "   'text': ' So is it some, some oracle which ends up writing the code?',\n",
       "   'tokens': [50613,\n",
       "    1406,\n",
       "    318,\n",
       "    340,\n",
       "    617,\n",
       "    11,\n",
       "    617,\n",
       "    393,\n",
       "    6008,\n",
       "    543,\n",
       "    5645,\n",
       "    510,\n",
       "    3597,\n",
       "    262,\n",
       "    2438,\n",
       "    30,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4044962212590888,\n",
       "   'compression_ratio': 1.761467889908257,\n",
       "   'no_speech_prob': 0.02665896527469158},\n",
       "  {'id': 38,\n",
       "   'seek': 16372,\n",
       "   'start': 173.72,\n",
       "   'end': 175.72,\n",
       "   'text': \" It's a whole writing program.\",\n",
       "   'tokens': [50863, 632, 338, 257, 2187, 3597, 1430, 13, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4044962212590888,\n",
       "   'compression_ratio': 1.761467889908257,\n",
       "   'no_speech_prob': 0.02665896527469158},\n",
       "  {'id': 39,\n",
       "   'seek': 16372,\n",
       "   'start': 176.72,\n",
       "   'end': 182.72,\n",
       "   'text': \" Of course there's one area, there's something on the computer architecture, so we're not going into that.\",\n",
       "   'tokens': [51013,\n",
       "    3226,\n",
       "    1781,\n",
       "    612,\n",
       "    338,\n",
       "    530,\n",
       "    1989,\n",
       "    11,\n",
       "    612,\n",
       "    338,\n",
       "    1223,\n",
       "    319,\n",
       "    262,\n",
       "    3644,\n",
       "    10959,\n",
       "    11,\n",
       "    523,\n",
       "    356,\n",
       "    821,\n",
       "    407,\n",
       "    1016,\n",
       "    656,\n",
       "    326,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4044962212590888,\n",
       "   'compression_ratio': 1.761467889908257,\n",
       "   'no_speech_prob': 0.02665896527469158},\n",
       "  {'id': 40,\n",
       "   'seek': 16372,\n",
       "   'start': 182.72,\n",
       "   'end': 184.72,\n",
       "   'text': \" But who I'd say is the machine learning program.\",\n",
       "   'tokens': [51313,\n",
       "    887,\n",
       "    508,\n",
       "    314,\n",
       "    1549,\n",
       "    910,\n",
       "    318,\n",
       "    262,\n",
       "    4572,\n",
       "    4673,\n",
       "    1430,\n",
       "    13,\n",
       "    51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4044962212590888,\n",
       "   'compression_ratio': 1.761467889908257,\n",
       "   'no_speech_prob': 0.02665896527469158},\n",
       "  {'id': 41,\n",
       "   'seek': 16372,\n",
       "   'start': 185.72,\n",
       "   'end': 187.72,\n",
       "   'text': \" So today's legislative program.\",\n",
       "   'tokens': [51463, 1406, 1909, 338, 10828, 1430, 13, 51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4044962212590888,\n",
       "   'compression_ratio': 1.761467889908257,\n",
       "   'no_speech_prob': 0.02665896527469158},\n",
       "  {'id': 42,\n",
       "   'seek': 16372,\n",
       "   'start': 187.72,\n",
       "   'end': 192.72,\n",
       "   'text': ' What is the exact meaning of adopting the executive program?',\n",
       "   'tokens': [51563,\n",
       "    1867,\n",
       "    318,\n",
       "    262,\n",
       "    2748,\n",
       "    3616,\n",
       "    286,\n",
       "    22868,\n",
       "    262,\n",
       "    4640,\n",
       "    1430,\n",
       "    30,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4044962212590888,\n",
       "   'compression_ratio': 1.761467889908257,\n",
       "   'no_speech_prob': 0.02665896527469158},\n",
       "  {'id': 43,\n",
       "   'seek': 19372,\n",
       "   'start': 194.72,\n",
       "   'end': 196.72,\n",
       "   'text': \" You don't have to replace this.\",\n",
       "   'tokens': [50413, 921, 836, 470, 423, 284, 6330, 428, 13, 50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3236794327244614,\n",
       "   'compression_ratio': 1.3522012578616351,\n",
       "   'no_speech_prob': 0.028133314102888107},\n",
       "  {'id': 44,\n",
       "   'seek': 19372,\n",
       "   'start': 196.72,\n",
       "   'end': 198.72,\n",
       "   'text': ' Okay, can you explain what does mean?',\n",
       "   'tokens': [50513, 16805, 11, 460, 345, 4727, 644, 857, 1612, 30, 50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3236794327244614,\n",
       "   'compression_ratio': 1.3522012578616351,\n",
       "   'no_speech_prob': 0.028133314102888107},\n",
       "  {'id': 45,\n",
       "   'seek': 19372,\n",
       "   'start': 206.72,\n",
       "   'end': 208.72,\n",
       "   'text': \" But he's on the right track.\",\n",
       "   'tokens': [51013, 887, 339, 338, 319, 262, 826, 2610, 13, 51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3236794327244614,\n",
       "   'compression_ratio': 1.3522012578616351,\n",
       "   'no_speech_prob': 0.028133314102888107},\n",
       "  {'id': 46,\n",
       "   'seek': 19372,\n",
       "   'start': 208.72,\n",
       "   'end': 212.72,\n",
       "   'text': \" Let's take an example to get this concept even better.\",\n",
       "   'tokens': [51113,\n",
       "    3914,\n",
       "    338,\n",
       "    1011,\n",
       "    281,\n",
       "    1672,\n",
       "    284,\n",
       "    651,\n",
       "    428,\n",
       "    3721,\n",
       "    772,\n",
       "    1365,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3236794327244614,\n",
       "   'compression_ratio': 1.3522012578616351,\n",
       "   'no_speech_prob': 0.028133314102888107},\n",
       "  {'id': 47,\n",
       "   'seek': 19372,\n",
       "   'start': 214.72,\n",
       "   'end': 216.72,\n",
       "   'text': ' Can you see these model digits?',\n",
       "   'tokens': [51413, 1680, 345, 766, 777, 2746, 19561, 30, 51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3236794327244614,\n",
       "   'compression_ratio': 1.3522012578616351,\n",
       "   'no_speech_prob': 0.028133314102888107},\n",
       "  {'id': 48,\n",
       "   'seek': 19372,\n",
       "   'start': 216.72,\n",
       "   'end': 219.72,\n",
       "   'text': ' These are digits from 0 to 9.',\n",
       "   'tokens': [51513, 2312, 389, 19561, 422, 657, 284, 860, 13, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3236794327244614,\n",
       "   'compression_ratio': 1.3522012578616351,\n",
       "   'no_speech_prob': 0.028133314102888107},\n",
       "  {'id': 49,\n",
       "   'seek': 21972,\n",
       "   'start': 220.72,\n",
       "   'end': 222.72,\n",
       "   'text': ' And these are from the dataset for in this.',\n",
       "   'tokens': [50413, 843, 777, 389, 422, 262, 27039, 329, 287, 428, 13, 50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2898260945021504,\n",
       "   'compression_ratio': 1.6008771929824561,\n",
       "   'no_speech_prob': 0.03229476138949394},\n",
       "  {'id': 50,\n",
       "   'seek': 21972,\n",
       "   'start': 222.72,\n",
       "   'end': 225.72,\n",
       "   'text': ' One of the most popular machine learning datasets.',\n",
       "   'tokens': [50513, 1881, 286, 262, 749, 2968, 4572, 4673, 40522, 13, 50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2898260945021504,\n",
       "   'compression_ratio': 1.6008771929824561,\n",
       "   'no_speech_prob': 0.03229476138949394},\n",
       "  {'id': 51,\n",
       "   'seek': 21972,\n",
       "   'start': 225.72,\n",
       "   'end': 234.72,\n",
       "   'text': ' Now the first task for all of us is we want to now write a program to recognize the digits.',\n",
       "   'tokens': [50663,\n",
       "    2735,\n",
       "    262,\n",
       "    717,\n",
       "    4876,\n",
       "    329,\n",
       "    477,\n",
       "    286,\n",
       "    514,\n",
       "    318,\n",
       "    356,\n",
       "    765,\n",
       "    284,\n",
       "    783,\n",
       "    3551,\n",
       "    257,\n",
       "    1430,\n",
       "    284,\n",
       "    7564,\n",
       "    262,\n",
       "    19561,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2898260945021504,\n",
       "   'compression_ratio': 1.6008771929824561,\n",
       "   'no_speech_prob': 0.03229476138949394},\n",
       "  {'id': 52,\n",
       "   'seek': 21972,\n",
       "   'start': 234.72,\n",
       "   'end': 236.72,\n",
       "   'text': \" And we'll start with code.\",\n",
       "   'tokens': [51113, 843, 356, 1183, 923, 351, 2438, 13, 51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2898260945021504,\n",
       "   'compression_ratio': 1.6008771929824561,\n",
       "   'no_speech_prob': 0.03229476138949394},\n",
       "  {'id': 53,\n",
       "   'seek': 21972,\n",
       "   'start': 236.72,\n",
       "   'end': 241.72,\n",
       "   'text': \" Can someone tell me how they'll recognize if a digit is 4 or not?\",\n",
       "   'tokens': [51213,\n",
       "    1680,\n",
       "    2130,\n",
       "    1560,\n",
       "    502,\n",
       "    703,\n",
       "    484,\n",
       "    1183,\n",
       "    7564,\n",
       "    611,\n",
       "    257,\n",
       "    16839,\n",
       "    318,\n",
       "    604,\n",
       "    393,\n",
       "    407,\n",
       "    30,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2898260945021504,\n",
       "   'compression_ratio': 1.6008771929824561,\n",
       "   'no_speech_prob': 0.03229476138949394},\n",
       "  {'id': 54,\n",
       "   'seek': 21972,\n",
       "   'start': 241.72,\n",
       "   'end': 243.72,\n",
       "   'text': \" We're looking at these specific rules.\",\n",
       "   'tokens': [51463, 775, 821, 2045, 379, 777, 2176, 3173, 13, 51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2898260945021504,\n",
       "   'compression_ratio': 1.6008771929824561,\n",
       "   'no_speech_prob': 0.03229476138949394},\n",
       "  {'id': 55,\n",
       "   'seek': 21972,\n",
       "   'start': 243.72,\n",
       "   'end': 247.72,\n",
       "   'text': ' What does how we add to the code that we need?',\n",
       "   'tokens': [51563,\n",
       "    1867,\n",
       "    857,\n",
       "    703,\n",
       "    356,\n",
       "    751,\n",
       "    284,\n",
       "    262,\n",
       "    2438,\n",
       "    326,\n",
       "    356,\n",
       "    761,\n",
       "    30,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2898260945021504,\n",
       "   'compression_ratio': 1.6008771929824561,\n",
       "   'no_speech_prob': 0.03229476138949394},\n",
       "  {'id': 56,\n",
       "   'seek': 24772,\n",
       "   'start': 248.72,\n",
       "   'end': 257.72,\n",
       "   'text': ' Can we start off as 4 can be quantified as a vertical line, a horizontal line, a vertical line.',\n",
       "   'tokens': [50413,\n",
       "    1680,\n",
       "    356,\n",
       "    923,\n",
       "    572,\n",
       "    355,\n",
       "    604,\n",
       "    460,\n",
       "    307,\n",
       "    5554,\n",
       "    1431,\n",
       "    355,\n",
       "    257,\n",
       "    11723,\n",
       "    1627,\n",
       "    11,\n",
       "    257,\n",
       "    16021,\n",
       "    1627,\n",
       "    11,\n",
       "    257,\n",
       "    11723,\n",
       "    1627,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3306344350179036,\n",
       "   'compression_ratio': 1.7484662576687116,\n",
       "   'no_speech_prob': 0.034349843859672546},\n",
       "  {'id': 57,\n",
       "   'seek': 24772,\n",
       "   'start': 257.72,\n",
       "   'end': 259.72,\n",
       "   'text': ' All of them are jointed.',\n",
       "   'tokens': [50863, 1439, 286, 606, 389, 6466, 276, 13, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3306344350179036,\n",
       "   'compression_ratio': 1.7484662576687116,\n",
       "   'no_speech_prob': 0.034349843859672546},\n",
       "  {'id': 58,\n",
       "   'seek': 24772,\n",
       "   'start': 259.72,\n",
       "   'end': 264.72,\n",
       "   'text': ' And then another vertical line going down from the first, from the last vertical line.',\n",
       "   'tokens': [50963,\n",
       "    843,\n",
       "    788,\n",
       "    1194,\n",
       "    11723,\n",
       "    1627,\n",
       "    1016,\n",
       "    866,\n",
       "    422,\n",
       "    262,\n",
       "    717,\n",
       "    11,\n",
       "    422,\n",
       "    262,\n",
       "    938,\n",
       "    11723,\n",
       "    1627,\n",
       "    13,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3306344350179036,\n",
       "   'compression_ratio': 1.7484662576687116,\n",
       "   'no_speech_prob': 0.034349843859672546},\n",
       "  {'id': 59,\n",
       "   'seek': 24772,\n",
       "   'start': 264.72,\n",
       "   'end': 272.72,\n",
       "   'text': ' Everything of that is that all that is there to 4 or if there are any models.',\n",
       "   'tokens': [51213,\n",
       "    11391,\n",
       "    286,\n",
       "    326,\n",
       "    318,\n",
       "    326,\n",
       "    477,\n",
       "    326,\n",
       "    318,\n",
       "    612,\n",
       "    284,\n",
       "    604,\n",
       "    393,\n",
       "    611,\n",
       "    612,\n",
       "    389,\n",
       "    597,\n",
       "    4981,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3306344350179036,\n",
       "   'compression_ratio': 1.7484662576687116,\n",
       "   'no_speech_prob': 0.034349843859672546},\n",
       "  {'id': 60,\n",
       "   'seek': 27272,\n",
       "   'start': 273.72,\n",
       "   'end': 281.72,\n",
       "   'text': ' What about the fact that the height of each of the vertical lines need to be very similar?',\n",
       "   'tokens': [50413,\n",
       "    1867,\n",
       "    546,\n",
       "    262,\n",
       "    1109,\n",
       "    326,\n",
       "    262,\n",
       "    6001,\n",
       "    286,\n",
       "    1123,\n",
       "    286,\n",
       "    262,\n",
       "    11723,\n",
       "    3951,\n",
       "    761,\n",
       "    284,\n",
       "    307,\n",
       "    845,\n",
       "    2092,\n",
       "    30,\n",
       "    50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2171604829676011,\n",
       "   'compression_ratio': 1.5566502463054188,\n",
       "   'no_speech_prob': 0.057658422738313675},\n",
       "  {'id': 61,\n",
       "   'seek': 27272,\n",
       "   'start': 281.72,\n",
       "   'end': 284.72,\n",
       "   'text': ' Can you write this kind of a rule?',\n",
       "   'tokens': [50813, 1680, 345, 3551, 428, 1611, 286, 257, 3896, 30, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2171604829676011,\n",
       "   'compression_ratio': 1.5566502463054188,\n",
       "   'no_speech_prob': 0.057658422738313675},\n",
       "  {'id': 62,\n",
       "   'seek': 27272,\n",
       "   'start': 284.72,\n",
       "   'end': 290.72,\n",
       "   'text': ' Or do you see a force where one of the lines is very, very long compared to the other?',\n",
       "   'tokens': [50963,\n",
       "    1471,\n",
       "    466,\n",
       "    345,\n",
       "    766,\n",
       "    257,\n",
       "    2700,\n",
       "    810,\n",
       "    530,\n",
       "    286,\n",
       "    262,\n",
       "    3951,\n",
       "    318,\n",
       "    845,\n",
       "    11,\n",
       "    845,\n",
       "    890,\n",
       "    3688,\n",
       "    284,\n",
       "    262,\n",
       "    584,\n",
       "    30,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2171604829676011,\n",
       "   'compression_ratio': 1.5566502463054188,\n",
       "   'no_speech_prob': 0.057658422738313675},\n",
       "  {'id': 63,\n",
       "   'seek': 27272,\n",
       "   'start': 290.72,\n",
       "   'end': 292.72,\n",
       "   'text': ' Generally not.',\n",
       "   'tokens': [51263, 23904, 407, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2171604829676011,\n",
       "   'compression_ratio': 1.5566502463054188,\n",
       "   'no_speech_prob': 0.057658422738313675},\n",
       "  {'id': 64,\n",
       "   'seek': 27272,\n",
       "   'start': 292.72,\n",
       "   'end': 296.72,\n",
       "   'text': ' So you have to report some of these constraints.',\n",
       "   'tokens': [51363,\n",
       "    1406,\n",
       "    345,\n",
       "    423,\n",
       "    284,\n",
       "    989,\n",
       "    617,\n",
       "    286,\n",
       "    777,\n",
       "    17778,\n",
       "    13,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2171604829676011,\n",
       "   'compression_ratio': 1.5566502463054188,\n",
       "   'no_speech_prob': 0.057658422738313675},\n",
       "  {'id': 65,\n",
       "   'seek': 27272,\n",
       "   'start': 296.72,\n",
       "   'end': 298.72,\n",
       "   'text': ' But are you done with it anything more?',\n",
       "   'tokens': [51563, 887, 389, 345, 1760, 351, 340, 1997, 517, 30, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2171604829676011,\n",
       "   'compression_ratio': 1.5566502463054188,\n",
       "   'no_speech_prob': 0.057658422738313675},\n",
       "  {'id': 66,\n",
       "   'seek': 29872,\n",
       "   'start': 299.72,\n",
       "   'end': 305.72,\n",
       "   'text': ' Just look through the example for do you see any force which would violate the difference',\n",
       "   'tokens': [50413,\n",
       "    2329,\n",
       "    804,\n",
       "    832,\n",
       "    262,\n",
       "    1672,\n",
       "    329,\n",
       "    466,\n",
       "    345,\n",
       "    766,\n",
       "    597,\n",
       "    2700,\n",
       "    543,\n",
       "    561,\n",
       "    16967,\n",
       "    262,\n",
       "    3580,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5040508015950521,\n",
       "   'compression_ratio': 1.516304347826087,\n",
       "   'no_speech_prob': 0.2439224272966385},\n",
       "  {'id': 67,\n",
       "   'seek': 29872,\n",
       "   'start': 305.72,\n",
       "   'end': 308.72,\n",
       "   'text': \" that we've seen it, specify the thought.\",\n",
       "   'tokens': [50713,\n",
       "    326,\n",
       "    356,\n",
       "    1053,\n",
       "    1775,\n",
       "    340,\n",
       "    11,\n",
       "    11986,\n",
       "    262,\n",
       "    1807,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5040508015950521,\n",
       "   'compression_ratio': 1.516304347826087,\n",
       "   'no_speech_prob': 0.2439224272966385},\n",
       "  {'id': 68,\n",
       "   'seek': 29872,\n",
       "   'start': 308.72,\n",
       "   'end': 313.72,\n",
       "   'text': ' And a thought will look that.',\n",
       "   'tokens': [50863, 843, 257, 1807, 481, 804, 326, 13, 51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5040508015950521,\n",
       "   'compression_ratio': 1.516304347826087,\n",
       "   'no_speech_prob': 0.2439224272966385},\n",
       "  {'id': 69,\n",
       "   'seek': 29872,\n",
       "   'start': 313.72,\n",
       "   'end': 316.72,\n",
       "   'text': ' Okay, the second last is one case.',\n",
       "   'tokens': [51113, 16805, 11, 262, 1218, 938, 318, 530, 1339, 13, 51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5040508015950521,\n",
       "   'compression_ratio': 1.516304347826087,\n",
       "   'no_speech_prob': 0.2439224272966385},\n",
       "  {'id': 70,\n",
       "   'seek': 29872,\n",
       "   'start': 316.72,\n",
       "   'end': 321.72,\n",
       "   'text': ' What about this one?',\n",
       "   'tokens': [51263, 1867, 546, 428, 530, 30, 51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5040508015950521,\n",
       "   'compression_ratio': 1.516304347826087,\n",
       "   'no_speech_prob': 0.2439224272966385},\n",
       "  {'id': 71,\n",
       "   'seek': 29872,\n",
       "   'start': 321.72,\n",
       "   'end': 327.72,\n",
       "   'text': ' Okay, so each of the vertical lines would be a little smaller.',\n",
       "   'tokens': [51513,\n",
       "    16805,\n",
       "    11,\n",
       "    523,\n",
       "    1123,\n",
       "    286,\n",
       "    262,\n",
       "    11723,\n",
       "    3951,\n",
       "    561,\n",
       "    307,\n",
       "    257,\n",
       "    1310,\n",
       "    4833,\n",
       "    13,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5040508015950521,\n",
       "   'compression_ratio': 1.516304347826087,\n",
       "   'no_speech_prob': 0.2439224272966385},\n",
       "  {'id': 72,\n",
       "   'seek': 32772,\n",
       "   'start': 328.72,\n",
       "   'end': 332.72,\n",
       "   'text': ' In many cases it would be a, and if I were to write, you will not understand it,',\n",
       "   'tokens': [50413,\n",
       "    554,\n",
       "    867,\n",
       "    2663,\n",
       "    340,\n",
       "    561,\n",
       "    307,\n",
       "    257,\n",
       "    11,\n",
       "    290,\n",
       "    611,\n",
       "    314,\n",
       "    547,\n",
       "    284,\n",
       "    3551,\n",
       "    11,\n",
       "    345,\n",
       "    481,\n",
       "    407,\n",
       "    1833,\n",
       "    340,\n",
       "    11,\n",
       "    50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.39716639284227717,\n",
       "   'compression_ratio': 1.6564885496183206,\n",
       "   'no_speech_prob': 0.03586013242602348},\n",
       "  {'id': 73,\n",
       "   'seek': 32772,\n",
       "   'start': 332.72,\n",
       "   'end': 334.72,\n",
       "   'text': ' or you will get it.',\n",
       "   'tokens': [50613, 393, 345, 481, 651, 340, 13, 50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.39716639284227717,\n",
       "   'compression_ratio': 1.6564885496183206,\n",
       "   'no_speech_prob': 0.03586013242602348},\n",
       "  {'id': 74,\n",
       "   'seek': 32772,\n",
       "   'start': 334.72,\n",
       "   'end': 337.72,\n",
       "   'text': ' So because people write different things.',\n",
       "   'tokens': [50713, 1406, 780, 661, 3551, 1180, 1243, 13, 50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.39716639284227717,\n",
       "   'compression_ratio': 1.6564885496183206,\n",
       "   'no_speech_prob': 0.03586013242602348},\n",
       "  {'id': 75,\n",
       "   'seek': 32772,\n",
       "   'start': 337.72,\n",
       "   'end': 339.72,\n",
       "   'text': \" So that's another rule that I like.\",\n",
       "   'tokens': [50863, 1406, 326, 338, 1194, 3896, 326, 314, 588, 13, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.39716639284227717,\n",
       "   'compression_ratio': 1.6564885496183206,\n",
       "   'no_speech_prob': 0.03586013242602348},\n",
       "  {'id': 76,\n",
       "   'seek': 32772,\n",
       "   'start': 339.72,\n",
       "   'end': 341.72,\n",
       "   'text': ' Now what do you mean by slides?',\n",
       "   'tokens': [50963, 2735, 644, 466, 345, 1612, 416, 19392, 30, 51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.39716639284227717,\n",
       "   'compression_ratio': 1.6564885496183206,\n",
       "   'no_speech_prob': 0.03586013242602348},\n",
       "  {'id': 77,\n",
       "   'seek': 32772,\n",
       "   'start': 341.72,\n",
       "   'end': 347.72,\n",
       "   'text': \" Well, it doesn't mean that it can have an inclination of some 10 degrees, 20 degrees, 30 degrees,\",\n",
       "   'tokens': [51063,\n",
       "    3894,\n",
       "    11,\n",
       "    340,\n",
       "    1595,\n",
       "    470,\n",
       "    1612,\n",
       "    326,\n",
       "    340,\n",
       "    460,\n",
       "    423,\n",
       "    281,\n",
       "    36793,\n",
       "    286,\n",
       "    617,\n",
       "    838,\n",
       "    7370,\n",
       "    11,\n",
       "    1160,\n",
       "    7370,\n",
       "    11,\n",
       "    1542,\n",
       "    7370,\n",
       "    11,\n",
       "    51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.39716639284227717,\n",
       "   'compression_ratio': 1.6564885496183206,\n",
       "   'no_speech_prob': 0.03586013242602348},\n",
       "  {'id': 78,\n",
       "   'seek': 32772,\n",
       "   'start': 347.72,\n",
       "   'end': 349.72,\n",
       "   'text': ' very excited, none of them.',\n",
       "   'tokens': [51363, 845, 6568, 11, 4844, 286, 606, 13, 51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.39716639284227717,\n",
       "   'compression_ratio': 1.6564885496183206,\n",
       "   'no_speech_prob': 0.03586013242602348},\n",
       "  {'id': 79,\n",
       "   'seek': 32772,\n",
       "   'start': 349.72,\n",
       "   'end': 354.72,\n",
       "   'text': \" So let's say you come up with some number, based on your experience, based on some rules of time.\",\n",
       "   'tokens': [51463,\n",
       "    1406,\n",
       "    1309,\n",
       "    338,\n",
       "    910,\n",
       "    345,\n",
       "    1282,\n",
       "    510,\n",
       "    351,\n",
       "    617,\n",
       "    1271,\n",
       "    11,\n",
       "    1912,\n",
       "    319,\n",
       "    534,\n",
       "    1998,\n",
       "    11,\n",
       "    1912,\n",
       "    319,\n",
       "    617,\n",
       "    3173,\n",
       "    286,\n",
       "    640,\n",
       "    13,\n",
       "    51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.39716639284227717,\n",
       "   'compression_ratio': 1.6564885496183206,\n",
       "   'no_speech_prob': 0.03586013242602348},\n",
       "  {'id': 80,\n",
       "   'seek': 35472,\n",
       "   'start': 355.72,\n",
       "   'end': 356.72,\n",
       "   'text': ' But is that all?',\n",
       "   'tokens': [50413, 887, 318, 326, 477, 30, 50463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2745918874387388,\n",
       "   'compression_ratio': 1.518018018018018,\n",
       "   'no_speech_prob': 0.04621245712041855},\n",
       "  {'id': 81,\n",
       "   'seek': 35472,\n",
       "   'start': 356.72,\n",
       "   'end': 360.72,\n",
       "   'text': ' No, some people write 4 with a star, right?',\n",
       "   'tokens': [50463,\n",
       "    1400,\n",
       "    11,\n",
       "    617,\n",
       "    661,\n",
       "    3551,\n",
       "    604,\n",
       "    351,\n",
       "    257,\n",
       "    3491,\n",
       "    11,\n",
       "    826,\n",
       "    30,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2745918874387388,\n",
       "   'compression_ratio': 1.518018018018018,\n",
       "   'no_speech_prob': 0.04621245712041855},\n",
       "  {'id': 82,\n",
       "   'seek': 35472,\n",
       "   'start': 360.72,\n",
       "   'end': 367.72,\n",
       "   'text': ' If you look at this, 1, 2, 3, 4, 5, 4, you have this particular line, we have to join',\n",
       "   'tokens': [50663,\n",
       "    1002,\n",
       "    345,\n",
       "    804,\n",
       "    379,\n",
       "    428,\n",
       "    11,\n",
       "    352,\n",
       "    11,\n",
       "    362,\n",
       "    11,\n",
       "    513,\n",
       "    11,\n",
       "    604,\n",
       "    11,\n",
       "    642,\n",
       "    11,\n",
       "    604,\n",
       "    11,\n",
       "    345,\n",
       "    423,\n",
       "    428,\n",
       "    1948,\n",
       "    1627,\n",
       "    11,\n",
       "    356,\n",
       "    423,\n",
       "    284,\n",
       "    4654,\n",
       "    51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2745918874387388,\n",
       "   'compression_ratio': 1.518018018018018,\n",
       "   'no_speech_prob': 0.04621245712041855},\n",
       "  {'id': 83,\n",
       "   'seek': 35472,\n",
       "   'start': 367.72,\n",
       "   'end': 370.72,\n",
       "   'text': ' like this before piloting the end, right?',\n",
       "   'tokens': [51013, 588, 428, 878, 8022, 278, 262, 886, 11, 826, 30, 51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2745918874387388,\n",
       "   'compression_ratio': 1.518018018018018,\n",
       "   'no_speech_prob': 0.04621245712041855},\n",
       "  {'id': 84,\n",
       "   'seek': 35472,\n",
       "   'start': 370.72,\n",
       "   'end': 373.72,\n",
       "   'text': \" So that is now another rule that I've written.\",\n",
       "   'tokens': [51163,\n",
       "    1406,\n",
       "    326,\n",
       "    318,\n",
       "    783,\n",
       "    1194,\n",
       "    3896,\n",
       "    326,\n",
       "    314,\n",
       "    1053,\n",
       "    3194,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2745918874387388,\n",
       "   'compression_ratio': 1.518018018018018,\n",
       "   'no_speech_prob': 0.04621245712041855},\n",
       "  {'id': 85,\n",
       "   'seek': 35472,\n",
       "   'start': 373.72,\n",
       "   'end': 379.72,\n",
       "   'text': \" You have already come up with 5, 6 of such rules, but that's not all.\",\n",
       "   'tokens': [51313,\n",
       "    921,\n",
       "    423,\n",
       "    1541,\n",
       "    1282,\n",
       "    510,\n",
       "    351,\n",
       "    642,\n",
       "    11,\n",
       "    718,\n",
       "    286,\n",
       "    884,\n",
       "    3173,\n",
       "    11,\n",
       "    475,\n",
       "    326,\n",
       "    338,\n",
       "    407,\n",
       "    477,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2745918874387388,\n",
       "   'compression_ratio': 1.518018018018018,\n",
       "   'no_speech_prob': 0.04621245712041855},\n",
       "  {'id': 86,\n",
       "   'seek': 35472,\n",
       "   'start': 379.72,\n",
       "   'end': 381.72,\n",
       "   'text': ' Anything else you can think of?',\n",
       "   'tokens': [51613, 21035, 2073, 345, 460, 892, 286, 30, 51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2745918874387388,\n",
       "   'compression_ratio': 1.518018018018018,\n",
       "   'no_speech_prob': 0.04621245712041855},\n",
       "  {'id': 87,\n",
       "   'seek': 38172,\n",
       "   'start': 381.72,\n",
       "   'end': 386.72,\n",
       "   'text': \" That's why we have not talked about the bits of the lines.\",\n",
       "   'tokens': [50363,\n",
       "    1320,\n",
       "    338,\n",
       "    1521,\n",
       "    356,\n",
       "    423,\n",
       "    407,\n",
       "    6619,\n",
       "    546,\n",
       "    262,\n",
       "    10340,\n",
       "    286,\n",
       "    262,\n",
       "    3951,\n",
       "    13,\n",
       "    50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2936407270885649,\n",
       "   'compression_ratio': 1.5532994923857868,\n",
       "   'no_speech_prob': 0.058845631778240204},\n",
       "  {'id': 88,\n",
       "   'seek': 38172,\n",
       "   'start': 386.72,\n",
       "   'end': 389.72,\n",
       "   'text': ' What can we think about that?',\n",
       "   'tokens': [50613, 1867, 460, 356, 892, 546, 326, 30, 50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2936407270885649,\n",
       "   'compression_ratio': 1.5532994923857868,\n",
       "   'no_speech_prob': 0.058845631778240204},\n",
       "  {'id': 89,\n",
       "   'seek': 38172,\n",
       "   'start': 389.72,\n",
       "   'end': 391.72,\n",
       "   'text': ' Can we cover some rules?',\n",
       "   'tokens': [50763, 1680, 356, 3002, 617, 3173, 30, 50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2936407270885649,\n",
       "   'compression_ratio': 1.5532994923857868,\n",
       "   'no_speech_prob': 0.058845631778240204},\n",
       "  {'id': 90,\n",
       "   'seek': 38172,\n",
       "   'start': 391.72,\n",
       "   'end': 399.72,\n",
       "   'text': \" Let's say if I'm writing the different mark or if I'm using the pen in different fashion,\",\n",
       "   'tokens': [50863,\n",
       "    3914,\n",
       "    338,\n",
       "    910,\n",
       "    611,\n",
       "    314,\n",
       "    1101,\n",
       "    3597,\n",
       "    262,\n",
       "    1180,\n",
       "    1317,\n",
       "    393,\n",
       "    611,\n",
       "    314,\n",
       "    1101,\n",
       "    1262,\n",
       "    262,\n",
       "    3112,\n",
       "    287,\n",
       "    1180,\n",
       "    6977,\n",
       "    11,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2936407270885649,\n",
       "   'compression_ratio': 1.5532994923857868,\n",
       "   'no_speech_prob': 0.058845631778240204},\n",
       "  {'id': 91,\n",
       "   'seek': 38172,\n",
       "   'start': 399.72,\n",
       "   'end': 404.72,\n",
       "   'text': ' where some of my strokes we fired will be thicker, right?',\n",
       "   'tokens': [51263,\n",
       "    810,\n",
       "    617,\n",
       "    286,\n",
       "    616,\n",
       "    29483,\n",
       "    356,\n",
       "    6294,\n",
       "    481,\n",
       "    307,\n",
       "    29175,\n",
       "    11,\n",
       "    826,\n",
       "    30,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2936407270885649,\n",
       "   'compression_ratio': 1.5532994923857868,\n",
       "   'no_speech_prob': 0.058845631778240204},\n",
       "  {'id': 92,\n",
       "   'seek': 38172,\n",
       "   'start': 404.72,\n",
       "   'end': 407.72,\n",
       "   'text': \" Maybe that's another particular rule, right?\",\n",
       "   'tokens': [51513, 6674, 326, 338, 1194, 1948, 3896, 11, 826, 30, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2936407270885649,\n",
       "   'compression_ratio': 1.5532994923857868,\n",
       "   'no_speech_prob': 0.058845631778240204},\n",
       "  {'id': 93,\n",
       "   'seek': 40772,\n",
       "   'start': 407.72,\n",
       "   'end': 412.72,\n",
       "   'text': ' There can be some cases where the width of each of the stroke is a little different.',\n",
       "   'tokens': [50363,\n",
       "    1318,\n",
       "    460,\n",
       "    307,\n",
       "    617,\n",
       "    2663,\n",
       "    810,\n",
       "    262,\n",
       "    9647,\n",
       "    286,\n",
       "    1123,\n",
       "    286,\n",
       "    262,\n",
       "    14000,\n",
       "    318,\n",
       "    257,\n",
       "    1310,\n",
       "    1180,\n",
       "    13,\n",
       "    50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22866994943191757,\n",
       "   'compression_ratio': 1.5105263157894737,\n",
       "   'no_speech_prob': 0.06310149282217026},\n",
       "  {'id': 94,\n",
       "   'seek': 40772,\n",
       "   'start': 412.72,\n",
       "   'end': 418.72,\n",
       "   'text': \" You'll have to again capture some of these characteristics, while writing some rules or\",\n",
       "   'tokens': [50613,\n",
       "    921,\n",
       "    1183,\n",
       "    423,\n",
       "    284,\n",
       "    757,\n",
       "    8006,\n",
       "    617,\n",
       "    286,\n",
       "    777,\n",
       "    9695,\n",
       "    11,\n",
       "    981,\n",
       "    3597,\n",
       "    617,\n",
       "    3173,\n",
       "    393,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22866994943191757,\n",
       "   'compression_ratio': 1.5105263157894737,\n",
       "   'no_speech_prob': 0.06310149282217026},\n",
       "  {'id': 95,\n",
       "   'seek': 40772,\n",
       "   'start': 418.72,\n",
       "   'end': 422.72,\n",
       "   'text': ' writing a program to recognize 4.',\n",
       "   'tokens': [50913, 3597, 257, 1430, 284, 7564, 604, 13, 51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22866994943191757,\n",
       "   'compression_ratio': 1.5105263157894737,\n",
       "   'no_speech_prob': 0.06310149282217026},\n",
       "  {'id': 96,\n",
       "   'seek': 40772,\n",
       "   'start': 422.72,\n",
       "   'end': 431.72,\n",
       "   'text': ' So what we have done thus far is explicitly programmed to classify order, right?',\n",
       "   'tokens': [51113,\n",
       "    1406,\n",
       "    644,\n",
       "    356,\n",
       "    423,\n",
       "    1760,\n",
       "    4145,\n",
       "    1290,\n",
       "    318,\n",
       "    11777,\n",
       "    27402,\n",
       "    284,\n",
       "    36509,\n",
       "    1502,\n",
       "    11,\n",
       "    826,\n",
       "    30,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22866994943191757,\n",
       "   'compression_ratio': 1.5105263157894737,\n",
       "   'no_speech_prob': 0.06310149282217026},\n",
       "  {'id': 97,\n",
       "   'seek': 43172,\n",
       "   'start': 431.72,\n",
       "   'end': 437.72,\n",
       "   'text': ' So now we understand what is explicit programming, what we know is completely different from this.',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    783,\n",
       "    356,\n",
       "    1833,\n",
       "    644,\n",
       "    318,\n",
       "    7952,\n",
       "    8300,\n",
       "    11,\n",
       "    644,\n",
       "    356,\n",
       "    760,\n",
       "    318,\n",
       "    3190,\n",
       "    1180,\n",
       "    422,\n",
       "    428,\n",
       "    13,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31688694520430133,\n",
       "   'compression_ratio': 1.6545454545454545,\n",
       "   'no_speech_prob': 0.11594157665967941},\n",
       "  {'id': 98,\n",
       "   'seek': 43172,\n",
       "   'start': 437.72,\n",
       "   'end': 441.72,\n",
       "   'text': ' So what if thus far does is we had data?',\n",
       "   'tokens': [50663,\n",
       "    1406,\n",
       "    644,\n",
       "    611,\n",
       "    4145,\n",
       "    1290,\n",
       "    857,\n",
       "    318,\n",
       "    356,\n",
       "    550,\n",
       "    1366,\n",
       "    30,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31688694520430133,\n",
       "   'compression_ratio': 1.6545454545454545,\n",
       "   'no_speech_prob': 0.11594157665967941},\n",
       "  {'id': 99,\n",
       "   'seek': 43172,\n",
       "   'start': 441.72,\n",
       "   'end': 446.72,\n",
       "   'text': ' Data was these examples that we already had.',\n",
       "   'tokens': [50863, 6060, 373, 777, 6096, 326, 356, 1541, 550, 13, 51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31688694520430133,\n",
       "   'compression_ratio': 1.6545454545454545,\n",
       "   'no_speech_prob': 0.11594157665967941},\n",
       "  {'id': 100,\n",
       "   'seek': 43172,\n",
       "   'start': 446.72,\n",
       "   'end': 448.72,\n",
       "   'text': ' We came up with some rules.',\n",
       "   'tokens': [51113, 775, 1625, 510, 351, 617, 3173, 13, 51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31688694520430133,\n",
       "   'compression_ratio': 1.6545454545454545,\n",
       "   'no_speech_prob': 0.11594157665967941},\n",
       "  {'id': 101,\n",
       "   'seek': 43172,\n",
       "   'start': 448.72,\n",
       "   'end': 453.72,\n",
       "   'text': ' So these were rules which we as experts suggested.',\n",
       "   'tokens': [51213,\n",
       "    1406,\n",
       "    777,\n",
       "    547,\n",
       "    3173,\n",
       "    543,\n",
       "    356,\n",
       "    355,\n",
       "    6154,\n",
       "    5220,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31688694520430133,\n",
       "   'compression_ratio': 1.6545454545454545,\n",
       "   'no_speech_prob': 0.11594157665967941},\n",
       "  {'id': 102,\n",
       "   'seek': 43172,\n",
       "   'start': 453.72,\n",
       "   'end': 458.72,\n",
       "   'text': ' And in traditional programming we have some kind of a pattern, some programming line would be right,',\n",
       "   'tokens': [51463,\n",
       "    843,\n",
       "    287,\n",
       "    4569,\n",
       "    8300,\n",
       "    356,\n",
       "    423,\n",
       "    617,\n",
       "    1611,\n",
       "    286,\n",
       "    257,\n",
       "    3912,\n",
       "    11,\n",
       "    617,\n",
       "    8300,\n",
       "    1627,\n",
       "    561,\n",
       "    307,\n",
       "    826,\n",
       "    11,\n",
       "    51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31688694520430133,\n",
       "   'compression_ratio': 1.6545454545454545,\n",
       "   'no_speech_prob': 0.11594157665967941},\n",
       "  {'id': 103,\n",
       "   'seek': 45872,\n",
       "   'start': 458.72,\n",
       "   'end': 461.72,\n",
       "   'text': ' which would recognize all of these.',\n",
       "   'tokens': [50363, 543, 561, 7564, 477, 286, 777, 13, 50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2953795566353747,\n",
       "   'compression_ratio': 1.6650485436893203,\n",
       "   'no_speech_prob': 0.13822758197784424},\n",
       "  {'id': 104,\n",
       "   'seek': 45872,\n",
       "   'start': 461.72,\n",
       "   'end': 465.72,\n",
       "   'text': ' Of course, what is presented as a vertical line or horizontal line?',\n",
       "   'tokens': [50513,\n",
       "    3226,\n",
       "    1781,\n",
       "    11,\n",
       "    644,\n",
       "    318,\n",
       "    5545,\n",
       "    355,\n",
       "    257,\n",
       "    11723,\n",
       "    1627,\n",
       "    393,\n",
       "    16021,\n",
       "    1627,\n",
       "    30,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2953795566353747,\n",
       "   'compression_ratio': 1.6650485436893203,\n",
       "   'no_speech_prob': 0.13822758197784424},\n",
       "  {'id': 105,\n",
       "   'seek': 45872,\n",
       "   'start': 465.72,\n",
       "   'end': 468.72,\n",
       "   'text': ' Are still higher constructs?',\n",
       "   'tokens': [50713, 4231, 991, 2440, 34175, 30, 50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2953795566353747,\n",
       "   'compression_ratio': 1.6650485436893203,\n",
       "   'no_speech_prob': 0.13822758197784424},\n",
       "  {'id': 106,\n",
       "   'seek': 45872,\n",
       "   'start': 468.72,\n",
       "   'end': 473.72,\n",
       "   'text': ' For example, vertical line a program computer does not know what is a vertical line.',\n",
       "   'tokens': [50863,\n",
       "    1114,\n",
       "    1672,\n",
       "    11,\n",
       "    11723,\n",
       "    1627,\n",
       "    257,\n",
       "    1430,\n",
       "    3644,\n",
       "    857,\n",
       "    407,\n",
       "    760,\n",
       "    644,\n",
       "    318,\n",
       "    257,\n",
       "    11723,\n",
       "    1627,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2953795566353747,\n",
       "   'compression_ratio': 1.6650485436893203,\n",
       "   'no_speech_prob': 0.13822758197784424},\n",
       "  {'id': 107,\n",
       "   'seek': 45872,\n",
       "   'start': 473.72,\n",
       "   'end': 476.72,\n",
       "   'text': ' So you have to again boil it down to the computer.',\n",
       "   'tokens': [51113,\n",
       "    1406,\n",
       "    345,\n",
       "    423,\n",
       "    284,\n",
       "    757,\n",
       "    20667,\n",
       "    340,\n",
       "    866,\n",
       "    284,\n",
       "    262,\n",
       "    3644,\n",
       "    13,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2953795566353747,\n",
       "   'compression_ratio': 1.6650485436893203,\n",
       "   'no_speech_prob': 0.13822758197784424},\n",
       "  {'id': 108,\n",
       "   'seek': 45872,\n",
       "   'start': 476.72,\n",
       "   'end': 480.72,\n",
       "   'text': ' What do you think the vertical line to the middle means?',\n",
       "   'tokens': [51263,\n",
       "    1867,\n",
       "    466,\n",
       "    345,\n",
       "    892,\n",
       "    262,\n",
       "    11723,\n",
       "    1627,\n",
       "    284,\n",
       "    262,\n",
       "    3504,\n",
       "    1724,\n",
       "    30,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2953795566353747,\n",
       "   'compression_ratio': 1.6650485436893203,\n",
       "   'no_speech_prob': 0.13822758197784424},\n",
       "  {'id': 109,\n",
       "   'seek': 45872,\n",
       "   'start': 480.72,\n",
       "   'end': 482.72,\n",
       "   'text': ' Same.',\n",
       "   'tokens': [51463, 16766, 13, 51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2953795566353747,\n",
       "   'compression_ratio': 1.6650485436893203,\n",
       "   'no_speech_prob': 0.13822758197784424},\n",
       "  {'id': 110,\n",
       "   'seek': 45872,\n",
       "   'start': 482.72,\n",
       "   'end': 483.72,\n",
       "   'text': ' Same.',\n",
       "   'tokens': [51563, 16766, 13, 51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2953795566353747,\n",
       "   'compression_ratio': 1.6650485436893203,\n",
       "   'no_speech_prob': 0.13822758197784424},\n",
       "  {'id': 111,\n",
       "   'seek': 45872,\n",
       "   'start': 483.72,\n",
       "   'end': 484.72,\n",
       "   'text': ' Same.',\n",
       "   'tokens': [51613, 16766, 13, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2953795566353747,\n",
       "   'compression_ratio': 1.6650485436893203,\n",
       "   'no_speech_prob': 0.13822758197784424},\n",
       "  {'id': 112,\n",
       "   'seek': 48472,\n",
       "   'start': 484.72,\n",
       "   'end': 485.72,\n",
       "   'text': ' Same.',\n",
       "   'tokens': [50363, 16766, 13, 50413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3417295787645423,\n",
       "   'compression_ratio': 1.5619469026548674,\n",
       "   'no_speech_prob': 0.16865146160125732},\n",
       "  {'id': 113,\n",
       "   'seek': 48472,\n",
       "   'start': 485.72,\n",
       "   'end': 486.72,\n",
       "   'text': ' Ex-axis.',\n",
       "   'tokens': [50413, 1475, 12, 22704, 13, 50463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3417295787645423,\n",
       "   'compression_ratio': 1.5619469026548674,\n",
       "   'no_speech_prob': 0.16865146160125732},\n",
       "  {'id': 114,\n",
       "   'seek': 48472,\n",
       "   'start': 486.72,\n",
       "   'end': 496.72,\n",
       "   'text': ' So think of it as pixels and all of the pixels would be of similar shape, like vertically going on.',\n",
       "   'tokens': [50463,\n",
       "    1406,\n",
       "    892,\n",
       "    286,\n",
       "    340,\n",
       "    355,\n",
       "    17848,\n",
       "    290,\n",
       "    477,\n",
       "    286,\n",
       "    262,\n",
       "    17848,\n",
       "    561,\n",
       "    307,\n",
       "    286,\n",
       "    2092,\n",
       "    5485,\n",
       "    11,\n",
       "    588,\n",
       "    31677,\n",
       "    1016,\n",
       "    319,\n",
       "    13,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3417295787645423,\n",
       "   'compression_ratio': 1.5619469026548674,\n",
       "   'no_speech_prob': 0.16865146160125732},\n",
       "  {'id': 115,\n",
       "   'seek': 48472,\n",
       "   'start': 496.72,\n",
       "   'end': 501.72,\n",
       "   'text': ' So we have data rules and traditional programming that gives us the answers.',\n",
       "   'tokens': [50963,\n",
       "    1406,\n",
       "    356,\n",
       "    423,\n",
       "    1366,\n",
       "    3173,\n",
       "    290,\n",
       "    4569,\n",
       "    8300,\n",
       "    326,\n",
       "    3607,\n",
       "    514,\n",
       "    262,\n",
       "    7429,\n",
       "    13,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3417295787645423,\n",
       "   'compression_ratio': 1.5619469026548674,\n",
       "   'no_speech_prob': 0.16865146160125732},\n",
       "  {'id': 116,\n",
       "   'seek': 48472,\n",
       "   'start': 501.72,\n",
       "   'end': 504.72,\n",
       "   'text': \" Now let's go back to the definition.\",\n",
       "   'tokens': [51213, 2735, 1309, 338, 467, 736, 284, 262, 6770, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3417295787645423,\n",
       "   'compression_ratio': 1.5619469026548674,\n",
       "   'no_speech_prob': 0.16865146160125732},\n",
       "  {'id': 117,\n",
       "   'seek': 48472,\n",
       "   'start': 504.72,\n",
       "   'end': 507.72,\n",
       "   'text': ' The genome is a period of study as computers.',\n",
       "   'tokens': [51363,\n",
       "    383,\n",
       "    19270,\n",
       "    318,\n",
       "    257,\n",
       "    2278,\n",
       "    286,\n",
       "    2050,\n",
       "    355,\n",
       "    9061,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3417295787645423,\n",
       "   'compression_ratio': 1.5619469026548674,\n",
       "   'no_speech_prob': 0.16865146160125732},\n",
       "  {'id': 118,\n",
       "   'seek': 48472,\n",
       "   'start': 507.72,\n",
       "   'end': 512.72,\n",
       "   'text': ' We have computers a little bit to learn without being explicit in the program.',\n",
       "   'tokens': [51513,\n",
       "    775,\n",
       "    423,\n",
       "    9061,\n",
       "    257,\n",
       "    1310,\n",
       "    1643,\n",
       "    284,\n",
       "    2193,\n",
       "    1231,\n",
       "    852,\n",
       "    7952,\n",
       "    287,\n",
       "    262,\n",
       "    1430,\n",
       "    13,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3417295787645423,\n",
       "   'compression_ratio': 1.5619469026548674,\n",
       "   'no_speech_prob': 0.16865146160125732},\n",
       "  {'id': 119,\n",
       "   'seek': 51272,\n",
       "   'start': 512.72,\n",
       "   'end': 518.72,\n",
       "   'text': ' And now to make this particular program, to tell me what, if you have to be able to',\n",
       "   'tokens': [50363,\n",
       "    843,\n",
       "    783,\n",
       "    284,\n",
       "    787,\n",
       "    428,\n",
       "    1948,\n",
       "    1430,\n",
       "    11,\n",
       "    284,\n",
       "    1560,\n",
       "    502,\n",
       "    644,\n",
       "    11,\n",
       "    611,\n",
       "    345,\n",
       "    423,\n",
       "    284,\n",
       "    307,\n",
       "    1498,\n",
       "    284,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5643555777413505,\n",
       "   'compression_ratio': 1.5902439024390245,\n",
       "   'no_speech_prob': 0.20182478427886963},\n",
       "  {'id': 120,\n",
       "   'seek': 51272,\n",
       "   'start': 518.72,\n",
       "   'end': 523.72,\n",
       "   'text': ' use traditional programming with machine learning, what do we need to do?',\n",
       "   'tokens': [50663,\n",
       "    779,\n",
       "    4569,\n",
       "    8300,\n",
       "    351,\n",
       "    4572,\n",
       "    4673,\n",
       "    11,\n",
       "    644,\n",
       "    466,\n",
       "    356,\n",
       "    761,\n",
       "    284,\n",
       "    466,\n",
       "    30,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5643555777413505,\n",
       "   'compression_ratio': 1.5902439024390245,\n",
       "   'no_speech_prob': 0.20182478427886963},\n",
       "  {'id': 121,\n",
       "   'seek': 51272,\n",
       "   'start': 523.72,\n",
       "   'end': 525.72,\n",
       "   'text': ' So we are not explicitly programming.',\n",
       "   'tokens': [50913, 1406, 356, 389, 407, 11777, 8300, 13, 51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5643555777413505,\n",
       "   'compression_ratio': 1.5902439024390245,\n",
       "   'no_speech_prob': 0.20182478427886963},\n",
       "  {'id': 122,\n",
       "   'seek': 51272,\n",
       "   'start': 525.72,\n",
       "   'end': 526.72,\n",
       "   'text': ' What changes?',\n",
       "   'tokens': [51013, 1867, 2458, 30, 51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5643555777413505,\n",
       "   'compression_ratio': 1.5902439024390245,\n",
       "   'no_speech_prob': 0.20182478427886963},\n",
       "  {'id': 123,\n",
       "   'seek': 51272,\n",
       "   'start': 526.72,\n",
       "   'end': 531.72,\n",
       "   'text': ' The Romans are gone there.',\n",
       "   'tokens': [51063, 383, 22482, 389, 3750, 612, 13, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5643555777413505,\n",
       "   'compression_ratio': 1.5902439024390245,\n",
       "   'no_speech_prob': 0.20182478427886963},\n",
       "  {'id': 124,\n",
       "   'seek': 51272,\n",
       "   'start': 531.72,\n",
       "   'end': 540.72,\n",
       "   'text': ' So what we are saying is, I am going to learn with the only explicitly- describe program.',\n",
       "   'tokens': [51313,\n",
       "    1406,\n",
       "    644,\n",
       "    356,\n",
       "    389,\n",
       "    2282,\n",
       "    318,\n",
       "    11,\n",
       "    314,\n",
       "    716,\n",
       "    1016,\n",
       "    284,\n",
       "    2193,\n",
       "    351,\n",
       "    262,\n",
       "    691,\n",
       "    11777,\n",
       "    12,\n",
       "    6901,\n",
       "    1430,\n",
       "    13,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5643555777413505,\n",
       "   'compression_ratio': 1.5902439024390245,\n",
       "   'no_speech_prob': 0.20182478427886963},\n",
       "  {'id': 125,\n",
       "   'seek': 54072,\n",
       "   'start': 540.72,\n",
       "   'end': 542.72,\n",
       "   'text': \" So we don't need the data.\",\n",
       "   'tokens': [50363, 1406, 356, 836, 470, 761, 262, 1366, 13, 50463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.34100779483192845,\n",
       "   'compression_ratio': 1.605263157894737,\n",
       "   'no_speech_prob': 0.1047397032380104},\n",
       "  {'id': 126,\n",
       "   'seek': 54072,\n",
       "   'start': 542.72,\n",
       "   'end': 544.72,\n",
       "   'text': \" We don't need the answers.\",\n",
       "   'tokens': [50463, 775, 836, 470, 761, 262, 7429, 13, 50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.34100779483192845,\n",
       "   'compression_ratio': 1.605263157894737,\n",
       "   'no_speech_prob': 0.1047397032380104},\n",
       "  {'id': 127,\n",
       "   'seek': 54072,\n",
       "   'start': 544.72,\n",
       "   'end': 551.72,\n",
       "   'text': ' And what we end up with is automatically some function of rules that are being run.',\n",
       "   'tokens': [50563,\n",
       "    843,\n",
       "    644,\n",
       "    356,\n",
       "    886,\n",
       "    510,\n",
       "    351,\n",
       "    318,\n",
       "    6338,\n",
       "    617,\n",
       "    2163,\n",
       "    286,\n",
       "    3173,\n",
       "    326,\n",
       "    389,\n",
       "    852,\n",
       "    1057,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.34100779483192845,\n",
       "   'compression_ratio': 1.605263157894737,\n",
       "   'no_speech_prob': 0.1047397032380104},\n",
       "  {'id': 128,\n",
       "   'seek': 54072,\n",
       "   'start': 551.72,\n",
       "   'end': 554.72,\n",
       "   'text': ' So this is how traditional programming is.',\n",
       "   'tokens': [50913, 1406, 428, 318, 703, 4569, 8300, 318, 13, 51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.34100779483192845,\n",
       "   'compression_ratio': 1.605263157894737,\n",
       "   'no_speech_prob': 0.1047397032380104},\n",
       "  {'id': 129,\n",
       "   'seek': 54072,\n",
       "   'start': 554.72,\n",
       "   'end': 557.72,\n",
       "   'text': ' The bad line of the system program is very different from machine learning.',\n",
       "   'tokens': [51063,\n",
       "    383,\n",
       "    2089,\n",
       "    1627,\n",
       "    286,\n",
       "    262,\n",
       "    1080,\n",
       "    1430,\n",
       "    318,\n",
       "    845,\n",
       "    1180,\n",
       "    422,\n",
       "    4572,\n",
       "    4673,\n",
       "    13,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.34100779483192845,\n",
       "   'compression_ratio': 1.605263157894737,\n",
       "   'no_speech_prob': 0.1047397032380104},\n",
       "  {'id': 130,\n",
       "   'seek': 54072,\n",
       "   'start': 557.72,\n",
       "   'end': 561.72,\n",
       "   'text': ' Which I have still done this, done this in a very abstract sense.',\n",
       "   'tokens': [51213,\n",
       "    9022,\n",
       "    314,\n",
       "    423,\n",
       "    991,\n",
       "    1760,\n",
       "    428,\n",
       "    11,\n",
       "    1760,\n",
       "    428,\n",
       "    287,\n",
       "    257,\n",
       "    845,\n",
       "    12531,\n",
       "    2565,\n",
       "    13,\n",
       "    51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.34100779483192845,\n",
       "   'compression_ratio': 1.605263157894737,\n",
       "   'no_speech_prob': 0.1047397032380104},\n",
       "  {'id': 131,\n",
       "   'seek': 54072,\n",
       "   'start': 561.72,\n",
       "   'end': 564.72,\n",
       "   'text': ' We are slowly going to go deeper from this.',\n",
       "   'tokens': [51413,\n",
       "    775,\n",
       "    389,\n",
       "    6364,\n",
       "    1016,\n",
       "    284,\n",
       "    467,\n",
       "    9211,\n",
       "    422,\n",
       "    428,\n",
       "    13,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.34100779483192845,\n",
       "   'compression_ratio': 1.605263157894737,\n",
       "   'no_speech_prob': 0.1047397032380104},\n",
       "  {'id': 132,\n",
       "   'seek': 56472,\n",
       "   'start': 564.72,\n",
       "   'end': 570.72,\n",
       "   'text': ' We also looked at another definition which was a more formal definition of machine learning,',\n",
       "   'tokens': [50363,\n",
       "    775,\n",
       "    635,\n",
       "    3114,\n",
       "    379,\n",
       "    1194,\n",
       "    6770,\n",
       "    543,\n",
       "    373,\n",
       "    257,\n",
       "    517,\n",
       "    8766,\n",
       "    6770,\n",
       "    286,\n",
       "    4572,\n",
       "    4673,\n",
       "    11,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.356550782591432,\n",
       "   'compression_ratio': 1.8465346534653466,\n",
       "   'no_speech_prob': 0.4163791239261627},\n",
       "  {'id': 133,\n",
       "   'seek': 56472,\n",
       "   'start': 570.72,\n",
       "   'end': 573.72,\n",
       "   'text': ' which was given by Tom, which I like.',\n",
       "   'tokens': [50663, 543, 373, 1813, 416, 4186, 11, 543, 314, 588, 13, 50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.356550782591432,\n",
       "   'compression_ratio': 1.8465346534653466,\n",
       "   'no_speech_prob': 0.4163791239261627},\n",
       "  {'id': 134,\n",
       "   'seek': 56472,\n",
       "   'start': 573.72,\n",
       "   'end': 576.72,\n",
       "   'text': ' Tom is learning from experience E.',\n",
       "   'tokens': [50813, 4186, 318, 4673, 422, 1998, 412, 13, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.356550782591432,\n",
       "   'compression_ratio': 1.8465346534653466,\n",
       "   'no_speech_prob': 0.4163791239261627},\n",
       "  {'id': 135,\n",
       "   'seek': 56472,\n",
       "   'start': 576.72,\n",
       "   'end': 583.72,\n",
       "   'text': ' If you look at the experience E, tasks, P, and a performance measure, P,',\n",
       "   'tokens': [50963,\n",
       "    1002,\n",
       "    345,\n",
       "    804,\n",
       "    379,\n",
       "    262,\n",
       "    1998,\n",
       "    412,\n",
       "    11,\n",
       "    8861,\n",
       "    11,\n",
       "    350,\n",
       "    11,\n",
       "    290,\n",
       "    257,\n",
       "    2854,\n",
       "    3953,\n",
       "    11,\n",
       "    350,\n",
       "    11,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.356550782591432,\n",
       "   'compression_ratio': 1.8465346534653466,\n",
       "   'no_speech_prob': 0.4163791239261627},\n",
       "  {'id': 136,\n",
       "   'seek': 56472,\n",
       "   'start': 583.72,\n",
       "   'end': 590.72,\n",
       "   'text': ' if the performance is improving in the particular task, as to measure by the performance measure.',\n",
       "   'tokens': [51313,\n",
       "    611,\n",
       "    262,\n",
       "    2854,\n",
       "    318,\n",
       "    10068,\n",
       "    287,\n",
       "    262,\n",
       "    1948,\n",
       "    4876,\n",
       "    11,\n",
       "    355,\n",
       "    284,\n",
       "    3953,\n",
       "    416,\n",
       "    262,\n",
       "    2854,\n",
       "    3953,\n",
       "    13,\n",
       "    51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.356550782591432,\n",
       "   'compression_ratio': 1.8465346534653466,\n",
       "   'no_speech_prob': 0.4163791239261627},\n",
       "  {'id': 137,\n",
       "   'seek': 56472,\n",
       "   'start': 590.72,\n",
       "   'end': 593.72,\n",
       "   'text': ' And it is improving with experience.',\n",
       "   'tokens': [51663, 843, 340, 318, 10068, 351, 1998, 13, 51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.356550782591432,\n",
       "   'compression_ratio': 1.8465346534653466,\n",
       "   'no_speech_prob': 0.4163791239261627},\n",
       "  {'id': 138,\n",
       "   'seek': 59372,\n",
       "   'start': 594.72,\n",
       "   'end': 598.72,\n",
       "   'text': \" Let's say in this particular case, the task is what?\",\n",
       "   'tokens': [50413,\n",
       "    3914,\n",
       "    338,\n",
       "    910,\n",
       "    287,\n",
       "    428,\n",
       "    1948,\n",
       "    1339,\n",
       "    11,\n",
       "    262,\n",
       "    4876,\n",
       "    318,\n",
       "    644,\n",
       "    30,\n",
       "    50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17453937530517577,\n",
       "   'compression_ratio': 1.6618357487922706,\n",
       "   'no_speech_prob': 0.032581742852926254},\n",
       "  {'id': 139,\n",
       "   'seek': 59372,\n",
       "   'start': 598.72,\n",
       "   'end': 600.72,\n",
       "   'text': ' For machine learning.',\n",
       "   'tokens': [50613, 1114, 4572, 4673, 13, 50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17453937530517577,\n",
       "   'compression_ratio': 1.6618357487922706,\n",
       "   'no_speech_prob': 0.032581742852926254},\n",
       "  {'id': 140,\n",
       "   'seek': 59372,\n",
       "   'start': 600.72,\n",
       "   'end': 602.72,\n",
       "   'text': ' To classify digits.',\n",
       "   'tokens': [50713, 1675, 36509, 19561, 13, 50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17453937530517577,\n",
       "   'compression_ratio': 1.6618357487922706,\n",
       "   'no_speech_prob': 0.032581742852926254},\n",
       "  {'id': 141,\n",
       "   'seek': 59372,\n",
       "   'start': 602.72,\n",
       "   'end': 605.72,\n",
       "   'text': ' And what is the input that is typically given?',\n",
       "   'tokens': [50813,\n",
       "    843,\n",
       "    644,\n",
       "    318,\n",
       "    262,\n",
       "    5128,\n",
       "    326,\n",
       "    318,\n",
       "    6032,\n",
       "    1813,\n",
       "    30,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17453937530517577,\n",
       "   'compression_ratio': 1.6618357487922706,\n",
       "   'no_speech_prob': 0.032581742852926254},\n",
       "  {'id': 142,\n",
       "   'seek': 59372,\n",
       "   'start': 605.72,\n",
       "   'end': 610.72,\n",
       "   'text': ' You have some, so you said that you have some experience.',\n",
       "   'tokens': [50963,\n",
       "    921,\n",
       "    423,\n",
       "    617,\n",
       "    11,\n",
       "    523,\n",
       "    345,\n",
       "    531,\n",
       "    326,\n",
       "    345,\n",
       "    423,\n",
       "    617,\n",
       "    1998,\n",
       "    13,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17453937530517577,\n",
       "   'compression_ratio': 1.6618357487922706,\n",
       "   'no_speech_prob': 0.032581742852926254},\n",
       "  {'id': 143,\n",
       "   'seek': 59372,\n",
       "   'start': 610.72,\n",
       "   'end': 616.72,\n",
       "   'text': ' The experience can be you have some images along with the true label.',\n",
       "   'tokens': [51213,\n",
       "    383,\n",
       "    1998,\n",
       "    460,\n",
       "    307,\n",
       "    345,\n",
       "    423,\n",
       "    617,\n",
       "    4263,\n",
       "    1863,\n",
       "    351,\n",
       "    262,\n",
       "    2081,\n",
       "    6167,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17453937530517577,\n",
       "   'compression_ratio': 1.6618357487922706,\n",
       "   'no_speech_prob': 0.032581742852926254},\n",
       "  {'id': 144,\n",
       "   'seek': 59372,\n",
       "   'start': 616.72,\n",
       "   'end': 622.72,\n",
       "   'text': ' So you have elements like this 0 along with that label that is actually 0.',\n",
       "   'tokens': [51513,\n",
       "    1406,\n",
       "    345,\n",
       "    423,\n",
       "    4847,\n",
       "    588,\n",
       "    428,\n",
       "    657,\n",
       "    1863,\n",
       "    351,\n",
       "    326,\n",
       "    6167,\n",
       "    326,\n",
       "    318,\n",
       "    1682,\n",
       "    657,\n",
       "    13,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17453937530517577,\n",
       "   'compression_ratio': 1.6618357487922706,\n",
       "   'no_speech_prob': 0.032581742852926254},\n",
       "  {'id': 145,\n",
       "   'seek': 62272,\n",
       "   'start': 622.72,\n",
       "   'end': 626.72,\n",
       "   'text': ' But you have various different examples.',\n",
       "   'tokens': [50363, 887, 345, 423, 2972, 1180, 6096, 13, 50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5125926696148115,\n",
       "   'compression_ratio': 1.59009009009009,\n",
       "   'no_speech_prob': 0.06987209618091583},\n",
       "  {'id': 146,\n",
       "   'seek': 62272,\n",
       "   'start': 626.72,\n",
       "   'end': 631.72,\n",
       "   'text': ' And the performance measure P, what do you think is the performance measure P?',\n",
       "   'tokens': [50563,\n",
       "    843,\n",
       "    262,\n",
       "    2854,\n",
       "    3953,\n",
       "    350,\n",
       "    11,\n",
       "    644,\n",
       "    466,\n",
       "    345,\n",
       "    892,\n",
       "    318,\n",
       "    262,\n",
       "    2854,\n",
       "    3953,\n",
       "    350,\n",
       "    30,\n",
       "    50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5125926696148115,\n",
       "   'compression_ratio': 1.59009009009009,\n",
       "   'no_speech_prob': 0.06987209618091583},\n",
       "  {'id': 147,\n",
       "   'seek': 62272,\n",
       "   'start': 631.72,\n",
       "   'end': 634.72,\n",
       "   'text': ' What do you want to optimize on?',\n",
       "   'tokens': [50813, 1867, 466, 345, 765, 284, 27183, 319, 30, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5125926696148115,\n",
       "   'compression_ratio': 1.59009009009009,\n",
       "   'no_speech_prob': 0.06987209618091583},\n",
       "  {'id': 148,\n",
       "   'seek': 62272,\n",
       "   'start': 634.72,\n",
       "   'end': 637.72,\n",
       "   'text': ' How correctly you are given to classify digits?',\n",
       "   'tokens': [50963, 1374, 9380, 345, 389, 1813, 284, 36509, 19561, 30, 51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5125926696148115,\n",
       "   'compression_ratio': 1.59009009009009,\n",
       "   'no_speech_prob': 0.06987209618091583},\n",
       "  {'id': 149,\n",
       "   'seek': 62272,\n",
       "   'start': 637.72,\n",
       "   'end': 643.72,\n",
       "   'text': ' So, could you come up with a more scientific sub-centum for correctness?',\n",
       "   'tokens': [51113,\n",
       "    1406,\n",
       "    11,\n",
       "    714,\n",
       "    345,\n",
       "    1282,\n",
       "    510,\n",
       "    351,\n",
       "    257,\n",
       "    517,\n",
       "    5654,\n",
       "    850,\n",
       "    12,\n",
       "    1087,\n",
       "    388,\n",
       "    329,\n",
       "    29409,\n",
       "    30,\n",
       "    51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5125926696148115,\n",
       "   'compression_ratio': 1.59009009009009,\n",
       "   'no_speech_prob': 0.06987209618091583},\n",
       "  {'id': 150,\n",
       "   'seek': 62272,\n",
       "   'start': 643.72,\n",
       "   'end': 644.72,\n",
       "   'text': ' I can see.',\n",
       "   'tokens': [51413, 314, 460, 766, 13, 51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5125926696148115,\n",
       "   'compression_ratio': 1.59009009009009,\n",
       "   'no_speech_prob': 0.06987209618091583},\n",
       "  {'id': 151,\n",
       "   'seek': 62272,\n",
       "   'start': 644.72,\n",
       "   'end': 645.72,\n",
       "   'text': ' Or similar sub-centum.',\n",
       "   'tokens': [51463, 1471, 2092, 850, 12, 1087, 388, 13, 51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5125926696148115,\n",
       "   'compression_ratio': 1.59009009009009,\n",
       "   'no_speech_prob': 0.06987209618091583},\n",
       "  {'id': 152,\n",
       "   'seek': 62272,\n",
       "   'start': 645.72,\n",
       "   'end': 649.72,\n",
       "   'text': ' So we look at some of these metrics in today.',\n",
       "   'tokens': [51513,\n",
       "    1406,\n",
       "    356,\n",
       "    804,\n",
       "    379,\n",
       "    617,\n",
       "    286,\n",
       "    777,\n",
       "    20731,\n",
       "    287,\n",
       "    1909,\n",
       "    13,\n",
       "    51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5125926696148115,\n",
       "   'compression_ratio': 1.59009009009009,\n",
       "   'no_speech_prob': 0.06987209618091583},\n",
       "  {'id': 153,\n",
       "   'seek': 64972,\n",
       "   'start': 649.72,\n",
       "   'end': 654.72,\n",
       "   'text': ' So we will start of place lecture after having revised what is machine learning.',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    356,\n",
       "    481,\n",
       "    923,\n",
       "    286,\n",
       "    1295,\n",
       "    19143,\n",
       "    706,\n",
       "    1719,\n",
       "    15556,\n",
       "    644,\n",
       "    318,\n",
       "    4572,\n",
       "    4673,\n",
       "    13,\n",
       "    50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31931531112805933,\n",
       "   'compression_ratio': 1.736842105263158,\n",
       "   'no_speech_prob': 0.029964325949549675},\n",
       "  {'id': 154,\n",
       "   'seek': 64972,\n",
       "   'start': 654.72,\n",
       "   'end': 658.72,\n",
       "   'text': ' We will start, we are now starting a company, all of us are starting a company.',\n",
       "   'tokens': [50613,\n",
       "    775,\n",
       "    481,\n",
       "    923,\n",
       "    11,\n",
       "    356,\n",
       "    389,\n",
       "    783,\n",
       "    3599,\n",
       "    257,\n",
       "    1664,\n",
       "    11,\n",
       "    477,\n",
       "    286,\n",
       "    514,\n",
       "    389,\n",
       "    3599,\n",
       "    257,\n",
       "    1664,\n",
       "    13,\n",
       "    50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31931531112805933,\n",
       "   'compression_ratio': 1.736842105263158,\n",
       "   'no_speech_prob': 0.029964325949549675},\n",
       "  {'id': 155,\n",
       "   'seek': 64972,\n",
       "   'start': 658.72,\n",
       "   'end': 664.72,\n",
       "   'text': ' And we want to be the basket of those words or some similar words we saw.',\n",
       "   'tokens': [50813,\n",
       "    843,\n",
       "    356,\n",
       "    765,\n",
       "    284,\n",
       "    307,\n",
       "    262,\n",
       "    7988,\n",
       "    286,\n",
       "    883,\n",
       "    2456,\n",
       "    393,\n",
       "    617,\n",
       "    2092,\n",
       "    2456,\n",
       "    356,\n",
       "    2497,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31931531112805933,\n",
       "   'compression_ratio': 1.736842105263158,\n",
       "   'no_speech_prob': 0.029964325949549675},\n",
       "  {'id': 156,\n",
       "   'seek': 64972,\n",
       "   'start': 664.72,\n",
       "   'end': 665.72,\n",
       "   'text': ' We want to scale.',\n",
       "   'tokens': [51113, 775, 765, 284, 5046, 13, 51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31931531112805933,\n",
       "   'compression_ratio': 1.736842105263158,\n",
       "   'no_speech_prob': 0.029964325949549675},\n",
       "  {'id': 157,\n",
       "   'seek': 64972,\n",
       "   'start': 665.72,\n",
       "   'end': 670.72,\n",
       "   'text': ' So if you remember one of the keywords which we use a lot in the previous lecture was scaled.',\n",
       "   'tokens': [51163,\n",
       "    1406,\n",
       "    611,\n",
       "    345,\n",
       "    3505,\n",
       "    530,\n",
       "    286,\n",
       "    262,\n",
       "    26286,\n",
       "    543,\n",
       "    356,\n",
       "    779,\n",
       "    257,\n",
       "    1256,\n",
       "    287,\n",
       "    262,\n",
       "    2180,\n",
       "    19143,\n",
       "    373,\n",
       "    27464,\n",
       "    13,\n",
       "    51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31931531112805933,\n",
       "   'compression_ratio': 1.736842105263158,\n",
       "   'no_speech_prob': 0.029964325949549675},\n",
       "  {'id': 158,\n",
       "   'seek': 64972,\n",
       "   'start': 670.72,\n",
       "   'end': 675.72,\n",
       "   'text': ' The problem statement is that you want to predict the quality or condition for computer.',\n",
       "   'tokens': [51413,\n",
       "    383,\n",
       "    1917,\n",
       "    2643,\n",
       "    318,\n",
       "    326,\n",
       "    345,\n",
       "    765,\n",
       "    284,\n",
       "    4331,\n",
       "    262,\n",
       "    3081,\n",
       "    393,\n",
       "    4006,\n",
       "    329,\n",
       "    3644,\n",
       "    13,\n",
       "    51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31931531112805933,\n",
       "   'compression_ratio': 1.736842105263158,\n",
       "   'no_speech_prob': 0.029964325949549675},\n",
       "  {'id': 159,\n",
       "   'seek': 64972,\n",
       "   'start': 675.72,\n",
       "   'end': 677.72,\n",
       "   'text': ' Given its visual features.',\n",
       "   'tokens': [51663, 11259, 663, 5874, 3033, 13, 51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31931531112805933,\n",
       "   'compression_ratio': 1.736842105263158,\n",
       "   'no_speech_prob': 0.029964325949549675},\n",
       "  {'id': 160,\n",
       "   'seek': 67772,\n",
       "   'start': 678.72,\n",
       "   'end': 685.72,\n",
       "   'text': ' So we say that our business use cases that growth rates are similar such grocery stores,',\n",
       "   'tokens': [50413,\n",
       "    1406,\n",
       "    356,\n",
       "    910,\n",
       "    326,\n",
       "    674,\n",
       "    1597,\n",
       "    779,\n",
       "    2663,\n",
       "    326,\n",
       "    3349,\n",
       "    3965,\n",
       "    389,\n",
       "    2092,\n",
       "    884,\n",
       "    16918,\n",
       "    7000,\n",
       "    11,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32327586279975046,\n",
       "   'compression_ratio': 1.6157205240174672,\n",
       "   'no_speech_prob': 0.10893561691045761},\n",
       "  {'id': 161,\n",
       "   'seek': 67772,\n",
       "   'start': 685.72,\n",
       "   'end': 689.72,\n",
       "   'text': ' they have some human in the loop who looks at each of the tomatoes.',\n",
       "   'tokens': [50763,\n",
       "    484,\n",
       "    423,\n",
       "    617,\n",
       "    1692,\n",
       "    287,\n",
       "    262,\n",
       "    9052,\n",
       "    508,\n",
       "    3073,\n",
       "    379,\n",
       "    1123,\n",
       "    286,\n",
       "    262,\n",
       "    23972,\n",
       "    13,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32327586279975046,\n",
       "   'compression_ratio': 1.6157205240174672,\n",
       "   'no_speech_prob': 0.10893561691045761},\n",
       "  {'id': 162,\n",
       "   'seek': 67772,\n",
       "   'start': 689.72,\n",
       "   'end': 693.72,\n",
       "   'text': \" And that is in let's say a per minute per tomato.\",\n",
       "   'tokens': [50963,\n",
       "    843,\n",
       "    326,\n",
       "    318,\n",
       "    287,\n",
       "    1309,\n",
       "    338,\n",
       "    910,\n",
       "    257,\n",
       "    583,\n",
       "    5664,\n",
       "    583,\n",
       "    24240,\n",
       "    13,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32327586279975046,\n",
       "   'compression_ratio': 1.6157205240174672,\n",
       "   'no_speech_prob': 0.10893561691045761},\n",
       "  {'id': 163,\n",
       "   'seek': 67772,\n",
       "   'start': 693.72,\n",
       "   'end': 699.72,\n",
       "   'text': ' So there is a lot of human input involved which is making the whole process look.',\n",
       "   'tokens': [51163,\n",
       "    1406,\n",
       "    612,\n",
       "    318,\n",
       "    257,\n",
       "    1256,\n",
       "    286,\n",
       "    1692,\n",
       "    5128,\n",
       "    2950,\n",
       "    543,\n",
       "    318,\n",
       "    1642,\n",
       "    262,\n",
       "    2187,\n",
       "    1429,\n",
       "    804,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32327586279975046,\n",
       "   'compression_ratio': 1.6157205240174672,\n",
       "   'no_speech_prob': 0.10893561691045761},\n",
       "  {'id': 164,\n",
       "   'seek': 67772,\n",
       "   'start': 699.72,\n",
       "   'end': 704.72,\n",
       "   'text': ' We plan to scale it by using computer vision with your features between the data.',\n",
       "   'tokens': [51463,\n",
       "    775,\n",
       "    1410,\n",
       "    284,\n",
       "    5046,\n",
       "    340,\n",
       "    416,\n",
       "    1262,\n",
       "    3644,\n",
       "    5761,\n",
       "    351,\n",
       "    534,\n",
       "    3033,\n",
       "    1022,\n",
       "    262,\n",
       "    1366,\n",
       "    13,\n",
       "    51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32327586279975046,\n",
       "   'compression_ratio': 1.6157205240174672,\n",
       "   'no_speech_prob': 0.10893561691045761},\n",
       "  {'id': 165,\n",
       "   'seek': 70472,\n",
       "   'start': 704.72,\n",
       "   'end': 707.72,\n",
       "   'text': ' So what we are going to do is we have now an assembly line.',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    644,\n",
       "    356,\n",
       "    389,\n",
       "    1016,\n",
       "    284,\n",
       "    466,\n",
       "    318,\n",
       "    356,\n",
       "    423,\n",
       "    783,\n",
       "    281,\n",
       "    10474,\n",
       "    1627,\n",
       "    13,\n",
       "    50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4413547946098156,\n",
       "   'compression_ratio': 2.072,\n",
       "   'no_speech_prob': 0.18143931031227112},\n",
       "  {'id': 166,\n",
       "   'seek': 70472,\n",
       "   'start': 707.72,\n",
       "   'end': 712.72,\n",
       "   'text': ' You put the tomatoes in the assembly line as the pass of snapshots are taken.',\n",
       "   'tokens': [50513,\n",
       "    921,\n",
       "    1234,\n",
       "    262,\n",
       "    23972,\n",
       "    287,\n",
       "    262,\n",
       "    10474,\n",
       "    1627,\n",
       "    355,\n",
       "    262,\n",
       "    1208,\n",
       "    286,\n",
       "    47787,\n",
       "    389,\n",
       "    2077,\n",
       "    13,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4413547946098156,\n",
       "   'compression_ratio': 2.072,\n",
       "   'no_speech_prob': 0.18143931031227112},\n",
       "  {'id': 167,\n",
       "   'seek': 70472,\n",
       "   'start': 712.72,\n",
       "   'end': 716.72,\n",
       "   'text': ' And you automatically classify whether it is a good tomato or bad tomato.',\n",
       "   'tokens': [50763,\n",
       "    843,\n",
       "    345,\n",
       "    6338,\n",
       "    36509,\n",
       "    1771,\n",
       "    340,\n",
       "    318,\n",
       "    257,\n",
       "    922,\n",
       "    24240,\n",
       "    393,\n",
       "    2089,\n",
       "    24240,\n",
       "    13,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4413547946098156,\n",
       "   'compression_ratio': 2.072,\n",
       "   'no_speech_prob': 0.18143931031227112},\n",
       "  {'id': 168,\n",
       "   'seek': 70472,\n",
       "   'start': 716.72,\n",
       "   'end': 718.72,\n",
       "   'text': ' And back of the tomatoes are from away.',\n",
       "   'tokens': [50963, 843, 736, 286, 262, 23972, 389, 422, 1497, 13, 51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4413547946098156,\n",
       "   'compression_ratio': 2.072,\n",
       "   'no_speech_prob': 0.18143931031227112},\n",
       "  {'id': 169,\n",
       "   'seek': 70472,\n",
       "   'start': 718.72,\n",
       "   'end': 719.72,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51063, 6498, 30, 51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4413547946098156,\n",
       "   'compression_ratio': 2.072,\n",
       "   'no_speech_prob': 0.18143931031227112},\n",
       "  {'id': 170,\n",
       "   'seek': 70472,\n",
       "   'start': 719.72,\n",
       "   'end': 720.72,\n",
       "   'text': ' So you are saying that you are saying that you are saying that you are saying that you are',\n",
       "   'tokens': [51113,\n",
       "    1406,\n",
       "    345,\n",
       "    389,\n",
       "    2282,\n",
       "    326,\n",
       "    345,\n",
       "    389,\n",
       "    2282,\n",
       "    326,\n",
       "    345,\n",
       "    389,\n",
       "    2282,\n",
       "    326,\n",
       "    345,\n",
       "    389,\n",
       "    2282,\n",
       "    326,\n",
       "    345,\n",
       "    389,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4413547946098156,\n",
       "   'compression_ratio': 2.072,\n",
       "   'no_speech_prob': 0.18143931031227112},\n",
       "  {'id': 171,\n",
       "   'seek': 70472,\n",
       "   'start': 720.72,\n",
       "   'end': 721.72,\n",
       "   'text': ' using a huge amount of human effort.',\n",
       "   'tokens': [51163, 1262, 257, 3236, 2033, 286, 1692, 3626, 13, 51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4413547946098156,\n",
       "   'compression_ratio': 2.072,\n",
       "   'no_speech_prob': 0.18143931031227112},\n",
       "  {'id': 172,\n",
       "   'seek': 70472,\n",
       "   'start': 721.72,\n",
       "   'end': 723.72,\n",
       "   'text': ' And what are you making your process greater?',\n",
       "   'tokens': [51213, 843, 644, 389, 345, 1642, 534, 1429, 3744, 30, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4413547946098156,\n",
       "   'compression_ratio': 2.072,\n",
       "   'no_speech_prob': 0.18143931031227112},\n",
       "  {'id': 173,\n",
       "   'seek': 70472,\n",
       "   'start': 723.72,\n",
       "   'end': 729.72,\n",
       "   'text': ' So you are saying that why this process we are able to make the living spirit.',\n",
       "   'tokens': [51313,\n",
       "    1406,\n",
       "    345,\n",
       "    389,\n",
       "    2282,\n",
       "    326,\n",
       "    1521,\n",
       "    428,\n",
       "    1429,\n",
       "    356,\n",
       "    389,\n",
       "    1498,\n",
       "    284,\n",
       "    787,\n",
       "    262,\n",
       "    2877,\n",
       "    4437,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4413547946098156,\n",
       "   'compression_ratio': 2.072,\n",
       "   'no_speech_prob': 0.18143931031227112},\n",
       "  {'id': 174,\n",
       "   'seek': 70472,\n",
       "   'start': 729.72,\n",
       "   'end': 730.72,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51613, 6498, 30, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4413547946098156,\n",
       "   'compression_ratio': 2.072,\n",
       "   'no_speech_prob': 0.18143931031227112},\n",
       "  {'id': 175,\n",
       "   'seek': 73072,\n",
       "   'start': 730.72,\n",
       "   'end': 735.72,\n",
       "   'text': \" So let's now do one of the machine learning aspects of this problem spirit.\",\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    1309,\n",
       "    338,\n",
       "    783,\n",
       "    466,\n",
       "    530,\n",
       "    286,\n",
       "    262,\n",
       "    4572,\n",
       "    4673,\n",
       "    7612,\n",
       "    286,\n",
       "    428,\n",
       "    1917,\n",
       "    4437,\n",
       "    13,\n",
       "    50613],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.31243458798057155,\n",
       "   'compression_ratio': 1.7028301886792452,\n",
       "   'no_speech_prob': 0.4712386131286621},\n",
       "  {'id': 176,\n",
       "   'seek': 73072,\n",
       "   'start': 735.72,\n",
       "   'end': 741.72,\n",
       "   'text': \" So if you remember, that's why I just spoken that there is an enerity of data.\",\n",
       "   'tokens': [50613,\n",
       "    1406,\n",
       "    611,\n",
       "    345,\n",
       "    3505,\n",
       "    11,\n",
       "    326,\n",
       "    338,\n",
       "    1521,\n",
       "    314,\n",
       "    655,\n",
       "    9635,\n",
       "    326,\n",
       "    612,\n",
       "    318,\n",
       "    281,\n",
       "    551,\n",
       "    263,\n",
       "    414,\n",
       "    286,\n",
       "    1366,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.31243458798057155,\n",
       "   'compression_ratio': 1.7028301886792452,\n",
       "   'no_speech_prob': 0.4712386131286621},\n",
       "  {'id': 177,\n",
       "   'seek': 73072,\n",
       "   'start': 741.72,\n",
       "   'end': 742.72,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50913, 6498, 30, 50963],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.31243458798057155,\n",
       "   'compression_ratio': 1.7028301886792452,\n",
       "   'no_speech_prob': 0.4712386131286621},\n",
       "  {'id': 178,\n",
       "   'seek': 73072,\n",
       "   'start': 742.72,\n",
       "   'end': 744.72,\n",
       "   'text': ' There is an enerity of experience and data.',\n",
       "   'tokens': [50963,\n",
       "    1318,\n",
       "    318,\n",
       "    281,\n",
       "    551,\n",
       "    263,\n",
       "    414,\n",
       "    286,\n",
       "    1998,\n",
       "    290,\n",
       "    1366,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.31243458798057155,\n",
       "   'compression_ratio': 1.7028301886792452,\n",
       "   'no_speech_prob': 0.4712386131286621},\n",
       "  {'id': 179,\n",
       "   'seek': 73072,\n",
       "   'start': 744.72,\n",
       "   'end': 749.72,\n",
       "   'text': \" So let's say that we have some pass data on the quality of tomatoes.\",\n",
       "   'tokens': [51063,\n",
       "    1406,\n",
       "    1309,\n",
       "    338,\n",
       "    910,\n",
       "    326,\n",
       "    356,\n",
       "    423,\n",
       "    617,\n",
       "    1208,\n",
       "    1366,\n",
       "    319,\n",
       "    262,\n",
       "    3081,\n",
       "    286,\n",
       "    23972,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.31243458798057155,\n",
       "   'compression_ratio': 1.7028301886792452,\n",
       "   'no_speech_prob': 0.4712386131286621},\n",
       "  {'id': 180,\n",
       "   'seek': 73072,\n",
       "   'start': 749.72,\n",
       "   'end': 755.72,\n",
       "   'text': ' We have collected thousands of tomatoes and for each of the tomatoes some human expert',\n",
       "   'tokens': [51313,\n",
       "    775,\n",
       "    423,\n",
       "    7723,\n",
       "    4138,\n",
       "    286,\n",
       "    23972,\n",
       "    290,\n",
       "    329,\n",
       "    1123,\n",
       "    286,\n",
       "    262,\n",
       "    23972,\n",
       "    617,\n",
       "    1692,\n",
       "    5887,\n",
       "    51613],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.31243458798057155,\n",
       "   'compression_ratio': 1.7028301886792452,\n",
       "   'no_speech_prob': 0.4712386131286621},\n",
       "  {'id': 181,\n",
       "   'seek': 75572,\n",
       "   'start': 755.72,\n",
       "   'end': 758.72,\n",
       "   'text': ' can identify whether it is a good tomato or bad tomato.',\n",
       "   'tokens': [50363,\n",
       "    460,\n",
       "    5911,\n",
       "    1771,\n",
       "    340,\n",
       "    318,\n",
       "    257,\n",
       "    922,\n",
       "    24240,\n",
       "    393,\n",
       "    2089,\n",
       "    24240,\n",
       "    13,\n",
       "    50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4102980931599935,\n",
       "   'compression_ratio': 1.7178423236514522,\n",
       "   'no_speech_prob': 0.658514678478241},\n",
       "  {'id': 182,\n",
       "   'seek': 75572,\n",
       "   'start': 758.72,\n",
       "   'end': 763.72,\n",
       "   'text': ' For now it is just if you are good or bad and not on the scale of all the tomatoes.',\n",
       "   'tokens': [50513,\n",
       "    1114,\n",
       "    783,\n",
       "    340,\n",
       "    318,\n",
       "    655,\n",
       "    611,\n",
       "    345,\n",
       "    389,\n",
       "    922,\n",
       "    393,\n",
       "    2089,\n",
       "    290,\n",
       "    407,\n",
       "    319,\n",
       "    262,\n",
       "    5046,\n",
       "    286,\n",
       "    477,\n",
       "    262,\n",
       "    23972,\n",
       "    13,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4102980931599935,\n",
       "   'compression_ratio': 1.7178423236514522,\n",
       "   'no_speech_prob': 0.658514678478241},\n",
       "  {'id': 183,\n",
       "   'seek': 75572,\n",
       "   'start': 763.72,\n",
       "   'end': 764.72,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50763, 6498, 30, 50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4102980931599935,\n",
       "   'compression_ratio': 1.7178423236514522,\n",
       "   'no_speech_prob': 0.658514678478241},\n",
       "  {'id': 184,\n",
       "   'seek': 75572,\n",
       "   'start': 764.72,\n",
       "   'end': 765.72,\n",
       "   'text': ' There are two classes.',\n",
       "   'tokens': [50813, 1318, 389, 734, 6097, 13, 50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4102980931599935,\n",
       "   'compression_ratio': 1.7178423236514522,\n",
       "   'no_speech_prob': 0.658514678478241},\n",
       "  {'id': 185,\n",
       "   'seek': 75572,\n",
       "   'start': 765.72,\n",
       "   'end': 770.72,\n",
       "   'text': ' What visual features do you think would be useful to characterize the tomato?',\n",
       "   'tokens': [50863,\n",
       "    1867,\n",
       "    5874,\n",
       "    3033,\n",
       "    466,\n",
       "    345,\n",
       "    892,\n",
       "    561,\n",
       "    307,\n",
       "    4465,\n",
       "    284,\n",
       "    34404,\n",
       "    262,\n",
       "    24240,\n",
       "    30,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4102980931599935,\n",
       "   'compression_ratio': 1.7178423236514522,\n",
       "   'no_speech_prob': 0.658514678478241},\n",
       "  {'id': 186,\n",
       "   'seek': 75572,\n",
       "   'start': 770.72,\n",
       "   'end': 771.72,\n",
       "   'text': ' Color?',\n",
       "   'tokens': [51113, 5315, 30, 51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4102980931599935,\n",
       "   'compression_ratio': 1.7178423236514522,\n",
       "   'no_speech_prob': 0.658514678478241},\n",
       "  {'id': 187,\n",
       "   'seek': 75572,\n",
       "   'start': 771.72,\n",
       "   'end': 775.72,\n",
       "   'text': ' Any...so what...what if you could be a good tomato?',\n",
       "   'tokens': [51163,\n",
       "    4377,\n",
       "    986,\n",
       "    568,\n",
       "    644,\n",
       "    986,\n",
       "    10919,\n",
       "    611,\n",
       "    345,\n",
       "    714,\n",
       "    307,\n",
       "    257,\n",
       "    922,\n",
       "    24240,\n",
       "    30,\n",
       "    51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4102980931599935,\n",
       "   'compression_ratio': 1.7178423236514522,\n",
       "   'no_speech_prob': 0.658514678478241},\n",
       "  {'id': 188,\n",
       "   'seek': 75572,\n",
       "   'start': 775.72,\n",
       "   'end': 776.72,\n",
       "   'text': ' You just...',\n",
       "   'tokens': [51363, 921, 655, 986, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4102980931599935,\n",
       "   'compression_ratio': 1.7178423236514522,\n",
       "   'no_speech_prob': 0.658514678478241},\n",
       "  {'id': 189,\n",
       "   'seek': 75572,\n",
       "   'start': 776.72,\n",
       "   'end': 779.72,\n",
       "   'text': ' Which is more red or more...',\n",
       "   'tokens': [51413, 9022, 318, 517, 2266, 393, 517, 986, 51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4102980931599935,\n",
       "   'compression_ratio': 1.7178423236514522,\n",
       "   'no_speech_prob': 0.658514678478241},\n",
       "  {'id': 190,\n",
       "   'seek': 75572,\n",
       "   'start': 779.72,\n",
       "   'end': 781.72,\n",
       "   'text': ' There is something on the shades of red.',\n",
       "   'tokens': [51563, 1318, 318, 1223, 319, 262, 23787, 286, 2266, 13, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4102980931599935,\n",
       "   'compression_ratio': 1.7178423236514522,\n",
       "   'no_speech_prob': 0.658514678478241},\n",
       "  {'id': 191,\n",
       "   'seek': 75572,\n",
       "   'start': 781.72,\n",
       "   'end': 783.72,\n",
       "   'text': ' What is the data made of?',\n",
       "   'tokens': [51663, 1867, 318, 262, 1366, 925, 286, 30, 51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4102980931599935,\n",
       "   'compression_ratio': 1.7178423236514522,\n",
       "   'no_speech_prob': 0.658514678478241},\n",
       "  {'id': 192,\n",
       "   'seek': 78372,\n",
       "   'start': 784.72,\n",
       "   'end': 790.72,\n",
       "   'text': ' Something which is either showing some greenish shade, it may be an anvil.',\n",
       "   'tokens': [50413,\n",
       "    13742,\n",
       "    543,\n",
       "    318,\n",
       "    2035,\n",
       "    4478,\n",
       "    617,\n",
       "    4077,\n",
       "    680,\n",
       "    17979,\n",
       "    11,\n",
       "    340,\n",
       "    743,\n",
       "    307,\n",
       "    281,\n",
       "    281,\n",
       "    2991,\n",
       "    13,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5243383465391217,\n",
       "   'compression_ratio': 1.7295918367346939,\n",
       "   'no_speech_prob': 0.2586539685726166},\n",
       "  {'id': 193,\n",
       "   'seek': 78372,\n",
       "   'start': 790.72,\n",
       "   'end': 796.72,\n",
       "   'text': ' Black definitely or if it has some fungus or some other attributes.',\n",
       "   'tokens': [50713,\n",
       "    2619,\n",
       "    4753,\n",
       "    393,\n",
       "    611,\n",
       "    340,\n",
       "    468,\n",
       "    617,\n",
       "    39526,\n",
       "    393,\n",
       "    617,\n",
       "    584,\n",
       "    12608,\n",
       "    13,\n",
       "    51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5243383465391217,\n",
       "   'compression_ratio': 1.7295918367346939,\n",
       "   'no_speech_prob': 0.2586539685726166},\n",
       "  {'id': 194,\n",
       "   'seek': 78372,\n",
       "   'start': 796.72,\n",
       "   'end': 799.72,\n",
       "   'text': ' What is the other attributes which make it a little bit of bad?',\n",
       "   'tokens': [51013,\n",
       "    1867,\n",
       "    318,\n",
       "    262,\n",
       "    584,\n",
       "    12608,\n",
       "    543,\n",
       "    787,\n",
       "    340,\n",
       "    257,\n",
       "    1310,\n",
       "    1643,\n",
       "    286,\n",
       "    2089,\n",
       "    30,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5243383465391217,\n",
       "   'compression_ratio': 1.7295918367346939,\n",
       "   'no_speech_prob': 0.2586539685726166},\n",
       "  {'id': 195,\n",
       "   'seek': 78372,\n",
       "   'start': 799.72,\n",
       "   'end': 801.72,\n",
       "   'text': ' It is a shade.',\n",
       "   'tokens': [51163, 632, 318, 257, 17979, 13, 51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5243383465391217,\n",
       "   'compression_ratio': 1.7295918367346939,\n",
       "   'no_speech_prob': 0.2586539685726166},\n",
       "  {'id': 196,\n",
       "   'seek': 78372,\n",
       "   'start': 801.72,\n",
       "   'end': 802.72,\n",
       "   'text': ' It is a shade.',\n",
       "   'tokens': [51263, 632, 318, 257, 17979, 13, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5243383465391217,\n",
       "   'compression_ratio': 1.7295918367346939,\n",
       "   'no_speech_prob': 0.2586539685726166},\n",
       "  {'id': 197,\n",
       "   'seek': 78372,\n",
       "   'start': 802.72,\n",
       "   'end': 804.72,\n",
       "   'text': ' Is there a text?',\n",
       "   'tokens': [51313, 1148, 612, 257, 2420, 30, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5243383465391217,\n",
       "   'compression_ratio': 1.7295918367346939,\n",
       "   'no_speech_prob': 0.2586539685726166},\n",
       "  {'id': 198,\n",
       "   'seek': 78372,\n",
       "   'start': 804.72,\n",
       "   'end': 807.72,\n",
       "   'text': ' It is a perfect circle.',\n",
       "   'tokens': [51413, 632, 318, 257, 2818, 9197, 13, 51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5243383465391217,\n",
       "   'compression_ratio': 1.7295918367346939,\n",
       "   'no_speech_prob': 0.2586539685726166},\n",
       "  {'id': 199,\n",
       "   'seek': 78372,\n",
       "   'start': 807.72,\n",
       "   'end': 812.72,\n",
       "   'text': ' So the...okay some...some...so the size is another attribute.',\n",
       "   'tokens': [51563,\n",
       "    1406,\n",
       "    262,\n",
       "    986,\n",
       "    482,\n",
       "    323,\n",
       "    617,\n",
       "    986,\n",
       "    11246,\n",
       "    986,\n",
       "    568,\n",
       "    262,\n",
       "    2546,\n",
       "    318,\n",
       "    1194,\n",
       "    11688,\n",
       "    13,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5243383465391217,\n",
       "   'compression_ratio': 1.7295918367346939,\n",
       "   'no_speech_prob': 0.2586539685726166},\n",
       "  {'id': 200,\n",
       "   'seek': 81272,\n",
       "   'start': 812.72,\n",
       "   'end': 819.72,\n",
       "   'text': \" Let's say that we have seen for now that all tomatoes are roughly over and smaller tomatoes\",\n",
       "   'tokens': [50363,\n",
       "    3914,\n",
       "    338,\n",
       "    910,\n",
       "    326,\n",
       "    356,\n",
       "    423,\n",
       "    1775,\n",
       "    329,\n",
       "    783,\n",
       "    326,\n",
       "    477,\n",
       "    23972,\n",
       "    389,\n",
       "    7323,\n",
       "    625,\n",
       "    290,\n",
       "    4833,\n",
       "    23972,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.26867744603107885,\n",
       "   'compression_ratio': 1.619047619047619,\n",
       "   'no_speech_prob': 0.04319014027714729},\n",
       "  {'id': 201,\n",
       "   'seek': 81272,\n",
       "   'start': 819.72,\n",
       "   'end': 822.72,\n",
       "   'text': ' are bad, very big tomatoes are also bad.',\n",
       "   'tokens': [50713,\n",
       "    389,\n",
       "    2089,\n",
       "    11,\n",
       "    845,\n",
       "    1263,\n",
       "    23972,\n",
       "    389,\n",
       "    635,\n",
       "    2089,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.26867744603107885,\n",
       "   'compression_ratio': 1.619047619047619,\n",
       "   'no_speech_prob': 0.04319014027714729},\n",
       "  {'id': 202,\n",
       "   'seek': 81272,\n",
       "   'start': 822.72,\n",
       "   'end': 827.72,\n",
       "   'text': ' They are very injected with some growth...growth chemicals.',\n",
       "   'tokens': [50863,\n",
       "    1119,\n",
       "    389,\n",
       "    845,\n",
       "    25077,\n",
       "    351,\n",
       "    617,\n",
       "    3349,\n",
       "    986,\n",
       "    27922,\n",
       "    12910,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.26867744603107885,\n",
       "   'compression_ratio': 1.619047619047619,\n",
       "   'no_speech_prob': 0.04319014027714729},\n",
       "  {'id': 203,\n",
       "   'seek': 81272,\n",
       "   'start': 827.72,\n",
       "   'end': 832.72,\n",
       "   'text': ' Size, whether we have seen, what are the other things you would typically do?',\n",
       "   'tokens': [51113,\n",
       "    12849,\n",
       "    11,\n",
       "    1771,\n",
       "    356,\n",
       "    423,\n",
       "    1775,\n",
       "    11,\n",
       "    644,\n",
       "    389,\n",
       "    262,\n",
       "    584,\n",
       "    1243,\n",
       "    345,\n",
       "    561,\n",
       "    6032,\n",
       "    466,\n",
       "    30,\n",
       "    51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.26867744603107885,\n",
       "   'compression_ratio': 1.619047619047619,\n",
       "   'no_speech_prob': 0.04319014027714729},\n",
       "  {'id': 204,\n",
       "   'seek': 81272,\n",
       "   'start': 832.72,\n",
       "   'end': 833.72,\n",
       "   'text': ' Fine.',\n",
       "   'tokens': [51363, 17867, 13, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.26867744603107885,\n",
       "   'compression_ratio': 1.619047619047619,\n",
       "   'no_speech_prob': 0.04319014027714729},\n",
       "  {'id': 205,\n",
       "   'seek': 81272,\n",
       "   'start': 833.72,\n",
       "   'end': 836.72,\n",
       "   'text': ' Yeah, but visual features will not look at the people.',\n",
       "   'tokens': [51413,\n",
       "    9425,\n",
       "    11,\n",
       "    475,\n",
       "    5874,\n",
       "    3033,\n",
       "    481,\n",
       "    407,\n",
       "    804,\n",
       "    379,\n",
       "    262,\n",
       "    661,\n",
       "    13,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.26867744603107885,\n",
       "   'compression_ratio': 1.619047619047619,\n",
       "   'no_speech_prob': 0.04319014027714729},\n",
       "  {'id': 206,\n",
       "   'seek': 81272,\n",
       "   'start': 836.72,\n",
       "   'end': 838.72,\n",
       "   'text': \" So you'll have to get some proxy for that.\",\n",
       "   'tokens': [51563,\n",
       "    1406,\n",
       "    345,\n",
       "    1183,\n",
       "    423,\n",
       "    284,\n",
       "    651,\n",
       "    617,\n",
       "    15741,\n",
       "    329,\n",
       "    326,\n",
       "    13,\n",
       "    51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.26867744603107885,\n",
       "   'compression_ratio': 1.619047619047619,\n",
       "   'no_speech_prob': 0.04319014027714729},\n",
       "  {'id': 207,\n",
       "   'seek': 83872,\n",
       "   'start': 839.72,\n",
       "   'end': 842.72,\n",
       "   'text': ' So that is another thing which I want all of us to take from the machine learning course.',\n",
       "   'tokens': [50413,\n",
       "    1406,\n",
       "    326,\n",
       "    318,\n",
       "    1194,\n",
       "    1517,\n",
       "    543,\n",
       "    314,\n",
       "    765,\n",
       "    477,\n",
       "    286,\n",
       "    514,\n",
       "    284,\n",
       "    1011,\n",
       "    422,\n",
       "    262,\n",
       "    4572,\n",
       "    4673,\n",
       "    1781,\n",
       "    13,\n",
       "    50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27517312367757163,\n",
       "   'compression_ratio': 1.7547169811320755,\n",
       "   'no_speech_prob': 0.15240785479545593},\n",
       "  {'id': 208,\n",
       "   'seek': 83872,\n",
       "   'start': 842.72,\n",
       "   'end': 845.72,\n",
       "   'text': ' What are some of the proxy features we could take from?',\n",
       "   'tokens': [50563,\n",
       "    1867,\n",
       "    389,\n",
       "    617,\n",
       "    286,\n",
       "    262,\n",
       "    15741,\n",
       "    3033,\n",
       "    356,\n",
       "    714,\n",
       "    1011,\n",
       "    422,\n",
       "    30,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27517312367757163,\n",
       "   'compression_ratio': 1.7547169811320755,\n",
       "   'no_speech_prob': 0.15240785479545593},\n",
       "  {'id': 209,\n",
       "   'seek': 83872,\n",
       "   'start': 845.72,\n",
       "   'end': 846.72,\n",
       "   'text': ' Yes, texture.',\n",
       "   'tokens': [50713, 3363, 11, 11743, 13, 50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27517312367757163,\n",
       "   'compression_ratio': 1.7547169811320755,\n",
       "   'no_speech_prob': 0.15240785479545593},\n",
       "  {'id': 210,\n",
       "   'seek': 83872,\n",
       "   'start': 846.72,\n",
       "   'end': 851.72,\n",
       "   'text': ' So texture will tell us something about the field of the community.',\n",
       "   'tokens': [50763,\n",
       "    1406,\n",
       "    11743,\n",
       "    481,\n",
       "    1560,\n",
       "    514,\n",
       "    1223,\n",
       "    546,\n",
       "    262,\n",
       "    2214,\n",
       "    286,\n",
       "    262,\n",
       "    2055,\n",
       "    13,\n",
       "    51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27517312367757163,\n",
       "   'compression_ratio': 1.7547169811320755,\n",
       "   'no_speech_prob': 0.15240785479545593},\n",
       "  {'id': 211,\n",
       "   'seek': 83872,\n",
       "   'start': 851.72,\n",
       "   'end': 855.72,\n",
       "   'text': \" Whether it's very rough, very smooth, very light and etc.\",\n",
       "   'tokens': [51013,\n",
       "    10127,\n",
       "    340,\n",
       "    338,\n",
       "    845,\n",
       "    5210,\n",
       "    11,\n",
       "    845,\n",
       "    7209,\n",
       "    11,\n",
       "    845,\n",
       "    1657,\n",
       "    290,\n",
       "    3503,\n",
       "    13,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27517312367757163,\n",
       "   'compression_ratio': 1.7547169811320755,\n",
       "   'no_speech_prob': 0.15240785479545593},\n",
       "  {'id': 212,\n",
       "   'seek': 83872,\n",
       "   'start': 855.72,\n",
       "   'end': 858.72,\n",
       "   'text': ' So we looked at these three specific features.',\n",
       "   'tokens': [51213, 1406, 356, 3114, 379, 777, 1115, 2176, 3033, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27517312367757163,\n",
       "   'compression_ratio': 1.7547169811320755,\n",
       "   'no_speech_prob': 0.15240785479545593},\n",
       "  {'id': 213,\n",
       "   'seek': 83872,\n",
       "   'start': 858.72,\n",
       "   'end': 859.72,\n",
       "   'text': ' Would there be others?',\n",
       "   'tokens': [51363, 10928, 612, 307, 1854, 30, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27517312367757163,\n",
       "   'compression_ratio': 1.7547169811320755,\n",
       "   'no_speech_prob': 0.15240785479545593},\n",
       "  {'id': 214,\n",
       "   'seek': 83872,\n",
       "   'start': 859.72,\n",
       "   'end': 862.72,\n",
       "   'text': ' Yes, there might be thousands of other features.',\n",
       "   'tokens': [51413,\n",
       "    3363,\n",
       "    11,\n",
       "    612,\n",
       "    1244,\n",
       "    307,\n",
       "    4138,\n",
       "    286,\n",
       "    584,\n",
       "    3033,\n",
       "    13,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27517312367757163,\n",
       "   'compression_ratio': 1.7547169811320755,\n",
       "   'no_speech_prob': 0.15240785479545593},\n",
       "  {'id': 215,\n",
       "   'seek': 83872,\n",
       "   'start': 862.72,\n",
       "   'end': 865.72,\n",
       "   'text': \" But for the purposes of this example, it's only these three.\",\n",
       "   'tokens': [51563,\n",
       "    887,\n",
       "    329,\n",
       "    262,\n",
       "    4959,\n",
       "    286,\n",
       "    428,\n",
       "    1672,\n",
       "    11,\n",
       "    340,\n",
       "    338,\n",
       "    691,\n",
       "    777,\n",
       "    1115,\n",
       "    13,\n",
       "    51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27517312367757163,\n",
       "   'compression_ratio': 1.7547169811320755,\n",
       "   'no_speech_prob': 0.15240785479545593},\n",
       "  {'id': 216,\n",
       "   'seek': 86572,\n",
       "   'start': 866.72,\n",
       "   'end': 871.72,\n",
       "   'text': ' So we were talking about some vast data or some vast experience that we already have.',\n",
       "   'tokens': [50413,\n",
       "    1406,\n",
       "    356,\n",
       "    547,\n",
       "    3375,\n",
       "    546,\n",
       "    617,\n",
       "    5909,\n",
       "    1366,\n",
       "    393,\n",
       "    617,\n",
       "    5909,\n",
       "    1998,\n",
       "    326,\n",
       "    356,\n",
       "    1541,\n",
       "    423,\n",
       "    13,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25985069274902345,\n",
       "   'compression_ratio': 1.6203208556149733,\n",
       "   'no_speech_prob': 0.020232999697327614},\n",
       "  {'id': 217,\n",
       "   'seek': 86572,\n",
       "   'start': 871.72,\n",
       "   'end': 875.72,\n",
       "   'text': ' Maybe it exists in a form of potato like this.',\n",
       "   'tokens': [50663,\n",
       "    6674,\n",
       "    340,\n",
       "    7160,\n",
       "    287,\n",
       "    257,\n",
       "    1296,\n",
       "    286,\n",
       "    21219,\n",
       "    588,\n",
       "    428,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25985069274902345,\n",
       "   'compression_ratio': 1.6203208556149733,\n",
       "   'no_speech_prob': 0.020232999697327614},\n",
       "  {'id': 218,\n",
       "   'seek': 86572,\n",
       "   'start': 875.72,\n",
       "   'end': 880.72,\n",
       "   'text': ' You have some sample of the...you have the color, size, texture and you have the condition.',\n",
       "   'tokens': [50863,\n",
       "    921,\n",
       "    423,\n",
       "    617,\n",
       "    6291,\n",
       "    286,\n",
       "    262,\n",
       "    986,\n",
       "    5832,\n",
       "    423,\n",
       "    262,\n",
       "    3124,\n",
       "    11,\n",
       "    2546,\n",
       "    11,\n",
       "    11743,\n",
       "    290,\n",
       "    345,\n",
       "    423,\n",
       "    262,\n",
       "    4006,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25985069274902345,\n",
       "   'compression_ratio': 1.6203208556149733,\n",
       "   'no_speech_prob': 0.020232999697327614},\n",
       "  {'id': 219,\n",
       "   'seek': 86572,\n",
       "   'start': 880.72,\n",
       "   'end': 885.72,\n",
       "   'text': ' So this condition has been manually and a data written down by a human expert.',\n",
       "   'tokens': [51113,\n",
       "    1406,\n",
       "    428,\n",
       "    4006,\n",
       "    468,\n",
       "    587,\n",
       "    14500,\n",
       "    290,\n",
       "    257,\n",
       "    1366,\n",
       "    3194,\n",
       "    866,\n",
       "    416,\n",
       "    257,\n",
       "    1692,\n",
       "    5887,\n",
       "    13,\n",
       "    51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25985069274902345,\n",
       "   'compression_ratio': 1.6203208556149733,\n",
       "   'no_speech_prob': 0.020232999697327614},\n",
       "  {'id': 220,\n",
       "   'seek': 88572,\n",
       "   'start': 885.72,\n",
       "   'end': 897.72,\n",
       "   'text': ' So in this particular table, you think sample number could be a useful attribute of feature',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    287,\n",
       "    428,\n",
       "    1948,\n",
       "    3084,\n",
       "    11,\n",
       "    345,\n",
       "    892,\n",
       "    6291,\n",
       "    1271,\n",
       "    714,\n",
       "    307,\n",
       "    257,\n",
       "    4465,\n",
       "    11688,\n",
       "    286,\n",
       "    3895,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.306970909460267,\n",
       "   'compression_ratio': 1.570469798657718,\n",
       "   'no_speech_prob': 0.5022116899490356},\n",
       "  {'id': 221,\n",
       "   'seek': 88572,\n",
       "   'start': 897.72,\n",
       "   'end': 899.72,\n",
       "   'text': ' to predict the condition?',\n",
       "   'tokens': [50963, 284, 4331, 262, 4006, 30, 51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.306970909460267,\n",
       "   'compression_ratio': 1.570469798657718,\n",
       "   'no_speech_prob': 0.5022116899490356},\n",
       "  {'id': 222,\n",
       "   'seek': 88572,\n",
       "   'start': 899.72,\n",
       "   'end': 902.72,\n",
       "   'text': ' How many think yes?',\n",
       "   'tokens': [51063, 1374, 867, 892, 3763, 30, 51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.306970909460267,\n",
       "   'compression_ratio': 1.570469798657718,\n",
       "   'no_speech_prob': 0.5022116899490356},\n",
       "  {'id': 223,\n",
       "   'seek': 88572,\n",
       "   'start': 902.72,\n",
       "   'end': 905.72,\n",
       "   'text': ' How many think no?',\n",
       "   'tokens': [51213, 1374, 867, 892, 645, 30, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.306970909460267,\n",
       "   'compression_ratio': 1.570469798657718,\n",
       "   'no_speech_prob': 0.5022116899490356},\n",
       "  {'id': 224,\n",
       "   'seek': 88572,\n",
       "   'start': 905.72,\n",
       "   'end': 906.72,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [51363, 16805, 13, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.306970909460267,\n",
       "   'compression_ratio': 1.570469798657718,\n",
       "   'no_speech_prob': 0.5022116899490356},\n",
       "  {'id': 225,\n",
       "   'seek': 88572,\n",
       "   'start': 906.72,\n",
       "   'end': 909.72,\n",
       "   'text': ' Now tell me that it could be a useful feature.',\n",
       "   'tokens': [51413,\n",
       "    2735,\n",
       "    1560,\n",
       "    502,\n",
       "    326,\n",
       "    340,\n",
       "    714,\n",
       "    307,\n",
       "    257,\n",
       "    4465,\n",
       "    3895,\n",
       "    13,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.306970909460267,\n",
       "   'compression_ratio': 1.570469798657718,\n",
       "   'no_speech_prob': 0.5022116899490356},\n",
       "  {'id': 226,\n",
       "   'seek': 88572,\n",
       "   'start': 909.72,\n",
       "   'end': 911.72,\n",
       "   'text': ' Now think more and more.',\n",
       "   'tokens': [51563, 2735, 892, 517, 290, 517, 13, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.306970909460267,\n",
       "   'compression_ratio': 1.570469798657718,\n",
       "   'no_speech_prob': 0.5022116899490356},\n",
       "  {'id': 227,\n",
       "   'seek': 91172,\n",
       "   'start': 911.72,\n",
       "   'end': 916.72,\n",
       "   'text': ' How could the sample number be useful?',\n",
       "   'tokens': [50363, 1374, 714, 262, 6291, 1271, 307, 4465, 30, 50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4893235100640191,\n",
       "   'compression_ratio': 1.3529411764705883,\n",
       "   'no_speech_prob': 0.3750438094139099},\n",
       "  {'id': 228,\n",
       "   'seek': 91172,\n",
       "   'start': 916.72,\n",
       "   'end': 923.72,\n",
       "   'text': ' Sorry.',\n",
       "   'tokens': [50613, 19061, 13, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4893235100640191,\n",
       "   'compression_ratio': 1.3529411764705883,\n",
       "   'no_speech_prob': 0.3750438094139099},\n",
       "  {'id': 229,\n",
       "   'seek': 91172,\n",
       "   'start': 923.72,\n",
       "   'end': 931.72,\n",
       "   'text': ' No, also the equation is orange.',\n",
       "   'tokens': [50963, 1400, 11, 635, 262, 16022, 318, 10912, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4893235100640191,\n",
       "   'compression_ratio': 1.3529411764705883,\n",
       "   'no_speech_prob': 0.3750438094139099},\n",
       "  {'id': 230,\n",
       "   'seek': 91172,\n",
       "   'start': 931.72,\n",
       "   'end': 936.72,\n",
       "   'text': ' If the other is orange, decide the small, the texture is smooth.',\n",
       "   'tokens': [51363,\n",
       "    1002,\n",
       "    262,\n",
       "    584,\n",
       "    318,\n",
       "    10912,\n",
       "    11,\n",
       "    5409,\n",
       "    262,\n",
       "    1402,\n",
       "    11,\n",
       "    262,\n",
       "    11743,\n",
       "    318,\n",
       "    7209,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4893235100640191,\n",
       "   'compression_ratio': 1.3529411764705883,\n",
       "   'no_speech_prob': 0.3750438094139099},\n",
       "  {'id': 231,\n",
       "   'seek': 91172,\n",
       "   'start': 936.72,\n",
       "   'end': 938.72,\n",
       "   'text': ' I can roughly say the condition is good.',\n",
       "   'tokens': [51613, 314, 460, 7323, 910, 262, 4006, 318, 922, 13, 51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4893235100640191,\n",
       "   'compression_ratio': 1.3529411764705883,\n",
       "   'no_speech_prob': 0.3750438094139099},\n",
       "  {'id': 232,\n",
       "   'seek': 93872,\n",
       "   'start': 938.72,\n",
       "   'end': 945.72,\n",
       "   'text': \" So let's say we have a sample number that is equal to 1, 10 because the parameters will be equal to 1.\",\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    1309,\n",
       "    338,\n",
       "    910,\n",
       "    356,\n",
       "    423,\n",
       "    257,\n",
       "    6291,\n",
       "    1271,\n",
       "    326,\n",
       "    318,\n",
       "    4961,\n",
       "    284,\n",
       "    352,\n",
       "    11,\n",
       "    838,\n",
       "    780,\n",
       "    262,\n",
       "    10007,\n",
       "    481,\n",
       "    307,\n",
       "    4961,\n",
       "    284,\n",
       "    352,\n",
       "    13,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6177574980492685,\n",
       "   'compression_ratio': 1.7233009708737863,\n",
       "   'no_speech_prob': 0.41865992546081543},\n",
       "  {'id': 233,\n",
       "   'seek': 93872,\n",
       "   'start': 945.72,\n",
       "   'end': 946.72,\n",
       "   'text': ' Yes.',\n",
       "   'tokens': [50713, 3363, 13, 50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6177574980492685,\n",
       "   'compression_ratio': 1.7233009708737863,\n",
       "   'no_speech_prob': 0.41865992546081543},\n",
       "  {'id': 234,\n",
       "   'seek': 93872,\n",
       "   'start': 946.72,\n",
       "   'end': 949.72,\n",
       "   'text': ' 1 and 2 are equal to 0.',\n",
       "   'tokens': [50763, 352, 290, 362, 389, 4961, 284, 657, 13, 50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6177574980492685,\n",
       "   'compression_ratio': 1.7233009708737863,\n",
       "   'no_speech_prob': 0.41865992546081543},\n",
       "  {'id': 235,\n",
       "   'seek': 93872,\n",
       "   'start': 949.72,\n",
       "   'end': 952.72,\n",
       "   'text': ' It sequentially arrives to 1 and 2.',\n",
       "   'tokens': [50913, 632, 4726, 3746, 14443, 284, 352, 290, 362, 13, 51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6177574980492685,\n",
       "   'compression_ratio': 1.7233009708737863,\n",
       "   'no_speech_prob': 0.41865992546081543},\n",
       "  {'id': 236,\n",
       "   'seek': 93872,\n",
       "   'start': 952.72,\n",
       "   'end': 958.72,\n",
       "   'text': ' So why do you think the sample number could be useful?',\n",
       "   'tokens': [51063,\n",
       "    1406,\n",
       "    1521,\n",
       "    466,\n",
       "    345,\n",
       "    892,\n",
       "    262,\n",
       "    6291,\n",
       "    1271,\n",
       "    714,\n",
       "    307,\n",
       "    4465,\n",
       "    30,\n",
       "    51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6177574980492685,\n",
       "   'compression_ratio': 1.7233009708737863,\n",
       "   'no_speech_prob': 0.41865992546081543},\n",
       "  {'id': 237,\n",
       "   'seek': 93872,\n",
       "   'start': 958.72,\n",
       "   'end': 963.72,\n",
       "   'text': \" So some of you get it to the point that let's say we sequentially arrange, then we will get something.\",\n",
       "   'tokens': [51363,\n",
       "    1406,\n",
       "    617,\n",
       "    286,\n",
       "    345,\n",
       "    651,\n",
       "    340,\n",
       "    284,\n",
       "    262,\n",
       "    966,\n",
       "    326,\n",
       "    1309,\n",
       "    338,\n",
       "    910,\n",
       "    356,\n",
       "    4726,\n",
       "    3746,\n",
       "    21674,\n",
       "    11,\n",
       "    788,\n",
       "    356,\n",
       "    481,\n",
       "    651,\n",
       "    1223,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6177574980492685,\n",
       "   'compression_ratio': 1.7233009708737863,\n",
       "   'no_speech_prob': 0.41865992546081543},\n",
       "  {'id': 238,\n",
       "   'seek': 93872,\n",
       "   'start': 963.72,\n",
       "   'end': 965.72,\n",
       "   'text': ' But are we getting something?',\n",
       "   'tokens': [51613, 887, 389, 356, 1972, 1223, 30, 51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6177574980492685,\n",
       "   'compression_ratio': 1.7233009708737863,\n",
       "   'no_speech_prob': 0.41865992546081543},\n",
       "  {'id': 239,\n",
       "   'seek': 96572,\n",
       "   'start': 965.72,\n",
       "   'end': 966.72,\n",
       "   'text': ' Yes.',\n",
       "   'tokens': [50363, 3363, 13, 50413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5687498163293909,\n",
       "   'compression_ratio': 1.6704545454545454,\n",
       "   'no_speech_prob': 0.05312124267220497},\n",
       "  {'id': 240,\n",
       "   'seek': 96572,\n",
       "   'start': 966.72,\n",
       "   'end': 971.72,\n",
       "   'text': ' So you can just write the same thing and then get qualified for the same time.',\n",
       "   'tokens': [50413,\n",
       "    1406,\n",
       "    345,\n",
       "    460,\n",
       "    655,\n",
       "    3551,\n",
       "    262,\n",
       "    976,\n",
       "    1517,\n",
       "    290,\n",
       "    788,\n",
       "    651,\n",
       "    10617,\n",
       "    329,\n",
       "    262,\n",
       "    976,\n",
       "    640,\n",
       "    13,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5687498163293909,\n",
       "   'compression_ratio': 1.6704545454545454,\n",
       "   'no_speech_prob': 0.05312124267220497},\n",
       "  {'id': 241,\n",
       "   'seek': 96572,\n",
       "   'start': 971.72,\n",
       "   'end': 972.72,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [50663, 16805, 13, 50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5687498163293909,\n",
       "   'compression_ratio': 1.6704545454545454,\n",
       "   'no_speech_prob': 0.05312124267220497},\n",
       "  {'id': 242,\n",
       "   'seek': 96572,\n",
       "   'start': 972.72,\n",
       "   'end': 979.72,\n",
       "   'text': ' So he is answering that maybe there is a notion of time associated with samples, very likely they could be.',\n",
       "   'tokens': [50713,\n",
       "    1406,\n",
       "    339,\n",
       "    318,\n",
       "    18877,\n",
       "    326,\n",
       "    3863,\n",
       "    612,\n",
       "    318,\n",
       "    257,\n",
       "    9495,\n",
       "    286,\n",
       "    640,\n",
       "    3917,\n",
       "    351,\n",
       "    8405,\n",
       "    11,\n",
       "    845,\n",
       "    1884,\n",
       "    484,\n",
       "    714,\n",
       "    307,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5687498163293909,\n",
       "   'compression_ratio': 1.6704545454545454,\n",
       "   'no_speech_prob': 0.05312124267220497},\n",
       "  {'id': 243,\n",
       "   'seek': 96572,\n",
       "   'start': 979.72,\n",
       "   'end': 986.72,\n",
       "   'text': ' And imagine a scenario where there is one specific time of the year, maybe when all of the variables are bad.',\n",
       "   'tokens': [51063,\n",
       "    843,\n",
       "    5967,\n",
       "    257,\n",
       "    8883,\n",
       "    810,\n",
       "    612,\n",
       "    318,\n",
       "    530,\n",
       "    2176,\n",
       "    640,\n",
       "    286,\n",
       "    262,\n",
       "    614,\n",
       "    11,\n",
       "    3863,\n",
       "    618,\n",
       "    477,\n",
       "    286,\n",
       "    262,\n",
       "    9633,\n",
       "    389,\n",
       "    2089,\n",
       "    13,\n",
       "    51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5687498163293909,\n",
       "   'compression_ratio': 1.6704545454545454,\n",
       "   'no_speech_prob': 0.05312124267220497},\n",
       "  {'id': 244,\n",
       "   'seek': 96572,\n",
       "   'start': 986.72,\n",
       "   'end': 993.72,\n",
       "   'text': ' Maybe if we produce a band, maybe the leader, which is bringing the tomatoes was hard, had gone wrong, something would have happened.',\n",
       "   'tokens': [51413,\n",
       "    6674,\n",
       "    611,\n",
       "    356,\n",
       "    4439,\n",
       "    257,\n",
       "    4097,\n",
       "    11,\n",
       "    3863,\n",
       "    262,\n",
       "    3554,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    6079,\n",
       "    262,\n",
       "    23972,\n",
       "    373,\n",
       "    1327,\n",
       "    11,\n",
       "    550,\n",
       "    3750,\n",
       "    2642,\n",
       "    11,\n",
       "    1223,\n",
       "    561,\n",
       "    423,\n",
       "    3022,\n",
       "    13,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5687498163293909,\n",
       "   'compression_ratio': 1.6704545454545454,\n",
       "   'no_speech_prob': 0.05312124267220497},\n",
       "  {'id': 245,\n",
       "   'seek': 99372,\n",
       "   'start': 993.72,\n",
       "   'end': 997.72,\n",
       "   'text': ' So in some very limited cases, the sample number could be used for the future.',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    287,\n",
       "    617,\n",
       "    845,\n",
       "    3614,\n",
       "    2663,\n",
       "    11,\n",
       "    262,\n",
       "    6291,\n",
       "    1271,\n",
       "    714,\n",
       "    307,\n",
       "    973,\n",
       "    329,\n",
       "    262,\n",
       "    2003,\n",
       "    13,\n",
       "    50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25687202247413427,\n",
       "   'compression_ratio': 1.7099236641221374,\n",
       "   'no_speech_prob': 0.02873552218079567},\n",
       "  {'id': 246,\n",
       "   'seek': 99372,\n",
       "   'start': 997.72,\n",
       "   'end': 1006.72,\n",
       "   'text': \" But it's more likely that it's probably better to include more features, which are capturing the types of things we are looking at.\",\n",
       "   'tokens': [50563,\n",
       "    887,\n",
       "    340,\n",
       "    338,\n",
       "    517,\n",
       "    1884,\n",
       "    326,\n",
       "    340,\n",
       "    338,\n",
       "    2192,\n",
       "    1365,\n",
       "    284,\n",
       "    2291,\n",
       "    517,\n",
       "    3033,\n",
       "    11,\n",
       "    543,\n",
       "    389,\n",
       "    21430,\n",
       "    262,\n",
       "    3858,\n",
       "    286,\n",
       "    1243,\n",
       "    356,\n",
       "    389,\n",
       "    2045,\n",
       "    379,\n",
       "    13,\n",
       "    51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25687202247413427,\n",
       "   'compression_ratio': 1.7099236641221374,\n",
       "   'no_speech_prob': 0.02873552218079567},\n",
       "  {'id': 247,\n",
       "   'seek': 99372,\n",
       "   'start': 1006.72,\n",
       "   'end': 1008.72,\n",
       "   'text': ' For example, what was its vehicle condition?',\n",
       "   'tokens': [51013, 1114, 1672, 11, 644, 373, 663, 4038, 4006, 30, 51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25687202247413427,\n",
       "   'compression_ratio': 1.7099236641221374,\n",
       "   'no_speech_prob': 0.02873552218079567},\n",
       "  {'id': 248,\n",
       "   'seek': 99372,\n",
       "   'start': 1008.72,\n",
       "   'end': 1012.72,\n",
       "   'text': ' How many hours have passed through the way it was made?',\n",
       "   'tokens': [51113,\n",
       "    1374,\n",
       "    867,\n",
       "    2250,\n",
       "    423,\n",
       "    3804,\n",
       "    832,\n",
       "    262,\n",
       "    835,\n",
       "    340,\n",
       "    373,\n",
       "    925,\n",
       "    30,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25687202247413427,\n",
       "   'compression_ratio': 1.7099236641221374,\n",
       "   'no_speech_prob': 0.02873552218079567},\n",
       "  {'id': 249,\n",
       "   'seek': 99372,\n",
       "   'start': 1012.72,\n",
       "   'end': 1014.72,\n",
       "   'text': ' Things like that.',\n",
       "   'tokens': [51313, 11597, 588, 326, 13, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25687202247413427,\n",
       "   'compression_ratio': 1.7099236641221374,\n",
       "   'no_speech_prob': 0.02873552218079567},\n",
       "  {'id': 250,\n",
       "   'seek': 99372,\n",
       "   'start': 1014.72,\n",
       "   'end': 1017.72,\n",
       "   'text': ' The sample number might be giving them this up.',\n",
       "   'tokens': [51413,\n",
       "    383,\n",
       "    6291,\n",
       "    1271,\n",
       "    1244,\n",
       "    307,\n",
       "    3501,\n",
       "    606,\n",
       "    428,\n",
       "    510,\n",
       "    13,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25687202247413427,\n",
       "   'compression_ratio': 1.7099236641221374,\n",
       "   'no_speech_prob': 0.02873552218079567},\n",
       "  {'id': 251,\n",
       "   'seek': 99372,\n",
       "   'start': 1017.72,\n",
       "   'end': 1021.72,\n",
       "   'text': ' But then this could be the same example as we saw in the last lecture.',\n",
       "   'tokens': [51563,\n",
       "    887,\n",
       "    788,\n",
       "    428,\n",
       "    714,\n",
       "    307,\n",
       "    262,\n",
       "    976,\n",
       "    1672,\n",
       "    355,\n",
       "    356,\n",
       "    2497,\n",
       "    287,\n",
       "    262,\n",
       "    938,\n",
       "    19143,\n",
       "    13,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25687202247413427,\n",
       "   'compression_ratio': 1.7099236641221374,\n",
       "   'no_speech_prob': 0.02873552218079567},\n",
       "  {'id': 252,\n",
       "   'seek': 102172,\n",
       "   'start': 1021.72,\n",
       "   'end': 1025.72,\n",
       "   'text': ' Where more ice beams means more sharp attacks.',\n",
       "   'tokens': [50363, 6350, 517, 4771, 26741, 1724, 517, 7786, 3434, 13, 50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25752280030069474,\n",
       "   'compression_ratio': 1.6201923076923077,\n",
       "   'no_speech_prob': 0.048792075365781784},\n",
       "  {'id': 253,\n",
       "   'seek': 102172,\n",
       "   'start': 1025.72,\n",
       "   'end': 1028.72,\n",
       "   'text': ' There was some correlation, but there was no correlation.',\n",
       "   'tokens': [50563,\n",
       "    1318,\n",
       "    373,\n",
       "    617,\n",
       "    16096,\n",
       "    11,\n",
       "    475,\n",
       "    612,\n",
       "    373,\n",
       "    645,\n",
       "    16096,\n",
       "    13,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25752280030069474,\n",
       "   'compression_ratio': 1.6201923076923077,\n",
       "   'no_speech_prob': 0.048792075365781784},\n",
       "  {'id': 254,\n",
       "   'seek': 102172,\n",
       "   'start': 1028.72,\n",
       "   'end': 1040.72,\n",
       "   'text': ' So we have thus discussed that the sample number is likely or unlikely to be a good feature depending on how we model the phone process.',\n",
       "   'tokens': [50713,\n",
       "    1406,\n",
       "    356,\n",
       "    423,\n",
       "    4145,\n",
       "    6693,\n",
       "    326,\n",
       "    262,\n",
       "    6291,\n",
       "    1271,\n",
       "    318,\n",
       "    1884,\n",
       "    393,\n",
       "    7485,\n",
       "    284,\n",
       "    307,\n",
       "    257,\n",
       "    922,\n",
       "    3895,\n",
       "    6906,\n",
       "    319,\n",
       "    703,\n",
       "    356,\n",
       "    2746,\n",
       "    262,\n",
       "    3072,\n",
       "    1429,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25752280030069474,\n",
       "   'compression_ratio': 1.6201923076923077,\n",
       "   'no_speech_prob': 0.048792075365781784},\n",
       "  {'id': 255,\n",
       "   'seek': 102172,\n",
       "   'start': 1040.72,\n",
       "   'end': 1043.72,\n",
       "   'text': \" So for now, let's ignore the sample number.\",\n",
       "   'tokens': [51313,\n",
       "    1406,\n",
       "    329,\n",
       "    783,\n",
       "    11,\n",
       "    1309,\n",
       "    338,\n",
       "    8856,\n",
       "    262,\n",
       "    6291,\n",
       "    1271,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25752280030069474,\n",
       "   'compression_ratio': 1.6201923076923077,\n",
       "   'no_speech_prob': 0.048792075365781784},\n",
       "  {'id': 256,\n",
       "   'seek': 102172,\n",
       "   'start': 1043.72,\n",
       "   'end': 1046.72,\n",
       "   'text': ' Imagine it does not provide any useful information.',\n",
       "   'tokens': [51463, 18450, 340, 857, 407, 2148, 597, 4465, 1321, 13, 51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25752280030069474,\n",
       "   'compression_ratio': 1.6201923076923077,\n",
       "   'no_speech_prob': 0.048792075365781784},\n",
       "  {'id': 257,\n",
       "   'seek': 104672,\n",
       "   'start': 1046.72,\n",
       "   'end': 1050.72,\n",
       "   'text': ' So then we have some data table, which looks like the problem.',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    788,\n",
       "    356,\n",
       "    423,\n",
       "    617,\n",
       "    1366,\n",
       "    3084,\n",
       "    11,\n",
       "    543,\n",
       "    3073,\n",
       "    588,\n",
       "    262,\n",
       "    1917,\n",
       "    13,\n",
       "    50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3617261822304029,\n",
       "   'compression_ratio': 1.5225225225225225,\n",
       "   'no_speech_prob': 0.12992818653583527},\n",
       "  {'id': 258,\n",
       "   'seek': 104672,\n",
       "   'start': 1050.72,\n",
       "   'end': 1056.72,\n",
       "   'text': ' We will call this entire table the training set.',\n",
       "   'tokens': [50563,\n",
       "    775,\n",
       "    481,\n",
       "    869,\n",
       "    428,\n",
       "    2104,\n",
       "    3084,\n",
       "    262,\n",
       "    3047,\n",
       "    900,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3617261822304029,\n",
       "   'compression_ratio': 1.5225225225225225,\n",
       "   'no_speech_prob': 0.12992818653583527},\n",
       "  {'id': 259,\n",
       "   'seek': 104672,\n",
       "   'start': 1056.72,\n",
       "   'end': 1061.72,\n",
       "   'text': \" And if you've noted, I have labeled them in different columns.\",\n",
       "   'tokens': [50863,\n",
       "    843,\n",
       "    611,\n",
       "    345,\n",
       "    1053,\n",
       "    4367,\n",
       "    11,\n",
       "    314,\n",
       "    423,\n",
       "    15494,\n",
       "    606,\n",
       "    287,\n",
       "    1180,\n",
       "    15180,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3617261822304029,\n",
       "   'compression_ratio': 1.5225225225225225,\n",
       "   'no_speech_prob': 0.12992818653583527},\n",
       "  {'id': 260,\n",
       "   'seek': 104672,\n",
       "   'start': 1061.72,\n",
       "   'end': 1064.72,\n",
       "   'text': ' Anyone wants to tell why they are different?',\n",
       "   'tokens': [51113, 17462, 3382, 284, 1560, 1521, 484, 389, 1180, 30, 51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3617261822304029,\n",
       "   'compression_ratio': 1.5225225225225225,\n",
       "   'no_speech_prob': 0.12992818653583527},\n",
       "  {'id': 261,\n",
       "   'seek': 104672,\n",
       "   'start': 1064.72,\n",
       "   'end': 1069.72,\n",
       "   'text': ' Okay, and put an output as a very technical term.',\n",
       "   'tokens': [51263,\n",
       "    16805,\n",
       "    11,\n",
       "    290,\n",
       "    1234,\n",
       "    281,\n",
       "    5072,\n",
       "    355,\n",
       "    257,\n",
       "    845,\n",
       "    6276,\n",
       "    3381,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3617261822304029,\n",
       "   'compression_ratio': 1.5225225225225225,\n",
       "   'no_speech_prob': 0.12992818653583527},\n",
       "  {'id': 262,\n",
       "   'seek': 104672,\n",
       "   'start': 1069.72,\n",
       "   'end': 1075.72,\n",
       "   'text': ' Any other term you could talk about these two paths of a so far way.',\n",
       "   'tokens': [51513,\n",
       "    4377,\n",
       "    584,\n",
       "    3381,\n",
       "    345,\n",
       "    714,\n",
       "    1561,\n",
       "    546,\n",
       "    777,\n",
       "    734,\n",
       "    13532,\n",
       "    286,\n",
       "    257,\n",
       "    523,\n",
       "    1290,\n",
       "    835,\n",
       "    13,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3617261822304029,\n",
       "   'compression_ratio': 1.5225225225225225,\n",
       "   'no_speech_prob': 0.12992818653583527},\n",
       "  {'id': 263,\n",
       "   'seek': 107572,\n",
       "   'start': 1075.72,\n",
       "   'end': 1078.72,\n",
       "   'text': ' So this looks like a matrix with real matrix.',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    428,\n",
       "    3073,\n",
       "    588,\n",
       "    257,\n",
       "    17593,\n",
       "    351,\n",
       "    1103,\n",
       "    17593,\n",
       "    13,\n",
       "    50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3721789405459449,\n",
       "   'compression_ratio': 1.941860465116279,\n",
       "   'no_speech_prob': 0.04835546389222145},\n",
       "  {'id': 264,\n",
       "   'seek': 107572,\n",
       "   'start': 1078.72,\n",
       "   'end': 1080.72,\n",
       "   'text': ' I think they get that performance.',\n",
       "   'tokens': [50513, 314, 892, 484, 651, 326, 2854, 13, 50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3721789405459449,\n",
       "   'compression_ratio': 1.941860465116279,\n",
       "   'no_speech_prob': 0.04835546389222145},\n",
       "  {'id': 265,\n",
       "   'seek': 107572,\n",
       "   'start': 1080.72,\n",
       "   'end': 1081.72,\n",
       "   'text': ' Experience and performance.',\n",
       "   'tokens': [50613, 16386, 290, 2854, 13, 50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3721789405459449,\n",
       "   'compression_ratio': 1.941860465116279,\n",
       "   'no_speech_prob': 0.04835546389222145},\n",
       "  {'id': 266,\n",
       "   'seek': 107572,\n",
       "   'start': 1081.72,\n",
       "   'end': 1084.72,\n",
       "   'text': ' So the condition is not very good performance.',\n",
       "   'tokens': [50663, 1406, 262, 4006, 318, 407, 845, 922, 2854, 13, 50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3721789405459449,\n",
       "   'compression_ratio': 1.941860465116279,\n",
       "   'no_speech_prob': 0.04835546389222145},\n",
       "  {'id': 267,\n",
       "   'seek': 107572,\n",
       "   'start': 1084.72,\n",
       "   'end': 1091.72,\n",
       "   'text': ' The condition is the annotation or the label or the output assigned to this particular item.',\n",
       "   'tokens': [50813,\n",
       "    383,\n",
       "    4006,\n",
       "    318,\n",
       "    262,\n",
       "    23025,\n",
       "    393,\n",
       "    262,\n",
       "    6167,\n",
       "    393,\n",
       "    262,\n",
       "    5072,\n",
       "    8686,\n",
       "    284,\n",
       "    428,\n",
       "    1948,\n",
       "    2378,\n",
       "    13,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3721789405459449,\n",
       "   'compression_ratio': 1.941860465116279,\n",
       "   'no_speech_prob': 0.04835546389222145},\n",
       "  {'id': 268,\n",
       "   'seek': 107572,\n",
       "   'start': 1091.72,\n",
       "   'end': 1094.72,\n",
       "   'text': ' So this is one parameter.',\n",
       "   'tokens': [51163, 1406, 428, 318, 530, 11507, 13, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3721789405459449,\n",
       "   'compression_ratio': 1.941860465116279,\n",
       "   'no_speech_prob': 0.04835546389222145},\n",
       "  {'id': 269,\n",
       "   'seek': 107572,\n",
       "   'start': 1094.72,\n",
       "   'end': 1096.72,\n",
       "   'text': ' The extra is one parameter.',\n",
       "   'tokens': [51313, 383, 3131, 318, 530, 11507, 13, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3721789405459449,\n",
       "   'compression_ratio': 1.941860465116279,\n",
       "   'no_speech_prob': 0.04835546389222145},\n",
       "  {'id': 270,\n",
       "   'seek': 107572,\n",
       "   'start': 1096.72,\n",
       "   'end': 1098.72,\n",
       "   'text': \" It's not very good performance.\",\n",
       "   'tokens': [51413, 632, 338, 407, 845, 922, 2854, 13, 51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3721789405459449,\n",
       "   'compression_ratio': 1.941860465116279,\n",
       "   'no_speech_prob': 0.04835546389222145},\n",
       "  {'id': 271,\n",
       "   'seek': 109872,\n",
       "   'start': 1099.72,\n",
       "   'end': 1105.72,\n",
       "   'text': ' We call these things as features, items, and code areas.',\n",
       "   'tokens': [50413,\n",
       "    775,\n",
       "    869,\n",
       "    777,\n",
       "    1243,\n",
       "    355,\n",
       "    3033,\n",
       "    11,\n",
       "    3709,\n",
       "    11,\n",
       "    290,\n",
       "    2438,\n",
       "    3006,\n",
       "    13,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.37173465887705487,\n",
       "   'compression_ratio': 1.727699530516432,\n",
       "   'no_speech_prob': 0.16502109169960022},\n",
       "  {'id': 272,\n",
       "   'seek': 109872,\n",
       "   'start': 1105.72,\n",
       "   'end': 1109.72,\n",
       "   'text': \" If we go back, let's look at the equation which I was asking.\",\n",
       "   'tokens': [50713,\n",
       "    1002,\n",
       "    356,\n",
       "    467,\n",
       "    736,\n",
       "    11,\n",
       "    1309,\n",
       "    338,\n",
       "    804,\n",
       "    379,\n",
       "    262,\n",
       "    16022,\n",
       "    543,\n",
       "    314,\n",
       "    373,\n",
       "    4737,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.37173465887705487,\n",
       "   'compression_ratio': 1.727699530516432,\n",
       "   'no_speech_prob': 0.16502109169960022},\n",
       "  {'id': 273,\n",
       "   'seek': 109872,\n",
       "   'start': 1109.72,\n",
       "   'end': 1112.72,\n",
       "   'text': ' What features do you think will be used?',\n",
       "   'tokens': [50913, 1867, 3033, 466, 345, 892, 481, 307, 973, 30, 51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.37173465887705487,\n",
       "   'compression_ratio': 1.727699530516432,\n",
       "   'no_speech_prob': 0.16502109169960022},\n",
       "  {'id': 274,\n",
       "   'seek': 109872,\n",
       "   'start': 1112.72,\n",
       "   'end': 1113.72,\n",
       "   'text': ' Make sense?',\n",
       "   'tokens': [51063, 6889, 2565, 30, 51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.37173465887705487,\n",
       "   'compression_ratio': 1.727699530516432,\n",
       "   'no_speech_prob': 0.16502109169960022},\n",
       "  {'id': 275,\n",
       "   'seek': 109872,\n",
       "   'start': 1113.72,\n",
       "   'end': 1115.72,\n",
       "   'text': ' These things are called features.',\n",
       "   'tokens': [51113, 2312, 1243, 389, 1444, 3033, 13, 51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.37173465887705487,\n",
       "   'compression_ratio': 1.727699530516432,\n",
       "   'no_speech_prob': 0.16502109169960022},\n",
       "  {'id': 276,\n",
       "   'seek': 109872,\n",
       "   'start': 1115.72,\n",
       "   'end': 1119.72,\n",
       "   'text': ' The first three columns in this table are called features.',\n",
       "   'tokens': [51213,\n",
       "    383,\n",
       "    717,\n",
       "    1115,\n",
       "    15180,\n",
       "    287,\n",
       "    428,\n",
       "    3084,\n",
       "    389,\n",
       "    1444,\n",
       "    3033,\n",
       "    13,\n",
       "    51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.37173465887705487,\n",
       "   'compression_ratio': 1.727699530516432,\n",
       "   'no_speech_prob': 0.16502109169960022},\n",
       "  {'id': 277,\n",
       "   'seek': 109872,\n",
       "   'start': 1119.72,\n",
       "   'end': 1122.72,\n",
       "   'text': ' They are telling us something useful about the parameter.',\n",
       "   'tokens': [51413,\n",
       "    1119,\n",
       "    389,\n",
       "    5149,\n",
       "    514,\n",
       "    1223,\n",
       "    4465,\n",
       "    546,\n",
       "    262,\n",
       "    11507,\n",
       "    13,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.37173465887705487,\n",
       "   'compression_ratio': 1.727699530516432,\n",
       "   'no_speech_prob': 0.16502109169960022},\n",
       "  {'id': 278,\n",
       "   'seek': 109872,\n",
       "   'start': 1122.72,\n",
       "   'end': 1125.72,\n",
       "   'text': ' What are the four features that are going on?',\n",
       "   'tokens': [51563,\n",
       "    1867,\n",
       "    389,\n",
       "    262,\n",
       "    1440,\n",
       "    3033,\n",
       "    326,\n",
       "    389,\n",
       "    1016,\n",
       "    319,\n",
       "    30,\n",
       "    51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.37173465887705487,\n",
       "   'compression_ratio': 1.727699530516432,\n",
       "   'no_speech_prob': 0.16502109169960022},\n",
       "  {'id': 279,\n",
       "   'seek': 112572,\n",
       "   'start': 1126.72,\n",
       "   'end': 1131.72,\n",
       "   'text': ' Those also equals, by the features that we have over here, they are all used anonymously.',\n",
       "   'tokens': [50413,\n",
       "    5845,\n",
       "    635,\n",
       "    21767,\n",
       "    11,\n",
       "    416,\n",
       "    262,\n",
       "    3033,\n",
       "    326,\n",
       "    356,\n",
       "    423,\n",
       "    625,\n",
       "    994,\n",
       "    11,\n",
       "    484,\n",
       "    389,\n",
       "    477,\n",
       "    973,\n",
       "    35373,\n",
       "    13,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47563650252971246,\n",
       "   'compression_ratio': 1.75,\n",
       "   'no_speech_prob': 0.06806159764528275},\n",
       "  {'id': 280,\n",
       "   'seek': 112572,\n",
       "   'start': 1131.72,\n",
       "   'end': 1134.72,\n",
       "   'text': ' But you will generally use features that are handy.',\n",
       "   'tokens': [50663,\n",
       "    887,\n",
       "    345,\n",
       "    481,\n",
       "    4143,\n",
       "    779,\n",
       "    3033,\n",
       "    326,\n",
       "    389,\n",
       "    15728,\n",
       "    13,\n",
       "    50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47563650252971246,\n",
       "   'compression_ratio': 1.75,\n",
       "   'no_speech_prob': 0.06806159764528275},\n",
       "  {'id': 281,\n",
       "   'seek': 112572,\n",
       "   'start': 1134.72,\n",
       "   'end': 1137.72,\n",
       "   'text': ' Obviates is generally used in some of the features.',\n",
       "   'tokens': [50813,\n",
       "    1835,\n",
       "    8903,\n",
       "    689,\n",
       "    318,\n",
       "    4143,\n",
       "    973,\n",
       "    287,\n",
       "    617,\n",
       "    286,\n",
       "    262,\n",
       "    3033,\n",
       "    13,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47563650252971246,\n",
       "   'compression_ratio': 1.75,\n",
       "   'no_speech_prob': 0.06806159764528275},\n",
       "  {'id': 282,\n",
       "   'seek': 112572,\n",
       "   'start': 1137.72,\n",
       "   'end': 1143.72,\n",
       "   'text': ' And the output of the condition in this case is called the output of the response wave',\n",
       "   'tokens': [50963,\n",
       "    843,\n",
       "    262,\n",
       "    5072,\n",
       "    286,\n",
       "    262,\n",
       "    4006,\n",
       "    287,\n",
       "    428,\n",
       "    1339,\n",
       "    318,\n",
       "    1444,\n",
       "    262,\n",
       "    5072,\n",
       "    286,\n",
       "    262,\n",
       "    2882,\n",
       "    6769,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47563650252971246,\n",
       "   'compression_ratio': 1.75,\n",
       "   'no_speech_prob': 0.06806159764528275},\n",
       "  {'id': 283,\n",
       "   'seek': 112572,\n",
       "   'start': 1143.72,\n",
       "   'end': 1147.72,\n",
       "   'text': \" and what is the response once you've observed some features.\",\n",
       "   'tokens': [51263,\n",
       "    290,\n",
       "    644,\n",
       "    318,\n",
       "    262,\n",
       "    2882,\n",
       "    1752,\n",
       "    345,\n",
       "    1053,\n",
       "    6515,\n",
       "    617,\n",
       "    3033,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47563650252971246,\n",
       "   'compression_ratio': 1.75,\n",
       "   'no_speech_prob': 0.06806159764528275},\n",
       "  {'id': 284,\n",
       "   'seek': 112572,\n",
       "   'start': 1147.72,\n",
       "   'end': 1148.72,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51463, 6498, 30, 51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47563650252971246,\n",
       "   'compression_ratio': 1.75,\n",
       "   'no_speech_prob': 0.06806159764528275},\n",
       "  {'id': 285,\n",
       "   'seek': 112572,\n",
       "   'start': 1148.72,\n",
       "   'end': 1152.72,\n",
       "   'text': ' Everyone, here to now.',\n",
       "   'tokens': [51513, 11075, 11, 994, 284, 783, 13, 51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47563650252971246,\n",
       "   'compression_ratio': 1.75,\n",
       "   'no_speech_prob': 0.06806159764528275},\n",
       "  {'id': 286,\n",
       "   'seek': 115272,\n",
       "   'start': 1153.72,\n",
       "   'end': 1156.72,\n",
       "   'text': ' Now, we call this a training set.',\n",
       "   'tokens': [50413, 2735, 11, 356, 869, 428, 257, 3047, 900, 13, 50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25711382352388823,\n",
       "   'compression_ratio': 1.5286624203821657,\n",
       "   'no_speech_prob': 0.016748905181884766},\n",
       "  {'id': 287,\n",
       "   'seek': 115272,\n",
       "   'start': 1156.72,\n",
       "   'end': 1159.72,\n",
       "   'text': \" And let's for now introduce a bit of populism.\",\n",
       "   'tokens': [50563,\n",
       "    843,\n",
       "    1309,\n",
       "    338,\n",
       "    329,\n",
       "    783,\n",
       "    10400,\n",
       "    257,\n",
       "    1643,\n",
       "    286,\n",
       "    47584,\n",
       "    13,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25711382352388823,\n",
       "   'compression_ratio': 1.5286624203821657,\n",
       "   'no_speech_prob': 0.016748905181884766},\n",
       "  {'id': 288,\n",
       "   'seek': 115272,\n",
       "   'start': 1159.72,\n",
       "   'end': 1163.72,\n",
       "   'text': ' We call this entire matrix as D.',\n",
       "   'tokens': [50713, 775, 869, 428, 2104, 17593, 355, 360, 13, 50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25711382352388823,\n",
       "   'compression_ratio': 1.5286624203821657,\n",
       "   'no_speech_prob': 0.016748905181884766},\n",
       "  {'id': 289,\n",
       "   'seek': 115272,\n",
       "   'start': 1163.72,\n",
       "   'end': 1164.72,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50913, 6498, 30, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25711382352388823,\n",
       "   'compression_ratio': 1.5286624203821657,\n",
       "   'no_speech_prob': 0.016748905181884766},\n",
       "  {'id': 290,\n",
       "   'seek': 115272,\n",
       "   'start': 1164.72,\n",
       "   'end': 1168.72,\n",
       "   'text': ' We call this feature matrix.',\n",
       "   'tokens': [50963, 775, 869, 428, 3895, 17593, 13, 51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25711382352388823,\n",
       "   'compression_ratio': 1.5286624203821657,\n",
       "   'no_speech_prob': 0.016748905181884766},\n",
       "  {'id': 291,\n",
       "   'seek': 115272,\n",
       "   'start': 1168.72,\n",
       "   'end': 1171.72,\n",
       "   'text': ' It contains N samples.',\n",
       "   'tokens': [51163, 632, 4909, 399, 8405, 13, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25711382352388823,\n",
       "   'compression_ratio': 1.5286624203821657,\n",
       "   'no_speech_prob': 0.016748905181884766},\n",
       "  {'id': 292,\n",
       "   'seek': 115272,\n",
       "   'start': 1171.72,\n",
       "   'end': 1173.72,\n",
       "   'text': ' What is N?',\n",
       "   'tokens': [51313, 1867, 318, 399, 30, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25711382352388823,\n",
       "   'compression_ratio': 1.5286624203821657,\n",
       "   'no_speech_prob': 0.016748905181884766},\n",
       "  {'id': 293,\n",
       "   'seek': 115272,\n",
       "   'start': 1173.72,\n",
       "   'end': 1175.72,\n",
       "   'text': ' N equals four samples.',\n",
       "   'tokens': [51413, 399, 21767, 1440, 8405, 13, 51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25711382352388823,\n",
       "   'compression_ratio': 1.5286624203821657,\n",
       "   'no_speech_prob': 0.016748905181884766},\n",
       "  {'id': 294,\n",
       "   'seek': 115272,\n",
       "   'start': 1175.72,\n",
       "   'end': 1181.72,\n",
       "   'text': ' And what is the features in this?',\n",
       "   'tokens': [51513, 843, 644, 318, 262, 3033, 287, 428, 30, 51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.25711382352388823,\n",
       "   'compression_ratio': 1.5286624203821657,\n",
       "   'no_speech_prob': 0.016748905181884766},\n",
       "  {'id': 295,\n",
       "   'seek': 118172,\n",
       "   'start': 1181.72,\n",
       "   'end': 1185.72,\n",
       "   'text': ' The number of features is color, size, and texture, which is three features.',\n",
       "   'tokens': [50363,\n",
       "    383,\n",
       "    1271,\n",
       "    286,\n",
       "    3033,\n",
       "    318,\n",
       "    3124,\n",
       "    11,\n",
       "    2546,\n",
       "    11,\n",
       "    290,\n",
       "    11743,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    1115,\n",
       "    3033,\n",
       "    13,\n",
       "    50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.29770954449971515,\n",
       "   'compression_ratio': 1.5056179775280898,\n",
       "   'no_speech_prob': 0.005151243880391121},\n",
       "  {'id': 296,\n",
       "   'seek': 118172,\n",
       "   'start': 1185.72,\n",
       "   'end': 1186.72,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50563, 6498, 30, 50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.29770954449971515,\n",
       "   'compression_ratio': 1.5056179775280898,\n",
       "   'no_speech_prob': 0.005151243880391121},\n",
       "  {'id': 297,\n",
       "   'seek': 118172,\n",
       "   'start': 1186.72,\n",
       "   'end': 1195.72,\n",
       "   'text': ' So the matrix X shown in the shader pane is a four rows three columns matrix.',\n",
       "   'tokens': [50613,\n",
       "    1406,\n",
       "    262,\n",
       "    17593,\n",
       "    1395,\n",
       "    3402,\n",
       "    287,\n",
       "    262,\n",
       "    33030,\n",
       "    37218,\n",
       "    318,\n",
       "    257,\n",
       "    1440,\n",
       "    15274,\n",
       "    1115,\n",
       "    15180,\n",
       "    17593,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.29770954449971515,\n",
       "   'compression_ratio': 1.5056179775280898,\n",
       "   'no_speech_prob': 0.005151243880391121},\n",
       "  {'id': 298,\n",
       "   'seek': 118172,\n",
       "   'start': 1195.72,\n",
       "   'end': 1199.72,\n",
       "   'text': ' It contains N samples, which are P and M. Right?',\n",
       "   'tokens': [51063,\n",
       "    632,\n",
       "    4909,\n",
       "    399,\n",
       "    8405,\n",
       "    11,\n",
       "    543,\n",
       "    389,\n",
       "    350,\n",
       "    290,\n",
       "    337,\n",
       "    13,\n",
       "    6498,\n",
       "    30,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.29770954449971515,\n",
       "   'compression_ratio': 1.5056179775280898,\n",
       "   'no_speech_prob': 0.005151243880391121},\n",
       "  {'id': 299,\n",
       "   'seek': 118172,\n",
       "   'start': 1199.72,\n",
       "   'end': 1206.72,\n",
       "   'text': ' We can write an individual sample as something like this.',\n",
       "   'tokens': [51263,\n",
       "    775,\n",
       "    460,\n",
       "    3551,\n",
       "    281,\n",
       "    1981,\n",
       "    6291,\n",
       "    355,\n",
       "    1223,\n",
       "    588,\n",
       "    428,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.29770954449971515,\n",
       "   'compression_ratio': 1.5056179775280898,\n",
       "   'no_speech_prob': 0.005151243880391121},\n",
       "  {'id': 300,\n",
       "   'seek': 120672,\n",
       "   'start': 1206.72,\n",
       "   'end': 1210.72,\n",
       "   'text': ' Like X1, we can write as orange, small, smooth.',\n",
       "   'tokens': [50363,\n",
       "    4525,\n",
       "    1395,\n",
       "    16,\n",
       "    11,\n",
       "    356,\n",
       "    460,\n",
       "    3551,\n",
       "    355,\n",
       "    10912,\n",
       "    11,\n",
       "    1402,\n",
       "    11,\n",
       "    7209,\n",
       "    13,\n",
       "    50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21595845639126973,\n",
       "   'compression_ratio': 1.6384976525821595,\n",
       "   'no_speech_prob': 0.2496437430381775},\n",
       "  {'id': 301,\n",
       "   'seek': 120672,\n",
       "   'start': 1210.72,\n",
       "   'end': 1212.72,\n",
       "   'text': ' Orange, small, smooth.',\n",
       "   'tokens': [50563, 11942, 11, 1402, 11, 7209, 13, 50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21595845639126973,\n",
       "   'compression_ratio': 1.6384976525821595,\n",
       "   'no_speech_prob': 0.2496437430381775},\n",
       "  {'id': 302,\n",
       "   'seek': 120672,\n",
       "   'start': 1212.72,\n",
       "   'end': 1213.72,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50663, 6498, 30, 50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21595845639126973,\n",
       "   'compression_ratio': 1.6384976525821595,\n",
       "   'no_speech_prob': 0.2496437430381775},\n",
       "  {'id': 303,\n",
       "   'seek': 120672,\n",
       "   'start': 1213.72,\n",
       "   'end': 1219.72,\n",
       "   'text': ' Does anyone want to tell you why X1 is written in a column format where in this particular',\n",
       "   'tokens': [50713,\n",
       "    8314,\n",
       "    2687,\n",
       "    765,\n",
       "    284,\n",
       "    1560,\n",
       "    345,\n",
       "    1521,\n",
       "    1395,\n",
       "    16,\n",
       "    318,\n",
       "    3194,\n",
       "    287,\n",
       "    257,\n",
       "    5721,\n",
       "    5794,\n",
       "    810,\n",
       "    287,\n",
       "    428,\n",
       "    1948,\n",
       "    51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21595845639126973,\n",
       "   'compression_ratio': 1.6384976525821595,\n",
       "   'no_speech_prob': 0.2496437430381775},\n",
       "  {'id': 304,\n",
       "   'seek': 120672,\n",
       "   'start': 1219.72,\n",
       "   'end': 1223.72,\n",
       "   'text': ' matrix X1 appears in a row?',\n",
       "   'tokens': [51013, 17593, 1395, 16, 3568, 287, 257, 5752, 30, 51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21595845639126973,\n",
       "   'compression_ratio': 1.6384976525821595,\n",
       "   'no_speech_prob': 0.2496437430381775},\n",
       "  {'id': 305,\n",
       "   'seek': 120672,\n",
       "   'start': 1223.72,\n",
       "   'end': 1224.72,\n",
       "   'text': ' Why?',\n",
       "   'tokens': [51213, 4162, 30, 51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21595845639126973,\n",
       "   'compression_ratio': 1.6384976525821595,\n",
       "   'no_speech_prob': 0.2496437430381775},\n",
       "  {'id': 306,\n",
       "   'seek': 120672,\n",
       "   'start': 1224.72,\n",
       "   'end': 1226.72,\n",
       "   'text': ' That is the operation.',\n",
       "   'tokens': [51263, 1320, 318, 262, 4905, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21595845639126973,\n",
       "   'compression_ratio': 1.6384976525821595,\n",
       "   'no_speech_prob': 0.2496437430381775},\n",
       "  {'id': 307,\n",
       "   'seek': 120672,\n",
       "   'start': 1226.72,\n",
       "   'end': 1227.72,\n",
       "   'text': ' Yes.',\n",
       "   'tokens': [51363, 3363, 13, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21595845639126973,\n",
       "   'compression_ratio': 1.6384976525821595,\n",
       "   'no_speech_prob': 0.2496437430381775},\n",
       "  {'id': 308,\n",
       "   'seek': 120672,\n",
       "   'start': 1227.72,\n",
       "   'end': 1233.72,\n",
       "   'text': ' So typically when you consider the features or you consider a particular sample, you consider',\n",
       "   'tokens': [51413,\n",
       "    1406,\n",
       "    6032,\n",
       "    618,\n",
       "    345,\n",
       "    2074,\n",
       "    262,\n",
       "    3033,\n",
       "    393,\n",
       "    345,\n",
       "    2074,\n",
       "    257,\n",
       "    1948,\n",
       "    6291,\n",
       "    11,\n",
       "    345,\n",
       "    2074,\n",
       "    51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21595845639126973,\n",
       "   'compression_ratio': 1.6384976525821595,\n",
       "   'no_speech_prob': 0.2496437430381775},\n",
       "  {'id': 309,\n",
       "   'seek': 120672,\n",
       "   'start': 1233.72,\n",
       "   'end': 1235.72,\n",
       "   'text': ' that to be a form vector.',\n",
       "   'tokens': [51713, 326, 284, 307, 257, 1296, 15879, 13, 51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21595845639126973,\n",
       "   'compression_ratio': 1.6384976525821595,\n",
       "   'no_speech_prob': 0.2496437430381775},\n",
       "  {'id': 310,\n",
       "   'seek': 123572,\n",
       "   'start': 1235.72,\n",
       "   'end': 1240.72,\n",
       "   'text': ' So this is where now we started to produce a little bit of annotations.',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    428,\n",
       "    318,\n",
       "    810,\n",
       "    783,\n",
       "    356,\n",
       "    2067,\n",
       "    284,\n",
       "    4439,\n",
       "    257,\n",
       "    1310,\n",
       "    1643,\n",
       "    286,\n",
       "    37647,\n",
       "    13,\n",
       "    50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38357145744457577,\n",
       "   'compression_ratio': 1.5764192139737991,\n",
       "   'no_speech_prob': 0.03141066059470177},\n",
       "  {'id': 311,\n",
       "   'seek': 123572,\n",
       "   'start': 1240.72,\n",
       "   'end': 1246.72,\n",
       "   'text': ' Eight sample is a column vector, which is what I am interested on.',\n",
       "   'tokens': [50613,\n",
       "    18087,\n",
       "    6291,\n",
       "    318,\n",
       "    257,\n",
       "    5721,\n",
       "    15879,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    644,\n",
       "    314,\n",
       "    716,\n",
       "    4609,\n",
       "    319,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38357145744457577,\n",
       "   'compression_ratio': 1.5764192139737991,\n",
       "   'no_speech_prob': 0.03141066059470177},\n",
       "  {'id': 312,\n",
       "   'seek': 123572,\n",
       "   'start': 1246.72,\n",
       "   'end': 1248.72,\n",
       "   'text': ' What is the dimension of this?',\n",
       "   'tokens': [50913, 1867, 318, 262, 15793, 286, 428, 30, 51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38357145744457577,\n",
       "   'compression_ratio': 1.5764192139737991,\n",
       "   'no_speech_prob': 0.03141066059470177},\n",
       "  {'id': 313,\n",
       "   'seek': 123572,\n",
       "   'start': 1248.72,\n",
       "   'end': 1251.72,\n",
       "   'text': ' P dot N equal to P in this case.',\n",
       "   'tokens': [51013,\n",
       "    350,\n",
       "    16605,\n",
       "    399,\n",
       "    4961,\n",
       "    284,\n",
       "    350,\n",
       "    287,\n",
       "    428,\n",
       "    1339,\n",
       "    13,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38357145744457577,\n",
       "   'compression_ratio': 1.5764192139737991,\n",
       "   'no_speech_prob': 0.03141066059470177},\n",
       "  {'id': 314,\n",
       "   'seek': 123572,\n",
       "   'start': 1251.72,\n",
       "   'end': 1252.72,\n",
       "   'text': ' Orange, small, smooth.',\n",
       "   'tokens': [51163, 11942, 11, 1402, 11, 7209, 13, 51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38357145744457577,\n",
       "   'compression_ratio': 1.5764192139737991,\n",
       "   'no_speech_prob': 0.03141066059470177},\n",
       "  {'id': 315,\n",
       "   'seek': 123572,\n",
       "   'start': 1252.72,\n",
       "   'end': 1253.72,\n",
       "   'text': ' P. Right?',\n",
       "   'tokens': [51213, 350, 13, 6498, 30, 51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38357145744457577,\n",
       "   'compression_ratio': 1.5764192139737991,\n",
       "   'no_speech_prob': 0.03141066059470177},\n",
       "  {'id': 316,\n",
       "   'seek': 123572,\n",
       "   'start': 1253.72,\n",
       "   'end': 1260.72,\n",
       "   'text': ' Does camera X as XI transpose where I is from month to month.',\n",
       "   'tokens': [51263,\n",
       "    8314,\n",
       "    4676,\n",
       "    1395,\n",
       "    355,\n",
       "    1395,\n",
       "    40,\n",
       "    1007,\n",
       "    3455,\n",
       "    810,\n",
       "    314,\n",
       "    318,\n",
       "    422,\n",
       "    1227,\n",
       "    284,\n",
       "    1227,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38357145744457577,\n",
       "   'compression_ratio': 1.5764192139737991,\n",
       "   'no_speech_prob': 0.03141066059470177},\n",
       "  {'id': 317,\n",
       "   'seek': 123572,\n",
       "   'start': 1260.72,\n",
       "   'end': 1261.72,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51613, 6498, 30, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38357145744457577,\n",
       "   'compression_ratio': 1.5764192139737991,\n",
       "   'no_speech_prob': 0.03141066059470177},\n",
       "  {'id': 318,\n",
       "   'seek': 123572,\n",
       "   'start': 1261.72,\n",
       "   'end': 1262.72,\n",
       "   'text': ' This is X1 transpose.',\n",
       "   'tokens': [51663, 770, 318, 1395, 16, 1007, 3455, 13, 51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38357145744457577,\n",
       "   'compression_ratio': 1.5764192139737991,\n",
       "   'no_speech_prob': 0.03141066059470177},\n",
       "  {'id': 319,\n",
       "   'seek': 123572,\n",
       "   'start': 1262.72,\n",
       "   'end': 1264.72,\n",
       "   'text': ' This is X2 transpose with our row.',\n",
       "   'tokens': [51713,\n",
       "    770,\n",
       "    318,\n",
       "    1395,\n",
       "    17,\n",
       "    1007,\n",
       "    3455,\n",
       "    351,\n",
       "    674,\n",
       "    5752,\n",
       "    13,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38357145744457577,\n",
       "   'compression_ratio': 1.5764192139737991,\n",
       "   'no_speech_prob': 0.03141066059470177},\n",
       "  {'id': 320,\n",
       "   'seek': 126472,\n",
       "   'start': 1264.72,\n",
       "   'end': 1271.72,\n",
       "   'text': ' This is, in fact, the third row is X3 transpose and X4 transpose.',\n",
       "   'tokens': [50363,\n",
       "    770,\n",
       "    318,\n",
       "    11,\n",
       "    287,\n",
       "    1109,\n",
       "    11,\n",
       "    262,\n",
       "    2368,\n",
       "    5752,\n",
       "    318,\n",
       "    1395,\n",
       "    18,\n",
       "    1007,\n",
       "    3455,\n",
       "    290,\n",
       "    1395,\n",
       "    19,\n",
       "    1007,\n",
       "    3455,\n",
       "    13,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.315645331767068,\n",
       "   'compression_ratio': 1.4090909090909092,\n",
       "   'no_speech_prob': 0.0533023402094841},\n",
       "  {'id': 321,\n",
       "   'seek': 126472,\n",
       "   'start': 1271.72,\n",
       "   'end': 1272.72,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50713, 6498, 30, 50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.315645331767068,\n",
       "   'compression_ratio': 1.4090909090909092,\n",
       "   'no_speech_prob': 0.0533023402094841},\n",
       "  {'id': 322,\n",
       "   'seek': 126472,\n",
       "   'start': 1272.72,\n",
       "   'end': 1279.72,\n",
       "   'text': ' So we are able to now write the matrix X in terms of the individual elements.',\n",
       "   'tokens': [50763,\n",
       "    1406,\n",
       "    356,\n",
       "    389,\n",
       "    1498,\n",
       "    284,\n",
       "    783,\n",
       "    3551,\n",
       "    262,\n",
       "    17593,\n",
       "    1395,\n",
       "    287,\n",
       "    2846,\n",
       "    286,\n",
       "    262,\n",
       "    1981,\n",
       "    4847,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.315645331767068,\n",
       "   'compression_ratio': 1.4090909090909092,\n",
       "   'no_speech_prob': 0.0533023402094841},\n",
       "  {'id': 323,\n",
       "   'seek': 126472,\n",
       "   'start': 1279.72,\n",
       "   'end': 1288.96,\n",
       "   'text': ' So when we have an output vector Y, now this is going to be Y non-',\n",
       "   'tokens': [51113,\n",
       "    1406,\n",
       "    618,\n",
       "    356,\n",
       "    423,\n",
       "    281,\n",
       "    5072,\n",
       "    15879,\n",
       "    575,\n",
       "    11,\n",
       "    783,\n",
       "    428,\n",
       "    318,\n",
       "    1016,\n",
       "    284,\n",
       "    307,\n",
       "    575,\n",
       "    1729,\n",
       "    12,\n",
       "    51575],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.315645331767068,\n",
       "   'compression_ratio': 1.4090909090909092,\n",
       "   'no_speech_prob': 0.0533023402094841},\n",
       "  {'id': 324,\n",
       "   'seek': 128896,\n",
       "   'start': 1288.96,\n",
       "   'end': 1289.96,\n",
       "   'text': ' output, we have a single output.',\n",
       "   'tokens': [50363, 5072, 11, 356, 423, 257, 2060, 5072, 13, 50413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2973098955656353,\n",
       "   'compression_ratio': 1.719387755102041,\n",
       "   'no_speech_prob': 0.5250136852264404},\n",
       "  {'id': 325,\n",
       "   'seek': 128896,\n",
       "   'start': 1289.96,\n",
       "   'end': 1296.96,\n",
       "   'text': ' Single output variable or response variable, which is going to be R N. Right?',\n",
       "   'tokens': [50413,\n",
       "    14206,\n",
       "    5072,\n",
       "    7885,\n",
       "    393,\n",
       "    2882,\n",
       "    7885,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    1016,\n",
       "    284,\n",
       "    307,\n",
       "    371,\n",
       "    399,\n",
       "    13,\n",
       "    6498,\n",
       "    30,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2973098955656353,\n",
       "   'compression_ratio': 1.719387755102041,\n",
       "   'no_speech_prob': 0.5250136852264404},\n",
       "  {'id': 326,\n",
       "   'seek': 128896,\n",
       "   'start': 1296.96,\n",
       "   'end': 1298.96,\n",
       "   'text': ' Because we have any examples.',\n",
       "   'tokens': [50763, 4362, 356, 423, 597, 6096, 13, 50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2973098955656353,\n",
       "   'compression_ratio': 1.719387755102041,\n",
       "   'no_speech_prob': 0.5250136852264404},\n",
       "  {'id': 327,\n",
       "   'seek': 128896,\n",
       "   'start': 1298.96,\n",
       "   'end': 1309.96,\n",
       "   'text': ' Can we thus write this training set D as a set where we have XI transpose from a YI and',\n",
       "   'tokens': [50863,\n",
       "    1680,\n",
       "    356,\n",
       "    4145,\n",
       "    3551,\n",
       "    428,\n",
       "    3047,\n",
       "    900,\n",
       "    360,\n",
       "    355,\n",
       "    257,\n",
       "    900,\n",
       "    810,\n",
       "    356,\n",
       "    423,\n",
       "    1395,\n",
       "    40,\n",
       "    1007,\n",
       "    3455,\n",
       "    422,\n",
       "    257,\n",
       "    575,\n",
       "    40,\n",
       "    290,\n",
       "    51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2973098955656353,\n",
       "   'compression_ratio': 1.719387755102041,\n",
       "   'no_speech_prob': 0.5250136852264404},\n",
       "  {'id': 328,\n",
       "   'seek': 128896,\n",
       "   'start': 1309.96,\n",
       "   'end': 1311.96,\n",
       "   'text': ' I release from month to month.',\n",
       "   'tokens': [51413, 314, 2650, 422, 1227, 284, 1227, 13, 51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2973098955656353,\n",
       "   'compression_ratio': 1.719387755102041,\n",
       "   'no_speech_prob': 0.5250136852264404},\n",
       "  {'id': 329,\n",
       "   'seek': 128896,\n",
       "   'start': 1311.96,\n",
       "   'end': 1312.96,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51513, 6498, 30, 51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2973098955656353,\n",
       "   'compression_ratio': 1.719387755102041,\n",
       "   'no_speech_prob': 0.5250136852264404},\n",
       "  {'id': 330,\n",
       "   'seek': 128896,\n",
       "   'start': 1312.96,\n",
       "   'end': 1316.96,\n",
       "   'text': ' So this way we are able to be able to create this entire training set.',\n",
       "   'tokens': [51563,\n",
       "    1406,\n",
       "    428,\n",
       "    835,\n",
       "    356,\n",
       "    389,\n",
       "    1498,\n",
       "    284,\n",
       "    307,\n",
       "    1498,\n",
       "    284,\n",
       "    2251,\n",
       "    428,\n",
       "    2104,\n",
       "    3047,\n",
       "    900,\n",
       "    13,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2973098955656353,\n",
       "   'compression_ratio': 1.719387755102041,\n",
       "   'no_speech_prob': 0.5250136852264404},\n",
       "  {'id': 331,\n",
       "   'seek': 131696,\n",
       "   'start': 1316.96,\n",
       "   'end': 1320.96,\n",
       "   'text': ' And it can size comma depending on the I X sample.',\n",
       "   'tokens': [50363,\n",
       "    843,\n",
       "    340,\n",
       "    460,\n",
       "    2546,\n",
       "    39650,\n",
       "    6906,\n",
       "    319,\n",
       "    262,\n",
       "    314,\n",
       "    1395,\n",
       "    6291,\n",
       "    13,\n",
       "    50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4345002763726738,\n",
       "   'compression_ratio': 1.4761904761904763,\n",
       "   'no_speech_prob': 0.038957834243774414},\n",
       "  {'id': 332,\n",
       "   'seek': 131696,\n",
       "   'start': 1320.96,\n",
       "   'end': 1321.96,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50563, 6498, 30, 50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4345002763726738,\n",
       "   'compression_ratio': 1.4761904761904763,\n",
       "   'no_speech_prob': 0.038957834243774414},\n",
       "  {'id': 333,\n",
       "   'seek': 131696,\n",
       "   'start': 1321.96,\n",
       "   'end': 1328.96,\n",
       "   'text': ' So again, XI belongs to, is a B M integral vector and Y is an N M integral vector.',\n",
       "   'tokens': [50613,\n",
       "    1406,\n",
       "    757,\n",
       "    11,\n",
       "    1395,\n",
       "    40,\n",
       "    14448,\n",
       "    284,\n",
       "    11,\n",
       "    318,\n",
       "    257,\n",
       "    347,\n",
       "    337,\n",
       "    19287,\n",
       "    15879,\n",
       "    290,\n",
       "    575,\n",
       "    318,\n",
       "    281,\n",
       "    399,\n",
       "    337,\n",
       "    19287,\n",
       "    15879,\n",
       "    13,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4345002763726738,\n",
       "   'compression_ratio': 1.4761904761904763,\n",
       "   'no_speech_prob': 0.038957834243774414},\n",
       "  {'id': 334,\n",
       "   'seek': 131696,\n",
       "   'start': 1328.96,\n",
       "   'end': 1332.96,\n",
       "   'text': ' Everyone clear this part?',\n",
       "   'tokens': [50963, 11075, 1598, 428, 636, 30, 51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4345002763726738,\n",
       "   'compression_ratio': 1.4761904761904763,\n",
       "   'no_speech_prob': 0.038957834243774414},\n",
       "  {'id': 335,\n",
       "   'seek': 131696,\n",
       "   'start': 1332.96,\n",
       "   'end': 1339.96,\n",
       "   'text': ' Now, the prediction tasks, this is where machine learning lengths usually.',\n",
       "   'tokens': [51163,\n",
       "    2735,\n",
       "    11,\n",
       "    262,\n",
       "    17724,\n",
       "    8861,\n",
       "    11,\n",
       "    428,\n",
       "    318,\n",
       "    810,\n",
       "    4572,\n",
       "    4673,\n",
       "    20428,\n",
       "    3221,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4345002763726738,\n",
       "   'compression_ratio': 1.4761904761904763,\n",
       "   'no_speech_prob': 0.038957834243774414},\n",
       "  {'id': 336,\n",
       "   'seek': 131696,\n",
       "   'start': 1339.96,\n",
       "   'end': 1340.96,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51513, 6498, 30, 51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4345002763726738,\n",
       "   'compression_ratio': 1.4761904761904763,\n",
       "   'no_speech_prob': 0.038957834243774414},\n",
       "  {'id': 337,\n",
       "   'seek': 131696,\n",
       "   'start': 1340.96,\n",
       "   'end': 1344.96,\n",
       "   'text': ' If you only have trained set, there is no access used for it.',\n",
       "   'tokens': [51563,\n",
       "    1002,\n",
       "    345,\n",
       "    691,\n",
       "    423,\n",
       "    8776,\n",
       "    900,\n",
       "    11,\n",
       "    612,\n",
       "    318,\n",
       "    645,\n",
       "    1895,\n",
       "    973,\n",
       "    329,\n",
       "    340,\n",
       "    13,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4345002763726738,\n",
       "   'compression_ratio': 1.4761904761904763,\n",
       "   'no_speech_prob': 0.038957834243774414},\n",
       "  {'id': 338,\n",
       "   'seek': 134496,\n",
       "   'start': 1344.96,\n",
       "   'end': 1350.96,\n",
       "   'text': ' What you wanted to do was for unseen samples of course for these samples for which a human',\n",
       "   'tokens': [50363,\n",
       "    1867,\n",
       "    345,\n",
       "    2227,\n",
       "    284,\n",
       "    466,\n",
       "    373,\n",
       "    329,\n",
       "    29587,\n",
       "    8405,\n",
       "    286,\n",
       "    1781,\n",
       "    329,\n",
       "    777,\n",
       "    8405,\n",
       "    329,\n",
       "    543,\n",
       "    257,\n",
       "    1692,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4728837694440569,\n",
       "   'compression_ratio': 1.6801801801801801,\n",
       "   'no_speech_prob': 0.10845834761857986},\n",
       "  {'id': 339,\n",
       "   'seek': 134496,\n",
       "   'start': 1350.96,\n",
       "   'end': 1353.96,\n",
       "   'text': ' has not yet annotated as a good commit or a bad commit.',\n",
       "   'tokens': [50663,\n",
       "    468,\n",
       "    407,\n",
       "    1865,\n",
       "    24708,\n",
       "    515,\n",
       "    355,\n",
       "    257,\n",
       "    922,\n",
       "    4589,\n",
       "    393,\n",
       "    257,\n",
       "    2089,\n",
       "    4589,\n",
       "    13,\n",
       "    50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4728837694440569,\n",
       "   'compression_ratio': 1.6801801801801801,\n",
       "   'no_speech_prob': 0.10845834761857986},\n",
       "  {'id': 340,\n",
       "   'seek': 134496,\n",
       "   'start': 1353.96,\n",
       "   'end': 1360.96,\n",
       "   'text': ' You want them to be fast in the seminary and compute the vision approach which there is',\n",
       "   'tokens': [50813,\n",
       "    921,\n",
       "    765,\n",
       "    606,\n",
       "    284,\n",
       "    307,\n",
       "    3049,\n",
       "    287,\n",
       "    262,\n",
       "    5026,\n",
       "    3219,\n",
       "    290,\n",
       "    24061,\n",
       "    262,\n",
       "    5761,\n",
       "    3164,\n",
       "    543,\n",
       "    612,\n",
       "    318,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4728837694440569,\n",
       "   'compression_ratio': 1.6801801801801801,\n",
       "   'no_speech_prob': 0.10845834761857986},\n",
       "  {'id': 341,\n",
       "   'seek': 134496,\n",
       "   'start': 1360.96,\n",
       "   'end': 1364.96,\n",
       "   'text': ' on camera, which is looking at these, the videos you want to play in the policy condition for',\n",
       "   'tokens': [51163,\n",
       "    319,\n",
       "    4676,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    2045,\n",
       "    379,\n",
       "    777,\n",
       "    11,\n",
       "    262,\n",
       "    5861,\n",
       "    345,\n",
       "    765,\n",
       "    284,\n",
       "    711,\n",
       "    287,\n",
       "    262,\n",
       "    2450,\n",
       "    4006,\n",
       "    329,\n",
       "    51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4728837694440569,\n",
       "   'compression_ratio': 1.6801801801801801,\n",
       "   'no_speech_prob': 0.10845834761857986},\n",
       "  {'id': 342,\n",
       "   'seek': 134496,\n",
       "   'start': 1364.96,\n",
       "   'end': 1365.96,\n",
       "   'text': ' it.',\n",
       "   'tokens': [51363, 340, 13, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4728837694440569,\n",
       "   'compression_ratio': 1.6801801801801801,\n",
       "   'no_speech_prob': 0.10845834761857986},\n",
       "  {'id': 343,\n",
       "   'seek': 134496,\n",
       "   'start': 1365.96,\n",
       "   'end': 1366.96,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51413, 6498, 30, 51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4728837694440569,\n",
       "   'compression_ratio': 1.6801801801801801,\n",
       "   'no_speech_prob': 0.10845834761857986},\n",
       "  {'id': 344,\n",
       "   'seek': 134496,\n",
       "   'start': 1366.96,\n",
       "   'end': 1368.96,\n",
       "   'text': ' This is a goal clear to everyone.',\n",
       "   'tokens': [51463, 770, 318, 257, 3061, 1598, 284, 2506, 13, 51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4728837694440569,\n",
       "   'compression_ratio': 1.6801801801801801,\n",
       "   'no_speech_prob': 0.10845834761857986},\n",
       "  {'id': 345,\n",
       "   'seek': 136896,\n",
       "   'start': 1369.96,\n",
       "   'end': 1375.96,\n",
       "   'text': \" So for future unseen tomatoes of which you don't have a human annotated answer, you want\",\n",
       "   'tokens': [50413,\n",
       "    1406,\n",
       "    329,\n",
       "    2003,\n",
       "    29587,\n",
       "    23972,\n",
       "    286,\n",
       "    543,\n",
       "    345,\n",
       "    836,\n",
       "    470,\n",
       "    423,\n",
       "    257,\n",
       "    1692,\n",
       "    24708,\n",
       "    515,\n",
       "    3280,\n",
       "    11,\n",
       "    345,\n",
       "    765,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24674718066899462,\n",
       "   'compression_ratio': 1.7012448132780082,\n",
       "   'no_speech_prob': 0.4615545868873596},\n",
       "  {'id': 346,\n",
       "   'seek': 136896,\n",
       "   'start': 1375.96,\n",
       "   'end': 1380.96,\n",
       "   'text': ' to tell whether the condition is better bad and then you want to call it a process.',\n",
       "   'tokens': [50713,\n",
       "    284,\n",
       "    1560,\n",
       "    1771,\n",
       "    262,\n",
       "    4006,\n",
       "    318,\n",
       "    1365,\n",
       "    2089,\n",
       "    290,\n",
       "    788,\n",
       "    345,\n",
       "    765,\n",
       "    284,\n",
       "    869,\n",
       "    340,\n",
       "    257,\n",
       "    1429,\n",
       "    13,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24674718066899462,\n",
       "   'compression_ratio': 1.7012448132780082,\n",
       "   'no_speech_prob': 0.4615545868873596},\n",
       "  {'id': 347,\n",
       "   'seek': 136896,\n",
       "   'start': 1380.96,\n",
       "   'end': 1387.96,\n",
       "   'text': ' So we have for these unseen samples that I would draw a line to separate these out.',\n",
       "   'tokens': [50963,\n",
       "    1406,\n",
       "    356,\n",
       "    423,\n",
       "    329,\n",
       "    777,\n",
       "    29587,\n",
       "    8405,\n",
       "    326,\n",
       "    314,\n",
       "    561,\n",
       "    3197,\n",
       "    257,\n",
       "    1627,\n",
       "    284,\n",
       "    4553,\n",
       "    777,\n",
       "    503,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24674718066899462,\n",
       "   'compression_ratio': 1.7012448132780082,\n",
       "   'no_speech_prob': 0.4615545868873596},\n",
       "  {'id': 348,\n",
       "   'seek': 136896,\n",
       "   'start': 1387.96,\n",
       "   'end': 1390.96,\n",
       "   'text': ' For these unseen samples we still observe the input features.',\n",
       "   'tokens': [51313,\n",
       "    1114,\n",
       "    777,\n",
       "    29587,\n",
       "    8405,\n",
       "    356,\n",
       "    991,\n",
       "    12414,\n",
       "    262,\n",
       "    5128,\n",
       "    3033,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24674718066899462,\n",
       "   'compression_ratio': 1.7012448132780082,\n",
       "   'no_speech_prob': 0.4615545868873596},\n",
       "  {'id': 349,\n",
       "   'seek': 136896,\n",
       "   'start': 1390.96,\n",
       "   'end': 1396.96,\n",
       "   'text': ' We still observe the color, size and texture as given by the computer vision system.',\n",
       "   'tokens': [51463,\n",
       "    775,\n",
       "    991,\n",
       "    12414,\n",
       "    262,\n",
       "    3124,\n",
       "    11,\n",
       "    2546,\n",
       "    290,\n",
       "    11743,\n",
       "    355,\n",
       "    1813,\n",
       "    416,\n",
       "    262,\n",
       "    3644,\n",
       "    5761,\n",
       "    1080,\n",
       "    13,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24674718066899462,\n",
       "   'compression_ratio': 1.7012448132780082,\n",
       "   'no_speech_prob': 0.4615545868873596},\n",
       "  {'id': 350,\n",
       "   'seek': 136896,\n",
       "   'start': 1396.96,\n",
       "   'end': 1397.96,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51763, 6498, 30, 51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24674718066899462,\n",
       "   'compression_ratio': 1.7012448132780082,\n",
       "   'no_speech_prob': 0.4615545868873596},\n",
       "  {'id': 351,\n",
       "   'seek': 139796,\n",
       "   'start': 1397.96,\n",
       "   'end': 1403.96,\n",
       "   'text': \" But we don't know the condition and that is what we're trying to do.\",\n",
       "   'tokens': [50363,\n",
       "    887,\n",
       "    356,\n",
       "    836,\n",
       "    470,\n",
       "    760,\n",
       "    262,\n",
       "    4006,\n",
       "    290,\n",
       "    326,\n",
       "    318,\n",
       "    644,\n",
       "    356,\n",
       "    821,\n",
       "    2111,\n",
       "    284,\n",
       "    466,\n",
       "    13,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22485913401064667,\n",
       "   'compression_ratio': 1.6476190476190475,\n",
       "   'no_speech_prob': 0.023081772029399872},\n",
       "  {'id': 352,\n",
       "   'seek': 139796,\n",
       "   'start': 1403.96,\n",
       "   'end': 1404.96,\n",
       "   'text': ' Yeah?',\n",
       "   'tokens': [50663, 9425, 30, 50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22485913401064667,\n",
       "   'compression_ratio': 1.6476190476190475,\n",
       "   'no_speech_prob': 0.023081772029399872},\n",
       "  {'id': 353,\n",
       "   'seek': 139796,\n",
       "   'start': 1404.96,\n",
       "   'end': 1408.96,\n",
       "   'text': ' We now break this whole matrix into two subsets.',\n",
       "   'tokens': [50713,\n",
       "    775,\n",
       "    783,\n",
       "    2270,\n",
       "    428,\n",
       "    2187,\n",
       "    17593,\n",
       "    656,\n",
       "    734,\n",
       "    6352,\n",
       "    1039,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22485913401064667,\n",
       "   'compression_ratio': 1.6476190476190475,\n",
       "   'no_speech_prob': 0.023081772029399872},\n",
       "  {'id': 354,\n",
       "   'seek': 139796,\n",
       "   'start': 1408.96,\n",
       "   'end': 1416.96,\n",
       "   'text': \" The first we've already discussed is the training set which we set as the matrix D.\",\n",
       "   'tokens': [50913,\n",
       "    383,\n",
       "    717,\n",
       "    356,\n",
       "    1053,\n",
       "    1541,\n",
       "    6693,\n",
       "    318,\n",
       "    262,\n",
       "    3047,\n",
       "    900,\n",
       "    543,\n",
       "    356,\n",
       "    900,\n",
       "    355,\n",
       "    262,\n",
       "    17593,\n",
       "    360,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22485913401064667,\n",
       "   'compression_ratio': 1.6476190476190475,\n",
       "   'no_speech_prob': 0.023081772029399872},\n",
       "  {'id': 355,\n",
       "   'seek': 139796,\n",
       "   'start': 1416.96,\n",
       "   'end': 1422.96,\n",
       "   'text': ' And now we have the test set where we have these specific entries on the condition as',\n",
       "   'tokens': [51313,\n",
       "    843,\n",
       "    783,\n",
       "    356,\n",
       "    423,\n",
       "    262,\n",
       "    1332,\n",
       "    900,\n",
       "    810,\n",
       "    356,\n",
       "    423,\n",
       "    777,\n",
       "    2176,\n",
       "    12784,\n",
       "    319,\n",
       "    262,\n",
       "    4006,\n",
       "    355,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22485913401064667,\n",
       "   'compression_ratio': 1.6476190476190475,\n",
       "   'no_speech_prob': 0.023081772029399872},\n",
       "  {'id': 356,\n",
       "   'seek': 139796,\n",
       "   'start': 1422.96,\n",
       "   'end': 1424.96,\n",
       "   'text': \" unknown which we're trying to estimate today.\",\n",
       "   'tokens': [51613, 6439, 543, 356, 821, 2111, 284, 8636, 1909, 13, 51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22485913401064667,\n",
       "   'compression_ratio': 1.6476190476190475,\n",
       "   'no_speech_prob': 0.023081772029399872},\n",
       "  {'id': 357,\n",
       "   'seek': 139796,\n",
       "   'start': 1424.96,\n",
       "   'end': 1425.96,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51713, 6498, 30, 51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22485913401064667,\n",
       "   'compression_ratio': 1.6476190476190475,\n",
       "   'no_speech_prob': 0.023081772029399872},\n",
       "  {'id': 358,\n",
       "   'seek': 142596,\n",
       "   'start': 1426.96,\n",
       "   'end': 1431.96,\n",
       "   'text': ' So the testing set will be very similar to the training set but it does not mean any',\n",
       "   'tokens': [50413,\n",
       "    1406,\n",
       "    262,\n",
       "    4856,\n",
       "    900,\n",
       "    481,\n",
       "    307,\n",
       "    845,\n",
       "    2092,\n",
       "    284,\n",
       "    262,\n",
       "    3047,\n",
       "    900,\n",
       "    475,\n",
       "    340,\n",
       "    857,\n",
       "    407,\n",
       "    1612,\n",
       "    597,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2985311552535656,\n",
       "   'compression_ratio': 1.5660377358490567,\n",
       "   'no_speech_prob': 0.07653558254241943},\n",
       "  {'id': 359,\n",
       "   'seek': 142596,\n",
       "   'start': 1431.96,\n",
       "   'end': 1433.96,\n",
       "   'text': ' levels for the output variable.',\n",
       "   'tokens': [50663, 2974, 329, 262, 5072, 7885, 13, 50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2985311552535656,\n",
       "   'compression_ratio': 1.5660377358490567,\n",
       "   'no_speech_prob': 0.07653558254241943},\n",
       "  {'id': 360,\n",
       "   'seek': 142596,\n",
       "   'start': 1433.96,\n",
       "   'end': 1434.96,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50763, 6498, 30, 50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2985311552535656,\n",
       "   'compression_ratio': 1.5660377358490567,\n",
       "   'no_speech_prob': 0.07653558254241943},\n",
       "  {'id': 361,\n",
       "   'seek': 142596,\n",
       "   'start': 1434.96,\n",
       "   'end': 1436.96,\n",
       "   'text': ' Everyone clear the distinction between training and testing?',\n",
       "   'tokens': [50813,\n",
       "    11075,\n",
       "    1598,\n",
       "    262,\n",
       "    12941,\n",
       "    1022,\n",
       "    3047,\n",
       "    290,\n",
       "    4856,\n",
       "    30,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2985311552535656,\n",
       "   'compression_ratio': 1.5660377358490567,\n",
       "   'no_speech_prob': 0.07653558254241943},\n",
       "  {'id': 362,\n",
       "   'seek': 142596,\n",
       "   'start': 1436.96,\n",
       "   'end': 1437.96,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50913, 6498, 30, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2985311552535656,\n",
       "   'compression_ratio': 1.5660377358490567,\n",
       "   'no_speech_prob': 0.07653558254241943},\n",
       "  {'id': 363,\n",
       "   'seek': 142596,\n",
       "   'start': 1437.96,\n",
       "   'end': 1438.96,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [50963, 16805, 13, 51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2985311552535656,\n",
       "   'compression_ratio': 1.5660377358490567,\n",
       "   'no_speech_prob': 0.07653558254241943},\n",
       "  {'id': 364,\n",
       "   'seek': 142596,\n",
       "   'start': 1438.96,\n",
       "   'end': 1445.96,\n",
       "   'text': \" So given the background that we have thus far, could we now tell what we're trying to do\",\n",
       "   'tokens': [51013,\n",
       "    1406,\n",
       "    1813,\n",
       "    262,\n",
       "    4469,\n",
       "    326,\n",
       "    356,\n",
       "    423,\n",
       "    4145,\n",
       "    1290,\n",
       "    11,\n",
       "    714,\n",
       "    356,\n",
       "    783,\n",
       "    1560,\n",
       "    644,\n",
       "    356,\n",
       "    821,\n",
       "    2111,\n",
       "    284,\n",
       "    466,\n",
       "    51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2985311552535656,\n",
       "   'compression_ratio': 1.5660377358490567,\n",
       "   'no_speech_prob': 0.07653558254241943},\n",
       "  {'id': 365,\n",
       "   'seek': 142596,\n",
       "   'start': 1445.96,\n",
       "   'end': 1450.96,\n",
       "   'text': ' from this example in a more succinct fashion?',\n",
       "   'tokens': [51363, 422, 428, 1672, 287, 257, 517, 46263, 6977, 30, 51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2985311552535656,\n",
       "   'compression_ratio': 1.5660377358490567,\n",
       "   'no_speech_prob': 0.07653558254241943},\n",
       "  {'id': 366,\n",
       "   'seek': 145096,\n",
       "   'start': 1450.96,\n",
       "   'end': 1456.96,\n",
       "   'text': ' What do we hope to do given the training set, given the test set?',\n",
       "   'tokens': [50363,\n",
       "    1867,\n",
       "    466,\n",
       "    356,\n",
       "    2911,\n",
       "    284,\n",
       "    466,\n",
       "    1813,\n",
       "    262,\n",
       "    3047,\n",
       "    900,\n",
       "    11,\n",
       "    1813,\n",
       "    262,\n",
       "    1332,\n",
       "    900,\n",
       "    30,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24903937916696808,\n",
       "   'compression_ratio': 1.6610169491525424,\n",
       "   'no_speech_prob': 0.15988998115062714},\n",
       "  {'id': 367,\n",
       "   'seek': 145096,\n",
       "   'start': 1456.96,\n",
       "   'end': 1459.96,\n",
       "   'text': ' And we have to have some learning component.',\n",
       "   'tokens': [50663, 843, 356, 423, 284, 423, 617, 4673, 7515, 13, 50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24903937916696808,\n",
       "   'compression_ratio': 1.6610169491525424,\n",
       "   'no_speech_prob': 0.15988998115062714},\n",
       "  {'id': 368,\n",
       "   'seek': 145096,\n",
       "   'start': 1459.96,\n",
       "   'end': 1465.96,\n",
       "   'text': \" It's the relating point of output.\",\n",
       "   'tokens': [50813, 632, 338, 262, 11270, 966, 286, 5072, 13, 51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24903937916696808,\n",
       "   'compression_ratio': 1.6610169491525424,\n",
       "   'no_speech_prob': 0.15988998115062714},\n",
       "  {'id': 369,\n",
       "   'seek': 145096,\n",
       "   'start': 1465.96,\n",
       "   'end': 1470.96,\n",
       "   'text': ' How do you relate the input to the output?',\n",
       "   'tokens': [51113,\n",
       "    1374,\n",
       "    466,\n",
       "    345,\n",
       "    15124,\n",
       "    262,\n",
       "    5128,\n",
       "    284,\n",
       "    262,\n",
       "    5072,\n",
       "    30,\n",
       "    51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24903937916696808,\n",
       "   'compression_ratio': 1.6610169491525424,\n",
       "   'no_speech_prob': 0.15988998115062714},\n",
       "  {'id': 370,\n",
       "   'seek': 145096,\n",
       "   'start': 1470.96,\n",
       "   'end': 1473.96,\n",
       "   'text': \" I don't need a precise answer but you can relate.\",\n",
       "   'tokens': [51363,\n",
       "    314,\n",
       "    836,\n",
       "    470,\n",
       "    761,\n",
       "    257,\n",
       "    7141,\n",
       "    3280,\n",
       "    475,\n",
       "    345,\n",
       "    460,\n",
       "    15124,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24903937916696808,\n",
       "   'compression_ratio': 1.6610169491525424,\n",
       "   'no_speech_prob': 0.15988998115062714},\n",
       "  {'id': 371,\n",
       "   'seek': 145096,\n",
       "   'start': 1473.96,\n",
       "   'end': 1479.96,\n",
       "   'text': ' You can write the output as some function of the input.',\n",
       "   'tokens': [51513,\n",
       "    921,\n",
       "    460,\n",
       "    3551,\n",
       "    262,\n",
       "    5072,\n",
       "    355,\n",
       "    617,\n",
       "    2163,\n",
       "    286,\n",
       "    262,\n",
       "    5128,\n",
       "    13,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24903937916696808,\n",
       "   'compression_ratio': 1.6610169491525424,\n",
       "   'no_speech_prob': 0.15988998115062714},\n",
       "  {'id': 372,\n",
       "   'seek': 147996,\n",
       "   'start': 1479.96,\n",
       "   'end': 1482.96,\n",
       "   'text': \" Thus far we don't know what kind of function is this.\",\n",
       "   'tokens': [50363,\n",
       "    6660,\n",
       "    1290,\n",
       "    356,\n",
       "    836,\n",
       "    470,\n",
       "    760,\n",
       "    644,\n",
       "    1611,\n",
       "    286,\n",
       "    2163,\n",
       "    318,\n",
       "    428,\n",
       "    13,\n",
       "    50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.26635013436371424,\n",
       "   'compression_ratio': 1.7710280373831775,\n",
       "   'no_speech_prob': 0.04162025451660156},\n",
       "  {'id': 373,\n",
       "   'seek': 147996,\n",
       "   'start': 1482.96,\n",
       "   'end': 1487.96,\n",
       "   'text': ' And if we do the volumes we have a different functions relating the output to the input.',\n",
       "   'tokens': [50513,\n",
       "    843,\n",
       "    611,\n",
       "    356,\n",
       "    466,\n",
       "    262,\n",
       "    15343,\n",
       "    356,\n",
       "    423,\n",
       "    257,\n",
       "    1180,\n",
       "    5499,\n",
       "    11270,\n",
       "    262,\n",
       "    5072,\n",
       "    284,\n",
       "    262,\n",
       "    5128,\n",
       "    13,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.26635013436371424,\n",
       "   'compression_ratio': 1.7710280373831775,\n",
       "   'no_speech_prob': 0.04162025451660156},\n",
       "  {'id': 374,\n",
       "   'seek': 147996,\n",
       "   'start': 1487.96,\n",
       "   'end': 1494.96,\n",
       "   'text': ' But we want to be able to predict the output using some functional complex set for now.',\n",
       "   'tokens': [50763,\n",
       "    887,\n",
       "    356,\n",
       "    765,\n",
       "    284,\n",
       "    307,\n",
       "    1498,\n",
       "    284,\n",
       "    4331,\n",
       "    262,\n",
       "    5072,\n",
       "    1262,\n",
       "    617,\n",
       "    10345,\n",
       "    3716,\n",
       "    900,\n",
       "    329,\n",
       "    783,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.26635013436371424,\n",
       "   'compression_ratio': 1.7710280373831775,\n",
       "   'no_speech_prob': 0.04162025451660156},\n",
       "  {'id': 375,\n",
       "   'seek': 147996,\n",
       "   'start': 1494.96,\n",
       "   'end': 1497.96,\n",
       "   'text': ' And where do we learn this F from?',\n",
       "   'tokens': [51113, 843, 810, 466, 356, 2193, 428, 376, 422, 30, 51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.26635013436371424,\n",
       "   'compression_ratio': 1.7710280373831775,\n",
       "   'no_speech_prob': 0.04162025451660156},\n",
       "  {'id': 376,\n",
       "   'seek': 147996,\n",
       "   'start': 1497.96,\n",
       "   'end': 1498.96,\n",
       "   'text': ' This function F from?',\n",
       "   'tokens': [51263, 770, 2163, 376, 422, 30, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.26635013436371424,\n",
       "   'compression_ratio': 1.7710280373831775,\n",
       "   'no_speech_prob': 0.04162025451660156},\n",
       "  {'id': 377,\n",
       "   'seek': 147996,\n",
       "   'start': 1498.96,\n",
       "   'end': 1499.96,\n",
       "   'text': ' It is.',\n",
       "   'tokens': [51313, 632, 318, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.26635013436371424,\n",
       "   'compression_ratio': 1.7710280373831775,\n",
       "   'no_speech_prob': 0.04162025451660156},\n",
       "  {'id': 378,\n",
       "   'seek': 147996,\n",
       "   'start': 1499.96,\n",
       "   'end': 1501.96,\n",
       "   'text': ' From the training set.',\n",
       "   'tokens': [51363, 3574, 262, 3047, 900, 13, 51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.26635013436371424,\n",
       "   'compression_ratio': 1.7710280373831775,\n",
       "   'no_speech_prob': 0.04162025451660156},\n",
       "  {'id': 379,\n",
       "   'seek': 147996,\n",
       "   'start': 1501.96,\n",
       "   'end': 1505.96,\n",
       "   'text': ' And where do we apply this function F on?',\n",
       "   'tokens': [51463, 843, 810, 466, 356, 4174, 428, 2163, 376, 319, 30, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.26635013436371424,\n",
       "   'compression_ratio': 1.7710280373831775,\n",
       "   'no_speech_prob': 0.04162025451660156},\n",
       "  {'id': 380,\n",
       "   'seek': 147996,\n",
       "   'start': 1505.96,\n",
       "   'end': 1507.96,\n",
       "   'text': ' On the testing set.',\n",
       "   'tokens': [51663, 1550, 262, 4856, 900, 13, 51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.26635013436371424,\n",
       "   'compression_ratio': 1.7710280373831775,\n",
       "   'no_speech_prob': 0.04162025451660156},\n",
       "  {'id': 381,\n",
       "   'seek': 150796,\n",
       "   'start': 1507.96,\n",
       "   'end': 1514.96,\n",
       "   'text': ' So that given this for this particular sample, given the inputs red, red and red, you want',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    326,\n",
       "    1813,\n",
       "    428,\n",
       "    329,\n",
       "    428,\n",
       "    1948,\n",
       "    6291,\n",
       "    11,\n",
       "    1813,\n",
       "    262,\n",
       "    17311,\n",
       "    2266,\n",
       "    11,\n",
       "    2266,\n",
       "    290,\n",
       "    2266,\n",
       "    11,\n",
       "    345,\n",
       "    765,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27773201719243473,\n",
       "   'compression_ratio': 1.5794392523364487,\n",
       "   'no_speech_prob': 0.050490714609622955},\n",
       "  {'id': 382,\n",
       "   'seek': 150796,\n",
       "   'start': 1514.96,\n",
       "   'end': 1515.96,\n",
       "   'text': ' to predict the condition.',\n",
       "   'tokens': [50713, 284, 4331, 262, 4006, 13, 50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27773201719243473,\n",
       "   'compression_ratio': 1.5794392523364487,\n",
       "   'no_speech_prob': 0.050490714609622955},\n",
       "  {'id': 383,\n",
       "   'seek': 150796,\n",
       "   'start': 1515.96,\n",
       "   'end': 1516.96,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50763, 6498, 30, 50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27773201719243473,\n",
       "   'compression_ratio': 1.5794392523364487,\n",
       "   'no_speech_prob': 0.050490714609622955},\n",
       "  {'id': 384,\n",
       "   'seek': 150796,\n",
       "   'start': 1516.96,\n",
       "   'end': 1520.96,\n",
       "   'text': \" And the general rule would be that we're able to do this accurately otherwise it does not\",\n",
       "   'tokens': [50813,\n",
       "    843,\n",
       "    262,\n",
       "    2276,\n",
       "    3896,\n",
       "    561,\n",
       "    307,\n",
       "    326,\n",
       "    356,\n",
       "    821,\n",
       "    1498,\n",
       "    284,\n",
       "    466,\n",
       "    428,\n",
       "    14351,\n",
       "    4306,\n",
       "    340,\n",
       "    857,\n",
       "    407,\n",
       "    51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27773201719243473,\n",
       "   'compression_ratio': 1.5794392523364487,\n",
       "   'no_speech_prob': 0.050490714609622955},\n",
       "  {'id': 385,\n",
       "   'seek': 150796,\n",
       "   'start': 1520.96,\n",
       "   'end': 1521.96,\n",
       "   'text': ' make any sense.',\n",
       "   'tokens': [51013, 787, 597, 2565, 13, 51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27773201719243473,\n",
       "   'compression_ratio': 1.5794392523364487,\n",
       "   'no_speech_prob': 0.050490714609622955},\n",
       "  {'id': 386,\n",
       "   'seek': 150796,\n",
       "   'start': 1521.96,\n",
       "   'end': 1522.96,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51063, 6498, 30, 51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27773201719243473,\n",
       "   'compression_ratio': 1.5794392523364487,\n",
       "   'no_speech_prob': 0.050490714609622955},\n",
       "  {'id': 387,\n",
       "   'seek': 150796,\n",
       "   'start': 1522.96,\n",
       "   'end': 1523.96,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [51113, 16805, 13, 51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27773201719243473,\n",
       "   'compression_ratio': 1.5794392523364487,\n",
       "   'no_speech_prob': 0.050490714609622955},\n",
       "  {'id': 388,\n",
       "   'seek': 150796,\n",
       "   'start': 1523.96,\n",
       "   'end': 1526.96,\n",
       "   'text': ' Now a big question.',\n",
       "   'tokens': [51163, 2735, 257, 1263, 1808, 13, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27773201719243473,\n",
       "   'compression_ratio': 1.5794392523364487,\n",
       "   'no_speech_prob': 0.050490714609622955},\n",
       "  {'id': 389,\n",
       "   'seek': 150796,\n",
       "   'start': 1526.96,\n",
       "   'end': 1533.96,\n",
       "   'text': ' Is predicting on the test set enough to say that the model is invalidating?',\n",
       "   'tokens': [51313,\n",
       "    1148,\n",
       "    25539,\n",
       "    319,\n",
       "    262,\n",
       "    1332,\n",
       "    900,\n",
       "    1576,\n",
       "    284,\n",
       "    910,\n",
       "    326,\n",
       "    262,\n",
       "    2746,\n",
       "    318,\n",
       "    12515,\n",
       "    803,\n",
       "    30,\n",
       "    51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27773201719243473,\n",
       "   'compression_ratio': 1.5794392523364487,\n",
       "   'no_speech_prob': 0.050490714609622955},\n",
       "  {'id': 390,\n",
       "   'seek': 153396,\n",
       "   'start': 1534.96,\n",
       "   'end': 1537.96,\n",
       "   'text': ' Why or why not?',\n",
       "   'tokens': [50413, 4162, 393, 1521, 407, 30, 50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3907863329041679,\n",
       "   'compression_ratio': 1.8546511627906976,\n",
       "   'no_speech_prob': 0.506791889667511},\n",
       "  {'id': 391,\n",
       "   'seek': 153396,\n",
       "   'start': 1537.96,\n",
       "   'end': 1543.96,\n",
       "   'text': ' The test set now is missing out the outliers.',\n",
       "   'tokens': [50563,\n",
       "    383,\n",
       "    1332,\n",
       "    900,\n",
       "    783,\n",
       "    318,\n",
       "    4814,\n",
       "    503,\n",
       "    262,\n",
       "    41528,\n",
       "    3183,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3907863329041679,\n",
       "   'compression_ratio': 1.8546511627906976,\n",
       "   'no_speech_prob': 0.506791889667511},\n",
       "  {'id': 392,\n",
       "   'seek': 153396,\n",
       "   'start': 1543.96,\n",
       "   'end': 1545.96,\n",
       "   'text': ' Missing out the outliers.',\n",
       "   'tokens': [50863, 25639, 503, 262, 41528, 3183, 13, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3907863329041679,\n",
       "   'compression_ratio': 1.8546511627906976,\n",
       "   'no_speech_prob': 0.506791889667511},\n",
       "  {'id': 393,\n",
       "   'seek': 153396,\n",
       "   'start': 1545.96,\n",
       "   'end': 1546.96,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [50963, 16805, 13, 51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3907863329041679,\n",
       "   'compression_ratio': 1.8546511627906976,\n",
       "   'no_speech_prob': 0.506791889667511},\n",
       "  {'id': 394,\n",
       "   'seek': 153396,\n",
       "   'start': 1546.96,\n",
       "   'end': 1549.96,\n",
       "   'text': ' So we will say that if test set, why do you missing out the outliers?',\n",
       "   'tokens': [51013,\n",
       "    1406,\n",
       "    356,\n",
       "    481,\n",
       "    910,\n",
       "    326,\n",
       "    611,\n",
       "    1332,\n",
       "    900,\n",
       "    11,\n",
       "    1521,\n",
       "    466,\n",
       "    345,\n",
       "    4814,\n",
       "    503,\n",
       "    262,\n",
       "    41528,\n",
       "    3183,\n",
       "    30,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3907863329041679,\n",
       "   'compression_ratio': 1.8546511627906976,\n",
       "   'no_speech_prob': 0.506791889667511},\n",
       "  {'id': 395,\n",
       "   'seek': 153396,\n",
       "   'start': 1549.96,\n",
       "   'end': 1552.96,\n",
       "   'text': ' So we can add a little more weight rate.',\n",
       "   'tokens': [51163,\n",
       "    1406,\n",
       "    356,\n",
       "    460,\n",
       "    751,\n",
       "    257,\n",
       "    1310,\n",
       "    517,\n",
       "    3463,\n",
       "    2494,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3907863329041679,\n",
       "   'compression_ratio': 1.8546511627906976,\n",
       "   'no_speech_prob': 0.506791889667511},\n",
       "  {'id': 396,\n",
       "   'seek': 153396,\n",
       "   'start': 1552.96,\n",
       "   'end': 1553.96,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [51313, 16805, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3907863329041679,\n",
       "   'compression_ratio': 1.8546511627906976,\n",
       "   'no_speech_prob': 0.506791889667511},\n",
       "  {'id': 397,\n",
       "   'seek': 153396,\n",
       "   'start': 1553.96,\n",
       "   'end': 1554.96,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [51363, 16805, 13, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3907863329041679,\n",
       "   'compression_ratio': 1.8546511627906976,\n",
       "   'no_speech_prob': 0.506791889667511},\n",
       "  {'id': 398,\n",
       "   'seek': 153396,\n",
       "   'start': 1554.96,\n",
       "   'end': 1555.96,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [51413, 16805, 13, 51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3907863329041679,\n",
       "   'compression_ratio': 1.8546511627906976,\n",
       "   'no_speech_prob': 0.506791889667511},\n",
       "  {'id': 399,\n",
       "   'seek': 153396,\n",
       "   'start': 1555.96,\n",
       "   'end': 1556.96,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [51463, 16805, 13, 51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3907863329041679,\n",
       "   'compression_ratio': 1.8546511627906976,\n",
       "   'no_speech_prob': 0.506791889667511},\n",
       "  {'id': 400,\n",
       "   'seek': 153396,\n",
       "   'start': 1556.96,\n",
       "   'end': 1557.96,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [51513, 16805, 13, 51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3907863329041679,\n",
       "   'compression_ratio': 1.8546511627906976,\n",
       "   'no_speech_prob': 0.506791889667511},\n",
       "  {'id': 401,\n",
       "   'seek': 153396,\n",
       "   'start': 1557.96,\n",
       "   'end': 1561.96,\n",
       "   'text': ' So the answer is the answer that he is giving is that they could be some exceptions.',\n",
       "   'tokens': [51563,\n",
       "    1406,\n",
       "    262,\n",
       "    3280,\n",
       "    318,\n",
       "    262,\n",
       "    3280,\n",
       "    326,\n",
       "    339,\n",
       "    318,\n",
       "    3501,\n",
       "    318,\n",
       "    326,\n",
       "    484,\n",
       "    714,\n",
       "    307,\n",
       "    617,\n",
       "    13269,\n",
       "    13,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3907863329041679,\n",
       "   'compression_ratio': 1.8546511627906976,\n",
       "   'no_speech_prob': 0.506791889667511},\n",
       "  {'id': 402,\n",
       "   'seek': 156196,\n",
       "   'start': 1561.96,\n",
       "   'end': 1563.96,\n",
       "   'text': ' They could be some outliers.',\n",
       "   'tokens': [50363, 1119, 714, 307, 617, 41528, 3183, 13, 50463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.48883965179210404,\n",
       "   'compression_ratio': 1.925,\n",
       "   'no_speech_prob': 0.2196381688117981},\n",
       "  {'id': 403,\n",
       "   'seek': 156196,\n",
       "   'start': 1563.96,\n",
       "   'end': 1566.96,\n",
       "   'text': ' But that is getting to the right answer.',\n",
       "   'tokens': [50463, 887, 326, 318, 1972, 284, 262, 826, 3280, 13, 50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.48883965179210404,\n",
       "   'compression_ratio': 1.925,\n",
       "   'no_speech_prob': 0.2196381688117981},\n",
       "  {'id': 404,\n",
       "   'seek': 156196,\n",
       "   'start': 1566.96,\n",
       "   'end': 1569.96,\n",
       "   'text': ' But you need to make a movement.',\n",
       "   'tokens': [50613, 887, 345, 761, 284, 787, 257, 3356, 13, 50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.48883965179210404,\n",
       "   'compression_ratio': 1.925,\n",
       "   'no_speech_prob': 0.2196381688117981},\n",
       "  {'id': 405,\n",
       "   'seek': 156196,\n",
       "   'start': 1569.96,\n",
       "   'end': 1572.96,\n",
       "   'text': ' The case that the contour is not a rotation.',\n",
       "   'tokens': [50763,\n",
       "    383,\n",
       "    1339,\n",
       "    326,\n",
       "    262,\n",
       "    542,\n",
       "    454,\n",
       "    318,\n",
       "    407,\n",
       "    257,\n",
       "    13179,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.48883965179210404,\n",
       "   'compression_ratio': 1.925,\n",
       "   'no_speech_prob': 0.2196381688117981},\n",
       "  {'id': 406,\n",
       "   'seek': 156196,\n",
       "   'start': 1572.96,\n",
       "   'end': 1575.96,\n",
       "   'text': ' The case that it does not have annotations.',\n",
       "   'tokens': [50913, 383, 1339, 326, 340, 857, 407, 423, 37647, 13, 51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.48883965179210404,\n",
       "   'compression_ratio': 1.925,\n",
       "   'no_speech_prob': 0.2196381688117981},\n",
       "  {'id': 407,\n",
       "   'seek': 156196,\n",
       "   'start': 1575.96,\n",
       "   'end': 1577.96,\n",
       "   'text': ' So what will it be?',\n",
       "   'tokens': [51063, 1406, 644, 481, 340, 307, 30, 51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.48883965179210404,\n",
       "   'compression_ratio': 1.925,\n",
       "   'no_speech_prob': 0.2196381688117981},\n",
       "  {'id': 408,\n",
       "   'seek': 156196,\n",
       "   'start': 1577.96,\n",
       "   'end': 1579.96,\n",
       "   'text': ' How will it be?',\n",
       "   'tokens': [51163, 1374, 481, 340, 307, 30, 51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.48883965179210404,\n",
       "   'compression_ratio': 1.925,\n",
       "   'no_speech_prob': 0.2196381688117981},\n",
       "  {'id': 409,\n",
       "   'seek': 156196,\n",
       "   'start': 1579.96,\n",
       "   'end': 1580.96,\n",
       "   'text': ' How will it be?',\n",
       "   'tokens': [51263, 1374, 481, 340, 307, 30, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.48883965179210404,\n",
       "   'compression_ratio': 1.925,\n",
       "   'no_speech_prob': 0.2196381688117981},\n",
       "  {'id': 410,\n",
       "   'seek': 156196,\n",
       "   'start': 1580.96,\n",
       "   'end': 1581.96,\n",
       "   'text': ' How will it be?',\n",
       "   'tokens': [51313, 1374, 481, 340, 307, 30, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.48883965179210404,\n",
       "   'compression_ratio': 1.925,\n",
       "   'no_speech_prob': 0.2196381688117981},\n",
       "  {'id': 411,\n",
       "   'seek': 156196,\n",
       "   'start': 1581.96,\n",
       "   'end': 1582.96,\n",
       "   'text': ' How will it be?',\n",
       "   'tokens': [51363, 1374, 481, 340, 307, 30, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.48883965179210404,\n",
       "   'compression_ratio': 1.925,\n",
       "   'no_speech_prob': 0.2196381688117981},\n",
       "  {'id': 412,\n",
       "   'seek': 156196,\n",
       "   'start': 1582.96,\n",
       "   'end': 1584.96,\n",
       "   'text': ' So we come to the specific question of how we do it.',\n",
       "   'tokens': [51413,\n",
       "    1406,\n",
       "    356,\n",
       "    1282,\n",
       "    284,\n",
       "    262,\n",
       "    2176,\n",
       "    1808,\n",
       "    286,\n",
       "    703,\n",
       "    356,\n",
       "    466,\n",
       "    340,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.48883965179210404,\n",
       "   'compression_ratio': 1.925,\n",
       "   'no_speech_prob': 0.2196381688117981},\n",
       "  {'id': 413,\n",
       "   'seek': 156196,\n",
       "   'start': 1584.96,\n",
       "   'end': 1585.96,\n",
       "   'text': ' We take the accuracy.',\n",
       "   'tokens': [51513, 775, 1011, 262, 9922, 13, 51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.48883965179210404,\n",
       "   'compression_ratio': 1.925,\n",
       "   'no_speech_prob': 0.2196381688117981},\n",
       "  {'id': 414,\n",
       "   'seek': 156196,\n",
       "   'start': 1585.96,\n",
       "   'end': 1586.96,\n",
       "   'text': ' Yeah.',\n",
       "   'tokens': [51563, 9425, 13, 51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.48883965179210404,\n",
       "   'compression_ratio': 1.925,\n",
       "   'no_speech_prob': 0.2196381688117981},\n",
       "  {'id': 415,\n",
       "   'seek': 156196,\n",
       "   'start': 1586.96,\n",
       "   'end': 1587.96,\n",
       "   'text': ' So we come to that.',\n",
       "   'tokens': [51613, 1406, 356, 1282, 284, 326, 13, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.48883965179210404,\n",
       "   'compression_ratio': 1.925,\n",
       "   'no_speech_prob': 0.2196381688117981},\n",
       "  {'id': 416,\n",
       "   'seek': 156196,\n",
       "   'start': 1587.96,\n",
       "   'end': 1588.96,\n",
       "   'text': ' But yes.',\n",
       "   'tokens': [51663, 887, 3763, 13, 51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.48883965179210404,\n",
       "   'compression_ratio': 1.925,\n",
       "   'no_speech_prob': 0.2196381688117981},\n",
       "  {'id': 417,\n",
       "   'seek': 158896,\n",
       "   'start': 1588.96,\n",
       "   'end': 1589.96,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [50363, 16805, 13, 50413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.41679027292988086,\n",
       "   'compression_ratio': 1.5414634146341464,\n",
       "   'no_speech_prob': 0.31121689081192017},\n",
       "  {'id': 418,\n",
       "   'seek': 158896,\n",
       "   'start': 1589.96,\n",
       "   'end': 1590.96,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [50413, 16805, 13, 50463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.41679027292988086,\n",
       "   'compression_ratio': 1.5414634146341464,\n",
       "   'no_speech_prob': 0.31121689081192017},\n",
       "  {'id': 419,\n",
       "   'seek': 158896,\n",
       "   'start': 1590.96,\n",
       "   'end': 1598.96,\n",
       "   'text': ' The test set may be a subset of the brain set.',\n",
       "   'tokens': [50463,\n",
       "    383,\n",
       "    1332,\n",
       "    900,\n",
       "    743,\n",
       "    307,\n",
       "    257,\n",
       "    24637,\n",
       "    286,\n",
       "    262,\n",
       "    3632,\n",
       "    900,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.41679027292988086,\n",
       "   'compression_ratio': 1.5414634146341464,\n",
       "   'no_speech_prob': 0.31121689081192017},\n",
       "  {'id': 420,\n",
       "   'seek': 158896,\n",
       "   'start': 1598.96,\n",
       "   'end': 1601.96,\n",
       "   'text': ' And your answer was that the test set might have some outliers.',\n",
       "   'tokens': [50863,\n",
       "    843,\n",
       "    534,\n",
       "    3280,\n",
       "    373,\n",
       "    326,\n",
       "    262,\n",
       "    1332,\n",
       "    900,\n",
       "    1244,\n",
       "    423,\n",
       "    617,\n",
       "    41528,\n",
       "    3183,\n",
       "    13,\n",
       "    51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.41679027292988086,\n",
       "   'compression_ratio': 1.5414634146341464,\n",
       "   'no_speech_prob': 0.31121689081192017},\n",
       "  {'id': 421,\n",
       "   'seek': 158896,\n",
       "   'start': 1601.96,\n",
       "   'end': 1604.96,\n",
       "   'text': ' Both of you are really there.',\n",
       "   'tokens': [51013, 5747, 286, 345, 389, 1107, 612, 13, 51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.41679027292988086,\n",
       "   'compression_ratio': 1.5414634146341464,\n",
       "   'no_speech_prob': 0.31121689081192017},\n",
       "  {'id': 422,\n",
       "   'seek': 158896,\n",
       "   'start': 1604.96,\n",
       "   'end': 1605.96,\n",
       "   'text': ' Come with us on.',\n",
       "   'tokens': [51163, 7911, 351, 514, 319, 13, 51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.41679027292988086,\n",
       "   'compression_ratio': 1.5414634146341464,\n",
       "   'no_speech_prob': 0.31121689081192017},\n",
       "  {'id': 423,\n",
       "   'seek': 158896,\n",
       "   'start': 1605.96,\n",
       "   'end': 1606.96,\n",
       "   'text': ' Oh, yes.',\n",
       "   'tokens': [51213, 3966, 11, 3763, 13, 51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.41679027292988086,\n",
       "   'compression_ratio': 1.5414634146341464,\n",
       "   'no_speech_prob': 0.31121689081192017},\n",
       "  {'id': 424,\n",
       "   'seek': 158896,\n",
       "   'start': 1606.96,\n",
       "   'end': 1607.96,\n",
       "   'text': ' Overthinking.',\n",
       "   'tokens': [51263, 3827, 28973, 13, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.41679027292988086,\n",
       "   'compression_ratio': 1.5414634146341464,\n",
       "   'no_speech_prob': 0.31121689081192017},\n",
       "  {'id': 425,\n",
       "   'seek': 158896,\n",
       "   'start': 1607.96,\n",
       "   'end': 1608.96,\n",
       "   'text': \" That's good.\",\n",
       "   'tokens': [51313, 1320, 338, 922, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.41679027292988086,\n",
       "   'compression_ratio': 1.5414634146341464,\n",
       "   'no_speech_prob': 0.31121689081192017},\n",
       "  {'id': 426,\n",
       "   'seek': 158896,\n",
       "   'start': 1608.96,\n",
       "   'end': 1611.96,\n",
       "   'text': ' So we have not thus introduced it on that over period.',\n",
       "   'tokens': [51363,\n",
       "    1406,\n",
       "    356,\n",
       "    423,\n",
       "    407,\n",
       "    4145,\n",
       "    5495,\n",
       "    340,\n",
       "    319,\n",
       "    326,\n",
       "    625,\n",
       "    2278,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.41679027292988086,\n",
       "   'compression_ratio': 1.5414634146341464,\n",
       "   'no_speech_prob': 0.31121689081192017},\n",
       "  {'id': 427,\n",
       "   'seek': 158896,\n",
       "   'start': 1611.96,\n",
       "   'end': 1616.96,\n",
       "   'text': ' Can you use some simpler numbers we have seen thus far?',\n",
       "   'tokens': [51513,\n",
       "    1680,\n",
       "    345,\n",
       "    779,\n",
       "    617,\n",
       "    18599,\n",
       "    3146,\n",
       "    356,\n",
       "    423,\n",
       "    1775,\n",
       "    4145,\n",
       "    1290,\n",
       "    30,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.41679027292988086,\n",
       "   'compression_ratio': 1.5414634146341464,\n",
       "   'no_speech_prob': 0.31121689081192017},\n",
       "  {'id': 428,\n",
       "   'seek': 161696,\n",
       "   'start': 1616.96,\n",
       "   'end': 1632.96,\n",
       "   'text': ' Think of sometimes you might have covered in some probability code.',\n",
       "   'tokens': [50363,\n",
       "    11382,\n",
       "    286,\n",
       "    3360,\n",
       "    345,\n",
       "    1244,\n",
       "    423,\n",
       "    5017,\n",
       "    287,\n",
       "    617,\n",
       "    12867,\n",
       "    2438,\n",
       "    13,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2108631706237793,\n",
       "   'compression_ratio': 1.4411764705882353,\n",
       "   'no_speech_prob': 0.23369640111923218},\n",
       "  {'id': 429,\n",
       "   'seek': 161696,\n",
       "   'start': 1632.96,\n",
       "   'end': 1638.96,\n",
       "   'text': ' So the ideal thing that we want to do is to be creating well of all possible inputs.',\n",
       "   'tokens': [51163,\n",
       "    1406,\n",
       "    262,\n",
       "    7306,\n",
       "    1517,\n",
       "    326,\n",
       "    356,\n",
       "    765,\n",
       "    284,\n",
       "    466,\n",
       "    318,\n",
       "    284,\n",
       "    307,\n",
       "    4441,\n",
       "    880,\n",
       "    286,\n",
       "    477,\n",
       "    1744,\n",
       "    17311,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2108631706237793,\n",
       "   'compression_ratio': 1.4411764705882353,\n",
       "   'no_speech_prob': 0.23369640111923218},\n",
       "  {'id': 430,\n",
       "   'seek': 161696,\n",
       "   'start': 1638.96,\n",
       "   'end': 1639.96,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51463, 6498, 30, 51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2108631706237793,\n",
       "   'compression_ratio': 1.4411764705882353,\n",
       "   'no_speech_prob': 0.23369640111923218},\n",
       "  {'id': 431,\n",
       "   'seek': 161696,\n",
       "   'start': 1639.96,\n",
       "   'end': 1642.96,\n",
       "   'text': ' The emphasis on all possible inputs.',\n",
       "   'tokens': [51513, 383, 12476, 319, 477, 1744, 17311, 13, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2108631706237793,\n",
       "   'compression_ratio': 1.4411764705882353,\n",
       "   'no_speech_prob': 0.23369640111923218},\n",
       "  {'id': 432,\n",
       "   'seek': 164296,\n",
       "   'start': 1643.96,\n",
       "   'end': 1645.96,\n",
       "   'text': ' But can you test that?',\n",
       "   'tokens': [50413, 887, 460, 345, 1332, 326, 30, 50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17950873281441482,\n",
       "   'compression_ratio': 1.6451612903225807,\n",
       "   'no_speech_prob': 0.5346368551254272},\n",
       "  {'id': 433,\n",
       "   'seek': 164296,\n",
       "   'start': 1645.96,\n",
       "   'end': 1648.96,\n",
       "   'text': ' Can the test set be all possible inputs?',\n",
       "   'tokens': [50513, 1680, 262, 1332, 900, 307, 477, 1744, 17311, 30, 50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17950873281441482,\n",
       "   'compression_ratio': 1.6451612903225807,\n",
       "   'no_speech_prob': 0.5346368551254272},\n",
       "  {'id': 434,\n",
       "   'seek': 164296,\n",
       "   'start': 1648.96,\n",
       "   'end': 1650.96,\n",
       "   'text': ' Maybe an ideal case.',\n",
       "   'tokens': [50663, 6674, 281, 7306, 1339, 13, 50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17950873281441482,\n",
       "   'compression_ratio': 1.6451612903225807,\n",
       "   'no_speech_prob': 0.5346368551254272},\n",
       "  {'id': 435,\n",
       "   'seek': 164296,\n",
       "   'start': 1650.96,\n",
       "   'end': 1651.96,\n",
       "   'text': ' Yes.',\n",
       "   'tokens': [50763, 3363, 13, 50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17950873281441482,\n",
       "   'compression_ratio': 1.6451612903225807,\n",
       "   'no_speech_prob': 0.5346368551254272},\n",
       "  {'id': 436,\n",
       "   'seek': 164296,\n",
       "   'start': 1651.96,\n",
       "   'end': 1657.96,\n",
       "   'text': ' But in a more practical case, you know, you will never be able to enumerate all possible test',\n",
       "   'tokens': [50813,\n",
       "    887,\n",
       "    287,\n",
       "    257,\n",
       "    517,\n",
       "    8472,\n",
       "    1339,\n",
       "    11,\n",
       "    345,\n",
       "    760,\n",
       "    11,\n",
       "    345,\n",
       "    481,\n",
       "    1239,\n",
       "    307,\n",
       "    1498,\n",
       "    284,\n",
       "    27056,\n",
       "    378,\n",
       "    477,\n",
       "    1744,\n",
       "    1332,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17950873281441482,\n",
       "   'compression_ratio': 1.6451612903225807,\n",
       "   'no_speech_prob': 0.5346368551254272},\n",
       "  {'id': 437,\n",
       "   'seek': 164296,\n",
       "   'start': 1657.96,\n",
       "   'end': 1658.96,\n",
       "   'text': ' cases.',\n",
       "   'tokens': [51113, 2663, 13, 51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17950873281441482,\n",
       "   'compression_ratio': 1.6451612903225807,\n",
       "   'no_speech_prob': 0.5346368551254272},\n",
       "  {'id': 438,\n",
       "   'seek': 164296,\n",
       "   'start': 1658.96,\n",
       "   'end': 1664.96,\n",
       "   'text': ' And now relating to the answer which some of you have already given.',\n",
       "   'tokens': [51163,\n",
       "    843,\n",
       "    783,\n",
       "    11270,\n",
       "    284,\n",
       "    262,\n",
       "    3280,\n",
       "    543,\n",
       "    617,\n",
       "    286,\n",
       "    345,\n",
       "    423,\n",
       "    1541,\n",
       "    1813,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17950873281441482,\n",
       "   'compression_ratio': 1.6451612903225807,\n",
       "   'no_speech_prob': 0.5346368551254272},\n",
       "  {'id': 439,\n",
       "   'seek': 164296,\n",
       "   'start': 1664.96,\n",
       "   'end': 1670.96,\n",
       "   'text': ' So one way to put it would be that the test set is only a sample from all possible inputs.',\n",
       "   'tokens': [51463,\n",
       "    1406,\n",
       "    530,\n",
       "    835,\n",
       "    284,\n",
       "    1234,\n",
       "    340,\n",
       "    561,\n",
       "    307,\n",
       "    326,\n",
       "    262,\n",
       "    1332,\n",
       "    900,\n",
       "    318,\n",
       "    691,\n",
       "    257,\n",
       "    6291,\n",
       "    422,\n",
       "    477,\n",
       "    1744,\n",
       "    17311,\n",
       "    13,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17950873281441482,\n",
       "   'compression_ratio': 1.6451612903225807,\n",
       "   'no_speech_prob': 0.5346368551254272},\n",
       "  {'id': 440,\n",
       "   'seek': 164296,\n",
       "   'start': 1670.96,\n",
       "   'end': 1671.96,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51763, 6498, 30, 51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17950873281441482,\n",
       "   'compression_ratio': 1.6451612903225807,\n",
       "   'no_speech_prob': 0.5346368551254272},\n",
       "  {'id': 441,\n",
       "   'seek': 167196,\n",
       "   'start': 1671.96,\n",
       "   'end': 1676.96,\n",
       "   'text': ' So this now relates to the answer we are talking about outliers.',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    428,\n",
       "    783,\n",
       "    18436,\n",
       "    284,\n",
       "    262,\n",
       "    3280,\n",
       "    356,\n",
       "    389,\n",
       "    3375,\n",
       "    546,\n",
       "    41528,\n",
       "    3183,\n",
       "    13,\n",
       "    50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4240844273331142,\n",
       "   'compression_ratio': 1.7377777777777779,\n",
       "   'no_speech_prob': 0.05923817306756973},\n",
       "  {'id': 442,\n",
       "   'seek': 167196,\n",
       "   'start': 1676.96,\n",
       "   'end': 1682.96,\n",
       "   'text': ' You could end up choosing a test set which is a very expensive test set.',\n",
       "   'tokens': [50613,\n",
       "    921,\n",
       "    714,\n",
       "    886,\n",
       "    510,\n",
       "    11236,\n",
       "    257,\n",
       "    1332,\n",
       "    900,\n",
       "    543,\n",
       "    318,\n",
       "    257,\n",
       "    845,\n",
       "    5789,\n",
       "    1332,\n",
       "    900,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4240844273331142,\n",
       "   'compression_ratio': 1.7377777777777779,\n",
       "   'no_speech_prob': 0.05923817306756973},\n",
       "  {'id': 443,\n",
       "   'seek': 167196,\n",
       "   'start': 1682.96,\n",
       "   'end': 1683.96,\n",
       "   'text': \" It's a lot of outlier.\",\n",
       "   'tokens': [50913, 632, 338, 257, 1256, 286, 503, 2505, 13, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4240844273331142,\n",
       "   'compression_ratio': 1.7377777777777779,\n",
       "   'no_speech_prob': 0.05923817306756973},\n",
       "  {'id': 444,\n",
       "   'seek': 167196,\n",
       "   'start': 1683.96,\n",
       "   'end': 1687.96,\n",
       "   'text': \" But there's a lot of internal outliers which might be present in all possible inputs.\",\n",
       "   'tokens': [50963,\n",
       "    887,\n",
       "    612,\n",
       "    338,\n",
       "    257,\n",
       "    1256,\n",
       "    286,\n",
       "    5387,\n",
       "    41528,\n",
       "    3183,\n",
       "    543,\n",
       "    1244,\n",
       "    307,\n",
       "    1944,\n",
       "    287,\n",
       "    477,\n",
       "    1744,\n",
       "    17311,\n",
       "    13,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4240844273331142,\n",
       "   'compression_ratio': 1.7377777777777779,\n",
       "   'no_speech_prob': 0.05923817306756973},\n",
       "  {'id': 445,\n",
       "   'seek': 167196,\n",
       "   'start': 1687.96,\n",
       "   'end': 1692.96,\n",
       "   'text': ' And also the next to your specific answer that the test set would be a part of the brain set',\n",
       "   'tokens': [51163,\n",
       "    843,\n",
       "    635,\n",
       "    262,\n",
       "    1306,\n",
       "    284,\n",
       "    534,\n",
       "    2176,\n",
       "    3280,\n",
       "    326,\n",
       "    262,\n",
       "    1332,\n",
       "    900,\n",
       "    561,\n",
       "    307,\n",
       "    257,\n",
       "    636,\n",
       "    286,\n",
       "    262,\n",
       "    3632,\n",
       "    900,\n",
       "    51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4240844273331142,\n",
       "   'compression_ratio': 1.7377777777777779,\n",
       "   'no_speech_prob': 0.05923817306756973},\n",
       "  {'id': 446,\n",
       "   'seek': 167196,\n",
       "   'start': 1692.96,\n",
       "   'end': 1696.96,\n",
       "   'text': \" because it's now a sample from all possible inputs.\",\n",
       "   'tokens': [51413,\n",
       "    780,\n",
       "    340,\n",
       "    338,\n",
       "    783,\n",
       "    257,\n",
       "    6291,\n",
       "    422,\n",
       "    477,\n",
       "    1744,\n",
       "    17311,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4240844273331142,\n",
       "   'compression_ratio': 1.7377777777777779,\n",
       "   'no_speech_prob': 0.05923817306756973},\n",
       "  {'id': 447,\n",
       "   'seek': 169696,\n",
       "   'start': 1697.96,\n",
       "   'end': 1703.96,\n",
       "   'text': \" More generally we have to think, let's think of it as there is some origin or there is\",\n",
       "   'tokens': [50413,\n",
       "    3125,\n",
       "    4143,\n",
       "    356,\n",
       "    423,\n",
       "    284,\n",
       "    892,\n",
       "    11,\n",
       "    1309,\n",
       "    338,\n",
       "    892,\n",
       "    286,\n",
       "    340,\n",
       "    355,\n",
       "    612,\n",
       "    318,\n",
       "    617,\n",
       "    8159,\n",
       "    393,\n",
       "    612,\n",
       "    318,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3583724825989966,\n",
       "   'compression_ratio': 1.6720647773279351,\n",
       "   'no_speech_prob': 0.4113057851791382},\n",
       "  {'id': 448,\n",
       "   'seek': 169696,\n",
       "   'start': 1703.96,\n",
       "   'end': 1710.96,\n",
       "   'text': ' some generating process which generates the brain data which I am calling there as the',\n",
       "   'tokens': [50713,\n",
       "    617,\n",
       "    15453,\n",
       "    1429,\n",
       "    543,\n",
       "    18616,\n",
       "    262,\n",
       "    3632,\n",
       "    1366,\n",
       "    543,\n",
       "    314,\n",
       "    716,\n",
       "    4585,\n",
       "    612,\n",
       "    355,\n",
       "    262,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3583724825989966,\n",
       "   'compression_ratio': 1.6720647773279351,\n",
       "   'no_speech_prob': 0.4113057851791382},\n",
       "  {'id': 449,\n",
       "   'seek': 169696,\n",
       "   'start': 1710.96,\n",
       "   'end': 1711.96,\n",
       "   'text': ' empirical data sample.',\n",
       "   'tokens': [51063, 21594, 1366, 6291, 13, 51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3583724825989966,\n",
       "   'compression_ratio': 1.6720647773279351,\n",
       "   'no_speech_prob': 0.4113057851791382},\n",
       "  {'id': 450,\n",
       "   'seek': 169696,\n",
       "   'start': 1711.96,\n",
       "   'end': 1714.96,\n",
       "   'text': \" And I've written it in a little bit on where I do.\",\n",
       "   'tokens': [51113,\n",
       "    843,\n",
       "    314,\n",
       "    1053,\n",
       "    3194,\n",
       "    340,\n",
       "    287,\n",
       "    257,\n",
       "    1310,\n",
       "    1643,\n",
       "    319,\n",
       "    810,\n",
       "    314,\n",
       "    466,\n",
       "    13,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3583724825989966,\n",
       "   'compression_ratio': 1.6720647773279351,\n",
       "   'no_speech_prob': 0.4113057851791382},\n",
       "  {'id': 451,\n",
       "   'seek': 169696,\n",
       "   'start': 1714.96,\n",
       "   'end': 1717.96,\n",
       "   'text': ' So this is identity and independence distributed.',\n",
       "   'tokens': [51263, 1406, 428, 318, 5369, 290, 10404, 9387, 13, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3583724825989966,\n",
       "   'compression_ratio': 1.6720647773279351,\n",
       "   'no_speech_prob': 0.4113057851791382},\n",
       "  {'id': 452,\n",
       "   'seek': 169696,\n",
       "   'start': 1717.96,\n",
       "   'end': 1722.96,\n",
       "   'text': \" If I would recommend that if you don't know this term again, go back and study some of\",\n",
       "   'tokens': [51413,\n",
       "    1002,\n",
       "    314,\n",
       "    561,\n",
       "    4313,\n",
       "    326,\n",
       "    611,\n",
       "    345,\n",
       "    836,\n",
       "    470,\n",
       "    760,\n",
       "    428,\n",
       "    3381,\n",
       "    757,\n",
       "    11,\n",
       "    467,\n",
       "    736,\n",
       "    290,\n",
       "    2050,\n",
       "    617,\n",
       "    286,\n",
       "    51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3583724825989966,\n",
       "   'compression_ratio': 1.6720647773279351,\n",
       "   'no_speech_prob': 0.4113057851791382},\n",
       "  {'id': 453,\n",
       "   'seek': 169696,\n",
       "   'start': 1722.96,\n",
       "   'end': 1725.96,\n",
       "   'text': ' the three records mentioned.',\n",
       "   'tokens': [51663, 262, 1115, 4406, 4750, 13, 51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3583724825989966,\n",
       "   'compression_ratio': 1.6720647773279351,\n",
       "   'no_speech_prob': 0.4113057851791382},\n",
       "  {'id': 454,\n",
       "   'seek': 172596,\n",
       "   'start': 1726.96,\n",
       "   'end': 1732.96,\n",
       "   'text': ' You sample from the hidden proof or you generate data from the queue process.',\n",
       "   'tokens': [50413,\n",
       "    921,\n",
       "    6291,\n",
       "    422,\n",
       "    262,\n",
       "    7104,\n",
       "    6617,\n",
       "    393,\n",
       "    345,\n",
       "    7716,\n",
       "    1366,\n",
       "    422,\n",
       "    262,\n",
       "    16834,\n",
       "    1429,\n",
       "    13,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3662180965893889,\n",
       "   'compression_ratio': 1.6612021857923498,\n",
       "   'no_speech_prob': 0.045000601559877396},\n",
       "  {'id': 455,\n",
       "   'seek': 172596,\n",
       "   'start': 1732.96,\n",
       "   'end': 1736.96,\n",
       "   'text': ' You are able to get some free data which you learn.',\n",
       "   'tokens': [50713,\n",
       "    921,\n",
       "    389,\n",
       "    1498,\n",
       "    284,\n",
       "    651,\n",
       "    617,\n",
       "    1479,\n",
       "    1366,\n",
       "    543,\n",
       "    345,\n",
       "    2193,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3662180965893889,\n",
       "   'compression_ratio': 1.6612021857923498,\n",
       "   'no_speech_prob': 0.045000601559877396},\n",
       "  {'id': 456,\n",
       "   'seek': 172596,\n",
       "   'start': 1736.96,\n",
       "   'end': 1742.96,\n",
       "   'text': ' You get a model which in a previous case was some function S that we will learn in.',\n",
       "   'tokens': [50913,\n",
       "    921,\n",
       "    651,\n",
       "    257,\n",
       "    2746,\n",
       "    543,\n",
       "    287,\n",
       "    257,\n",
       "    2180,\n",
       "    1339,\n",
       "    373,\n",
       "    617,\n",
       "    2163,\n",
       "    311,\n",
       "    326,\n",
       "    356,\n",
       "    481,\n",
       "    2193,\n",
       "    287,\n",
       "    13,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3662180965893889,\n",
       "   'compression_ratio': 1.6612021857923498,\n",
       "   'no_speech_prob': 0.045000601559877396},\n",
       "  {'id': 457,\n",
       "   'seek': 172596,\n",
       "   'start': 1742.96,\n",
       "   'end': 1748.96,\n",
       "   'text': \" Once you've learned by function you predict using unseen data, you predict another sample.\",\n",
       "   'tokens': [51213,\n",
       "    4874,\n",
       "    345,\n",
       "    1053,\n",
       "    4499,\n",
       "    416,\n",
       "    2163,\n",
       "    345,\n",
       "    4331,\n",
       "    1262,\n",
       "    29587,\n",
       "    1366,\n",
       "    11,\n",
       "    345,\n",
       "    4331,\n",
       "    1194,\n",
       "    6291,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3662180965893889,\n",
       "   'compression_ratio': 1.6612021857923498,\n",
       "   'no_speech_prob': 0.045000601559877396},\n",
       "  {'id': 458,\n",
       "   'seek': 174896,\n",
       "   'start': 1748.96,\n",
       "   'end': 1754.96,\n",
       "   'text': ' So that sample is again also coming from the same data set, from the same underlying',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    326,\n",
       "    6291,\n",
       "    318,\n",
       "    757,\n",
       "    635,\n",
       "    2406,\n",
       "    422,\n",
       "    262,\n",
       "    976,\n",
       "    1366,\n",
       "    900,\n",
       "    11,\n",
       "    422,\n",
       "    262,\n",
       "    976,\n",
       "    10238,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.401133638747195,\n",
       "   'compression_ratio': 1.9068627450980393,\n",
       "   'no_speech_prob': 0.24574114382266998},\n",
       "  {'id': 459,\n",
       "   'seek': 174896,\n",
       "   'start': 1754.96,\n",
       "   'end': 1759.96,\n",
       "   'text': ' distributed or the same generating process by all the way.',\n",
       "   'tokens': [50663,\n",
       "    9387,\n",
       "    393,\n",
       "    262,\n",
       "    976,\n",
       "    15453,\n",
       "    1429,\n",
       "    416,\n",
       "    477,\n",
       "    262,\n",
       "    835,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.401133638747195,\n",
       "   'compression_ratio': 1.9068627450980393,\n",
       "   'no_speech_prob': 0.24574114382266998},\n",
       "  {'id': 460,\n",
       "   'seek': 174896,\n",
       "   'start': 1759.96,\n",
       "   'end': 1764.96,\n",
       "   'text': ' So what now we get is that the training set and the test set of samples are from the',\n",
       "   'tokens': [50913,\n",
       "    1406,\n",
       "    644,\n",
       "    783,\n",
       "    356,\n",
       "    651,\n",
       "    318,\n",
       "    326,\n",
       "    262,\n",
       "    3047,\n",
       "    900,\n",
       "    290,\n",
       "    262,\n",
       "    1332,\n",
       "    900,\n",
       "    286,\n",
       "    8405,\n",
       "    389,\n",
       "    422,\n",
       "    262,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.401133638747195,\n",
       "   'compression_ratio': 1.9068627450980393,\n",
       "   'no_speech_prob': 0.24574114382266998},\n",
       "  {'id': 461,\n",
       "   'seek': 174896,\n",
       "   'start': 1764.96,\n",
       "   'end': 1766.96,\n",
       "   'text': ' hidden proof distribution.',\n",
       "   'tokens': [51163, 7104, 6617, 6082, 13, 51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.401133638747195,\n",
       "   'compression_ratio': 1.9068627450980393,\n",
       "   'no_speech_prob': 0.24574114382266998},\n",
       "  {'id': 462,\n",
       "   'seek': 174896,\n",
       "   'start': 1766.96,\n",
       "   'end': 1769.96,\n",
       "   'text': ' Sometimes it is also known as population.',\n",
       "   'tokens': [51263, 8975, 340, 318, 635, 1900, 355, 3265, 13, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.401133638747195,\n",
       "   'compression_ratio': 1.9068627450980393,\n",
       "   'no_speech_prob': 0.24574114382266998},\n",
       "  {'id': 463,\n",
       "   'seek': 174896,\n",
       "   'start': 1769.96,\n",
       "   'end': 1772.96,\n",
       "   'text': ' You get some samples from the population.',\n",
       "   'tokens': [51413, 921, 651, 617, 8405, 422, 262, 3265, 13, 51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.401133638747195,\n",
       "   'compression_ratio': 1.9068627450980393,\n",
       "   'no_speech_prob': 0.24574114382266998},\n",
       "  {'id': 464,\n",
       "   'seek': 174896,\n",
       "   'start': 1772.96,\n",
       "   'end': 1776.96,\n",
       "   'text': ' So the test set will not contain all the samples.',\n",
       "   'tokens': [51563,\n",
       "    1406,\n",
       "    262,\n",
       "    1332,\n",
       "    900,\n",
       "    481,\n",
       "    407,\n",
       "    3994,\n",
       "    477,\n",
       "    262,\n",
       "    8405,\n",
       "    13,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.401133638747195,\n",
       "   'compression_ratio': 1.9068627450980393,\n",
       "   'no_speech_prob': 0.24574114382266998},\n",
       "  {'id': 465,\n",
       "   'seek': 177696,\n",
       "   'start': 1776.96,\n",
       "   'end': 1782.96,\n",
       "   'text': ' In order to say that our model generalizes perfectly, we would have had to see the entire',\n",
       "   'tokens': [50363,\n",
       "    554,\n",
       "    1502,\n",
       "    284,\n",
       "    910,\n",
       "    326,\n",
       "    674,\n",
       "    2746,\n",
       "    2276,\n",
       "    4340,\n",
       "    7138,\n",
       "    11,\n",
       "    356,\n",
       "    561,\n",
       "    423,\n",
       "    550,\n",
       "    284,\n",
       "    766,\n",
       "    262,\n",
       "    2104,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3883802165155825,\n",
       "   'compression_ratio': 1.5,\n",
       "   'no_speech_prob': 0.050091516226530075},\n",
       "  {'id': 466,\n",
       "   'seek': 177696,\n",
       "   'start': 1782.96,\n",
       "   'end': 1787.96,\n",
       "   'text': ' population which is never the same.',\n",
       "   'tokens': [50663, 3265, 543, 318, 1239, 262, 976, 13, 50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3883802165155825,\n",
       "   'compression_ratio': 1.5,\n",
       "   'no_speech_prob': 0.050091516226530075},\n",
       "  {'id': 467,\n",
       "   'seek': 177696,\n",
       "   'start': 1787.96,\n",
       "   'end': 1794.96,\n",
       "   'text': ' And you have much more deeper differences between the test set and the group population.',\n",
       "   'tokens': [50913,\n",
       "    843,\n",
       "    345,\n",
       "    423,\n",
       "    881,\n",
       "    517,\n",
       "    9211,\n",
       "    5400,\n",
       "    1022,\n",
       "    262,\n",
       "    1332,\n",
       "    900,\n",
       "    290,\n",
       "    262,\n",
       "    1448,\n",
       "    3265,\n",
       "    13,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3883802165155825,\n",
       "   'compression_ratio': 1.5,\n",
       "   'no_speech_prob': 0.050091516226530075},\n",
       "  {'id': 468,\n",
       "   'seek': 177696,\n",
       "   'start': 1794.96,\n",
       "   'end': 1801.96,\n",
       "   'text': ' Once we study bias in various terms, hopefully it will come from the next lecture.',\n",
       "   'tokens': [51263,\n",
       "    4874,\n",
       "    356,\n",
       "    2050,\n",
       "    10690,\n",
       "    287,\n",
       "    2972,\n",
       "    2846,\n",
       "    11,\n",
       "    11481,\n",
       "    340,\n",
       "    481,\n",
       "    1282,\n",
       "    422,\n",
       "    262,\n",
       "    1306,\n",
       "    19143,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3883802165155825,\n",
       "   'compression_ratio': 1.5,\n",
       "   'no_speech_prob': 0.050091516226530075},\n",
       "  {'id': 469,\n",
       "   'seek': 180196,\n",
       "   'start': 1802.96,\n",
       "   'end': 1804.96,\n",
       "   'text': ' Everyone clear the line?',\n",
       "   'tokens': [50413, 11075, 1598, 262, 1627, 30, 50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4127022238338695,\n",
       "   'compression_ratio': 1.5829596412556053,\n",
       "   'no_speech_prob': 0.30858728289604187},\n",
       "  {'id': 470,\n",
       "   'seek': 180196,\n",
       "   'start': 1807.96,\n",
       "   'end': 1812.96,\n",
       "   'text': ' Okay, so we have last part seen one particular type of machine learning task where you will',\n",
       "   'tokens': [50663,\n",
       "    16805,\n",
       "    11,\n",
       "    523,\n",
       "    356,\n",
       "    423,\n",
       "    938,\n",
       "    636,\n",
       "    1775,\n",
       "    530,\n",
       "    1948,\n",
       "    2099,\n",
       "    286,\n",
       "    4572,\n",
       "    4673,\n",
       "    4876,\n",
       "    810,\n",
       "    345,\n",
       "    481,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4127022238338695,\n",
       "   'compression_ratio': 1.5829596412556053,\n",
       "   'no_speech_prob': 0.30858728289604187},\n",
       "  {'id': 471,\n",
       "   'seek': 180196,\n",
       "   'start': 1812.96,\n",
       "   'end': 1817.96,\n",
       "   'text': ' try to classify whether the object or whether the particular the meters would have had.',\n",
       "   'tokens': [50913,\n",
       "    1949,\n",
       "    284,\n",
       "    36509,\n",
       "    1771,\n",
       "    262,\n",
       "    2134,\n",
       "    393,\n",
       "    1771,\n",
       "    262,\n",
       "    1948,\n",
       "    262,\n",
       "    10700,\n",
       "    561,\n",
       "    423,\n",
       "    550,\n",
       "    13,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4127022238338695,\n",
       "   'compression_ratio': 1.5829596412556053,\n",
       "   'no_speech_prob': 0.30858728289604187},\n",
       "  {'id': 472,\n",
       "   'seek': 180196,\n",
       "   'start': 1817.96,\n",
       "   'end': 1820.96,\n",
       "   'text': ' But now we can have a very different example.',\n",
       "   'tokens': [51163, 887, 783, 356, 460, 423, 257, 845, 1180, 1672, 13, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4127022238338695,\n",
       "   'compression_ratio': 1.5829596412556053,\n",
       "   'no_speech_prob': 0.30858728289604187},\n",
       "  {'id': 473,\n",
       "   'seek': 180196,\n",
       "   'start': 1820.96,\n",
       "   'end': 1824.96,\n",
       "   'text': ' We want to predict the energy consumption of IT on the other campus.',\n",
       "   'tokens': [51313,\n",
       "    775,\n",
       "    765,\n",
       "    284,\n",
       "    4331,\n",
       "    262,\n",
       "    2568,\n",
       "    7327,\n",
       "    286,\n",
       "    7283,\n",
       "    319,\n",
       "    262,\n",
       "    584,\n",
       "    7611,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4127022238338695,\n",
       "   'compression_ratio': 1.5829596412556053,\n",
       "   'no_speech_prob': 0.30858728289604187},\n",
       "  {'id': 474,\n",
       "   'seek': 180196,\n",
       "   'start': 1824.96,\n",
       "   'end': 1827.96,\n",
       "   'text': ' Okay, so again the same exercise.',\n",
       "   'tokens': [51513, 16805, 11, 523, 757, 262, 976, 5517, 13, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4127022238338695,\n",
       "   'compression_ratio': 1.5829596412556053,\n",
       "   'no_speech_prob': 0.30858728289604187},\n",
       "  {'id': 475,\n",
       "   'seek': 182796,\n",
       "   'start': 1827.96,\n",
       "   'end': 1831.96,\n",
       "   'text': ' For more factors, you will think the energy consumption should depend on.',\n",
       "   'tokens': [50363,\n",
       "    1114,\n",
       "    517,\n",
       "    5087,\n",
       "    11,\n",
       "    345,\n",
       "    481,\n",
       "    892,\n",
       "    262,\n",
       "    2568,\n",
       "    7327,\n",
       "    815,\n",
       "    4745,\n",
       "    319,\n",
       "    13,\n",
       "    50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4511920326634457,\n",
       "   'compression_ratio': 1.5753424657534247,\n",
       "   'no_speech_prob': 0.35390013456344604},\n",
       "  {'id': 476,\n",
       "   'seek': 182796,\n",
       "   'start': 1831.96,\n",
       "   'end': 1834.96,\n",
       "   'text': ' Can you quantify that?',\n",
       "   'tokens': [50563, 1680, 345, 36336, 326, 30, 50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4511920326634457,\n",
       "   'compression_ratio': 1.5753424657534247,\n",
       "   'no_speech_prob': 0.35390013456344604},\n",
       "  {'id': 477,\n",
       "   'seek': 182796,\n",
       "   'start': 1834.96,\n",
       "   'end': 1838.96,\n",
       "   'text': ' Because whether it is again one specific aspect of IT.',\n",
       "   'tokens': [50713,\n",
       "    4362,\n",
       "    1771,\n",
       "    340,\n",
       "    318,\n",
       "    757,\n",
       "    530,\n",
       "    2176,\n",
       "    4843,\n",
       "    286,\n",
       "    7283,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4511920326634457,\n",
       "   'compression_ratio': 1.5753424657534247,\n",
       "   'no_speech_prob': 0.35390013456344604},\n",
       "  {'id': 478,\n",
       "   'seek': 182796,\n",
       "   'start': 1838.96,\n",
       "   'end': 1840.96,\n",
       "   'text': ' You may need temperature, okay.',\n",
       "   'tokens': [50913, 921, 743, 761, 5951, 11, 8788, 13, 51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4511920326634457,\n",
       "   'compression_ratio': 1.5753424657534247,\n",
       "   'no_speech_prob': 0.35390013456344604},\n",
       "  {'id': 479,\n",
       "   'seek': 182796,\n",
       "   'start': 1840.96,\n",
       "   'end': 1843.96,\n",
       "   'text': ' What do you expect the humidity is more?',\n",
       "   'tokens': [51013, 1867, 466, 345, 1607, 262, 27716, 318, 517, 30, 51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4511920326634457,\n",
       "   'compression_ratio': 1.5753424657534247,\n",
       "   'no_speech_prob': 0.35390013456344604},\n",
       "  {'id': 480,\n",
       "   'seek': 182796,\n",
       "   'start': 1843.96,\n",
       "   'end': 1846.96,\n",
       "   'text': ' Do you think they will do more of it?',\n",
       "   'tokens': [51163, 2141, 345, 892, 484, 481, 466, 517, 286, 340, 30, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4511920326634457,\n",
       "   'compression_ratio': 1.5753424657534247,\n",
       "   'no_speech_prob': 0.35390013456344604},\n",
       "  {'id': 481,\n",
       "   'seek': 182796,\n",
       "   'start': 1846.96,\n",
       "   'end': 1847.96,\n",
       "   'text': ' More?',\n",
       "   'tokens': [51313, 3125, 30, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4511920326634457,\n",
       "   'compression_ratio': 1.5753424657534247,\n",
       "   'no_speech_prob': 0.35390013456344604},\n",
       "  {'id': 482,\n",
       "   'seek': 182796,\n",
       "   'start': 1847.96,\n",
       "   'end': 1850.96,\n",
       "   'text': ' Okay, more of the temperature.',\n",
       "   'tokens': [51363, 16805, 11, 517, 286, 262, 5951, 13, 51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4511920326634457,\n",
       "   'compression_ratio': 1.5753424657534247,\n",
       "   'no_speech_prob': 0.35390013456344604},\n",
       "  {'id': 483,\n",
       "   'seek': 182796,\n",
       "   'start': 1850.96,\n",
       "   'end': 1854.96,\n",
       "   'text': ' Temperature is more, what energy do you want?',\n",
       "   'tokens': [51513, 34467, 318, 517, 11, 644, 2568, 466, 345, 765, 30, 51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4511920326634457,\n",
       "   'compression_ratio': 1.5753424657534247,\n",
       "   'no_speech_prob': 0.35390013456344604},\n",
       "  {'id': 484,\n",
       "   'seek': 185496,\n",
       "   'start': 1854.96,\n",
       "   'end': 1855.96,\n",
       "   'text': ' Five.',\n",
       "   'tokens': [50363, 10579, 13, 50413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5475499116921727,\n",
       "   'compression_ratio': 1.4941176470588236,\n",
       "   'no_speech_prob': 0.25579744577407837},\n",
       "  {'id': 485,\n",
       "   'seek': 185496,\n",
       "   'start': 1855.96,\n",
       "   'end': 1857.96,\n",
       "   'text': ' More energy is less.',\n",
       "   'tokens': [50413, 3125, 2568, 318, 1342, 13, 50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5475499116921727,\n",
       "   'compression_ratio': 1.4941176470588236,\n",
       "   'no_speech_prob': 0.25579744577407837},\n",
       "  {'id': 486,\n",
       "   'seek': 185496,\n",
       "   'start': 1857.96,\n",
       "   'end': 1862.96,\n",
       "   'text': ' Okay, what are the other factors in the application?',\n",
       "   'tokens': [50513,\n",
       "    16805,\n",
       "    11,\n",
       "    644,\n",
       "    389,\n",
       "    262,\n",
       "    584,\n",
       "    5087,\n",
       "    287,\n",
       "    262,\n",
       "    3586,\n",
       "    30,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5475499116921727,\n",
       "   'compression_ratio': 1.4941176470588236,\n",
       "   'no_speech_prob': 0.25579744577407837},\n",
       "  {'id': 487,\n",
       "   'seek': 185496,\n",
       "   'start': 1862.96,\n",
       "   'end': 1864.96,\n",
       "   'text': ' Elic, okay.',\n",
       "   'tokens': [50763, 412, 677, 11, 8788, 13, 50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5475499116921727,\n",
       "   'compression_ratio': 1.4941176470588236,\n",
       "   'no_speech_prob': 0.25579744577407837},\n",
       "  {'id': 488,\n",
       "   'seek': 185496,\n",
       "   'start': 1864.96,\n",
       "   'end': 1869.96,\n",
       "   'text': ' Then, okay, number of people, number of occupants.',\n",
       "   'tokens': [50863,\n",
       "    3244,\n",
       "    11,\n",
       "    8788,\n",
       "    11,\n",
       "    1271,\n",
       "    286,\n",
       "    661,\n",
       "    11,\n",
       "    1271,\n",
       "    286,\n",
       "    35242,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5475499116921727,\n",
       "   'compression_ratio': 1.4941176470588236,\n",
       "   'no_speech_prob': 0.25579744577407837},\n",
       "  {'id': 489,\n",
       "   'seek': 185496,\n",
       "   'start': 1869.96,\n",
       "   'end': 1872.96,\n",
       "   'text': ' And if there are more occupants, do you expect more energy will happen?',\n",
       "   'tokens': [51113,\n",
       "    843,\n",
       "    611,\n",
       "    612,\n",
       "    389,\n",
       "    517,\n",
       "    35242,\n",
       "    11,\n",
       "    466,\n",
       "    345,\n",
       "    1607,\n",
       "    517,\n",
       "    2568,\n",
       "    481,\n",
       "    1645,\n",
       "    30,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5475499116921727,\n",
       "   'compression_ratio': 1.4941176470588236,\n",
       "   'no_speech_prob': 0.25579744577407837},\n",
       "  {'id': 490,\n",
       "   'seek': 185496,\n",
       "   'start': 1872.96,\n",
       "   'end': 1874.96,\n",
       "   'text': ' Generally yes.',\n",
       "   'tokens': [51263, 23904, 3763, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5475499116921727,\n",
       "   'compression_ratio': 1.4941176470588236,\n",
       "   'no_speech_prob': 0.25579744577407837},\n",
       "  {'id': 491,\n",
       "   'seek': 185496,\n",
       "   'start': 1874.96,\n",
       "   'end': 1876.96,\n",
       "   'text': ' Any other factor?',\n",
       "   'tokens': [51363, 4377, 584, 5766, 30, 51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5475499116921727,\n",
       "   'compression_ratio': 1.4941176470588236,\n",
       "   'no_speech_prob': 0.25579744577407837},\n",
       "  {'id': 492,\n",
       "   'seek': 185496,\n",
       "   'start': 1876.96,\n",
       "   'end': 1877.96,\n",
       "   'text': ' Sorry.',\n",
       "   'tokens': [51463, 19061, 13, 51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5475499116921727,\n",
       "   'compression_ratio': 1.4941176470588236,\n",
       "   'no_speech_prob': 0.25579744577407837},\n",
       "  {'id': 493,\n",
       "   'seek': 187796,\n",
       "   'start': 1878.96,\n",
       "   'end': 1886.96,\n",
       "   'text': ' Okay, one of the things I have to say is that there are some other aspects of a campus',\n",
       "   'tokens': [50413,\n",
       "    16805,\n",
       "    11,\n",
       "    530,\n",
       "    286,\n",
       "    262,\n",
       "    1243,\n",
       "    314,\n",
       "    423,\n",
       "    284,\n",
       "    910,\n",
       "    318,\n",
       "    326,\n",
       "    612,\n",
       "    389,\n",
       "    617,\n",
       "    584,\n",
       "    7612,\n",
       "    286,\n",
       "    257,\n",
       "    7611,\n",
       "    50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.795966832778033,\n",
       "   'compression_ratio': 1.5698924731182795,\n",
       "   'no_speech_prob': 0.5684173107147217},\n",
       "  {'id': 494,\n",
       "   'seek': 187796,\n",
       "   'start': 1886.96,\n",
       "   'end': 1891.96,\n",
       "   'text': \" energy they don't manage, they are going to call this a quality term, some of the energy.\",\n",
       "   'tokens': [50813,\n",
       "    2568,\n",
       "    484,\n",
       "    836,\n",
       "    470,\n",
       "    6687,\n",
       "    11,\n",
       "    484,\n",
       "    389,\n",
       "    1016,\n",
       "    284,\n",
       "    869,\n",
       "    428,\n",
       "    257,\n",
       "    3081,\n",
       "    3381,\n",
       "    11,\n",
       "    617,\n",
       "    286,\n",
       "    262,\n",
       "    2568,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.795966832778033,\n",
       "   'compression_ratio': 1.5698924731182795,\n",
       "   'no_speech_prob': 0.5684173107147217},\n",
       "  {'id': 495,\n",
       "   'seek': 187796,\n",
       "   'start': 1891.96,\n",
       "   'end': 1894.96,\n",
       "   'text': ' What are the assets?',\n",
       "   'tokens': [51063, 1867, 389, 262, 6798, 30, 51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.795966832778033,\n",
       "   'compression_ratio': 1.5698924731182795,\n",
       "   'no_speech_prob': 0.5684173107147217},\n",
       "  {'id': 496,\n",
       "   'seek': 187796,\n",
       "   'start': 1894.96,\n",
       "   'end': 1897.96,\n",
       "   'text': ' This level is less.',\n",
       "   'tokens': [51213, 770, 1241, 318, 1342, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.795966832778033,\n",
       "   'compression_ratio': 1.5698924731182795,\n",
       "   'no_speech_prob': 0.5684173107147217},\n",
       "  {'id': 497,\n",
       "   'seek': 187796,\n",
       "   'start': 1897.96,\n",
       "   'end': 1899.96,\n",
       "   'text': ' Lab switches, this level.',\n",
       "   'tokens': [51363, 3498, 18225, 11, 428, 1241, 13, 51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.795966832778033,\n",
       "   'compression_ratio': 1.5698924731182795,\n",
       "   'no_speech_prob': 0.5684173107147217},\n",
       "  {'id': 498,\n",
       "   'seek': 187796,\n",
       "   'start': 1899.96,\n",
       "   'end': 1904.96,\n",
       "   'text': \" Lab usage, let's say, machinery or let's say IT.\",\n",
       "   'tokens': [51463,\n",
       "    3498,\n",
       "    8748,\n",
       "    11,\n",
       "    1309,\n",
       "    338,\n",
       "    910,\n",
       "    11,\n",
       "    20230,\n",
       "    393,\n",
       "    1309,\n",
       "    338,\n",
       "    910,\n",
       "    7283,\n",
       "    13,\n",
       "    51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.795966832778033,\n",
       "   'compression_ratio': 1.5698924731182795,\n",
       "   'no_speech_prob': 0.5684173107147217},\n",
       "  {'id': 499,\n",
       "   'seek': 190496,\n",
       "   'start': 1904.96,\n",
       "   'end': 1907.96,\n",
       "   'text': ' So, we think number of computers could be one of the examples.',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    11,\n",
       "    356,\n",
       "    892,\n",
       "    1271,\n",
       "    286,\n",
       "    9061,\n",
       "    714,\n",
       "    307,\n",
       "    530,\n",
       "    286,\n",
       "    262,\n",
       "    6096,\n",
       "    13,\n",
       "    50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.463809928894043,\n",
       "   'compression_ratio': 1.6283185840707965,\n",
       "   'no_speech_prob': 0.23349596560001373},\n",
       "  {'id': 500,\n",
       "   'seek': 190496,\n",
       "   'start': 1907.96,\n",
       "   'end': 1912.96,\n",
       "   'text': ' The more the computers, the more the servers will generate strength more energy.',\n",
       "   'tokens': [50513,\n",
       "    383,\n",
       "    517,\n",
       "    262,\n",
       "    9061,\n",
       "    11,\n",
       "    262,\n",
       "    517,\n",
       "    262,\n",
       "    9597,\n",
       "    481,\n",
       "    7716,\n",
       "    4202,\n",
       "    517,\n",
       "    2568,\n",
       "    13,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.463809928894043,\n",
       "   'compression_ratio': 1.6283185840707965,\n",
       "   'no_speech_prob': 0.23349596560001373},\n",
       "  {'id': 501,\n",
       "   'seek': 190496,\n",
       "   'start': 1912.96,\n",
       "   'end': 1915.96,\n",
       "   'text': ' Any other factor we could think about?',\n",
       "   'tokens': [50763, 4377, 584, 5766, 356, 714, 892, 546, 30, 50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.463809928894043,\n",
       "   'compression_ratio': 1.6283185840707965,\n",
       "   'no_speech_prob': 0.23349596560001373},\n",
       "  {'id': 502,\n",
       "   'seek': 190496,\n",
       "   'start': 1915.96,\n",
       "   'end': 1920.96,\n",
       "   'text': ' We can make them a status in some sense captured by the number of occupants.',\n",
       "   'tokens': [50913,\n",
       "    775,\n",
       "    460,\n",
       "    787,\n",
       "    606,\n",
       "    257,\n",
       "    3722,\n",
       "    287,\n",
       "    617,\n",
       "    2565,\n",
       "    7907,\n",
       "    416,\n",
       "    262,\n",
       "    1271,\n",
       "    286,\n",
       "    35242,\n",
       "    13,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.463809928894043,\n",
       "   'compression_ratio': 1.6283185840707965,\n",
       "   'no_speech_prob': 0.23349596560001373},\n",
       "  {'id': 503,\n",
       "   'seek': 190496,\n",
       "   'start': 1920.96,\n",
       "   'end': 1921.96,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51163, 6498, 30, 51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.463809928894043,\n",
       "   'compression_ratio': 1.6283185840707965,\n",
       "   'no_speech_prob': 0.23349596560001373},\n",
       "  {'id': 504,\n",
       "   'seek': 190496,\n",
       "   'start': 1921.96,\n",
       "   'end': 1926.96,\n",
       "   'text': \" So, we don't have to explicitly write whether it's a big or a big thing.\",\n",
       "   'tokens': [51213,\n",
       "    1406,\n",
       "    11,\n",
       "    356,\n",
       "    836,\n",
       "    470,\n",
       "    423,\n",
       "    284,\n",
       "    11777,\n",
       "    3551,\n",
       "    1771,\n",
       "    340,\n",
       "    338,\n",
       "    257,\n",
       "    1263,\n",
       "    393,\n",
       "    257,\n",
       "    1263,\n",
       "    1517,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.463809928894043,\n",
       "   'compression_ratio': 1.6283185840707965,\n",
       "   'no_speech_prob': 0.23349596560001373},\n",
       "  {'id': 505,\n",
       "   'seek': 190496,\n",
       "   'start': 1926.96,\n",
       "   'end': 1929.96,\n",
       "   'text': ' That is a big factor.',\n",
       "   'tokens': [51463, 1320, 318, 257, 1263, 5766, 13, 51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.463809928894043,\n",
       "   'compression_ratio': 1.6283185840707965,\n",
       "   'no_speech_prob': 0.23349596560001373},\n",
       "  {'id': 506,\n",
       "   'seek': 190496,\n",
       "   'start': 1929.96,\n",
       "   'end': 1930.96,\n",
       "   'text': ' Sorry?',\n",
       "   'tokens': [51613, 19061, 30, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.463809928894043,\n",
       "   'compression_ratio': 1.6283185840707965,\n",
       "   'no_speech_prob': 0.23349596560001373},\n",
       "  {'id': 507,\n",
       "   'seek': 193096,\n",
       "   'start': 1931.96,\n",
       "   'end': 1936.96,\n",
       "   'text': ' Okay, so the question is how does weekend or week to relate to the population?',\n",
       "   'tokens': [50413,\n",
       "    16805,\n",
       "    11,\n",
       "    523,\n",
       "    262,\n",
       "    1808,\n",
       "    318,\n",
       "    703,\n",
       "    857,\n",
       "    5041,\n",
       "    393,\n",
       "    1285,\n",
       "    284,\n",
       "    15124,\n",
       "    284,\n",
       "    262,\n",
       "    3265,\n",
       "    30,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3939359869275774,\n",
       "   'compression_ratio': 1.4295774647887325,\n",
       "   'no_speech_prob': 0.30677908658981323},\n",
       "  {'id': 508,\n",
       "   'seek': 193096,\n",
       "   'start': 1936.96,\n",
       "   'end': 1951.96,\n",
       "   'text': \" So, I am saying that in some sense, when it's a weekend, you would assume that many of the people are, let's say, not in the\",\n",
       "   'tokens': [50663,\n",
       "    1406,\n",
       "    11,\n",
       "    314,\n",
       "    716,\n",
       "    2282,\n",
       "    326,\n",
       "    287,\n",
       "    617,\n",
       "    2565,\n",
       "    11,\n",
       "    618,\n",
       "    340,\n",
       "    338,\n",
       "    257,\n",
       "    5041,\n",
       "    11,\n",
       "    345,\n",
       "    561,\n",
       "    7048,\n",
       "    326,\n",
       "    867,\n",
       "    286,\n",
       "    262,\n",
       "    661,\n",
       "    389,\n",
       "    11,\n",
       "    1309,\n",
       "    338,\n",
       "    910,\n",
       "    11,\n",
       "    407,\n",
       "    287,\n",
       "    262,\n",
       "    51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3939359869275774,\n",
       "   'compression_ratio': 1.4295774647887325,\n",
       "   'no_speech_prob': 0.30677908658981323},\n",
       "  {'id': 509,\n",
       "   'seek': 195196,\n",
       "   'start': 1951.96,\n",
       "   'end': 1958.96,\n",
       "   'text': ' future, that would be lesser than the weekend.',\n",
       "   'tokens': [50363,\n",
       "    2003,\n",
       "    11,\n",
       "    326,\n",
       "    561,\n",
       "    307,\n",
       "    14494,\n",
       "    621,\n",
       "    262,\n",
       "    5041,\n",
       "    13,\n",
       "    50713],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.6337908426920573,\n",
       "   'compression_ratio': 1.5853658536585367,\n",
       "   'no_speech_prob': 0.5240150690078735},\n",
       "  {'id': 510,\n",
       "   'seek': 195196,\n",
       "   'start': 1958.96,\n",
       "   'end': 1961.96,\n",
       "   'text': ' Yes, why are you there?',\n",
       "   'tokens': [50713, 3363, 11, 1521, 389, 345, 612, 30, 50863],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.6337908426920573,\n",
       "   'compression_ratio': 1.5853658536585367,\n",
       "   'no_speech_prob': 0.5240150690078735},\n",
       "  {'id': 511,\n",
       "   'seek': 195196,\n",
       "   'start': 1961.96,\n",
       "   'end': 1964.96,\n",
       "   'text': ' So, you could always come up with some counter-events.',\n",
       "   'tokens': [50863,\n",
       "    1406,\n",
       "    11,\n",
       "    345,\n",
       "    714,\n",
       "    1464,\n",
       "    1282,\n",
       "    510,\n",
       "    351,\n",
       "    617,\n",
       "    3753,\n",
       "    12,\n",
       "    31534,\n",
       "    13,\n",
       "    51013],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.6337908426920573,\n",
       "   'compression_ratio': 1.5853658536585367,\n",
       "   'no_speech_prob': 0.5240150690078735},\n",
       "  {'id': 512,\n",
       "   'seek': 195196,\n",
       "   'start': 1964.96,\n",
       "   'end': 1965.96,\n",
       "   'text': ' Yes.',\n",
       "   'tokens': [51013, 3363, 13, 51063],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.6337908426920573,\n",
       "   'compression_ratio': 1.5853658536585367,\n",
       "   'no_speech_prob': 0.5240150690078735},\n",
       "  {'id': 513,\n",
       "   'seek': 195196,\n",
       "   'start': 1965.96,\n",
       "   'end': 1970.96,\n",
       "   'text': ' But there may be some people who would be leaving, some people who would be coming.',\n",
       "   'tokens': [51063,\n",
       "    887,\n",
       "    612,\n",
       "    743,\n",
       "    307,\n",
       "    617,\n",
       "    661,\n",
       "    508,\n",
       "    561,\n",
       "    307,\n",
       "    4305,\n",
       "    11,\n",
       "    617,\n",
       "    661,\n",
       "    508,\n",
       "    561,\n",
       "    307,\n",
       "    2406,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.6337908426920573,\n",
       "   'compression_ratio': 1.5853658536585367,\n",
       "   'no_speech_prob': 0.5240150690078735},\n",
       "  {'id': 514,\n",
       "   'seek': 195196,\n",
       "   'start': 1970.96,\n",
       "   'end': 1974.96,\n",
       "   'text': ' They and I, we can all meet different people.',\n",
       "   'tokens': [51313,\n",
       "    1119,\n",
       "    290,\n",
       "    314,\n",
       "    11,\n",
       "    356,\n",
       "    460,\n",
       "    477,\n",
       "    1826,\n",
       "    1180,\n",
       "    661,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.6337908426920573,\n",
       "   'compression_ratio': 1.5853658536585367,\n",
       "   'no_speech_prob': 0.5240150690078735},\n",
       "  {'id': 515,\n",
       "   'seek': 197496,\n",
       "   'start': 1975.96,\n",
       "   'end': 1979.96,\n",
       "   'text': ' Okay, so he is saying that the hour of the day is also an important factor.',\n",
       "   'tokens': [50413,\n",
       "    16805,\n",
       "    11,\n",
       "    523,\n",
       "    339,\n",
       "    318,\n",
       "    2282,\n",
       "    326,\n",
       "    262,\n",
       "    1711,\n",
       "    286,\n",
       "    262,\n",
       "    1110,\n",
       "    318,\n",
       "    635,\n",
       "    281,\n",
       "    1593,\n",
       "    5766,\n",
       "    13,\n",
       "    50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6399761331492457,\n",
       "   'compression_ratio': 1.703125,\n",
       "   'no_speech_prob': 0.2028401494026184},\n",
       "  {'id': 516,\n",
       "   'seek': 197496,\n",
       "   'start': 1979.96,\n",
       "   'end': 1984.96,\n",
       "   'text': ' How can you gain tellers which are expected more energy consumption?',\n",
       "   'tokens': [50613,\n",
       "    1374,\n",
       "    460,\n",
       "    345,\n",
       "    4461,\n",
       "    1560,\n",
       "    364,\n",
       "    543,\n",
       "    389,\n",
       "    2938,\n",
       "    517,\n",
       "    2568,\n",
       "    7327,\n",
       "    30,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6399761331492457,\n",
       "   'compression_ratio': 1.703125,\n",
       "   'no_speech_prob': 0.2028401494026184},\n",
       "  {'id': 517,\n",
       "   'seek': 197496,\n",
       "   'start': 1984.96,\n",
       "   'end': 1988.96,\n",
       "   'text': ' So, in the night we got 15, we can all get 20, 20, 20, 20.',\n",
       "   'tokens': [50863,\n",
       "    1406,\n",
       "    11,\n",
       "    287,\n",
       "    262,\n",
       "    1755,\n",
       "    356,\n",
       "    1392,\n",
       "    1315,\n",
       "    11,\n",
       "    356,\n",
       "    460,\n",
       "    477,\n",
       "    651,\n",
       "    1160,\n",
       "    11,\n",
       "    1160,\n",
       "    11,\n",
       "    1160,\n",
       "    11,\n",
       "    1160,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6399761331492457,\n",
       "   'compression_ratio': 1.703125,\n",
       "   'no_speech_prob': 0.2028401494026184},\n",
       "  {'id': 518,\n",
       "   'seek': 197496,\n",
       "   'start': 1988.96,\n",
       "   'end': 1992.96,\n",
       "   'text': ' Yes, in the night I assume, but we not have a fine.',\n",
       "   'tokens': [51063,\n",
       "    3363,\n",
       "    11,\n",
       "    287,\n",
       "    262,\n",
       "    1755,\n",
       "    314,\n",
       "    7048,\n",
       "    11,\n",
       "    475,\n",
       "    356,\n",
       "    407,\n",
       "    423,\n",
       "    257,\n",
       "    3734,\n",
       "    13,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6399761331492457,\n",
       "   'compression_ratio': 1.703125,\n",
       "   'no_speech_prob': 0.2028401494026184},\n",
       "  {'id': 519,\n",
       "   'seek': 197496,\n",
       "   'start': 1992.96,\n",
       "   'end': 1996.96,\n",
       "   'text': \" For now, let's assume that, 24, 20, 9 people have to 3, 10, so it's a lot harder.\",\n",
       "   'tokens': [51263,\n",
       "    1114,\n",
       "    783,\n",
       "    11,\n",
       "    1309,\n",
       "    338,\n",
       "    7048,\n",
       "    326,\n",
       "    11,\n",
       "    1987,\n",
       "    11,\n",
       "    1160,\n",
       "    11,\n",
       "    860,\n",
       "    661,\n",
       "    423,\n",
       "    284,\n",
       "    513,\n",
       "    11,\n",
       "    838,\n",
       "    11,\n",
       "    523,\n",
       "    340,\n",
       "    338,\n",
       "    257,\n",
       "    1256,\n",
       "    7069,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6399761331492457,\n",
       "   'compression_ratio': 1.703125,\n",
       "   'no_speech_prob': 0.2028401494026184},\n",
       "  {'id': 520,\n",
       "   'seek': 197496,\n",
       "   'start': 1996.96,\n",
       "   'end': 1999.96,\n",
       "   'text': ' So, in the night I mean, 10, 20, see the lot to be low.',\n",
       "   'tokens': [51463,\n",
       "    1406,\n",
       "    11,\n",
       "    287,\n",
       "    262,\n",
       "    1755,\n",
       "    314,\n",
       "    1612,\n",
       "    11,\n",
       "    838,\n",
       "    11,\n",
       "    1160,\n",
       "    11,\n",
       "    766,\n",
       "    262,\n",
       "    1256,\n",
       "    284,\n",
       "    307,\n",
       "    1877,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6399761331492457,\n",
       "   'compression_ratio': 1.703125,\n",
       "   'no_speech_prob': 0.2028401494026184},\n",
       "  {'id': 521,\n",
       "   'seek': 197496,\n",
       "   'start': 1999.96,\n",
       "   'end': 2002.96,\n",
       "   'text': ' At least in the right, 10, 20, 20, 20, 20.',\n",
       "   'tokens': [51613,\n",
       "    1629,\n",
       "    1551,\n",
       "    287,\n",
       "    262,\n",
       "    826,\n",
       "    11,\n",
       "    838,\n",
       "    11,\n",
       "    1160,\n",
       "    11,\n",
       "    1160,\n",
       "    11,\n",
       "    1160,\n",
       "    11,\n",
       "    1160,\n",
       "    13,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6399761331492457,\n",
       "   'compression_ratio': 1.703125,\n",
       "   'no_speech_prob': 0.2028401494026184},\n",
       "  {'id': 522,\n",
       "   'seek': 200296,\n",
       "   'start': 2003.96,\n",
       "   'end': 2010.96,\n",
       "   'text': ' So, more people with generally poor energy, higher temperature, generally higher energy.',\n",
       "   'tokens': [50413,\n",
       "    1406,\n",
       "    11,\n",
       "    517,\n",
       "    661,\n",
       "    351,\n",
       "    4143,\n",
       "    3595,\n",
       "    2568,\n",
       "    11,\n",
       "    2440,\n",
       "    5951,\n",
       "    11,\n",
       "    4143,\n",
       "    2440,\n",
       "    2568,\n",
       "    13,\n",
       "    50763],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.7070443289620536,\n",
       "   'compression_ratio': 1.855263157894737,\n",
       "   'no_speech_prob': 0.04248209297657013},\n",
       "  {'id': 523,\n",
       "   'seek': 200296,\n",
       "   'start': 2010.96,\n",
       "   'end': 2013.96,\n",
       "   'text': ' Again, it can be constructed here like this now.',\n",
       "   'tokens': [50763,\n",
       "    6521,\n",
       "    11,\n",
       "    340,\n",
       "    460,\n",
       "    307,\n",
       "    12006,\n",
       "    994,\n",
       "    588,\n",
       "    428,\n",
       "    783,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.7070443289620536,\n",
       "   'compression_ratio': 1.855263157894737,\n",
       "   'no_speech_prob': 0.04248209297657013},\n",
       "  {'id': 524,\n",
       "   'seek': 200296,\n",
       "   'start': 2013.96,\n",
       "   'end': 2017.96,\n",
       "   'text': ' We have people temperature and this, well the purpose of the relationship is to be in people',\n",
       "   'tokens': [50913,\n",
       "    775,\n",
       "    423,\n",
       "    661,\n",
       "    5951,\n",
       "    290,\n",
       "    428,\n",
       "    11,\n",
       "    880,\n",
       "    262,\n",
       "    4007,\n",
       "    286,\n",
       "    262,\n",
       "    2776,\n",
       "    318,\n",
       "    284,\n",
       "    307,\n",
       "    287,\n",
       "    661,\n",
       "    51113],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.7070443289620536,\n",
       "   'compression_ratio': 1.855263157894737,\n",
       "   'no_speech_prob': 0.04248209297657013},\n",
       "  {'id': 525,\n",
       "   'seek': 200296,\n",
       "   'start': 2017.96,\n",
       "   'end': 2022.96,\n",
       "   'text': ' and people and temperature and energy, you know, for now, I mean some of the people are',\n",
       "   'tokens': [51113,\n",
       "    290,\n",
       "    661,\n",
       "    290,\n",
       "    5951,\n",
       "    290,\n",
       "    2568,\n",
       "    11,\n",
       "    345,\n",
       "    760,\n",
       "    11,\n",
       "    329,\n",
       "    783,\n",
       "    11,\n",
       "    314,\n",
       "    1612,\n",
       "    617,\n",
       "    286,\n",
       "    262,\n",
       "    661,\n",
       "    389,\n",
       "    51363],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.7070443289620536,\n",
       "   'compression_ratio': 1.855263157894737,\n",
       "   'no_speech_prob': 0.04248209297657013},\n",
       "  {'id': 526,\n",
       "   'seek': 200296,\n",
       "   'start': 2022.96,\n",
       "   'end': 2023.96,\n",
       "   'text': ' doing it also.',\n",
       "   'tokens': [51363, 1804, 340, 635, 13, 51413],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.7070443289620536,\n",
       "   'compression_ratio': 1.855263157894737,\n",
       "   'no_speech_prob': 0.04248209297657013},\n",
       "  {'id': 527,\n",
       "   'seek': 200296,\n",
       "   'start': 2023.96,\n",
       "   'end': 2027.96,\n",
       "   'text': ' You could use jewels, but, you know, rather, more generally, I am certain, certain level.',\n",
       "   'tokens': [51413,\n",
       "    921,\n",
       "    714,\n",
       "    779,\n",
       "    42701,\n",
       "    11,\n",
       "    475,\n",
       "    11,\n",
       "    345,\n",
       "    760,\n",
       "    11,\n",
       "    2138,\n",
       "    11,\n",
       "    517,\n",
       "    4143,\n",
       "    11,\n",
       "    314,\n",
       "    716,\n",
       "    1728,\n",
       "    11,\n",
       "    1728,\n",
       "    1241,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.7070443289620536,\n",
       "   'compression_ratio': 1.855263157894737,\n",
       "   'no_speech_prob': 0.04248209297657013},\n",
       "  {'id': 528,\n",
       "   'seek': 202796,\n",
       "   'start': 2027.96,\n",
       "   'end': 2029.96,\n",
       "   'text': ' Now, what is the training center?',\n",
       "   'tokens': [50363, 2735, 11, 644, 318, 262, 3047, 3641, 30, 50463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.43417449951171877,\n",
       "   'compression_ratio': 1.7336065573770492,\n",
       "   'no_speech_prob': 0.22827059030532837},\n",
       "  {'id': 529,\n",
       "   'seek': 202796,\n",
       "   'start': 2029.96,\n",
       "   'end': 2036.96,\n",
       "   'text': ' The first three rows and they consider them as pre-made side because they have the labels,',\n",
       "   'tokens': [50463,\n",
       "    383,\n",
       "    717,\n",
       "    1115,\n",
       "    15274,\n",
       "    290,\n",
       "    484,\n",
       "    2074,\n",
       "    606,\n",
       "    355,\n",
       "    662,\n",
       "    12,\n",
       "    9727,\n",
       "    1735,\n",
       "    780,\n",
       "    484,\n",
       "    423,\n",
       "    262,\n",
       "    14722,\n",
       "    11,\n",
       "    50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.43417449951171877,\n",
       "   'compression_ratio': 1.7336065573770492,\n",
       "   'no_speech_prob': 0.22827059030532837},\n",
       "  {'id': 530,\n",
       "   'seek': 202796,\n",
       "   'start': 2036.96,\n",
       "   'end': 2040.96,\n",
       "   'text': ' also mentioned the output variable or response variable also maintenance.',\n",
       "   'tokens': [50813,\n",
       "    635,\n",
       "    4750,\n",
       "    262,\n",
       "    5072,\n",
       "    7885,\n",
       "    393,\n",
       "    2882,\n",
       "    7885,\n",
       "    635,\n",
       "    9262,\n",
       "    13,\n",
       "    51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.43417449951171877,\n",
       "   'compression_ratio': 1.7336065573770492,\n",
       "   'no_speech_prob': 0.22827059030532837},\n",
       "  {'id': 531,\n",
       "   'seek': 202796,\n",
       "   'start': 2040.96,\n",
       "   'end': 2045.96,\n",
       "   'text': ' Where as the set shown below of the last two samples, becomes a test set.',\n",
       "   'tokens': [51013,\n",
       "    6350,\n",
       "    355,\n",
       "    262,\n",
       "    900,\n",
       "    3402,\n",
       "    2174,\n",
       "    286,\n",
       "    262,\n",
       "    938,\n",
       "    734,\n",
       "    8405,\n",
       "    11,\n",
       "    4329,\n",
       "    257,\n",
       "    1332,\n",
       "    900,\n",
       "    13,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.43417449951171877,\n",
       "   'compression_ratio': 1.7336065573770492,\n",
       "   'no_speech_prob': 0.22827059030532837},\n",
       "  {'id': 532,\n",
       "   'seek': 202796,\n",
       "   'start': 2045.96,\n",
       "   'end': 2051.96,\n",
       "   'text': ' Where the labels or the response variable or the target rate of the application have not been mentioned.',\n",
       "   'tokens': [51263,\n",
       "    6350,\n",
       "    262,\n",
       "    14722,\n",
       "    393,\n",
       "    262,\n",
       "    2882,\n",
       "    7885,\n",
       "    393,\n",
       "    262,\n",
       "    2496,\n",
       "    2494,\n",
       "    286,\n",
       "    262,\n",
       "    3586,\n",
       "    423,\n",
       "    407,\n",
       "    587,\n",
       "    4750,\n",
       "    13,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.43417449951171877,\n",
       "   'compression_ratio': 1.7336065573770492,\n",
       "   'no_speech_prob': 0.22827059030532837},\n",
       "  {'id': 533,\n",
       "   'seek': 202796,\n",
       "   'start': 2051.96,\n",
       "   'end': 2054.96,\n",
       "   'text': \" And this is what you're trying to say, right?\",\n",
       "   'tokens': [51563,\n",
       "    843,\n",
       "    428,\n",
       "    318,\n",
       "    644,\n",
       "    345,\n",
       "    821,\n",
       "    2111,\n",
       "    284,\n",
       "    910,\n",
       "    11,\n",
       "    826,\n",
       "    30,\n",
       "    51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.43417449951171877,\n",
       "   'compression_ratio': 1.7336065573770492,\n",
       "   'no_speech_prob': 0.22827059030532837},\n",
       "  {'id': 534,\n",
       "   'seek': 205496,\n",
       "   'start': 2055.96,\n",
       "   'end': 2060.96,\n",
       "   'text': ' So, you have thus far seen two different kinds of examples.',\n",
       "   'tokens': [50413,\n",
       "    1406,\n",
       "    11,\n",
       "    345,\n",
       "    423,\n",
       "    4145,\n",
       "    1290,\n",
       "    1775,\n",
       "    734,\n",
       "    1180,\n",
       "    6982,\n",
       "    286,\n",
       "    6096,\n",
       "    13,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.265045236658167,\n",
       "   'compression_ratio': 1.5555555555555556,\n",
       "   'no_speech_prob': 0.03898805007338524},\n",
       "  {'id': 535,\n",
       "   'seek': 205496,\n",
       "   'start': 2060.96,\n",
       "   'end': 2067.96,\n",
       "   'text': \" Let's try and make a little more abstractly because of two specific classes of problems.\",\n",
       "   'tokens': [50663,\n",
       "    3914,\n",
       "    338,\n",
       "    1949,\n",
       "    290,\n",
       "    787,\n",
       "    257,\n",
       "    1310,\n",
       "    517,\n",
       "    12531,\n",
       "    306,\n",
       "    780,\n",
       "    286,\n",
       "    734,\n",
       "    2176,\n",
       "    6097,\n",
       "    286,\n",
       "    2761,\n",
       "    13,\n",
       "    51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.265045236658167,\n",
       "   'compression_ratio': 1.5555555555555556,\n",
       "   'no_speech_prob': 0.03898805007338524},\n",
       "  {'id': 536,\n",
       "   'seek': 205496,\n",
       "   'start': 2067.96,\n",
       "   'end': 2072.96,\n",
       "   'text': ' I am going to write the first class of problems as classification.',\n",
       "   'tokens': [51013,\n",
       "    314,\n",
       "    716,\n",
       "    1016,\n",
       "    284,\n",
       "    3551,\n",
       "    262,\n",
       "    717,\n",
       "    1398,\n",
       "    286,\n",
       "    2761,\n",
       "    355,\n",
       "    17923,\n",
       "    13,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.265045236658167,\n",
       "   'compression_ratio': 1.5555555555555556,\n",
       "   'no_speech_prob': 0.03898805007338524},\n",
       "  {'id': 537,\n",
       "   'seek': 205496,\n",
       "   'start': 2072.96,\n",
       "   'end': 2077.96,\n",
       "   'text': ' Here the output variable of concern is discrete in nature, right?',\n",
       "   'tokens': [51263,\n",
       "    3423,\n",
       "    262,\n",
       "    5072,\n",
       "    7885,\n",
       "    286,\n",
       "    2328,\n",
       "    318,\n",
       "    28810,\n",
       "    287,\n",
       "    3450,\n",
       "    11,\n",
       "    826,\n",
       "    30,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.265045236658167,\n",
       "   'compression_ratio': 1.5555555555555556,\n",
       "   'no_speech_prob': 0.03898805007338524},\n",
       "  {'id': 538,\n",
       "   'seek': 205496,\n",
       "   'start': 2077.96,\n",
       "   'end': 2080.96,\n",
       "   'text': ' There is a number here, I understand what is discrete.',\n",
       "   'tokens': [51513,\n",
       "    1318,\n",
       "    318,\n",
       "    257,\n",
       "    1271,\n",
       "    994,\n",
       "    11,\n",
       "    314,\n",
       "    1833,\n",
       "    644,\n",
       "    318,\n",
       "    28810,\n",
       "    13,\n",
       "    51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.265045236658167,\n",
       "   'compression_ratio': 1.5555555555555556,\n",
       "   'no_speech_prob': 0.03898805007338524},\n",
       "  {'id': 539,\n",
       "   'seek': 208096,\n",
       "   'start': 2081.96,\n",
       "   'end': 2084.96,\n",
       "   'text': ' So, discrete means it could be one of few classes.',\n",
       "   'tokens': [50413,\n",
       "    1406,\n",
       "    11,\n",
       "    28810,\n",
       "    1724,\n",
       "    340,\n",
       "    714,\n",
       "    307,\n",
       "    530,\n",
       "    286,\n",
       "    1178,\n",
       "    6097,\n",
       "    13,\n",
       "    50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3575511861730505,\n",
       "   'compression_ratio': 1.8193832599118942,\n",
       "   'no_speech_prob': 0.09960552304983139},\n",
       "  {'id': 540,\n",
       "   'seek': 208096,\n",
       "   'start': 2084.96,\n",
       "   'end': 2090.96,\n",
       "   'text': \" It could either be any, so this one of the examples of discrete is binary, whether it's on or off.\",\n",
       "   'tokens': [50563,\n",
       "    632,\n",
       "    714,\n",
       "    2035,\n",
       "    307,\n",
       "    597,\n",
       "    11,\n",
       "    523,\n",
       "    428,\n",
       "    530,\n",
       "    286,\n",
       "    262,\n",
       "    6096,\n",
       "    286,\n",
       "    28810,\n",
       "    318,\n",
       "    13934,\n",
       "    11,\n",
       "    1771,\n",
       "    340,\n",
       "    338,\n",
       "    319,\n",
       "    393,\n",
       "    572,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3575511861730505,\n",
       "   'compression_ratio': 1.8193832599118942,\n",
       "   'no_speech_prob': 0.09960552304983139},\n",
       "  {'id': 541,\n",
       "   'seek': 208096,\n",
       "   'start': 2090.96,\n",
       "   'end': 2093.96,\n",
       "   'text': ' It could also be done to be one of three classes.',\n",
       "   'tokens': [50863,\n",
       "    632,\n",
       "    714,\n",
       "    635,\n",
       "    307,\n",
       "    1760,\n",
       "    284,\n",
       "    307,\n",
       "    530,\n",
       "    286,\n",
       "    1115,\n",
       "    6097,\n",
       "    13,\n",
       "    51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3575511861730505,\n",
       "   'compression_ratio': 1.8193832599118942,\n",
       "   'no_speech_prob': 0.09960552304983139},\n",
       "  {'id': 542,\n",
       "   'seek': 208096,\n",
       "   'start': 2093.96,\n",
       "   'end': 2095.96,\n",
       "   'text': ' It could also be binary.',\n",
       "   'tokens': [51013, 632, 714, 635, 307, 13934, 13, 51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3575511861730505,\n",
       "   'compression_ratio': 1.8193832599118942,\n",
       "   'no_speech_prob': 0.09960552304983139},\n",
       "  {'id': 543,\n",
       "   'seek': 208096,\n",
       "   'start': 2095.96,\n",
       "   'end': 2103.96,\n",
       "   'text': ' Both formerly they say that why I belong to a set from one to C where we have C classes.',\n",
       "   'tokens': [51113,\n",
       "    5747,\n",
       "    15734,\n",
       "    484,\n",
       "    910,\n",
       "    326,\n",
       "    1521,\n",
       "    314,\n",
       "    5594,\n",
       "    284,\n",
       "    257,\n",
       "    900,\n",
       "    422,\n",
       "    530,\n",
       "    284,\n",
       "    327,\n",
       "    810,\n",
       "    356,\n",
       "    423,\n",
       "    327,\n",
       "    6097,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3575511861730505,\n",
       "   'compression_ratio': 1.8193832599118942,\n",
       "   'no_speech_prob': 0.09960552304983139},\n",
       "  {'id': 544,\n",
       "   'seek': 208096,\n",
       "   'start': 2103.96,\n",
       "   'end': 2109.96,\n",
       "   'text': ' We have seen one example can even tell you more examples of classification tasks in my new version.',\n",
       "   'tokens': [51513,\n",
       "    775,\n",
       "    423,\n",
       "    1775,\n",
       "    530,\n",
       "    1672,\n",
       "    460,\n",
       "    772,\n",
       "    1560,\n",
       "    345,\n",
       "    517,\n",
       "    6096,\n",
       "    286,\n",
       "    17923,\n",
       "    8861,\n",
       "    287,\n",
       "    616,\n",
       "    649,\n",
       "    2196,\n",
       "    13,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3575511861730505,\n",
       "   'compression_ratio': 1.8193832599118942,\n",
       "   'no_speech_prob': 0.09960552304983139},\n",
       "  {'id': 545,\n",
       "   'seek': 210996,\n",
       "   'start': 2109.96,\n",
       "   'end': 2130.96,\n",
       "   'text': ' So, in the example that is given is given is you want to predict Google when, right?',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    11,\n",
       "    287,\n",
       "    262,\n",
       "    1672,\n",
       "    326,\n",
       "    318,\n",
       "    1813,\n",
       "    318,\n",
       "    1813,\n",
       "    318,\n",
       "    345,\n",
       "    765,\n",
       "    284,\n",
       "    4331,\n",
       "    3012,\n",
       "    618,\n",
       "    11,\n",
       "    826,\n",
       "    30,\n",
       "    51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4588055732922676,\n",
       "   'compression_ratio': 1.2844827586206897,\n",
       "   'no_speech_prob': 0.21588236093521118},\n",
       "  {'id': 546,\n",
       "   'seek': 210996,\n",
       "   'start': 2130.96,\n",
       "   'end': 2134.96,\n",
       "   'text': ' So, in fact this reminds me of some very interesting simulation.',\n",
       "   'tokens': [51413,\n",
       "    1406,\n",
       "    11,\n",
       "    287,\n",
       "    1109,\n",
       "    428,\n",
       "    17603,\n",
       "    502,\n",
       "    286,\n",
       "    617,\n",
       "    845,\n",
       "    3499,\n",
       "    18640,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4588055732922676,\n",
       "   'compression_ratio': 1.2844827586206897,\n",
       "   'no_speech_prob': 0.21588236093521118},\n",
       "  {'id': 547,\n",
       "   'seek': 213496,\n",
       "   'start': 2134.96,\n",
       "   'end': 2138.96,\n",
       "   'text': ' I think there is a very nice log by a data server.',\n",
       "   'tokens': [50363,\n",
       "    314,\n",
       "    892,\n",
       "    612,\n",
       "    318,\n",
       "    257,\n",
       "    845,\n",
       "    3621,\n",
       "    2604,\n",
       "    416,\n",
       "    257,\n",
       "    1366,\n",
       "    4382,\n",
       "    13,\n",
       "    50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.46075588025544817,\n",
       "   'compression_ratio': 1.600896860986547,\n",
       "   'no_speech_prob': 0.6076913475990295},\n",
       "  {'id': 548,\n",
       "   'seek': 213496,\n",
       "   'start': 2138.96,\n",
       "   'end': 2145.96,\n",
       "   'text': ' Those of you who follow sports as well as data, should be really looking into that.',\n",
       "   'tokens': [50563,\n",
       "    5845,\n",
       "    286,\n",
       "    345,\n",
       "    508,\n",
       "    1061,\n",
       "    5701,\n",
       "    355,\n",
       "    880,\n",
       "    355,\n",
       "    1366,\n",
       "    11,\n",
       "    815,\n",
       "    307,\n",
       "    1107,\n",
       "    2045,\n",
       "    656,\n",
       "    326,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.46075588025544817,\n",
       "   'compression_ratio': 1.600896860986547,\n",
       "   'no_speech_prob': 0.6076913475990295},\n",
       "  {'id': 549,\n",
       "   'seek': 213496,\n",
       "   'start': 2145.96,\n",
       "   'end': 2151.96,\n",
       "   'text': ' And some of these log is fact greatly winners of the football champions team and the NBA, et cetera.',\n",
       "   'tokens': [50913,\n",
       "    843,\n",
       "    617,\n",
       "    286,\n",
       "    777,\n",
       "    2604,\n",
       "    318,\n",
       "    1109,\n",
       "    9257,\n",
       "    14591,\n",
       "    286,\n",
       "    262,\n",
       "    4346,\n",
       "    7827,\n",
       "    1074,\n",
       "    290,\n",
       "    262,\n",
       "    7403,\n",
       "    11,\n",
       "    2123,\n",
       "    269,\n",
       "    2357,\n",
       "    64,\n",
       "    13,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.46075588025544817,\n",
       "   'compression_ratio': 1.600896860986547,\n",
       "   'no_speech_prob': 0.6076913475990295},\n",
       "  {'id': 550,\n",
       "   'seek': 213496,\n",
       "   'start': 2151.96,\n",
       "   'end': 2153.96,\n",
       "   'text': ' You look over the masses now.',\n",
       "   'tokens': [51213, 921, 804, 625, 262, 14568, 783, 13, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.46075588025544817,\n",
       "   'compression_ratio': 1.600896860986547,\n",
       "   'no_speech_prob': 0.6076913475990295},\n",
       "  {'id': 551,\n",
       "   'seek': 213496,\n",
       "   'start': 2153.96,\n",
       "   'end': 2160.96,\n",
       "   'text': ' And they have some, they have some confidence with the same group in the league, et cetera.',\n",
       "   'tokens': [51313,\n",
       "    843,\n",
       "    484,\n",
       "    423,\n",
       "    617,\n",
       "    11,\n",
       "    484,\n",
       "    423,\n",
       "    617,\n",
       "    6628,\n",
       "    351,\n",
       "    262,\n",
       "    976,\n",
       "    1448,\n",
       "    287,\n",
       "    262,\n",
       "    4652,\n",
       "    11,\n",
       "    2123,\n",
       "    269,\n",
       "    2357,\n",
       "    64,\n",
       "    13,\n",
       "    51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.46075588025544817,\n",
       "   'compression_ratio': 1.600896860986547,\n",
       "   'no_speech_prob': 0.6076913475990295},\n",
       "  {'id': 552,\n",
       "   'seek': 216096,\n",
       "   'start': 2160.96,\n",
       "   'end': 2162.96,\n",
       "   'text': ' So, what are the kinds of numbers you have?',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    11,\n",
       "    644,\n",
       "    389,\n",
       "    262,\n",
       "    6982,\n",
       "    286,\n",
       "    3146,\n",
       "    345,\n",
       "    423,\n",
       "    30,\n",
       "    50463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5321157923284566,\n",
       "   'compression_ratio': 1.5648535564853556,\n",
       "   'no_speech_prob': 0.4053543210029602},\n",
       "  {'id': 553,\n",
       "   'seek': 216096,\n",
       "   'start': 2162.96,\n",
       "   'end': 2165.96,\n",
       "   'text': \" Let's focus on how or something like this.\",\n",
       "   'tokens': [50463,\n",
       "    3914,\n",
       "    338,\n",
       "    2962,\n",
       "    319,\n",
       "    703,\n",
       "    393,\n",
       "    1223,\n",
       "    588,\n",
       "    428,\n",
       "    13,\n",
       "    50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5321157923284566,\n",
       "   'compression_ratio': 1.5648535564853556,\n",
       "   'no_speech_prob': 0.4053543210029602},\n",
       "  {'id': 554,\n",
       "   'seek': 216096,\n",
       "   'start': 2165.96,\n",
       "   'end': 2170.96,\n",
       "   'text': ' When you also have tie your top, or particular cases.',\n",
       "   'tokens': [50613,\n",
       "    1649,\n",
       "    345,\n",
       "    635,\n",
       "    423,\n",
       "    9839,\n",
       "    534,\n",
       "    1353,\n",
       "    11,\n",
       "    393,\n",
       "    1948,\n",
       "    2663,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5321157923284566,\n",
       "   'compression_ratio': 1.5648535564853556,\n",
       "   'no_speech_prob': 0.4053543210029602},\n",
       "  {'id': 555,\n",
       "   'seek': 216096,\n",
       "   'start': 2170.96,\n",
       "   'end': 2172.96,\n",
       "   'text': ' So, this is not full class.',\n",
       "   'tokens': [50863, 1406, 11, 428, 318, 407, 1336, 1398, 13, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5321157923284566,\n",
       "   'compression_ratio': 1.5648535564853556,\n",
       "   'no_speech_prob': 0.4053543210029602},\n",
       "  {'id': 556,\n",
       "   'seek': 216096,\n",
       "   'start': 2172.96,\n",
       "   'end': 2176.96,\n",
       "   'text': ' And what kind of input features do you think you have to get?',\n",
       "   'tokens': [50963,\n",
       "    843,\n",
       "    644,\n",
       "    1611,\n",
       "    286,\n",
       "    5128,\n",
       "    3033,\n",
       "    466,\n",
       "    345,\n",
       "    892,\n",
       "    345,\n",
       "    423,\n",
       "    284,\n",
       "    651,\n",
       "    30,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5321157923284566,\n",
       "   'compression_ratio': 1.5648535564853556,\n",
       "   'no_speech_prob': 0.4053543210029602},\n",
       "  {'id': 557,\n",
       "   'seek': 216096,\n",
       "   'start': 2178.96,\n",
       "   'end': 2181.96,\n",
       "   'text': ' And everyone else can also take this one out.',\n",
       "   'tokens': [51263,\n",
       "    843,\n",
       "    2506,\n",
       "    2073,\n",
       "    460,\n",
       "    635,\n",
       "    1011,\n",
       "    428,\n",
       "    530,\n",
       "    503,\n",
       "    13,\n",
       "    51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5321157923284566,\n",
       "   'compression_ratio': 1.5648535564853556,\n",
       "   'no_speech_prob': 0.4053543210029602},\n",
       "  {'id': 558,\n",
       "   'seek': 216096,\n",
       "   'start': 2181.96,\n",
       "   'end': 2187.96,\n",
       "   'text': ' So, if you want to predict whether India and Sri Lanka are playing, like, we do 20, who will win.',\n",
       "   'tokens': [51413,\n",
       "    1406,\n",
       "    11,\n",
       "    611,\n",
       "    345,\n",
       "    765,\n",
       "    284,\n",
       "    4331,\n",
       "    1771,\n",
       "    3794,\n",
       "    290,\n",
       "    20872,\n",
       "    28143,\n",
       "    389,\n",
       "    2712,\n",
       "    11,\n",
       "    588,\n",
       "    11,\n",
       "    356,\n",
       "    466,\n",
       "    1160,\n",
       "    11,\n",
       "    508,\n",
       "    481,\n",
       "    1592,\n",
       "    13,\n",
       "    51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5321157923284566,\n",
       "   'compression_ratio': 1.5648535564853556,\n",
       "   'no_speech_prob': 0.4053543210029602},\n",
       "  {'id': 559,\n",
       "   'seek': 218796,\n",
       "   'start': 2188.96,\n",
       "   'end': 2190.96,\n",
       "   'text': ' So, how would you find that?',\n",
       "   'tokens': [50413, 1406, 11, 703, 561, 345, 1064, 326, 30, 50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.360066894792084,\n",
       "   'compression_ratio': 1.7081545064377683,\n",
       "   'no_speech_prob': 0.130547434091568},\n",
       "  {'id': 560,\n",
       "   'seek': 218796,\n",
       "   'start': 2190.96,\n",
       "   'end': 2192.96,\n",
       "   'text': ' We need to ask you to ask them.',\n",
       "   'tokens': [50513, 775, 761, 284, 1265, 345, 284, 1265, 606, 13, 50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.360066894792084,\n",
       "   'compression_ratio': 1.7081545064377683,\n",
       "   'no_speech_prob': 0.130547434091568},\n",
       "  {'id': 561,\n",
       "   'seek': 218796,\n",
       "   'start': 2192.96,\n",
       "   'end': 2193.96,\n",
       "   'text': ' Playing 11th.',\n",
       "   'tokens': [50613, 23911, 1367, 400, 13, 50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.360066894792084,\n",
       "   'compression_ratio': 1.7081545064377683,\n",
       "   'no_speech_prob': 0.130547434091568},\n",
       "  {'id': 562,\n",
       "   'seek': 218796,\n",
       "   'start': 2193.96,\n",
       "   'end': 2196.96,\n",
       "   'text': ' Playing 11th, so playing 11th, fine.',\n",
       "   'tokens': [50663,\n",
       "    23911,\n",
       "    1367,\n",
       "    400,\n",
       "    11,\n",
       "    523,\n",
       "    2712,\n",
       "    1367,\n",
       "    400,\n",
       "    11,\n",
       "    3734,\n",
       "    13,\n",
       "    50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.360066894792084,\n",
       "   'compression_ratio': 1.7081545064377683,\n",
       "   'no_speech_prob': 0.130547434091568},\n",
       "  {'id': 563,\n",
       "   'seek': 218796,\n",
       "   'start': 2196.96,\n",
       "   'end': 2199.96,\n",
       "   'text': ' So, you know, by playing 11th, you mean the names?',\n",
       "   'tokens': [50813,\n",
       "    1406,\n",
       "    11,\n",
       "    345,\n",
       "    760,\n",
       "    11,\n",
       "    416,\n",
       "    2712,\n",
       "    1367,\n",
       "    400,\n",
       "    11,\n",
       "    345,\n",
       "    1612,\n",
       "    262,\n",
       "    3891,\n",
       "    30,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.360066894792084,\n",
       "   'compression_ratio': 1.7081545064377683,\n",
       "   'no_speech_prob': 0.130547434091568},\n",
       "  {'id': 564,\n",
       "   'seek': 218796,\n",
       "   'start': 2199.96,\n",
       "   'end': 2200.96,\n",
       "   'text': ' 20th.',\n",
       "   'tokens': [50963, 1160, 400, 13, 51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.360066894792084,\n",
       "   'compression_ratio': 1.7081545064377683,\n",
       "   'no_speech_prob': 0.130547434091568},\n",
       "  {'id': 565,\n",
       "   'seek': 218796,\n",
       "   'start': 2200.96,\n",
       "   'end': 2201.96,\n",
       "   'text': ' Probably not.',\n",
       "   'tokens': [51013, 18578, 407, 13, 51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.360066894792084,\n",
       "   'compression_ratio': 1.7081545064377683,\n",
       "   'no_speech_prob': 0.130547434091568},\n",
       "  {'id': 566,\n",
       "   'seek': 218796,\n",
       "   'start': 2201.96,\n",
       "   'end': 2203.96,\n",
       "   'text': ' So, some notion of their ratings, right?',\n",
       "   'tokens': [51063, 1406, 11, 617, 9495, 286, 511, 10109, 11, 826, 30, 51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.360066894792084,\n",
       "   'compression_ratio': 1.7081545064377683,\n",
       "   'no_speech_prob': 0.130547434091568},\n",
       "  {'id': 567,\n",
       "   'seek': 218796,\n",
       "   'start': 2203.96,\n",
       "   'end': 2208.96,\n",
       "   'text': ' All that having said that, only yesterday I read about the very interesting article.',\n",
       "   'tokens': [51163,\n",
       "    1439,\n",
       "    326,\n",
       "    1719,\n",
       "    531,\n",
       "    326,\n",
       "    11,\n",
       "    691,\n",
       "    7415,\n",
       "    314,\n",
       "    1100,\n",
       "    546,\n",
       "    262,\n",
       "    845,\n",
       "    3499,\n",
       "    2708,\n",
       "    13,\n",
       "    51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.360066894792084,\n",
       "   'compression_ratio': 1.7081545064377683,\n",
       "   'no_speech_prob': 0.130547434091568},\n",
       "  {'id': 568,\n",
       "   'seek': 218796,\n",
       "   'start': 2208.96,\n",
       "   'end': 2213.96,\n",
       "   'text': ' So, there was some research paper which mentioned that some of those really chess playing',\n",
       "   'tokens': [51413,\n",
       "    1406,\n",
       "    11,\n",
       "    612,\n",
       "    373,\n",
       "    617,\n",
       "    2267,\n",
       "    3348,\n",
       "    543,\n",
       "    4750,\n",
       "    326,\n",
       "    617,\n",
       "    286,\n",
       "    883,\n",
       "    1107,\n",
       "    19780,\n",
       "    2712,\n",
       "    51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.360066894792084,\n",
       "   'compression_ratio': 1.7081545064377683,\n",
       "   'no_speech_prob': 0.130547434091568},\n",
       "  {'id': 569,\n",
       "   'seek': 221396,\n",
       "   'start': 2213.96,\n",
       "   'end': 2218.96,\n",
       "   'text': ' are the clear of the natural language process, natural language processing game.',\n",
       "   'tokens': [50363,\n",
       "    389,\n",
       "    262,\n",
       "    1598,\n",
       "    286,\n",
       "    262,\n",
       "    3288,\n",
       "    3303,\n",
       "    1429,\n",
       "    11,\n",
       "    3288,\n",
       "    3303,\n",
       "    7587,\n",
       "    983,\n",
       "    13,\n",
       "    50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44460908905798646,\n",
       "   'compression_ratio': 1.7444444444444445,\n",
       "   'no_speech_prob': 0.1141372099518776},\n",
       "  {'id': 570,\n",
       "   'seek': 221396,\n",
       "   'start': 2218.96,\n",
       "   'end': 2222.96,\n",
       "   'text': ' And not looking at the inherent notion of what both means.',\n",
       "   'tokens': [50613,\n",
       "    843,\n",
       "    407,\n",
       "    2045,\n",
       "    379,\n",
       "    262,\n",
       "    11519,\n",
       "    9495,\n",
       "    286,\n",
       "    644,\n",
       "    1111,\n",
       "    1724,\n",
       "    13,\n",
       "    50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44460908905798646,\n",
       "   'compression_ratio': 1.7444444444444445,\n",
       "   'no_speech_prob': 0.1141372099518776},\n",
       "  {'id': 571,\n",
       "   'seek': 221396,\n",
       "   'start': 2222.96,\n",
       "   'end': 2225.96,\n",
       "   'text': ' So, they just gave it a specific easy code, et cetera.',\n",
       "   'tokens': [50813,\n",
       "    1406,\n",
       "    11,\n",
       "    484,\n",
       "    655,\n",
       "    2921,\n",
       "    340,\n",
       "    257,\n",
       "    2176,\n",
       "    2562,\n",
       "    2438,\n",
       "    11,\n",
       "    2123,\n",
       "    269,\n",
       "    2357,\n",
       "    64,\n",
       "    13,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44460908905798646,\n",
       "   'compression_ratio': 1.7444444444444445,\n",
       "   'no_speech_prob': 0.1141372099518776},\n",
       "  {'id': 572,\n",
       "   'seek': 221396,\n",
       "   'start': 2225.96,\n",
       "   'end': 2228.96,\n",
       "   'text': ' And that was also a little bit of a comedy level test task.',\n",
       "   'tokens': [50963,\n",
       "    843,\n",
       "    326,\n",
       "    373,\n",
       "    635,\n",
       "    257,\n",
       "    1310,\n",
       "    1643,\n",
       "    286,\n",
       "    257,\n",
       "    10997,\n",
       "    1241,\n",
       "    1332,\n",
       "    4876,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44460908905798646,\n",
       "   'compression_ratio': 1.7444444444444445,\n",
       "   'no_speech_prob': 0.1141372099518776},\n",
       "  {'id': 573,\n",
       "   'seek': 221396,\n",
       "   'start': 2228.96,\n",
       "   'end': 2232.96,\n",
       "   'text': ' So, those of bell words where they might find this very interesting and shocking.',\n",
       "   'tokens': [51113,\n",
       "    1406,\n",
       "    11,\n",
       "    883,\n",
       "    286,\n",
       "    8966,\n",
       "    2456,\n",
       "    810,\n",
       "    484,\n",
       "    1244,\n",
       "    1064,\n",
       "    428,\n",
       "    845,\n",
       "    3499,\n",
       "    290,\n",
       "    14702,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44460908905798646,\n",
       "   'compression_ratio': 1.7444444444444445,\n",
       "   'no_speech_prob': 0.1141372099518776},\n",
       "  {'id': 574,\n",
       "   'seek': 221396,\n",
       "   'start': 2232.96,\n",
       "   'end': 2233.96,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [51313, 16805, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44460908905798646,\n",
       "   'compression_ratio': 1.7444444444444445,\n",
       "   'no_speech_prob': 0.1141372099518776},\n",
       "  {'id': 575,\n",
       "   'seek': 221396,\n",
       "   'start': 2233.96,\n",
       "   'end': 2236.96,\n",
       "   'text': ' For cricket, maybe we are looking at the player ratings.',\n",
       "   'tokens': [51363,\n",
       "    1114,\n",
       "    18836,\n",
       "    11,\n",
       "    3863,\n",
       "    356,\n",
       "    389,\n",
       "    2045,\n",
       "    379,\n",
       "    262,\n",
       "    2137,\n",
       "    10109,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44460908905798646,\n",
       "   'compression_ratio': 1.7444444444444445,\n",
       "   'no_speech_prob': 0.1141372099518776},\n",
       "  {'id': 576,\n",
       "   'seek': 221396,\n",
       "   'start': 2236.96,\n",
       "   'end': 2242.96,\n",
       "   'text': ' Maybe the player age, maybe the fitness level, something on that start.',\n",
       "   'tokens': [51513,\n",
       "    6674,\n",
       "    262,\n",
       "    2137,\n",
       "    2479,\n",
       "    11,\n",
       "    3863,\n",
       "    262,\n",
       "    13547,\n",
       "    1241,\n",
       "    11,\n",
       "    1223,\n",
       "    319,\n",
       "    326,\n",
       "    923,\n",
       "    13,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44460908905798646,\n",
       "   'compression_ratio': 1.7444444444444445,\n",
       "   'no_speech_prob': 0.1141372099518776},\n",
       "  {'id': 577,\n",
       "   'seek': 224296,\n",
       "   'start': 2243.96,\n",
       "   'end': 2244.96,\n",
       "   'text': ' Why?',\n",
       "   'tokens': [50413, 4162, 30, 50463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5902255249023437,\n",
       "   'compression_ratio': 1.4660194174757282,\n",
       "   'no_speech_prob': 0.6192111968994141},\n",
       "  {'id': 578,\n",
       "   'seek': 224296,\n",
       "   'start': 2244.96,\n",
       "   'end': 2246.96,\n",
       "   'text': \" It's not some last names.\",\n",
       "   'tokens': [50463, 632, 338, 407, 617, 938, 3891, 13, 50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5902255249023437,\n",
       "   'compression_ratio': 1.4660194174757282,\n",
       "   'no_speech_prob': 0.6192111968994141},\n",
       "  {'id': 579,\n",
       "   'seek': 224296,\n",
       "   'start': 2246.96,\n",
       "   'end': 2247.96,\n",
       "   'text': ' Yes.',\n",
       "   'tokens': [50563, 3363, 13, 50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5902255249023437,\n",
       "   'compression_ratio': 1.4660194174757282,\n",
       "   'no_speech_prob': 0.6192111968994141},\n",
       "  {'id': 580,\n",
       "   'seek': 224296,\n",
       "   'start': 2247.96,\n",
       "   'end': 2251.96,\n",
       "   'text': ' If there are, almost is the way.',\n",
       "   'tokens': [50613, 1002, 612, 389, 11, 2048, 318, 262, 835, 13, 50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5902255249023437,\n",
       "   'compression_ratio': 1.4660194174757282,\n",
       "   'no_speech_prob': 0.6192111968994141},\n",
       "  {'id': 581,\n",
       "   'seek': 224296,\n",
       "   'start': 2251.96,\n",
       "   'end': 2256.96,\n",
       "   'text': ' And in fact, if any of you play games like T by NAR, what do you do all that?',\n",
       "   'tokens': [50813,\n",
       "    843,\n",
       "    287,\n",
       "    1109,\n",
       "    11,\n",
       "    611,\n",
       "    597,\n",
       "    286,\n",
       "    345,\n",
       "    711,\n",
       "    1830,\n",
       "    588,\n",
       "    309,\n",
       "    416,\n",
       "    399,\n",
       "    1503,\n",
       "    11,\n",
       "    644,\n",
       "    466,\n",
       "    345,\n",
       "    466,\n",
       "    477,\n",
       "    326,\n",
       "    30,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5902255249023437,\n",
       "   'compression_ratio': 1.4660194174757282,\n",
       "   'no_speech_prob': 0.6192111968994141},\n",
       "  {'id': 582,\n",
       "   'seek': 224296,\n",
       "   'start': 2256.96,\n",
       "   'end': 2259.96,\n",
       "   'text': ' They take you to the configuration menu.',\n",
       "   'tokens': [51063, 1119, 1011, 345, 284, 262, 8398, 6859, 13, 51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5902255249023437,\n",
       "   'compression_ratio': 1.4660194174757282,\n",
       "   'no_speech_prob': 0.6192111968994141},\n",
       "  {'id': 583,\n",
       "   'seek': 224296,\n",
       "   'start': 2259.96,\n",
       "   'end': 2261.96,\n",
       "   'text': ' And they are able to simulate both seasons.',\n",
       "   'tokens': [51213, 843, 484, 389, 1498, 284, 29308, 1111, 7028, 13, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5902255249023437,\n",
       "   'compression_ratio': 1.4660194174757282,\n",
       "   'no_speech_prob': 0.6192111968994141},\n",
       "  {'id': 584,\n",
       "   'seek': 224296,\n",
       "   'start': 2261.96,\n",
       "   'end': 2262.96,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [51313, 16805, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5902255249023437,\n",
       "   'compression_ratio': 1.4660194174757282,\n",
       "   'no_speech_prob': 0.6192111968994141},\n",
       "  {'id': 585,\n",
       "   'seek': 224296,\n",
       "   'start': 2262.96,\n",
       "   'end': 2265.96,\n",
       "   'text': ' Any other task, documentation, talk you can think of.',\n",
       "   'tokens': [51363,\n",
       "    4377,\n",
       "    584,\n",
       "    4876,\n",
       "    11,\n",
       "    10314,\n",
       "    11,\n",
       "    1561,\n",
       "    345,\n",
       "    460,\n",
       "    892,\n",
       "    286,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5902255249023437,\n",
       "   'compression_ratio': 1.4660194174757282,\n",
       "   'no_speech_prob': 0.6192111968994141},\n",
       "  {'id': 586,\n",
       "   'seek': 224296,\n",
       "   'start': 2265.96,\n",
       "   'end': 2267.96,\n",
       "   'text': \" And don't.\",\n",
       "   'tokens': [51513, 843, 836, 470, 13, 51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5902255249023437,\n",
       "   'compression_ratio': 1.4660194174757282,\n",
       "   'no_speech_prob': 0.6192111968994141},\n",
       "  {'id': 587,\n",
       "   'seek': 226796,\n",
       "   'start': 2268.96,\n",
       "   'end': 2269.96,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [50413, 16805, 13, 50463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38080102426034435,\n",
       "   'compression_ratio': 1.682608695652174,\n",
       "   'no_speech_prob': 0.6226423978805542},\n",
       "  {'id': 588,\n",
       "   'seek': 226796,\n",
       "   'start': 2269.96,\n",
       "   'end': 2275.96,\n",
       "   'text': \" So, how much data and image you want to classify whether it's an image or it's an university\",\n",
       "   'tokens': [50463,\n",
       "    1406,\n",
       "    11,\n",
       "    703,\n",
       "    881,\n",
       "    1366,\n",
       "    290,\n",
       "    2939,\n",
       "    345,\n",
       "    765,\n",
       "    284,\n",
       "    36509,\n",
       "    1771,\n",
       "    340,\n",
       "    338,\n",
       "    281,\n",
       "    2939,\n",
       "    393,\n",
       "    340,\n",
       "    338,\n",
       "    281,\n",
       "    6403,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38080102426034435,\n",
       "   'compression_ratio': 1.682608695652174,\n",
       "   'no_speech_prob': 0.6226423978805542},\n",
       "  {'id': 589,\n",
       "   'seek': 226796,\n",
       "   'start': 2275.96,\n",
       "   'end': 2277.96,\n",
       "   'text': ' or something around the thing.',\n",
       "   'tokens': [50763, 393, 1223, 1088, 262, 1517, 13, 50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38080102426034435,\n",
       "   'compression_ratio': 1.682608695652174,\n",
       "   'no_speech_prob': 0.6226423978805542},\n",
       "  {'id': 590,\n",
       "   'seek': 226796,\n",
       "   'start': 2277.96,\n",
       "   'end': 2279.96,\n",
       "   'text': ' You have not two output classes.',\n",
       "   'tokens': [50863, 921, 423, 407, 734, 5072, 6097, 13, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38080102426034435,\n",
       "   'compression_ratio': 1.682608695652174,\n",
       "   'no_speech_prob': 0.6226423978805542},\n",
       "  {'id': 591,\n",
       "   'seek': 226796,\n",
       "   'start': 2279.96,\n",
       "   'end': 2284.96,\n",
       "   'text': \" And what is the input that you're given?\",\n",
       "   'tokens': [50963, 843, 644, 318, 262, 5128, 326, 345, 821, 1813, 30, 51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38080102426034435,\n",
       "   'compression_ratio': 1.682608695652174,\n",
       "   'no_speech_prob': 0.6226423978805542},\n",
       "  {'id': 592,\n",
       "   'seek': 226796,\n",
       "   'start': 2284.96,\n",
       "   'end': 2287.96,\n",
       "   'text': ' So, the input would be an image.',\n",
       "   'tokens': [51213, 1406, 11, 262, 5128, 561, 307, 281, 2939, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38080102426034435,\n",
       "   'compression_ratio': 1.682608695652174,\n",
       "   'no_speech_prob': 0.6226423978805542},\n",
       "  {'id': 593,\n",
       "   'seek': 226796,\n",
       "   'start': 2287.96,\n",
       "   'end': 2288.96,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51363, 6498, 30, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38080102426034435,\n",
       "   'compression_ratio': 1.682608695652174,\n",
       "   'no_speech_prob': 0.6226423978805542},\n",
       "  {'id': 594,\n",
       "   'seek': 226796,\n",
       "   'start': 2288.96,\n",
       "   'end': 2291.96,\n",
       "   'text': ' Input now would be an image of some item somewhere.',\n",
       "   'tokens': [51413,\n",
       "    23412,\n",
       "    783,\n",
       "    561,\n",
       "    307,\n",
       "    281,\n",
       "    2939,\n",
       "    286,\n",
       "    617,\n",
       "    2378,\n",
       "    7382,\n",
       "    13,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38080102426034435,\n",
       "   'compression_ratio': 1.682608695652174,\n",
       "   'no_speech_prob': 0.6226423978805542},\n",
       "  {'id': 595,\n",
       "   'seek': 226796,\n",
       "   'start': 2291.96,\n",
       "   'end': 2296.96,\n",
       "   'text': ' So, what previously you look, the kinds of inputs that we had were putting into the matrix.',\n",
       "   'tokens': [51563,\n",
       "    1406,\n",
       "    11,\n",
       "    644,\n",
       "    4271,\n",
       "    345,\n",
       "    804,\n",
       "    11,\n",
       "    262,\n",
       "    6982,\n",
       "    286,\n",
       "    17311,\n",
       "    326,\n",
       "    356,\n",
       "    550,\n",
       "    547,\n",
       "    5137,\n",
       "    656,\n",
       "    262,\n",
       "    17593,\n",
       "    13,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38080102426034435,\n",
       "   'compression_ratio': 1.682608695652174,\n",
       "   'no_speech_prob': 0.6226423978805542},\n",
       "  {'id': 596,\n",
       "   'seek': 229696,\n",
       "   'start': 2296.96,\n",
       "   'end': 2303.96,\n",
       "   'text': \" So, in sample, most corresponding to only, you know, let's say p-\",\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    11,\n",
       "    287,\n",
       "    6291,\n",
       "    11,\n",
       "    749,\n",
       "    11188,\n",
       "    284,\n",
       "    691,\n",
       "    11,\n",
       "    345,\n",
       "    760,\n",
       "    11,\n",
       "    1309,\n",
       "    338,\n",
       "    910,\n",
       "    279,\n",
       "    12,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4121923117802061,\n",
       "   'compression_ratio': 1.8465608465608465,\n",
       "   'no_speech_prob': 0.06510825455188751},\n",
       "  {'id': 597,\n",
       "   'seek': 229696,\n",
       "   'start': 2303.96,\n",
       "   'end': 2306.96,\n",
       "   'text': \" But now you have a, let's say p cross q matrix.\",\n",
       "   'tokens': [50713,\n",
       "    887,\n",
       "    783,\n",
       "    345,\n",
       "    423,\n",
       "    257,\n",
       "    11,\n",
       "    1309,\n",
       "    338,\n",
       "    910,\n",
       "    279,\n",
       "    3272,\n",
       "    10662,\n",
       "    17593,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4121923117802061,\n",
       "   'compression_ratio': 1.8465608465608465,\n",
       "   'no_speech_prob': 0.06510825455188751},\n",
       "  {'id': 598,\n",
       "   'seek': 229696,\n",
       "   'start': 2306.96,\n",
       "   'end': 2310.96,\n",
       "   'text': ' So, again you have to figure out earlier, you will put the p cross q matrix into that particular',\n",
       "   'tokens': [50863,\n",
       "    1406,\n",
       "    11,\n",
       "    757,\n",
       "    345,\n",
       "    423,\n",
       "    284,\n",
       "    3785,\n",
       "    503,\n",
       "    2961,\n",
       "    11,\n",
       "    345,\n",
       "    481,\n",
       "    1234,\n",
       "    262,\n",
       "    279,\n",
       "    3272,\n",
       "    10662,\n",
       "    17593,\n",
       "    656,\n",
       "    326,\n",
       "    1948,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4121923117802061,\n",
       "   'compression_ratio': 1.8465608465608465,\n",
       "   'no_speech_prob': 0.06510825455188751},\n",
       "  {'id': 599,\n",
       "   'seek': 229696,\n",
       "   'start': 2310.96,\n",
       "   'end': 2312.96,\n",
       "   'text': ' scheme which we have.',\n",
       "   'tokens': [51063, 7791, 543, 356, 423, 13, 51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4121923117802061,\n",
       "   'compression_ratio': 1.8465608465608465,\n",
       "   'no_speech_prob': 0.06510825455188751},\n",
       "  {'id': 600,\n",
       "   'seek': 229696,\n",
       "   'start': 2312.96,\n",
       "   'end': 2313.96,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [51163, 16805, 13, 51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4121923117802061,\n",
       "   'compression_ratio': 1.8465608465608465,\n",
       "   'no_speech_prob': 0.06510825455188751},\n",
       "  {'id': 601,\n",
       "   'seek': 229696,\n",
       "   'start': 2313.96,\n",
       "   'end': 2314.96,\n",
       "   'text': ' Any other example?',\n",
       "   'tokens': [51213, 4377, 584, 1672, 30, 51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4121923117802061,\n",
       "   'compression_ratio': 1.8465608465608465,\n",
       "   'no_speech_prob': 0.06510825455188751},\n",
       "  {'id': 602,\n",
       "   'seek': 229696,\n",
       "   'start': 2314.96,\n",
       "   'end': 2315.96,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [51263, 16805, 13, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4121923117802061,\n",
       "   'compression_ratio': 1.8465608465608465,\n",
       "   'no_speech_prob': 0.06510825455188751},\n",
       "  {'id': 603,\n",
       "   'seek': 229696,\n",
       "   'start': 2315.96,\n",
       "   'end': 2325.96,\n",
       "   'text': \" Shouldn't be, let me, let me, let me, let me, let me, let me, let me, let me, let me,\",\n",
       "   'tokens': [51313,\n",
       "    10358,\n",
       "    77,\n",
       "    470,\n",
       "    307,\n",
       "    11,\n",
       "    1309,\n",
       "    502,\n",
       "    11,\n",
       "    1309,\n",
       "    502,\n",
       "    11,\n",
       "    1309,\n",
       "    502,\n",
       "    11,\n",
       "    1309,\n",
       "    502,\n",
       "    11,\n",
       "    1309,\n",
       "    502,\n",
       "    11,\n",
       "    1309,\n",
       "    502,\n",
       "    11,\n",
       "    1309,\n",
       "    502,\n",
       "    11,\n",
       "    1309,\n",
       "    502,\n",
       "    11,\n",
       "    1309,\n",
       "    502,\n",
       "    11,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4121923117802061,\n",
       "   'compression_ratio': 1.8465608465608465,\n",
       "   'no_speech_prob': 0.06510825455188751},\n",
       "  {'id': 604,\n",
       "   'seek': 232596,\n",
       "   'start': 2325.96,\n",
       "   'end': 2326.96,\n",
       "   'text': ' interrupt them.',\n",
       "   'tokens': [50363, 11313, 606, 13, 50413],\n",
       "   'temperature': 1.0,\n",
       "   'avg_logprob': -2.6030987633599176,\n",
       "   'compression_ratio': 1.0227272727272727,\n",
       "   'no_speech_prob': 0.23538467288017273},\n",
       "  {'id': 605,\n",
       "   'seek': 232596,\n",
       "   'start': 2326.96,\n",
       "   'end': 2327.96,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [50413, 16805, 13, 50463],\n",
       "   'temperature': 1.0,\n",
       "   'avg_logprob': -2.6030987633599176,\n",
       "   'compression_ratio': 1.0227272727272727,\n",
       "   'no_speech_prob': 0.23538467288017273},\n",
       "  {'id': 606,\n",
       "   'seek': 232596,\n",
       "   'start': 2327.96,\n",
       "   'end': 2328.96,\n",
       "   'text': ' So, okay.',\n",
       "   'tokens': [50463, 1406, 11, 8788, 13, 50513],\n",
       "   'temperature': 1.0,\n",
       "   'avg_logprob': -2.6030987633599176,\n",
       "   'compression_ratio': 1.0227272727272727,\n",
       "   'no_speech_prob': 0.23538467288017273},\n",
       "  {'id': 607,\n",
       "   'seek': 232596,\n",
       "   'start': 2328.96,\n",
       "   'end': 2329.96,\n",
       "   'text': ' We have two databases based onnikENG.',\n",
       "   'tokens': [50513, 775, 423, 734, 20083, 1912, 319, 17187, 26808, 13, 50563],\n",
       "   'temperature': 1.0,\n",
       "   'avg_logprob': -2.6030987633599176,\n",
       "   'compression_ratio': 1.0227272727272727,\n",
       "   'no_speech_prob': 0.23538467288017273},\n",
       "  {'id': 608,\n",
       "   'seek': 232596,\n",
       "   'start': 2329.96,\n",
       "   'end': 2349.86,\n",
       "   'text': ' And, you know, Ocean',\n",
       "   'tokens': [50563, 843, 11, 345, 760, 11, 10692, 51558],\n",
       "   'temperature': 1.0,\n",
       "   'avg_logprob': -2.6030987633599176,\n",
       "   'compression_ratio': 1.0227272727272727,\n",
       "   'no_speech_prob': 0.23538467288017273},\n",
       "  {'id': 609,\n",
       "   'seek': 234986,\n",
       "   'start': 2349.86,\n",
       "   'end': 2355.86,\n",
       "   'text': ' talk about this later, there is also some notion of ordering associated with grades.',\n",
       "   'tokens': [50363,\n",
       "    1561,\n",
       "    546,\n",
       "    428,\n",
       "    1568,\n",
       "    11,\n",
       "    612,\n",
       "    318,\n",
       "    635,\n",
       "    617,\n",
       "    9495,\n",
       "    286,\n",
       "    16216,\n",
       "    3917,\n",
       "    351,\n",
       "    19051,\n",
       "    13,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5547514976339137,\n",
       "   'compression_ratio': 1.5778688524590163,\n",
       "   'no_speech_prob': 0.21887581050395966},\n",
       "  {'id': 610,\n",
       "   'seek': 234986,\n",
       "   'start': 2355.86,\n",
       "   'end': 2362.86,\n",
       "   'text': ' Sometimes you want to provide the data in order. We are not going to be able to perform.',\n",
       "   'tokens': [50663,\n",
       "    8975,\n",
       "    345,\n",
       "    765,\n",
       "    284,\n",
       "    2148,\n",
       "    262,\n",
       "    1366,\n",
       "    287,\n",
       "    1502,\n",
       "    13,\n",
       "    775,\n",
       "    389,\n",
       "    407,\n",
       "    1016,\n",
       "    284,\n",
       "    307,\n",
       "    1498,\n",
       "    284,\n",
       "    1620,\n",
       "    13,\n",
       "    51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5547514976339137,\n",
       "   'compression_ratio': 1.5778688524590163,\n",
       "   'no_speech_prob': 0.21887581050395966},\n",
       "  {'id': 611,\n",
       "   'seek': 234986,\n",
       "   'start': 2362.86,\n",
       "   'end': 2367.86,\n",
       "   'text': ' The second example that we saw fits into something known as regression.',\n",
       "   'tokens': [51013,\n",
       "    383,\n",
       "    1218,\n",
       "    1672,\n",
       "    326,\n",
       "    356,\n",
       "    2497,\n",
       "    11414,\n",
       "    656,\n",
       "    1223,\n",
       "    1900,\n",
       "    355,\n",
       "    20683,\n",
       "    13,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5547514976339137,\n",
       "   'compression_ratio': 1.5778688524590163,\n",
       "   'no_speech_prob': 0.21887581050395966},\n",
       "  {'id': 612,\n",
       "   'seek': 234986,\n",
       "   'start': 2367.86,\n",
       "   'end': 2371.86,\n",
       "   'text': ' They output variables, continuous and nature, right? To allow the experience.',\n",
       "   'tokens': [51263,\n",
       "    1119,\n",
       "    5072,\n",
       "    9633,\n",
       "    11,\n",
       "    12948,\n",
       "    290,\n",
       "    3450,\n",
       "    11,\n",
       "    826,\n",
       "    30,\n",
       "    1675,\n",
       "    1249,\n",
       "    262,\n",
       "    1998,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5547514976339137,\n",
       "   'compression_ratio': 1.5778688524590163,\n",
       "   'no_speech_prob': 0.21887581050395966},\n",
       "  {'id': 613,\n",
       "   'seek': 234986,\n",
       "   'start': 2371.86,\n",
       "   'end': 2376.86,\n",
       "   'text': ' As you can see in that, so you can write yi is a real number.',\n",
       "   'tokens': [51463,\n",
       "    1081,\n",
       "    345,\n",
       "    460,\n",
       "    766,\n",
       "    287,\n",
       "    326,\n",
       "    11,\n",
       "    523,\n",
       "    345,\n",
       "    460,\n",
       "    3551,\n",
       "    331,\n",
       "    72,\n",
       "    318,\n",
       "    257,\n",
       "    1103,\n",
       "    1271,\n",
       "    13,\n",
       "    51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5547514976339137,\n",
       "   'compression_ratio': 1.5778688524590163,\n",
       "   'no_speech_prob': 0.21887581050395966},\n",
       "  {'id': 614,\n",
       "   'seek': 237686,\n",
       "   'start': 2376.86,\n",
       "   'end': 2379.86,\n",
       "   'text': ' Okay, give me some examples of regression.',\n",
       "   'tokens': [50363, 16805, 11, 1577, 502, 617, 6096, 286, 20683, 13, 50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5254302422205607,\n",
       "   'compression_ratio': 1.7849462365591398,\n",
       "   'no_speech_prob': 0.28873389959335327},\n",
       "  {'id': 615,\n",
       "   'seek': 237686,\n",
       "   'start': 2382.86,\n",
       "   'end': 2384.86,\n",
       "   'text': ' You want to predict a real number.',\n",
       "   'tokens': [50663, 921, 765, 284, 4331, 257, 1103, 1271, 13, 50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5254302422205607,\n",
       "   'compression_ratio': 1.7849462365591398,\n",
       "   'no_speech_prob': 0.28873389959335327},\n",
       "  {'id': 616,\n",
       "   'seek': 237686,\n",
       "   'start': 2384.86,\n",
       "   'end': 2386.86,\n",
       "   'text': ' The amount of grades you want to write.',\n",
       "   'tokens': [50763, 383, 2033, 286, 19051, 345, 765, 284, 3551, 13, 50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5254302422205607,\n",
       "   'compression_ratio': 1.7849462365591398,\n",
       "   'no_speech_prob': 0.28873389959335327},\n",
       "  {'id': 617,\n",
       "   'seek': 237686,\n",
       "   'start': 2386.86,\n",
       "   'end': 2390.86,\n",
       "   'text': ' The amount of grades you want to write all.',\n",
       "   'tokens': [50863,\n",
       "    383,\n",
       "    2033,\n",
       "    286,\n",
       "    19051,\n",
       "    345,\n",
       "    765,\n",
       "    284,\n",
       "    3551,\n",
       "    477,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5254302422205607,\n",
       "   'compression_ratio': 1.7849462365591398,\n",
       "   'no_speech_prob': 0.28873389959335327},\n",
       "  {'id': 618,\n",
       "   'seek': 237686,\n",
       "   'start': 2390.86,\n",
       "   'end': 2395.86,\n",
       "   'text': \" So that's the reason. I have to say that I have to write.\",\n",
       "   'tokens': [51063,\n",
       "    1406,\n",
       "    326,\n",
       "    338,\n",
       "    262,\n",
       "    1738,\n",
       "    13,\n",
       "    314,\n",
       "    423,\n",
       "    284,\n",
       "    910,\n",
       "    326,\n",
       "    314,\n",
       "    423,\n",
       "    284,\n",
       "    3551,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5254302422205607,\n",
       "   'compression_ratio': 1.7849462365591398,\n",
       "   'no_speech_prob': 0.28873389959335327},\n",
       "  {'id': 619,\n",
       "   'seek': 237686,\n",
       "   'start': 2395.86,\n",
       "   'end': 2396.86,\n",
       "   'text': ' Stop market.',\n",
       "   'tokens': [51313, 13707, 1910, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5254302422205607,\n",
       "   'compression_ratio': 1.7849462365591398,\n",
       "   'no_speech_prob': 0.28873389959335327},\n",
       "  {'id': 620,\n",
       "   'seek': 237686,\n",
       "   'start': 2396.86,\n",
       "   'end': 2398.86,\n",
       "   'text': ' Stop market. What do you want to predict?',\n",
       "   'tokens': [51363,\n",
       "    13707,\n",
       "    1910,\n",
       "    13,\n",
       "    1867,\n",
       "    466,\n",
       "    345,\n",
       "    765,\n",
       "    284,\n",
       "    4331,\n",
       "    30,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5254302422205607,\n",
       "   'compression_ratio': 1.7849462365591398,\n",
       "   'no_speech_prob': 0.28873389959335327},\n",
       "  {'id': 621,\n",
       "   'seek': 237686,\n",
       "   'start': 2398.86,\n",
       "   'end': 2403.86,\n",
       "   'text': ' The price of a particular stock. Okay, any other example?',\n",
       "   'tokens': [51463,\n",
       "    383,\n",
       "    2756,\n",
       "    286,\n",
       "    257,\n",
       "    1948,\n",
       "    4283,\n",
       "    13,\n",
       "    16805,\n",
       "    11,\n",
       "    597,\n",
       "    584,\n",
       "    1672,\n",
       "    30,\n",
       "    51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5254302422205607,\n",
       "   'compression_ratio': 1.7849462365591398,\n",
       "   'no_speech_prob': 0.28873389959335327},\n",
       "  {'id': 622,\n",
       "   'seek': 240386,\n",
       "   'start': 2403.86,\n",
       "   'end': 2405.86,\n",
       "   'text': \" That's four times.\",\n",
       "   'tokens': [50363, 1320, 338, 1440, 1661, 13, 50463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5094533849645544,\n",
       "   'compression_ratio': 1.5875,\n",
       "   'no_speech_prob': 0.12600767612457275},\n",
       "  {'id': 623,\n",
       "   'seek': 240386,\n",
       "   'start': 2405.86,\n",
       "   'end': 2406.86,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [50463, 16805, 13, 50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5094533849645544,\n",
       "   'compression_ratio': 1.5875,\n",
       "   'no_speech_prob': 0.12600767612457275},\n",
       "  {'id': 624,\n",
       "   'seek': 240386,\n",
       "   'start': 2406.86,\n",
       "   'end': 2407.86,\n",
       "   'text': ' How many runs of four?',\n",
       "   'tokens': [50513, 1374, 867, 4539, 286, 1440, 30, 50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5094533849645544,\n",
       "   'compression_ratio': 1.5875,\n",
       "   'no_speech_prob': 0.12600767612457275},\n",
       "  {'id': 625,\n",
       "   'seek': 240386,\n",
       "   'start': 2407.86,\n",
       "   'end': 2409.86,\n",
       "   'text': ' Okay, how many runs with our teams?',\n",
       "   'tokens': [50563, 16805, 11, 703, 867, 4539, 351, 674, 3466, 30, 50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5094533849645544,\n",
       "   'compression_ratio': 1.5875,\n",
       "   'no_speech_prob': 0.12600767612457275},\n",
       "  {'id': 626,\n",
       "   'seek': 240386,\n",
       "   'start': 2409.86,\n",
       "   'end': 2412.86,\n",
       "   'text': ' Again, very interesting points of grades.',\n",
       "   'tokens': [50663, 6521, 11, 845, 3499, 2173, 286, 19051, 13, 50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5094533849645544,\n",
       "   'compression_ratio': 1.5875,\n",
       "   'no_speech_prob': 0.12600767612457275},\n",
       "  {'id': 627,\n",
       "   'seek': 240386,\n",
       "   'start': 2412.86,\n",
       "   'end': 2417.86,\n",
       "   'text': ' Again, if you look at all the sports, people have already come up with some rules of the family.',\n",
       "   'tokens': [50813,\n",
       "    6521,\n",
       "    11,\n",
       "    611,\n",
       "    345,\n",
       "    804,\n",
       "    379,\n",
       "    477,\n",
       "    262,\n",
       "    5701,\n",
       "    11,\n",
       "    661,\n",
       "    423,\n",
       "    1541,\n",
       "    1282,\n",
       "    510,\n",
       "    351,\n",
       "    617,\n",
       "    3173,\n",
       "    286,\n",
       "    262,\n",
       "    1641,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5094533849645544,\n",
       "   'compression_ratio': 1.5875,\n",
       "   'no_speech_prob': 0.12600767612457275},\n",
       "  {'id': 628,\n",
       "   'seek': 240386,\n",
       "   'start': 2417.86,\n",
       "   'end': 2421.86,\n",
       "   'text': ' You are only three back to down, and you get half to 30, you would be double.',\n",
       "   'tokens': [51063,\n",
       "    921,\n",
       "    389,\n",
       "    691,\n",
       "    1115,\n",
       "    736,\n",
       "    284,\n",
       "    866,\n",
       "    11,\n",
       "    290,\n",
       "    345,\n",
       "    651,\n",
       "    2063,\n",
       "    284,\n",
       "    1542,\n",
       "    11,\n",
       "    345,\n",
       "    561,\n",
       "    307,\n",
       "    4274,\n",
       "    13,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5094533849645544,\n",
       "   'compression_ratio': 1.5875,\n",
       "   'no_speech_prob': 0.12600767612457275},\n",
       "  {'id': 629,\n",
       "   'seek': 240386,\n",
       "   'start': 2421.86,\n",
       "   'end': 2426.86,\n",
       "   'text': ' You can always verify those rules.',\n",
       "   'tokens': [51263, 921, 460, 1464, 11767, 883, 3173, 13, 51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5094533849645544,\n",
       "   'compression_ratio': 1.5875,\n",
       "   'no_speech_prob': 0.12600767612457275},\n",
       "  {'id': 630,\n",
       "   'seek': 240386,\n",
       "   'start': 2426.86,\n",
       "   'end': 2430.86,\n",
       "   'text': ' And before we get into the actual algorithms,',\n",
       "   'tokens': [51513, 843, 878, 356, 651, 656, 262, 4036, 16113, 11, 51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5094533849645544,\n",
       "   'compression_ratio': 1.5875,\n",
       "   'no_speech_prob': 0.12600767612457275},\n",
       "  {'id': 631,\n",
       "   'seek': 243086,\n",
       "   'start': 2430.86,\n",
       "   'end': 2435.86,\n",
       "   'text': ' I wanted to talk about the performance measure P, which we discussed in the definition.',\n",
       "   'tokens': [50363,\n",
       "    314,\n",
       "    2227,\n",
       "    284,\n",
       "    1561,\n",
       "    546,\n",
       "    262,\n",
       "    2854,\n",
       "    3953,\n",
       "    350,\n",
       "    11,\n",
       "    543,\n",
       "    356,\n",
       "    6693,\n",
       "    287,\n",
       "    262,\n",
       "    6770,\n",
       "    13,\n",
       "    50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21720005310687823,\n",
       "   'compression_ratio': 1.6721991701244814,\n",
       "   'no_speech_prob': 0.025444671511650085},\n",
       "  {'id': 632,\n",
       "   'seek': 243086,\n",
       "   'start': 2435.86,\n",
       "   'end': 2440.86,\n",
       "   'text': ' We talked about experience P, task P, and performance measure P.',\n",
       "   'tokens': [50613,\n",
       "    775,\n",
       "    6619,\n",
       "    546,\n",
       "    1998,\n",
       "    350,\n",
       "    11,\n",
       "    4876,\n",
       "    350,\n",
       "    11,\n",
       "    290,\n",
       "    2854,\n",
       "    3953,\n",
       "    350,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21720005310687823,\n",
       "   'compression_ratio': 1.6721991701244814,\n",
       "   'no_speech_prob': 0.025444671511650085},\n",
       "  {'id': 633,\n",
       "   'seek': 243086,\n",
       "   'start': 2440.86,\n",
       "   'end': 2445.86,\n",
       "   'text': \" I thought it's more important to first understand what different metrics mean,\",\n",
       "   'tokens': [50863,\n",
       "    314,\n",
       "    1807,\n",
       "    340,\n",
       "    338,\n",
       "    517,\n",
       "    1593,\n",
       "    284,\n",
       "    717,\n",
       "    1833,\n",
       "    644,\n",
       "    1180,\n",
       "    20731,\n",
       "    1612,\n",
       "    11,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21720005310687823,\n",
       "   'compression_ratio': 1.6721991701244814,\n",
       "   'no_speech_prob': 0.025444671511650085},\n",
       "  {'id': 634,\n",
       "   'seek': 243086,\n",
       "   'start': 2445.86,\n",
       "   'end': 2449.86,\n",
       "   'text': ' and what does it mean that we have done a good job in machine learning or not?',\n",
       "   'tokens': [51113,\n",
       "    290,\n",
       "    644,\n",
       "    857,\n",
       "    340,\n",
       "    1612,\n",
       "    326,\n",
       "    356,\n",
       "    423,\n",
       "    1760,\n",
       "    257,\n",
       "    922,\n",
       "    1693,\n",
       "    287,\n",
       "    4572,\n",
       "    4673,\n",
       "    393,\n",
       "    407,\n",
       "    30,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21720005310687823,\n",
       "   'compression_ratio': 1.6721991701244814,\n",
       "   'no_speech_prob': 0.025444671511650085},\n",
       "  {'id': 635,\n",
       "   'seek': 243086,\n",
       "   'start': 2449.86,\n",
       "   'end': 2452.86,\n",
       "   'text': ' We started with some metrics of graph education.',\n",
       "   'tokens': [51313, 775, 2067, 351, 617, 20731, 286, 4823, 3707, 13, 51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21720005310687823,\n",
       "   'compression_ratio': 1.6721991701244814,\n",
       "   'no_speech_prob': 0.025444671511650085},\n",
       "  {'id': 636,\n",
       "   'seek': 243086,\n",
       "   'start': 2452.86,\n",
       "   'end': 2457.86,\n",
       "   'text': \" Let's assume that we had a ground growth y.\",\n",
       "   'tokens': [51463,\n",
       "    3914,\n",
       "    338,\n",
       "    7048,\n",
       "    326,\n",
       "    356,\n",
       "    550,\n",
       "    257,\n",
       "    2323,\n",
       "    3349,\n",
       "    331,\n",
       "    13,\n",
       "    51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.21720005310687823,\n",
       "   'compression_ratio': 1.6721991701244814,\n",
       "   'no_speech_prob': 0.025444671511650085},\n",
       "  {'id': 637,\n",
       "   'seek': 245786,\n",
       "   'start': 2457.86,\n",
       "   'end': 2460.86,\n",
       "   'text': \" The number means the correct labels that we've got.\",\n",
       "   'tokens': [50363,\n",
       "    383,\n",
       "    1271,\n",
       "    1724,\n",
       "    262,\n",
       "    3376,\n",
       "    14722,\n",
       "    326,\n",
       "    356,\n",
       "    1053,\n",
       "    1392,\n",
       "    13,\n",
       "    50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3213203814851136,\n",
       "   'compression_ratio': 1.7974137931034482,\n",
       "   'no_speech_prob': 0.05334091931581497},\n",
       "  {'id': 638,\n",
       "   'seek': 245786,\n",
       "   'start': 2460.86,\n",
       "   'end': 2465.86,\n",
       "   'text': \" Let's say we had a particular set of two meters.\",\n",
       "   'tokens': [50513,\n",
       "    3914,\n",
       "    338,\n",
       "    910,\n",
       "    356,\n",
       "    550,\n",
       "    257,\n",
       "    1948,\n",
       "    900,\n",
       "    286,\n",
       "    734,\n",
       "    10700,\n",
       "    13,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3213203814851136,\n",
       "   'compression_ratio': 1.7974137931034482,\n",
       "   'no_speech_prob': 0.05334091931581497},\n",
       "  {'id': 639,\n",
       "   'seek': 245786,\n",
       "   'start': 2465.86,\n",
       "   'end': 2468.86,\n",
       "   'text': ' For the first meter, we know that it was good.',\n",
       "   'tokens': [50763,\n",
       "    1114,\n",
       "    262,\n",
       "    717,\n",
       "    16430,\n",
       "    11,\n",
       "    356,\n",
       "    760,\n",
       "    326,\n",
       "    340,\n",
       "    373,\n",
       "    922,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3213203814851136,\n",
       "   'compression_ratio': 1.7974137931034482,\n",
       "   'no_speech_prob': 0.05334091931581497},\n",
       "  {'id': 640,\n",
       "   'seek': 245786,\n",
       "   'start': 2468.86,\n",
       "   'end': 2470.86,\n",
       "   'text': ' Some human and a different.',\n",
       "   'tokens': [50913, 2773, 1692, 290, 257, 1180, 13, 51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3213203814851136,\n",
       "   'compression_ratio': 1.7974137931034482,\n",
       "   'no_speech_prob': 0.05334091931581497},\n",
       "  {'id': 641,\n",
       "   'seek': 245786,\n",
       "   'start': 2470.86,\n",
       "   'end': 2473.86,\n",
       "   'text': ' Second meter, some unsighted is good, and the other three, some unsighted.',\n",
       "   'tokens': [51013,\n",
       "    5498,\n",
       "    16430,\n",
       "    11,\n",
       "    617,\n",
       "    5576,\n",
       "    432,\n",
       "    276,\n",
       "    318,\n",
       "    922,\n",
       "    11,\n",
       "    290,\n",
       "    262,\n",
       "    584,\n",
       "    1115,\n",
       "    11,\n",
       "    617,\n",
       "    5576,\n",
       "    432,\n",
       "    276,\n",
       "    13,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3213203814851136,\n",
       "   'compression_ratio': 1.7974137931034482,\n",
       "   'no_speech_prob': 0.05334091931581497},\n",
       "  {'id': 642,\n",
       "   'seek': 245786,\n",
       "   'start': 2473.86,\n",
       "   'end': 2476.86,\n",
       "   'text': ' Some export label that was bad.',\n",
       "   'tokens': [51163, 2773, 10784, 6167, 326, 373, 2089, 13, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3213203814851136,\n",
       "   'compression_ratio': 1.7974137931034482,\n",
       "   'no_speech_prob': 0.05334091931581497},\n",
       "  {'id': 643,\n",
       "   'seek': 245786,\n",
       "   'start': 2476.86,\n",
       "   'end': 2480.86,\n",
       "   'text': \" And then there is some algorithms, some function F that we've learned.\",\n",
       "   'tokens': [51313,\n",
       "    843,\n",
       "    788,\n",
       "    612,\n",
       "    318,\n",
       "    617,\n",
       "    16113,\n",
       "    11,\n",
       "    617,\n",
       "    2163,\n",
       "    376,\n",
       "    326,\n",
       "    356,\n",
       "    1053,\n",
       "    4499,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3213203814851136,\n",
       "   'compression_ratio': 1.7974137931034482,\n",
       "   'no_speech_prob': 0.05334091931581497},\n",
       "  {'id': 644,\n",
       "   'seek': 245786,\n",
       "   'start': 2480.86,\n",
       "   'end': 2485.86,\n",
       "   'text': ' That ends up predicting, good, good, good, good, good, and bad.',\n",
       "   'tokens': [51513,\n",
       "    1320,\n",
       "    5645,\n",
       "    510,\n",
       "    25539,\n",
       "    11,\n",
       "    922,\n",
       "    11,\n",
       "    922,\n",
       "    11,\n",
       "    922,\n",
       "    11,\n",
       "    922,\n",
       "    11,\n",
       "    922,\n",
       "    11,\n",
       "    290,\n",
       "    2089,\n",
       "    13,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3213203814851136,\n",
       "   'compression_ratio': 1.7974137931034482,\n",
       "   'no_speech_prob': 0.05334091931581497},\n",
       "  {'id': 645,\n",
       "   'seek': 248586,\n",
       "   'start': 2485.86,\n",
       "   'end': 2489.86,\n",
       "   'text': ' And we call this vector as y-act.',\n",
       "   'tokens': [50363, 843, 356, 869, 428, 15879, 355, 331, 12, 529, 13, 50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3421990040982707,\n",
       "   'compression_ratio': 1.529126213592233,\n",
       "   'no_speech_prob': 0.0310000441968441},\n",
       "  {'id': 646,\n",
       "   'seek': 248586,\n",
       "   'start': 2489.86,\n",
       "   'end': 2493.86,\n",
       "   'text': \" So we'll use this hat a lot in machine learning.\",\n",
       "   'tokens': [50563,\n",
       "    1406,\n",
       "    356,\n",
       "    1183,\n",
       "    779,\n",
       "    428,\n",
       "    6877,\n",
       "    257,\n",
       "    1256,\n",
       "    287,\n",
       "    4572,\n",
       "    4673,\n",
       "    13,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3421990040982707,\n",
       "   'compression_ratio': 1.529126213592233,\n",
       "   'no_speech_prob': 0.0310000441968441},\n",
       "  {'id': 647,\n",
       "   'seek': 248586,\n",
       "   'start': 2493.86,\n",
       "   'end': 2496.86,\n",
       "   'text': ' hat generally signifies an estimate.',\n",
       "   'tokens': [50763, 6877, 4143, 43854, 281, 8636, 13, 50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3421990040982707,\n",
       "   'compression_ratio': 1.529126213592233,\n",
       "   'no_speech_prob': 0.0310000441968441},\n",
       "  {'id': 648,\n",
       "   'seek': 248586,\n",
       "   'start': 2496.86,\n",
       "   'end': 2501.86,\n",
       "   'text': ' What is your estimate of these labels of the parameters?',\n",
       "   'tokens': [50913,\n",
       "    1867,\n",
       "    318,\n",
       "    534,\n",
       "    8636,\n",
       "    286,\n",
       "    777,\n",
       "    14722,\n",
       "    286,\n",
       "    262,\n",
       "    10007,\n",
       "    30,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3421990040982707,\n",
       "   'compression_ratio': 1.529126213592233,\n",
       "   'no_speech_prob': 0.0310000441968441},\n",
       "  {'id': 649,\n",
       "   'seek': 248586,\n",
       "   'start': 2501.86,\n",
       "   'end': 2504.86,\n",
       "   'text': ' So it is y-act.',\n",
       "   'tokens': [51163, 1406, 340, 318, 331, 12, 529, 13, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3421990040982707,\n",
       "   'compression_ratio': 1.529126213592233,\n",
       "   'no_speech_prob': 0.0310000441968441},\n",
       "  {'id': 650,\n",
       "   'seek': 248586,\n",
       "   'start': 2504.86,\n",
       "   'end': 2507.86,\n",
       "   'text': ' And number comes from the actual premise set.',\n",
       "   'tokens': [51313, 843, 1271, 2058, 422, 262, 4036, 18659, 900, 13, 51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3421990040982707,\n",
       "   'compression_ratio': 1.529126213592233,\n",
       "   'no_speech_prob': 0.0310000441968441},\n",
       "  {'id': 651,\n",
       "   'seek': 248586,\n",
       "   'start': 2507.86,\n",
       "   'end': 2510.86,\n",
       "   'text': ' For now, this is something we have somehow interpreted.',\n",
       "   'tokens': [51463,\n",
       "    1114,\n",
       "    783,\n",
       "    11,\n",
       "    428,\n",
       "    318,\n",
       "    1223,\n",
       "    356,\n",
       "    423,\n",
       "    7599,\n",
       "    16173,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3421990040982707,\n",
       "   'compression_ratio': 1.529126213592233,\n",
       "   'no_speech_prob': 0.0310000441968441},\n",
       "  {'id': 652,\n",
       "   'seek': 248586,\n",
       "   'start': 2510.86,\n",
       "   'end': 2512.86,\n",
       "   'text': ' We know the example.',\n",
       "   'tokens': [51613, 775, 760, 262, 1672, 13, 51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3421990040982707,\n",
       "   'compression_ratio': 1.529126213592233,\n",
       "   'no_speech_prob': 0.0310000441968441},\n",
       "  {'id': 653,\n",
       "   'seek': 251286,\n",
       "   'start': 2512.86,\n",
       "   'end': 2515.86,\n",
       "   'text': ' And the prediction is made by Vma.',\n",
       "   'tokens': [50363, 843, 262, 17724, 318, 925, 416, 569, 2611, 13, 50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6723227987484056,\n",
       "   'compression_ratio': 1.5051020408163265,\n",
       "   'no_speech_prob': 0.0938156396150589},\n",
       "  {'id': 654,\n",
       "   'seek': 251286,\n",
       "   'start': 2515.86,\n",
       "   'end': 2520.86,\n",
       "   'text': ' So what are the different metrics we could use to tell the data in the data.',\n",
       "   'tokens': [50513,\n",
       "    1406,\n",
       "    644,\n",
       "    389,\n",
       "    262,\n",
       "    1180,\n",
       "    20731,\n",
       "    356,\n",
       "    714,\n",
       "    779,\n",
       "    284,\n",
       "    1560,\n",
       "    262,\n",
       "    1366,\n",
       "    287,\n",
       "    262,\n",
       "    1366,\n",
       "    13,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6723227987484056,\n",
       "   'compression_ratio': 1.5051020408163265,\n",
       "   'no_speech_prob': 0.0938156396150589},\n",
       "  {'id': 655,\n",
       "   'seek': 251286,\n",
       "   'start': 2520.86,\n",
       "   'end': 2521.86,\n",
       "   'text': ' What is it?',\n",
       "   'tokens': [50763, 1867, 318, 340, 30, 50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6723227987484056,\n",
       "   'compression_ratio': 1.5051020408163265,\n",
       "   'no_speech_prob': 0.0938156396150589},\n",
       "  {'id': 656,\n",
       "   'seek': 251286,\n",
       "   'start': 2521.86,\n",
       "   'end': 2523.86,\n",
       "   'text': ' We have done a good job in predicting.',\n",
       "   'tokens': [50813, 775, 423, 1760, 257, 922, 1693, 287, 25539, 13, 50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6723227987484056,\n",
       "   'compression_ratio': 1.5051020408163265,\n",
       "   'no_speech_prob': 0.0938156396150589},\n",
       "  {'id': 657,\n",
       "   'seek': 251286,\n",
       "   'start': 2523.86,\n",
       "   'end': 2526.86,\n",
       "   'text': ' What has been done back down?',\n",
       "   'tokens': [50913, 1867, 468, 587, 1760, 736, 866, 30, 51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6723227987484056,\n",
       "   'compression_ratio': 1.5051020408163265,\n",
       "   'no_speech_prob': 0.0938156396150589},\n",
       "  {'id': 658,\n",
       "   'seek': 251286,\n",
       "   'start': 2526.86,\n",
       "   'end': 2529.86,\n",
       "   'text': \" It's bad job.\",\n",
       "   'tokens': [51063, 632, 338, 2089, 1693, 13, 51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6723227987484056,\n",
       "   'compression_ratio': 1.5051020408163265,\n",
       "   'no_speech_prob': 0.0938156396150589},\n",
       "  {'id': 659,\n",
       "   'seek': 251286,\n",
       "   'start': 2529.86,\n",
       "   'end': 2532.86,\n",
       "   'text': ' How many times you have done good?',\n",
       "   'tokens': [51213, 1374, 867, 1661, 345, 423, 1760, 922, 30, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6723227987484056,\n",
       "   'compression_ratio': 1.5051020408163265,\n",
       "   'no_speech_prob': 0.0938156396150589},\n",
       "  {'id': 660,\n",
       "   'seek': 251286,\n",
       "   'start': 2532.86,\n",
       "   'end': 2535.86,\n",
       "   'text': ' Okay, why?',\n",
       "   'tokens': [51363, 16805, 11, 1521, 30, 51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6723227987484056,\n",
       "   'compression_ratio': 1.5051020408163265,\n",
       "   'no_speech_prob': 0.0938156396150589},\n",
       "  {'id': 661,\n",
       "   'seek': 251286,\n",
       "   'start': 2535.86,\n",
       "   'end': 2537.86,\n",
       "   'text': \" I think we're in the three-hundred.\",\n",
       "   'tokens': [51513,\n",
       "    314,\n",
       "    892,\n",
       "    356,\n",
       "    821,\n",
       "    287,\n",
       "    262,\n",
       "    1115,\n",
       "    12,\n",
       "    71,\n",
       "    3229,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6723227987484056,\n",
       "   'compression_ratio': 1.5051020408163265,\n",
       "   'no_speech_prob': 0.0938156396150589},\n",
       "  {'id': 662,\n",
       "   'seek': 251286,\n",
       "   'start': 2537.86,\n",
       "   'end': 2540.86,\n",
       "   'text': ' Sorry.',\n",
       "   'tokens': [51613, 19061, 13, 51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6723227987484056,\n",
       "   'compression_ratio': 1.5051020408163265,\n",
       "   'no_speech_prob': 0.0938156396150589},\n",
       "  {'id': 663,\n",
       "   'seek': 254086,\n",
       "   'start': 2540.86,\n",
       "   'end': 2543.86,\n",
       "   'text': ' Depends on the answer.',\n",
       "   'tokens': [50363, 2129, 2412, 319, 262, 3280, 13, 50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4156854608085718,\n",
       "   'compression_ratio': 1.6294416243654823,\n",
       "   'no_speech_prob': 0.17181605100631714},\n",
       "  {'id': 664,\n",
       "   'seek': 254086,\n",
       "   'start': 2543.86,\n",
       "   'end': 2547.86,\n",
       "   'text': ' The answer is depends on the state of the art, which is a very valid answer because what is fine to say is that you want to',\n",
       "   'tokens': [50513,\n",
       "    383,\n",
       "    3280,\n",
       "    318,\n",
       "    8338,\n",
       "    319,\n",
       "    262,\n",
       "    1181,\n",
       "    286,\n",
       "    262,\n",
       "    1242,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    257,\n",
       "    845,\n",
       "    4938,\n",
       "    3280,\n",
       "    780,\n",
       "    644,\n",
       "    318,\n",
       "    3734,\n",
       "    284,\n",
       "    910,\n",
       "    318,\n",
       "    326,\n",
       "    345,\n",
       "    765,\n",
       "    284,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4156854608085718,\n",
       "   'compression_ratio': 1.6294416243654823,\n",
       "   'no_speech_prob': 0.17181605100631714},\n",
       "  {'id': 665,\n",
       "   'seek': 254086,\n",
       "   'start': 2547.86,\n",
       "   'end': 2556.86,\n",
       "   'text': ' to externalize the accuracy of the metric that we put up on it.',\n",
       "   'tokens': [50713,\n",
       "    284,\n",
       "    7097,\n",
       "    1096,\n",
       "    262,\n",
       "    9922,\n",
       "    286,\n",
       "    262,\n",
       "    18663,\n",
       "    326,\n",
       "    356,\n",
       "    1234,\n",
       "    510,\n",
       "    319,\n",
       "    340,\n",
       "    13,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4156854608085718,\n",
       "   'compression_ratio': 1.6294416243654823,\n",
       "   'no_speech_prob': 0.17181605100631714},\n",
       "  {'id': 666,\n",
       "   'seek': 254086,\n",
       "   'start': 2556.86,\n",
       "   'end': 2560.86,\n",
       "   'text': ' Just say 80% accurate does not mean it.',\n",
       "   'tokens': [51163, 2329, 910, 4019, 4, 7187, 857, 407, 1612, 340, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4156854608085718,\n",
       "   'compression_ratio': 1.6294416243654823,\n",
       "   'no_speech_prob': 0.17181605100631714},\n",
       "  {'id': 667,\n",
       "   'seek': 254086,\n",
       "   'start': 2560.86,\n",
       "   'end': 2569.86,\n",
       "   'text': ' Only if the best report thus far was 60% and 80% accuracy means a lot.',\n",
       "   'tokens': [51363,\n",
       "    5514,\n",
       "    611,\n",
       "    262,\n",
       "    1266,\n",
       "    989,\n",
       "    4145,\n",
       "    1290,\n",
       "    373,\n",
       "    3126,\n",
       "    4,\n",
       "    290,\n",
       "    4019,\n",
       "    4,\n",
       "    9922,\n",
       "    1724,\n",
       "    257,\n",
       "    1256,\n",
       "    13,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4156854608085718,\n",
       "   'compression_ratio': 1.6294416243654823,\n",
       "   'no_speech_prob': 0.17181605100631714},\n",
       "  {'id': 668,\n",
       "   'seek': 256986,\n",
       "   'start': 2569.86,\n",
       "   'end': 2577.86,\n",
       "   'text': ' We first look at a very simple metric on the accuracy, which basically tells us that how many you look at the',\n",
       "   'tokens': [50363,\n",
       "    775,\n",
       "    717,\n",
       "    804,\n",
       "    379,\n",
       "    257,\n",
       "    845,\n",
       "    2829,\n",
       "    18663,\n",
       "    319,\n",
       "    262,\n",
       "    9922,\n",
       "    11,\n",
       "    543,\n",
       "    6209,\n",
       "    4952,\n",
       "    514,\n",
       "    326,\n",
       "    703,\n",
       "    867,\n",
       "    345,\n",
       "    804,\n",
       "    379,\n",
       "    262,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24188624037073014,\n",
       "   'compression_ratio': 1.696078431372549,\n",
       "   'no_speech_prob': 0.012950519099831581},\n",
       "  {'id': 669,\n",
       "   'seek': 256986,\n",
       "   'start': 2577.86,\n",
       "   'end': 2580.86,\n",
       "   'text': ' accuracy across y-act.',\n",
       "   'tokens': [50763, 9922, 1973, 331, 12, 529, 13, 50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24188624037073014,\n",
       "   'compression_ratio': 1.696078431372549,\n",
       "   'no_speech_prob': 0.012950519099831581},\n",
       "  {'id': 670,\n",
       "   'seek': 256986,\n",
       "   'start': 2580.86,\n",
       "   'end': 2584.86,\n",
       "   'text': ' You look at the predictions across specific rows and this.',\n",
       "   'tokens': [50913,\n",
       "    921,\n",
       "    804,\n",
       "    379,\n",
       "    262,\n",
       "    16277,\n",
       "    1973,\n",
       "    2176,\n",
       "    15274,\n",
       "    290,\n",
       "    428,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24188624037073014,\n",
       "   'compression_ratio': 1.696078431372549,\n",
       "   'no_speech_prob': 0.012950519099831581},\n",
       "  {'id': 671,\n",
       "   'seek': 256986,\n",
       "   'start': 2584.86,\n",
       "   'end': 2587.86,\n",
       "   'text': ' And how many times is the y-act equal to y?',\n",
       "   'tokens': [51113,\n",
       "    843,\n",
       "    703,\n",
       "    867,\n",
       "    1661,\n",
       "    318,\n",
       "    262,\n",
       "    331,\n",
       "    12,\n",
       "    529,\n",
       "    4961,\n",
       "    284,\n",
       "    331,\n",
       "    30,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24188624037073014,\n",
       "   'compression_ratio': 1.696078431372549,\n",
       "   'no_speech_prob': 0.012950519099831581},\n",
       "  {'id': 672,\n",
       "   'seek': 256986,\n",
       "   'start': 2587.86,\n",
       "   'end': 2590.86,\n",
       "   'text': ' Divided by the length of y-act.',\n",
       "   'tokens': [51263, 4777, 1384, 416, 262, 4129, 286, 331, 12, 529, 13, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24188624037073014,\n",
       "   'compression_ratio': 1.696078431372549,\n",
       "   'no_speech_prob': 0.012950519099831581},\n",
       "  {'id': 673,\n",
       "   'seek': 256986,\n",
       "   'start': 2590.86,\n",
       "   'end': 2591.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51413, 6498, 30, 51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24188624037073014,\n",
       "   'compression_ratio': 1.696078431372549,\n",
       "   'no_speech_prob': 0.012950519099831581},\n",
       "  {'id': 674,\n",
       "   'seek': 256986,\n",
       "   'start': 2591.86,\n",
       "   'end': 2596.86,\n",
       "   'text': ' So how many times have we accurately or correctly predicted the linear?',\n",
       "   'tokens': [51463,\n",
       "    1406,\n",
       "    703,\n",
       "    867,\n",
       "    1661,\n",
       "    423,\n",
       "    356,\n",
       "    14351,\n",
       "    393,\n",
       "    9380,\n",
       "    11001,\n",
       "    262,\n",
       "    14174,\n",
       "    30,\n",
       "    51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.24188624037073014,\n",
       "   'compression_ratio': 1.696078431372549,\n",
       "   'no_speech_prob': 0.012950519099831581},\n",
       "  {'id': 675,\n",
       "   'seek': 259686,\n",
       "   'start': 2596.86,\n",
       "   'end': 2602.86,\n",
       "   'text': ' The accuracy in this case is in terms of proportion is 0.6 in terms of percentage is 60%.',\n",
       "   'tokens': [50363,\n",
       "    383,\n",
       "    9922,\n",
       "    287,\n",
       "    428,\n",
       "    1339,\n",
       "    318,\n",
       "    287,\n",
       "    2846,\n",
       "    286,\n",
       "    9823,\n",
       "    318,\n",
       "    657,\n",
       "    13,\n",
       "    21,\n",
       "    287,\n",
       "    2846,\n",
       "    286,\n",
       "    5873,\n",
       "    318,\n",
       "    3126,\n",
       "    7225,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.18780372453772504,\n",
       "   'compression_ratio': 1.5391304347826087,\n",
       "   'no_speech_prob': 0.019788742065429688},\n",
       "  {'id': 676,\n",
       "   'seek': 259686,\n",
       "   'start': 2602.86,\n",
       "   'end': 2603.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50663, 6498, 30, 50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.18780372453772504,\n",
       "   'compression_ratio': 1.5391304347826087,\n",
       "   'no_speech_prob': 0.019788742065429688},\n",
       "  {'id': 677,\n",
       "   'seek': 259686,\n",
       "   'start': 2603.86,\n",
       "   'end': 2608.86,\n",
       "   'text': ' So it tells you one specific number, but this is often not enough.',\n",
       "   'tokens': [50713,\n",
       "    1406,\n",
       "    340,\n",
       "    4952,\n",
       "    345,\n",
       "    530,\n",
       "    2176,\n",
       "    1271,\n",
       "    11,\n",
       "    475,\n",
       "    428,\n",
       "    318,\n",
       "    1690,\n",
       "    407,\n",
       "    1576,\n",
       "    13,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.18780372453772504,\n",
       "   'compression_ratio': 1.5391304347826087,\n",
       "   'no_speech_prob': 0.019788742065429688},\n",
       "  {'id': 678,\n",
       "   'seek': 259686,\n",
       "   'start': 2608.86,\n",
       "   'end': 2612.86,\n",
       "   'text': ' And there are different cases in which we need to again contextualize with.',\n",
       "   'tokens': [50963,\n",
       "    843,\n",
       "    612,\n",
       "    389,\n",
       "    1180,\n",
       "    2663,\n",
       "    287,\n",
       "    543,\n",
       "    356,\n",
       "    761,\n",
       "    284,\n",
       "    757,\n",
       "    38356,\n",
       "    1096,\n",
       "    351,\n",
       "    13,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.18780372453772504,\n",
       "   'compression_ratio': 1.5391304347826087,\n",
       "   'no_speech_prob': 0.019788742065429688},\n",
       "  {'id': 679,\n",
       "   'seek': 259686,\n",
       "   'start': 2612.86,\n",
       "   'end': 2618.86,\n",
       "   'text': \" Let's look at some specific types of data to motivate our metric.\",\n",
       "   'tokens': [51163,\n",
       "    3914,\n",
       "    338,\n",
       "    804,\n",
       "    379,\n",
       "    617,\n",
       "    2176,\n",
       "    3858,\n",
       "    286,\n",
       "    1366,\n",
       "    284,\n",
       "    35065,\n",
       "    674,\n",
       "    18663,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.18780372453772504,\n",
       "   'compression_ratio': 1.5391304347826087,\n",
       "   'no_speech_prob': 0.019788742065429688},\n",
       "  {'id': 680,\n",
       "   'seek': 259686,\n",
       "   'start': 2618.86,\n",
       "   'end': 2621.86,\n",
       "   'text': \" Let's imagine that we have one zero one samples.\",\n",
       "   'tokens': [51463,\n",
       "    3914,\n",
       "    338,\n",
       "    5967,\n",
       "    326,\n",
       "    356,\n",
       "    423,\n",
       "    530,\n",
       "    6632,\n",
       "    530,\n",
       "    8405,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.18780372453772504,\n",
       "   'compression_ratio': 1.5391304347826087,\n",
       "   'no_speech_prob': 0.019788742065429688},\n",
       "  {'id': 681,\n",
       "   'seek': 262186,\n",
       "   'start': 2621.86,\n",
       "   'end': 2626.86,\n",
       "   'text': \" And you're predicting something which is not a scale of either, which is either word or band.\",\n",
       "   'tokens': [50363,\n",
       "    843,\n",
       "    345,\n",
       "    821,\n",
       "    25539,\n",
       "    1223,\n",
       "    543,\n",
       "    318,\n",
       "    407,\n",
       "    257,\n",
       "    5046,\n",
       "    286,\n",
       "    2035,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    2035,\n",
       "    1573,\n",
       "    393,\n",
       "    4097,\n",
       "    13,\n",
       "    50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3590939158485049,\n",
       "   'compression_ratio': 1.5736040609137056,\n",
       "   'no_speech_prob': 0.13460473716259003},\n",
       "  {'id': 682,\n",
       "   'seek': 262186,\n",
       "   'start': 2626.86,\n",
       "   'end': 2633.86,\n",
       "   'text': ' And we have, and for examples where the norm of all the actual samples are good.',\n",
       "   'tokens': [50613,\n",
       "    843,\n",
       "    356,\n",
       "    423,\n",
       "    11,\n",
       "    290,\n",
       "    329,\n",
       "    6096,\n",
       "    810,\n",
       "    262,\n",
       "    2593,\n",
       "    286,\n",
       "    477,\n",
       "    262,\n",
       "    4036,\n",
       "    8405,\n",
       "    389,\n",
       "    922,\n",
       "    13,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3590939158485049,\n",
       "   'compression_ratio': 1.5736040609137056,\n",
       "   'no_speech_prob': 0.13460473716259003},\n",
       "  {'id': 683,\n",
       "   'seek': 262186,\n",
       "   'start': 2633.86,\n",
       "   'end': 2634.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50963, 6498, 30, 51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3590939158485049,\n",
       "   'compression_ratio': 1.5736040609137056,\n",
       "   'no_speech_prob': 0.13460473716259003},\n",
       "  {'id': 684,\n",
       "   'seek': 262186,\n",
       "   'start': 2634.86,\n",
       "   'end': 2641.86,\n",
       "   'text': ' And one sample where the actual quality is bad.',\n",
       "   'tokens': [51013,\n",
       "    843,\n",
       "    530,\n",
       "    6291,\n",
       "    810,\n",
       "    262,\n",
       "    4036,\n",
       "    3081,\n",
       "    318,\n",
       "    2089,\n",
       "    13,\n",
       "    51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3590939158485049,\n",
       "   'compression_ratio': 1.5736040609137056,\n",
       "   'no_speech_prob': 0.13460473716259003},\n",
       "  {'id': 685,\n",
       "   'seek': 262186,\n",
       "   'start': 2641.86,\n",
       "   'end': 2642.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51363, 6498, 30, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3590939158485049,\n",
       "   'compression_ratio': 1.5736040609137056,\n",
       "   'no_speech_prob': 0.13460473716259003},\n",
       "  {'id': 686,\n",
       "   'seek': 262186,\n",
       "   'start': 2642.86,\n",
       "   'end': 2648.86,\n",
       "   'text': \" Now, they could be multiple cases when it's such kind of a data-specific.\",\n",
       "   'tokens': [51413,\n",
       "    2735,\n",
       "    11,\n",
       "    484,\n",
       "    714,\n",
       "    307,\n",
       "    3294,\n",
       "    2663,\n",
       "    618,\n",
       "    340,\n",
       "    338,\n",
       "    884,\n",
       "    1611,\n",
       "    286,\n",
       "    257,\n",
       "    1366,\n",
       "    12,\n",
       "    11423,\n",
       "    13,\n",
       "    51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3590939158485049,\n",
       "   'compression_ratio': 1.5736040609137056,\n",
       "   'no_speech_prob': 0.13460473716259003},\n",
       "  {'id': 687,\n",
       "   'seek': 264886,\n",
       "   'start': 2648.86,\n",
       "   'end': 2658.86,\n",
       "   'text': \" For example, the cancer strain, you would hope that in most cases, cancer strain, we will have people's health as good.\",\n",
       "   'tokens': [50363,\n",
       "    1114,\n",
       "    1672,\n",
       "    11,\n",
       "    262,\n",
       "    4890,\n",
       "    14022,\n",
       "    11,\n",
       "    345,\n",
       "    561,\n",
       "    2911,\n",
       "    326,\n",
       "    287,\n",
       "    749,\n",
       "    2663,\n",
       "    11,\n",
       "    4890,\n",
       "    14022,\n",
       "    11,\n",
       "    356,\n",
       "    481,\n",
       "    423,\n",
       "    661,\n",
       "    338,\n",
       "    1535,\n",
       "    355,\n",
       "    922,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31487049040247184,\n",
       "   'compression_ratio': 1.829059829059829,\n",
       "   'no_speech_prob': 0.21526391804218292},\n",
       "  {'id': 688,\n",
       "   'seek': 264886,\n",
       "   'start': 2658.86,\n",
       "   'end': 2659.86,\n",
       "   'text': \" They don't have cancer.\",\n",
       "   'tokens': [50863, 1119, 836, 470, 423, 4890, 13, 50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31487049040247184,\n",
       "   'compression_ratio': 1.829059829059829,\n",
       "   'no_speech_prob': 0.21526391804218292},\n",
       "  {'id': 689,\n",
       "   'seek': 264886,\n",
       "   'start': 2659.86,\n",
       "   'end': 2662.86,\n",
       "   'text': ' Unfortunately, for very small, they will be cancer.',\n",
       "   'tokens': [50913,\n",
       "    8989,\n",
       "    11,\n",
       "    329,\n",
       "    845,\n",
       "    1402,\n",
       "    11,\n",
       "    484,\n",
       "    481,\n",
       "    307,\n",
       "    4890,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31487049040247184,\n",
       "   'compression_ratio': 1.829059829059829,\n",
       "   'no_speech_prob': 0.21526391804218292},\n",
       "  {'id': 690,\n",
       "   'seek': 264886,\n",
       "   'start': 2662.86,\n",
       "   'end': 2667.86,\n",
       "   'text': \" But in general, if we look at some data, we'll expect it to look something like this.\",\n",
       "   'tokens': [51063,\n",
       "    887,\n",
       "    287,\n",
       "    2276,\n",
       "    11,\n",
       "    611,\n",
       "    356,\n",
       "    804,\n",
       "    379,\n",
       "    617,\n",
       "    1366,\n",
       "    11,\n",
       "    356,\n",
       "    1183,\n",
       "    1607,\n",
       "    340,\n",
       "    284,\n",
       "    804,\n",
       "    1223,\n",
       "    588,\n",
       "    428,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31487049040247184,\n",
       "   'compression_ratio': 1.829059829059829,\n",
       "   'no_speech_prob': 0.21526391804218292},\n",
       "  {'id': 691,\n",
       "   'seek': 264886,\n",
       "   'start': 2667.86,\n",
       "   'end': 2671.86,\n",
       "   'text': ' Go to good, go to good, go to good, go to cancer, go to cancer, go to cancer, go to other cancer.',\n",
       "   'tokens': [51313,\n",
       "    1514,\n",
       "    284,\n",
       "    922,\n",
       "    11,\n",
       "    467,\n",
       "    284,\n",
       "    922,\n",
       "    11,\n",
       "    467,\n",
       "    284,\n",
       "    922,\n",
       "    11,\n",
       "    467,\n",
       "    284,\n",
       "    4890,\n",
       "    11,\n",
       "    467,\n",
       "    284,\n",
       "    4890,\n",
       "    11,\n",
       "    467,\n",
       "    284,\n",
       "    4890,\n",
       "    11,\n",
       "    467,\n",
       "    284,\n",
       "    584,\n",
       "    4890,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31487049040247184,\n",
       "   'compression_ratio': 1.829059829059829,\n",
       "   'no_speech_prob': 0.21526391804218292},\n",
       "  {'id': 692,\n",
       "   'seek': 264886,\n",
       "   'start': 2671.86,\n",
       "   'end': 2672.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51513, 6498, 30, 51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31487049040247184,\n",
       "   'compression_ratio': 1.829059829059829,\n",
       "   'no_speech_prob': 0.21526391804218292},\n",
       "  {'id': 693,\n",
       "   'seek': 264886,\n",
       "   'start': 2672.86,\n",
       "   'end': 2675.86,\n",
       "   'text': ' So you end up with an imbalance data set.',\n",
       "   'tokens': [51563,\n",
       "    1406,\n",
       "    345,\n",
       "    886,\n",
       "    510,\n",
       "    351,\n",
       "    281,\n",
       "    32556,\n",
       "    1366,\n",
       "    900,\n",
       "    13,\n",
       "    51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.31487049040247184,\n",
       "   'compression_ratio': 1.829059829059829,\n",
       "   'no_speech_prob': 0.21526391804218292},\n",
       "  {'id': 694,\n",
       "   'seek': 267586,\n",
       "   'start': 2675.86,\n",
       "   'end': 2685.86,\n",
       "   'text': \" And maybe even if I'm a detect, if someone is trying to detect forms of imagery or forms of speech, most of the time you shouldn't have no bad code on code on code on code on it.\",\n",
       "   'tokens': [50363,\n",
       "    843,\n",
       "    3863,\n",
       "    772,\n",
       "    611,\n",
       "    314,\n",
       "    1101,\n",
       "    257,\n",
       "    4886,\n",
       "    11,\n",
       "    611,\n",
       "    2130,\n",
       "    318,\n",
       "    2111,\n",
       "    284,\n",
       "    4886,\n",
       "    5107,\n",
       "    286,\n",
       "    19506,\n",
       "    393,\n",
       "    5107,\n",
       "    286,\n",
       "    4046,\n",
       "    11,\n",
       "    749,\n",
       "    286,\n",
       "    262,\n",
       "    640,\n",
       "    345,\n",
       "    6584,\n",
       "    470,\n",
       "    423,\n",
       "    645,\n",
       "    2089,\n",
       "    2438,\n",
       "    319,\n",
       "    2438,\n",
       "    319,\n",
       "    2438,\n",
       "    319,\n",
       "    2438,\n",
       "    319,\n",
       "    340,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5228347778320312,\n",
       "   'compression_ratio': 1.5754716981132075,\n",
       "   'no_speech_prob': 0.09952838718891144},\n",
       "  {'id': 695,\n",
       "   'seek': 267586,\n",
       "   'start': 2685.86,\n",
       "   'end': 2687.86,\n",
       "   'text': ' And some plans to work.',\n",
       "   'tokens': [50863, 843, 617, 3352, 284, 670, 13, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5228347778320312,\n",
       "   'compression_ratio': 1.5754716981132075,\n",
       "   'no_speech_prob': 0.09952838718891144},\n",
       "  {'id': 696,\n",
       "   'seek': 267586,\n",
       "   'start': 2687.86,\n",
       "   'end': 2693.86,\n",
       "   'text': ' Otherwise, people will be getting only twice a period of time.',\n",
       "   'tokens': [50963,\n",
       "    15323,\n",
       "    11,\n",
       "    661,\n",
       "    481,\n",
       "    307,\n",
       "    1972,\n",
       "    691,\n",
       "    5403,\n",
       "    257,\n",
       "    2278,\n",
       "    286,\n",
       "    640,\n",
       "    13,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5228347778320312,\n",
       "   'compression_ratio': 1.5754716981132075,\n",
       "   'no_speech_prob': 0.09952838718891144},\n",
       "  {'id': 697,\n",
       "   'seek': 267586,\n",
       "   'start': 2693.86,\n",
       "   'end': 2698.86,\n",
       "   'text': \" Now, let's look at a different metric now.\",\n",
       "   'tokens': [51263,\n",
       "    2735,\n",
       "    11,\n",
       "    1309,\n",
       "    338,\n",
       "    804,\n",
       "    379,\n",
       "    257,\n",
       "    1180,\n",
       "    18663,\n",
       "    783,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5228347778320312,\n",
       "   'compression_ratio': 1.5754716981132075,\n",
       "   'no_speech_prob': 0.09952838718891144},\n",
       "  {'id': 698,\n",
       "   'seek': 267586,\n",
       "   'start': 2698.86,\n",
       "   'end': 2700.86,\n",
       "   'text': ' It was part of precision.',\n",
       "   'tokens': [51513, 632, 373, 636, 286, 15440, 13, 51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5228347778320312,\n",
       "   'compression_ratio': 1.5754716981132075,\n",
       "   'no_speech_prob': 0.09952838718891144},\n",
       "  {'id': 699,\n",
       "   'seek': 270086,\n",
       "   'start': 2700.86,\n",
       "   'end': 2705.86,\n",
       "   'text': \" Let's look at any number of the same paper as picture earlier.\",\n",
       "   'tokens': [50363,\n",
       "    3914,\n",
       "    338,\n",
       "    804,\n",
       "    379,\n",
       "    597,\n",
       "    1271,\n",
       "    286,\n",
       "    262,\n",
       "    976,\n",
       "    3348,\n",
       "    355,\n",
       "    4286,\n",
       "    2961,\n",
       "    13,\n",
       "    50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5360704079652444,\n",
       "   'compression_ratio': 1.811659192825112,\n",
       "   'no_speech_prob': 0.05920053645968437},\n",
       "  {'id': 700,\n",
       "   'seek': 270086,\n",
       "   'start': 2705.86,\n",
       "   'end': 2712.86,\n",
       "   'text': ' Now, before looking at this slide, can someone tell you what you understand very strong precision?',\n",
       "   'tokens': [50613,\n",
       "    2735,\n",
       "    11,\n",
       "    878,\n",
       "    2045,\n",
       "    379,\n",
       "    428,\n",
       "    10649,\n",
       "    11,\n",
       "    460,\n",
       "    2130,\n",
       "    1560,\n",
       "    345,\n",
       "    644,\n",
       "    345,\n",
       "    1833,\n",
       "    845,\n",
       "    1913,\n",
       "    15440,\n",
       "    30,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5360704079652444,\n",
       "   'compression_ratio': 1.811659192825112,\n",
       "   'no_speech_prob': 0.05920053645968437},\n",
       "  {'id': 701,\n",
       "   'seek': 270086,\n",
       "   'start': 2712.86,\n",
       "   'end': 2715.86,\n",
       "   'text': ' In general, in this functional layman process.',\n",
       "   'tokens': [50963,\n",
       "    554,\n",
       "    2276,\n",
       "    11,\n",
       "    287,\n",
       "    428,\n",
       "    10345,\n",
       "    3830,\n",
       "    805,\n",
       "    1429,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5360704079652444,\n",
       "   'compression_ratio': 1.811659192825112,\n",
       "   'no_speech_prob': 0.05920053645968437},\n",
       "  {'id': 702,\n",
       "   'seek': 270086,\n",
       "   'start': 2715.86,\n",
       "   'end': 2718.86,\n",
       "   'text': \" If it's a probability of it.\",\n",
       "   'tokens': [51113, 1002, 340, 338, 257, 12867, 286, 340, 13, 51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5360704079652444,\n",
       "   'compression_ratio': 1.811659192825112,\n",
       "   'no_speech_prob': 0.05920053645968437},\n",
       "  {'id': 703,\n",
       "   'seek': 270086,\n",
       "   'start': 2718.86,\n",
       "   'end': 2719.86,\n",
       "   'text': ' Sorry.',\n",
       "   'tokens': [51263, 19061, 13, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5360704079652444,\n",
       "   'compression_ratio': 1.811659192825112,\n",
       "   'no_speech_prob': 0.05920053645968437},\n",
       "  {'id': 704,\n",
       "   'seek': 270086,\n",
       "   'start': 2719.86,\n",
       "   'end': 2720.86,\n",
       "   'text': \" If it's a probability of it.\",\n",
       "   'tokens': [51313, 1002, 340, 338, 257, 12867, 286, 340, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5360704079652444,\n",
       "   'compression_ratio': 1.811659192825112,\n",
       "   'no_speech_prob': 0.05920053645968437},\n",
       "  {'id': 705,\n",
       "   'seek': 270086,\n",
       "   'start': 2720.86,\n",
       "   'end': 2721.86,\n",
       "   'text': ' A probability, okay.',\n",
       "   'tokens': [51363, 317, 12867, 11, 8788, 13, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5360704079652444,\n",
       "   'compression_ratio': 1.811659192825112,\n",
       "   'no_speech_prob': 0.05920053645968437},\n",
       "  {'id': 706,\n",
       "   'seek': 270086,\n",
       "   'start': 2721.86,\n",
       "   'end': 2724.86,\n",
       "   'text': ' What does it mean to be very precise?',\n",
       "   'tokens': [51413, 1867, 857, 340, 1612, 284, 307, 845, 7141, 30, 51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5360704079652444,\n",
       "   'compression_ratio': 1.811659192825112,\n",
       "   'no_speech_prob': 0.05920053645968437},\n",
       "  {'id': 707,\n",
       "   'seek': 270086,\n",
       "   'start': 2724.86,\n",
       "   'end': 2727.86,\n",
       "   'text': ' It can be a difference.',\n",
       "   'tokens': [51563, 632, 460, 307, 257, 3580, 13, 51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5360704079652444,\n",
       "   'compression_ratio': 1.811659192825112,\n",
       "   'no_speech_prob': 0.05920053645968437},\n",
       "  {'id': 708,\n",
       "   'seek': 270086,\n",
       "   'start': 2727.86,\n",
       "   'end': 2728.86,\n",
       "   'text': ' It can be a difference.',\n",
       "   'tokens': [51713, 632, 460, 307, 257, 3580, 13, 51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5360704079652444,\n",
       "   'compression_ratio': 1.811659192825112,\n",
       "   'no_speech_prob': 0.05920053645968437},\n",
       "  {'id': 709,\n",
       "   'seek': 270086,\n",
       "   'start': 2728.86,\n",
       "   'end': 2729.86,\n",
       "   'text': ' It can be a difference.',\n",
       "   'tokens': [51763, 632, 460, 307, 257, 3580, 13, 51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5360704079652444,\n",
       "   'compression_ratio': 1.811659192825112,\n",
       "   'no_speech_prob': 0.05920053645968437},\n",
       "  {'id': 710,\n",
       "   'seek': 272986,\n",
       "   'start': 2729.86,\n",
       "   'end': 2734.86,\n",
       "   'text': ' Any other, what does it mean to be precise?',\n",
       "   'tokens': [50363,\n",
       "    4377,\n",
       "    584,\n",
       "    11,\n",
       "    644,\n",
       "    857,\n",
       "    340,\n",
       "    1612,\n",
       "    284,\n",
       "    307,\n",
       "    7141,\n",
       "    30,\n",
       "    50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4776747483473558,\n",
       "   'compression_ratio': 1.4736842105263157,\n",
       "   'no_speech_prob': 0.17546339333057404},\n",
       "  {'id': 711,\n",
       "   'seek': 272986,\n",
       "   'start': 2734.86,\n",
       "   'end': 2744.86,\n",
       "   'text': ' What do you mean by when someone asks, can you speak with precise?',\n",
       "   'tokens': [50613,\n",
       "    1867,\n",
       "    466,\n",
       "    345,\n",
       "    1612,\n",
       "    416,\n",
       "    618,\n",
       "    2130,\n",
       "    7893,\n",
       "    11,\n",
       "    460,\n",
       "    345,\n",
       "    2740,\n",
       "    351,\n",
       "    7141,\n",
       "    30,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4776747483473558,\n",
       "   'compression_ratio': 1.4736842105263157,\n",
       "   'no_speech_prob': 0.17546339333057404},\n",
       "  {'id': 712,\n",
       "   'seek': 272986,\n",
       "   'start': 2744.86,\n",
       "   'end': 2747.86,\n",
       "   'text': ' Or can you write down the term of the measure?',\n",
       "   'tokens': [51113,\n",
       "    1471,\n",
       "    460,\n",
       "    345,\n",
       "    3551,\n",
       "    866,\n",
       "    262,\n",
       "    3381,\n",
       "    286,\n",
       "    262,\n",
       "    3953,\n",
       "    30,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4776747483473558,\n",
       "   'compression_ratio': 1.4736842105263157,\n",
       "   'no_speech_prob': 0.17546339333057404},\n",
       "  {'id': 713,\n",
       "   'seek': 272986,\n",
       "   'start': 2747.86,\n",
       "   'end': 2748.86,\n",
       "   'text': ' Sorry.',\n",
       "   'tokens': [51263, 19061, 13, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4776747483473558,\n",
       "   'compression_ratio': 1.4736842105263157,\n",
       "   'no_speech_prob': 0.17546339333057404},\n",
       "  {'id': 714,\n",
       "   'seek': 272986,\n",
       "   'start': 2748.86,\n",
       "   'end': 2749.86,\n",
       "   'text': ' To the mark.',\n",
       "   'tokens': [51313, 1675, 262, 1317, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4776747483473558,\n",
       "   'compression_ratio': 1.4736842105263157,\n",
       "   'no_speech_prob': 0.17546339333057404},\n",
       "  {'id': 715,\n",
       "   'seek': 272986,\n",
       "   'start': 2749.86,\n",
       "   'end': 2750.86,\n",
       "   'text': ' To the mark.',\n",
       "   'tokens': [51363, 1675, 262, 1317, 13, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4776747483473558,\n",
       "   'compression_ratio': 1.4736842105263157,\n",
       "   'no_speech_prob': 0.17546339333057404},\n",
       "  {'id': 716,\n",
       "   'seek': 272986,\n",
       "   'start': 2750.86,\n",
       "   'end': 2751.86,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [51413, 16805, 13, 51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4776747483473558,\n",
       "   'compression_ratio': 1.4736842105263157,\n",
       "   'no_speech_prob': 0.17546339333057404},\n",
       "  {'id': 717,\n",
       "   'seek': 275186,\n",
       "   'start': 2751.86,\n",
       "   'end': 2758.86,\n",
       "   'text': \" What do you think of precision in terms of whatever your writing or whatever you're predicting or how to that you mean?\",\n",
       "   'tokens': [50363,\n",
       "    1867,\n",
       "    466,\n",
       "    345,\n",
       "    892,\n",
       "    286,\n",
       "    15440,\n",
       "    287,\n",
       "    2846,\n",
       "    286,\n",
       "    4232,\n",
       "    534,\n",
       "    3597,\n",
       "    393,\n",
       "    4232,\n",
       "    345,\n",
       "    821,\n",
       "    25539,\n",
       "    393,\n",
       "    703,\n",
       "    284,\n",
       "    326,\n",
       "    345,\n",
       "    1612,\n",
       "    30,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4085224307313257,\n",
       "   'compression_ratio': 1.7714285714285714,\n",
       "   'no_speech_prob': 0.578262209892273},\n",
       "  {'id': 718,\n",
       "   'seek': 275186,\n",
       "   'start': 2758.86,\n",
       "   'end': 2760.86,\n",
       "   'text': ' How true that is.',\n",
       "   'tokens': [50713, 1374, 2081, 326, 318, 13, 50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4085224307313257,\n",
       "   'compression_ratio': 1.7714285714285714,\n",
       "   'no_speech_prob': 0.578262209892273},\n",
       "  {'id': 719,\n",
       "   'seek': 275186,\n",
       "   'start': 2760.86,\n",
       "   'end': 2763.86,\n",
       "   'text': ' Or how much sense that does mean.',\n",
       "   'tokens': [50813, 1471, 703, 881, 2565, 326, 857, 1612, 13, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4085224307313257,\n",
       "   'compression_ratio': 1.7714285714285714,\n",
       "   'no_speech_prob': 0.578262209892273},\n",
       "  {'id': 720,\n",
       "   'seek': 275186,\n",
       "   'start': 2763.86,\n",
       "   'end': 2771.86,\n",
       "   'text': \" So, more English terms in layman terms might mean that how much sense does it mean what you're writing.\",\n",
       "   'tokens': [50963,\n",
       "    1406,\n",
       "    11,\n",
       "    517,\n",
       "    3594,\n",
       "    2846,\n",
       "    287,\n",
       "    3830,\n",
       "    805,\n",
       "    2846,\n",
       "    1244,\n",
       "    1612,\n",
       "    326,\n",
       "    703,\n",
       "    881,\n",
       "    2565,\n",
       "    857,\n",
       "    340,\n",
       "    1612,\n",
       "    644,\n",
       "    345,\n",
       "    821,\n",
       "    3597,\n",
       "    13,\n",
       "    51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4085224307313257,\n",
       "   'compression_ratio': 1.7714285714285714,\n",
       "   'no_speech_prob': 0.578262209892273},\n",
       "  {'id': 721,\n",
       "   'seek': 275186,\n",
       "   'start': 2771.86,\n",
       "   'end': 2772.86,\n",
       "   'text': ' Okay.',\n",
       "   'tokens': [51363, 16805, 13, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4085224307313257,\n",
       "   'compression_ratio': 1.7714285714285714,\n",
       "   'no_speech_prob': 0.578262209892273},\n",
       "  {'id': 722,\n",
       "   'seek': 275186,\n",
       "   'start': 2772.86,\n",
       "   'end': 2780.86,\n",
       "   'text': ' So, now, when you work on the definition, you look at the times you predicted good, right?',\n",
       "   'tokens': [51413,\n",
       "    1406,\n",
       "    11,\n",
       "    783,\n",
       "    11,\n",
       "    618,\n",
       "    345,\n",
       "    670,\n",
       "    319,\n",
       "    262,\n",
       "    6770,\n",
       "    11,\n",
       "    345,\n",
       "    804,\n",
       "    379,\n",
       "    262,\n",
       "    1661,\n",
       "    345,\n",
       "    11001,\n",
       "    922,\n",
       "    11,\n",
       "    826,\n",
       "    30,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4085224307313257,\n",
       "   'compression_ratio': 1.7714285714285714,\n",
       "   'no_speech_prob': 0.578262209892273},\n",
       "  {'id': 723,\n",
       "   'seek': 278086,\n",
       "   'start': 2780.86,\n",
       "   'end': 2782.86,\n",
       "   'text': ' You predicted good how many times?',\n",
       "   'tokens': [50363, 921, 11001, 922, 703, 867, 1661, 30, 50463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32339651244027273,\n",
       "   'compression_ratio': 1.7142857142857142,\n",
       "   'no_speech_prob': 0.01686965301632881},\n",
       "  {'id': 724,\n",
       "   'seek': 278086,\n",
       "   'start': 2782.86,\n",
       "   'end': 2784.86,\n",
       "   'text': ' 1, 2, 3 and 4.',\n",
       "   'tokens': [50463, 352, 11, 362, 11, 513, 290, 604, 13, 50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32339651244027273,\n",
       "   'compression_ratio': 1.7142857142857142,\n",
       "   'no_speech_prob': 0.01686965301632881},\n",
       "  {'id': 725,\n",
       "   'seek': 278086,\n",
       "   'start': 2784.86,\n",
       "   'end': 2787.86,\n",
       "   'text': ' Out of these, 4 times you predicted good.',\n",
       "   'tokens': [50563,\n",
       "    3806,\n",
       "    286,\n",
       "    777,\n",
       "    11,\n",
       "    604,\n",
       "    1661,\n",
       "    345,\n",
       "    11001,\n",
       "    922,\n",
       "    13,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32339651244027273,\n",
       "   'compression_ratio': 1.7142857142857142,\n",
       "   'no_speech_prob': 0.01686965301632881},\n",
       "  {'id': 726,\n",
       "   'seek': 278086,\n",
       "   'start': 2787.86,\n",
       "   'end': 2789.86,\n",
       "   'text': ' How many times were you actually good?',\n",
       "   'tokens': [50713, 1374, 867, 1661, 547, 345, 1682, 922, 30, 50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32339651244027273,\n",
       "   'compression_ratio': 1.7142857142857142,\n",
       "   'no_speech_prob': 0.01686965301632881},\n",
       "  {'id': 727,\n",
       "   'seek': 278086,\n",
       "   'start': 2789.86,\n",
       "   'end': 2792.86,\n",
       "   'text': ' Or was the ground truth also sense good?',\n",
       "   'tokens': [50813, 1471, 373, 262, 2323, 3872, 635, 2565, 922, 30, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32339651244027273,\n",
       "   'compression_ratio': 1.7142857142857142,\n",
       "   'no_speech_prob': 0.01686965301632881},\n",
       "  {'id': 728,\n",
       "   'seek': 278086,\n",
       "   'start': 2792.86,\n",
       "   'end': 2793.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50963, 6498, 30, 51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32339651244027273,\n",
       "   'compression_ratio': 1.7142857142857142,\n",
       "   'no_speech_prob': 0.01686965301632881},\n",
       "  {'id': 729,\n",
       "   'seek': 278086,\n",
       "   'start': 2793.86,\n",
       "   'end': 2796.86,\n",
       "   'text': ' So, you predicted good 4 times.',\n",
       "   'tokens': [51013, 1406, 11, 345, 11001, 922, 604, 1661, 13, 51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32339651244027273,\n",
       "   'compression_ratio': 1.7142857142857142,\n",
       "   'no_speech_prob': 0.01686965301632881},\n",
       "  {'id': 730,\n",
       "   'seek': 278086,\n",
       "   'start': 2796.86,\n",
       "   'end': 2799.86,\n",
       "   'text': ' But you will not predict the size in predicting good.',\n",
       "   'tokens': [51163,\n",
       "    887,\n",
       "    345,\n",
       "    481,\n",
       "    407,\n",
       "    4331,\n",
       "    262,\n",
       "    2546,\n",
       "    287,\n",
       "    25539,\n",
       "    922,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32339651244027273,\n",
       "   'compression_ratio': 1.7142857142857142,\n",
       "   'no_speech_prob': 0.01686965301632881},\n",
       "  {'id': 731,\n",
       "   'seek': 278086,\n",
       "   'start': 2799.86,\n",
       "   'end': 2805.86,\n",
       "   'text': ' Your precision was thus far, thus, 2 or 4, which is the algorithm.',\n",
       "   'tokens': [51313,\n",
       "    3406,\n",
       "    15440,\n",
       "    373,\n",
       "    4145,\n",
       "    1290,\n",
       "    11,\n",
       "    4145,\n",
       "    11,\n",
       "    362,\n",
       "    393,\n",
       "    604,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    262,\n",
       "    11862,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32339651244027273,\n",
       "   'compression_ratio': 1.7142857142857142,\n",
       "   'no_speech_prob': 0.01686965301632881},\n",
       "  {'id': 732,\n",
       "   'seek': 278086,\n",
       "   'start': 2805.86,\n",
       "   'end': 2806.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51613, 6498, 30, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32339651244027273,\n",
       "   'compression_ratio': 1.7142857142857142,\n",
       "   'no_speech_prob': 0.01686965301632881},\n",
       "  {'id': 733,\n",
       "   'seek': 278086,\n",
       "   'start': 2806.86,\n",
       "   'end': 2808.86,\n",
       "   'text': ' Does everyone get the definition?',\n",
       "   'tokens': [51663, 8314, 2506, 651, 262, 6770, 30, 51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32339651244027273,\n",
       "   'compression_ratio': 1.7142857142857142,\n",
       "   'no_speech_prob': 0.01686965301632881},\n",
       "  {'id': 734,\n",
       "   'seek': 280886,\n",
       "   'start': 2808.86,\n",
       "   'end': 2812.86,\n",
       "   'text': ' How precise are you in predicting a particular class?',\n",
       "   'tokens': [50363,\n",
       "    1374,\n",
       "    7141,\n",
       "    389,\n",
       "    345,\n",
       "    287,\n",
       "    25539,\n",
       "    257,\n",
       "    1948,\n",
       "    1398,\n",
       "    30,\n",
       "    50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.20513136990099068,\n",
       "   'compression_ratio': 1.6772486772486772,\n",
       "   'no_speech_prob': 0.004791190382093191},\n",
       "  {'id': 735,\n",
       "   'seek': 280886,\n",
       "   'start': 2812.86,\n",
       "   'end': 2816.86,\n",
       "   'text': ' Now, precision can be defined in terms of the specific part.',\n",
       "   'tokens': [50563,\n",
       "    2735,\n",
       "    11,\n",
       "    15440,\n",
       "    460,\n",
       "    307,\n",
       "    5447,\n",
       "    287,\n",
       "    2846,\n",
       "    286,\n",
       "    262,\n",
       "    2176,\n",
       "    636,\n",
       "    13,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.20513136990099068,\n",
       "   'compression_ratio': 1.6772486772486772,\n",
       "   'no_speech_prob': 0.004791190382093191},\n",
       "  {'id': 736,\n",
       "   'seek': 280886,\n",
       "   'start': 2816.86,\n",
       "   'end': 2819.86,\n",
       "   'text': ' You could also define precision for bad.',\n",
       "   'tokens': [50763, 921, 714, 635, 8160, 15440, 329, 2089, 13, 50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.20513136990099068,\n",
       "   'compression_ratio': 1.6772486772486772,\n",
       "   'no_speech_prob': 0.004791190382093191},\n",
       "  {'id': 737,\n",
       "   'seek': 280886,\n",
       "   'start': 2819.86,\n",
       "   'end': 2820.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50913, 6498, 30, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.20513136990099068,\n",
       "   'compression_ratio': 1.6772486772486772,\n",
       "   'no_speech_prob': 0.004791190382093191},\n",
       "  {'id': 738,\n",
       "   'seek': 280886,\n",
       "   'start': 2820.86,\n",
       "   'end': 2822.86,\n",
       "   'text': ' What is the precision for bad?',\n",
       "   'tokens': [50963, 1867, 318, 262, 15440, 329, 2089, 30, 51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.20513136990099068,\n",
       "   'compression_ratio': 1.6772486772486772,\n",
       "   'no_speech_prob': 0.004791190382093191},\n",
       "  {'id': 739,\n",
       "   'seek': 280886,\n",
       "   'start': 2822.86,\n",
       "   'end': 2830.86,\n",
       "   'text': ' You predicted bad once, but for that specific time it was actually not bad.',\n",
       "   'tokens': [51063,\n",
       "    921,\n",
       "    11001,\n",
       "    2089,\n",
       "    1752,\n",
       "    11,\n",
       "    475,\n",
       "    329,\n",
       "    326,\n",
       "    2176,\n",
       "    640,\n",
       "    340,\n",
       "    373,\n",
       "    1682,\n",
       "    407,\n",
       "    2089,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.20513136990099068,\n",
       "   'compression_ratio': 1.6772486772486772,\n",
       "   'no_speech_prob': 0.004791190382093191},\n",
       "  {'id': 740,\n",
       "   'seek': 280886,\n",
       "   'start': 2830.86,\n",
       "   'end': 2834.86,\n",
       "   'text': ' So, you have got 0 precision in predicting bad.',\n",
       "   'tokens': [51463,\n",
       "    1406,\n",
       "    11,\n",
       "    345,\n",
       "    423,\n",
       "    1392,\n",
       "    657,\n",
       "    15440,\n",
       "    287,\n",
       "    25539,\n",
       "    2089,\n",
       "    13,\n",
       "    51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.20513136990099068,\n",
       "   'compression_ratio': 1.6772486772486772,\n",
       "   'no_speech_prob': 0.004791190382093191},\n",
       "  {'id': 741,\n",
       "   'seek': 283486,\n",
       "   'start': 2834.86,\n",
       "   'end': 2839.86,\n",
       "   'text': ' So, precision for bad to 10v is 0 or 1 is going to be 0, precision for bad as now 2 or 4.',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    11,\n",
       "    15440,\n",
       "    329,\n",
       "    2089,\n",
       "    284,\n",
       "    838,\n",
       "    85,\n",
       "    318,\n",
       "    657,\n",
       "    393,\n",
       "    352,\n",
       "    318,\n",
       "    1016,\n",
       "    284,\n",
       "    307,\n",
       "    657,\n",
       "    11,\n",
       "    15440,\n",
       "    329,\n",
       "    2089,\n",
       "    355,\n",
       "    783,\n",
       "    362,\n",
       "    393,\n",
       "    604,\n",
       "    13,\n",
       "    50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4096016089121501,\n",
       "   'compression_ratio': 1.6,\n",
       "   'no_speech_prob': 0.24505464732646942},\n",
       "  {'id': 742,\n",
       "   'seek': 283486,\n",
       "   'start': 2839.86,\n",
       "   'end': 2840.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50613, 6498, 30, 50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4096016089121501,\n",
       "   'compression_ratio': 1.6,\n",
       "   'no_speech_prob': 0.24505464732646942},\n",
       "  {'id': 743,\n",
       "   'seek': 283486,\n",
       "   'start': 2840.86,\n",
       "   'end': 2846.86,\n",
       "   'text': ' Or what technically you would write in fraction of relevant expenses, amongst the retreats.',\n",
       "   'tokens': [50663,\n",
       "    1471,\n",
       "    644,\n",
       "    14497,\n",
       "    345,\n",
       "    561,\n",
       "    3551,\n",
       "    287,\n",
       "    13390,\n",
       "    286,\n",
       "    5981,\n",
       "    9307,\n",
       "    11,\n",
       "    12077,\n",
       "    262,\n",
       "    13703,\n",
       "    82,\n",
       "    13,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4096016089121501,\n",
       "   'compression_ratio': 1.6,\n",
       "   'no_speech_prob': 0.24505464732646942},\n",
       "  {'id': 744,\n",
       "   'seek': 283486,\n",
       "   'start': 2846.86,\n",
       "   'end': 2847.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50963, 6498, 30, 51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4096016089121501,\n",
       "   'compression_ratio': 1.6,\n",
       "   'no_speech_prob': 0.24505464732646942},\n",
       "  {'id': 745,\n",
       "   'seek': 283486,\n",
       "   'start': 2847.86,\n",
       "   'end': 2856.86,\n",
       "   'text': ' Now, we come to another method called the recon, which is of fairly similar notion.',\n",
       "   'tokens': [51013,\n",
       "    2735,\n",
       "    11,\n",
       "    356,\n",
       "    1282,\n",
       "    284,\n",
       "    1194,\n",
       "    2446,\n",
       "    1444,\n",
       "    262,\n",
       "    8195,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    286,\n",
       "    6547,\n",
       "    2092,\n",
       "    9495,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4096016089121501,\n",
       "   'compression_ratio': 1.6,\n",
       "   'no_speech_prob': 0.24505464732646942},\n",
       "  {'id': 746,\n",
       "   'seek': 283486,\n",
       "   'start': 2856.86,\n",
       "   'end': 2858.86,\n",
       "   'text': ' Now, what is the word English?',\n",
       "   'tokens': [51463, 2735, 11, 644, 318, 262, 1573, 3594, 30, 51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4096016089121501,\n",
       "   'compression_ratio': 1.6,\n",
       "   'no_speech_prob': 0.24505464732646942},\n",
       "  {'id': 747,\n",
       "   'seek': 283486,\n",
       "   'start': 2858.86,\n",
       "   'end': 2860.86,\n",
       "   'text': ' What is the English word?',\n",
       "   'tokens': [51563, 1867, 318, 262, 3594, 1573, 30, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4096016089121501,\n",
       "   'compression_ratio': 1.6,\n",
       "   'no_speech_prob': 0.24505464732646942},\n",
       "  {'id': 748,\n",
       "   'seek': 286086,\n",
       "   'start': 2860.86,\n",
       "   'end': 2867.86,\n",
       "   'text': ' What does it mean that person X has a very good recall?',\n",
       "   'tokens': [50363,\n",
       "    1867,\n",
       "    857,\n",
       "    340,\n",
       "    1612,\n",
       "    326,\n",
       "    1048,\n",
       "    1395,\n",
       "    468,\n",
       "    257,\n",
       "    845,\n",
       "    922,\n",
       "    10014,\n",
       "    30,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4481509594207114,\n",
       "   'compression_ratio': 1.6744186046511629,\n",
       "   'no_speech_prob': 0.20495779812335968},\n",
       "  {'id': 749,\n",
       "   'seek': 286086,\n",
       "   'start': 2867.86,\n",
       "   'end': 2868.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50713, 6498, 30, 50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4481509594207114,\n",
       "   'compression_ratio': 1.6744186046511629,\n",
       "   'no_speech_prob': 0.20495779812335968},\n",
       "  {'id': 750,\n",
       "   'seek': 286086,\n",
       "   'start': 2868.86,\n",
       "   'end': 2869.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50763, 6498, 30, 50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4481509594207114,\n",
       "   'compression_ratio': 1.6744186046511629,\n",
       "   'no_speech_prob': 0.20495779812335968},\n",
       "  {'id': 751,\n",
       "   'seek': 286086,\n",
       "   'start': 2869.86,\n",
       "   'end': 2870.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50813, 6498, 30, 50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4481509594207114,\n",
       "   'compression_ratio': 1.6744186046511629,\n",
       "   'no_speech_prob': 0.20495779812335968},\n",
       "  {'id': 752,\n",
       "   'seek': 286086,\n",
       "   'start': 2870.86,\n",
       "   'end': 2871.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50863, 6498, 30, 50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4481509594207114,\n",
       "   'compression_ratio': 1.6744186046511629,\n",
       "   'no_speech_prob': 0.20495779812335968},\n",
       "  {'id': 753,\n",
       "   'seek': 286086,\n",
       "   'start': 2871.86,\n",
       "   'end': 2873.86,\n",
       "   'text': ' It is a good remember.',\n",
       "   'tokens': [50913, 632, 318, 257, 922, 3505, 13, 51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4481509594207114,\n",
       "   'compression_ratio': 1.6744186046511629,\n",
       "   'no_speech_prob': 0.20495779812335968},\n",
       "  {'id': 754,\n",
       "   'seek': 286086,\n",
       "   'start': 2873.86,\n",
       "   'end': 2874.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51013, 6498, 30, 51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4481509594207114,\n",
       "   'compression_ratio': 1.6744186046511629,\n",
       "   'no_speech_prob': 0.20495779812335968},\n",
       "  {'id': 755,\n",
       "   'seek': 286086,\n",
       "   'start': 2874.86,\n",
       "   'end': 2875.86,\n",
       "   'text': ' One thing on that mind.',\n",
       "   'tokens': [51063, 1881, 1517, 319, 326, 2000, 13, 51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4481509594207114,\n",
       "   'compression_ratio': 1.6744186046511629,\n",
       "   'no_speech_prob': 0.20495779812335968},\n",
       "  {'id': 756,\n",
       "   'seek': 286086,\n",
       "   'start': 2875.86,\n",
       "   'end': 2881.86,\n",
       "   'text': ' So, the definition of recall is how many times it was actually good?',\n",
       "   'tokens': [51113,\n",
       "    1406,\n",
       "    11,\n",
       "    262,\n",
       "    6770,\n",
       "    286,\n",
       "    10014,\n",
       "    318,\n",
       "    703,\n",
       "    867,\n",
       "    1661,\n",
       "    340,\n",
       "    373,\n",
       "    1682,\n",
       "    922,\n",
       "    30,\n",
       "    51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4481509594207114,\n",
       "   'compression_ratio': 1.6744186046511629,\n",
       "   'no_speech_prob': 0.20495779812335968},\n",
       "  {'id': 757,\n",
       "   'seek': 286086,\n",
       "   'start': 2881.86,\n",
       "   'end': 2886.86,\n",
       "   'text': ' How much of the, how much of that you were able to recall in a prediction?',\n",
       "   'tokens': [51413,\n",
       "    1374,\n",
       "    881,\n",
       "    286,\n",
       "    262,\n",
       "    11,\n",
       "    703,\n",
       "    881,\n",
       "    286,\n",
       "    326,\n",
       "    345,\n",
       "    547,\n",
       "    1498,\n",
       "    284,\n",
       "    10014,\n",
       "    287,\n",
       "    257,\n",
       "    17724,\n",
       "    30,\n",
       "    51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4481509594207114,\n",
       "   'compression_ratio': 1.6744186046511629,\n",
       "   'no_speech_prob': 0.20495779812335968},\n",
       "  {'id': 758,\n",
       "   'seek': 286086,\n",
       "   'start': 2886.86,\n",
       "   'end': 2887.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51663, 6498, 30, 51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4481509594207114,\n",
       "   'compression_ratio': 1.6744186046511629,\n",
       "   'no_speech_prob': 0.20495779812335968},\n",
       "  {'id': 759,\n",
       "   'seek': 288786,\n",
       "   'start': 2887.86,\n",
       "   'end': 2890.86,\n",
       "   'text': ' So, it was good, air, air and air.',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    11,\n",
       "    340,\n",
       "    373,\n",
       "    922,\n",
       "    11,\n",
       "    1633,\n",
       "    11,\n",
       "    1633,\n",
       "    290,\n",
       "    1633,\n",
       "    13,\n",
       "    50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3719232999361478,\n",
       "   'compression_ratio': 1.6926829268292682,\n",
       "   'no_speech_prob': 0.2440796047449112},\n",
       "  {'id': 760,\n",
       "   'seek': 288786,\n",
       "   'start': 2890.86,\n",
       "   'end': 2893.86,\n",
       "   'text': ' I have, you showed it to the apple.',\n",
       "   'tokens': [50513, 314, 423, 11, 345, 3751, 340, 284, 262, 17180, 13, 50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3719232999361478,\n",
       "   'compression_ratio': 1.6926829268292682,\n",
       "   'no_speech_prob': 0.2440796047449112},\n",
       "  {'id': 761,\n",
       "   'seek': 288786,\n",
       "   'start': 2893.86,\n",
       "   'end': 2897.86,\n",
       "   'text': ' We have been able to recall two of these three.',\n",
       "   'tokens': [50663,\n",
       "    775,\n",
       "    423,\n",
       "    587,\n",
       "    1498,\n",
       "    284,\n",
       "    10014,\n",
       "    734,\n",
       "    286,\n",
       "    777,\n",
       "    1115,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3719232999361478,\n",
       "   'compression_ratio': 1.6926829268292682,\n",
       "   'no_speech_prob': 0.2440796047449112},\n",
       "  {'id': 762,\n",
       "   'seek': 288786,\n",
       "   'start': 2897.86,\n",
       "   'end': 2901.86,\n",
       "   'text': ' So, three times the condition of the meter was good.',\n",
       "   'tokens': [50863,\n",
       "    1406,\n",
       "    11,\n",
       "    1115,\n",
       "    1661,\n",
       "    262,\n",
       "    4006,\n",
       "    286,\n",
       "    262,\n",
       "    16430,\n",
       "    373,\n",
       "    922,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3719232999361478,\n",
       "   'compression_ratio': 1.6926829268292682,\n",
       "   'no_speech_prob': 0.2440796047449112},\n",
       "  {'id': 763,\n",
       "   'seek': 288786,\n",
       "   'start': 2901.86,\n",
       "   'end': 2903.86,\n",
       "   'text': ' We have been able to recall two times.',\n",
       "   'tokens': [51063, 775, 423, 587, 1498, 284, 10014, 734, 1661, 13, 51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3719232999361478,\n",
       "   'compression_ratio': 1.6926829268292682,\n",
       "   'no_speech_prob': 0.2440796047449112},\n",
       "  {'id': 764,\n",
       "   'seek': 288786,\n",
       "   'start': 2903.86,\n",
       "   'end': 2906.86,\n",
       "   'text': \" That's the goal is to do with the system.\",\n",
       "   'tokens': [51163,\n",
       "    1320,\n",
       "    338,\n",
       "    262,\n",
       "    3061,\n",
       "    318,\n",
       "    284,\n",
       "    466,\n",
       "    351,\n",
       "    262,\n",
       "    1080,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3719232999361478,\n",
       "   'compression_ratio': 1.6926829268292682,\n",
       "   'no_speech_prob': 0.2440796047449112},\n",
       "  {'id': 765,\n",
       "   'seek': 288786,\n",
       "   'start': 2906.86,\n",
       "   'end': 2907.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51313, 6498, 30, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3719232999361478,\n",
       "   'compression_ratio': 1.6926829268292682,\n",
       "   'no_speech_prob': 0.2440796047449112},\n",
       "  {'id': 766,\n",
       "   'seek': 288786,\n",
       "   'start': 2907.86,\n",
       "   'end': 2910.86,\n",
       "   'text': ' We see the difference between precision and the clock.',\n",
       "   'tokens': [51363,\n",
       "    775,\n",
       "    766,\n",
       "    262,\n",
       "    3580,\n",
       "    1022,\n",
       "    15440,\n",
       "    290,\n",
       "    262,\n",
       "    8801,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3719232999361478,\n",
       "   'compression_ratio': 1.6926829268292682,\n",
       "   'no_speech_prob': 0.2440796047449112},\n",
       "  {'id': 767,\n",
       "   'seek': 288786,\n",
       "   'start': 2910.86,\n",
       "   'end': 2914.86,\n",
       "   'text': ' Everyone will be able to listen.',\n",
       "   'tokens': [51513, 11075, 481, 307, 1498, 284, 6004, 13, 51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3719232999361478,\n",
       "   'compression_ratio': 1.6926829268292682,\n",
       "   'no_speech_prob': 0.2440796047449112},\n",
       "  {'id': 768,\n",
       "   'seek': 291486,\n",
       "   'start': 2915.86,\n",
       "   'end': 2917.86,\n",
       "   'text': ' Apple again.',\n",
       "   'tokens': [50413, 4196, 757, 13, 50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14439957230179398,\n",
       "   'compression_ratio': 1.615,\n",
       "   'no_speech_prob': 0.24516305327415466},\n",
       "  {'id': 769,\n",
       "   'seek': 291486,\n",
       "   'start': 2917.86,\n",
       "   'end': 2921.86,\n",
       "   'text': ' We are trying to predict whether tissues cancerous or not.',\n",
       "   'tokens': [50513,\n",
       "    775,\n",
       "    389,\n",
       "    2111,\n",
       "    284,\n",
       "    4331,\n",
       "    1771,\n",
       "    21379,\n",
       "    4890,\n",
       "    516,\n",
       "    393,\n",
       "    407,\n",
       "    13,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14439957230179398,\n",
       "   'compression_ratio': 1.615,\n",
       "   'no_speech_prob': 0.24516305327415466},\n",
       "  {'id': 770,\n",
       "   'seek': 291486,\n",
       "   'start': 2921.86,\n",
       "   'end': 2933.86,\n",
       "   'text': ' In the ground truth, we see that we have 100 samples out of which only one of them has cancer, which is the last sample, which is shown over here.',\n",
       "   'tokens': [50713,\n",
       "    554,\n",
       "    262,\n",
       "    2323,\n",
       "    3872,\n",
       "    11,\n",
       "    356,\n",
       "    766,\n",
       "    326,\n",
       "    356,\n",
       "    423,\n",
       "    1802,\n",
       "    8405,\n",
       "    503,\n",
       "    286,\n",
       "    543,\n",
       "    691,\n",
       "    530,\n",
       "    286,\n",
       "    606,\n",
       "    468,\n",
       "    4890,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    262,\n",
       "    938,\n",
       "    6291,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    3402,\n",
       "    625,\n",
       "    994,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14439957230179398,\n",
       "   'compression_ratio': 1.615,\n",
       "   'no_speech_prob': 0.24516305327415466},\n",
       "  {'id': 771,\n",
       "   'seek': 291486,\n",
       "   'start': 2933.86,\n",
       "   'end': 2942.86,\n",
       "   'text': ' And when we are predicting, we predict 99 times that the person or the specific sample is not cancerous.',\n",
       "   'tokens': [51313,\n",
       "    843,\n",
       "    618,\n",
       "    356,\n",
       "    389,\n",
       "    25539,\n",
       "    11,\n",
       "    356,\n",
       "    4331,\n",
       "    7388,\n",
       "    1661,\n",
       "    326,\n",
       "    262,\n",
       "    1048,\n",
       "    393,\n",
       "    262,\n",
       "    2176,\n",
       "    6291,\n",
       "    318,\n",
       "    407,\n",
       "    4890,\n",
       "    516,\n",
       "    13,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14439957230179398,\n",
       "   'compression_ratio': 1.615,\n",
       "   'no_speech_prob': 0.24516305327415466},\n",
       "  {'id': 772,\n",
       "   'seek': 294286,\n",
       "   'start': 2942.86,\n",
       "   'end': 2946.86,\n",
       "   'text': ' And one time, this is the first sample we predicted to be cancerous.',\n",
       "   'tokens': [50363,\n",
       "    843,\n",
       "    530,\n",
       "    640,\n",
       "    11,\n",
       "    428,\n",
       "    318,\n",
       "    262,\n",
       "    717,\n",
       "    6291,\n",
       "    356,\n",
       "    11001,\n",
       "    284,\n",
       "    307,\n",
       "    4890,\n",
       "    516,\n",
       "    13,\n",
       "    50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.158450190226237,\n",
       "   'compression_ratio': 1.7280701754385965,\n",
       "   'no_speech_prob': 0.07744191586971283},\n",
       "  {'id': 773,\n",
       "   'seek': 294286,\n",
       "   'start': 2946.86,\n",
       "   'end': 2947.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50563, 6498, 30, 50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.158450190226237,\n",
       "   'compression_ratio': 1.7280701754385965,\n",
       "   'no_speech_prob': 0.07744191586971283},\n",
       "  {'id': 774,\n",
       "   'seek': 294286,\n",
       "   'start': 2947.86,\n",
       "   'end': 2953.86,\n",
       "   'text': \" So, now let's try and understand the precision and recall for this set of predictions.\",\n",
       "   'tokens': [50613,\n",
       "    1406,\n",
       "    11,\n",
       "    783,\n",
       "    1309,\n",
       "    338,\n",
       "    1949,\n",
       "    290,\n",
       "    1833,\n",
       "    262,\n",
       "    15440,\n",
       "    290,\n",
       "    10014,\n",
       "    329,\n",
       "    428,\n",
       "    900,\n",
       "    286,\n",
       "    16277,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.158450190226237,\n",
       "   'compression_ratio': 1.7280701754385965,\n",
       "   'no_speech_prob': 0.07744191586971283},\n",
       "  {'id': 775,\n",
       "   'seek': 294286,\n",
       "   'start': 2953.86,\n",
       "   'end': 2958.86,\n",
       "   'text': ' The accuracy of the system is fairly good.',\n",
       "   'tokens': [50913, 383, 9922, 286, 262, 1080, 318, 6547, 922, 13, 51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.158450190226237,\n",
       "   'compression_ratio': 1.7280701754385965,\n",
       "   'no_speech_prob': 0.07744191586971283},\n",
       "  {'id': 776,\n",
       "   'seek': 294286,\n",
       "   'start': 2958.86,\n",
       "   'end': 2962.86,\n",
       "   'text': ' Out of the total hundred times, we were accurate 98 times.',\n",
       "   'tokens': [51163,\n",
       "    3806,\n",
       "    286,\n",
       "    262,\n",
       "    2472,\n",
       "    3470,\n",
       "    1661,\n",
       "    11,\n",
       "    356,\n",
       "    547,\n",
       "    7187,\n",
       "    9661,\n",
       "    1661,\n",
       "    13,\n",
       "    51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.158450190226237,\n",
       "   'compression_ratio': 1.7280701754385965,\n",
       "   'no_speech_prob': 0.07744191586971283},\n",
       "  {'id': 777,\n",
       "   'seek': 294286,\n",
       "   'start': 2962.86,\n",
       "   'end': 2965.86,\n",
       "   'text': ' The only two times we are getting wrong is one.',\n",
       "   'tokens': [51363,\n",
       "    383,\n",
       "    691,\n",
       "    734,\n",
       "    1661,\n",
       "    356,\n",
       "    389,\n",
       "    1972,\n",
       "    2642,\n",
       "    318,\n",
       "    530,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.158450190226237,\n",
       "   'compression_ratio': 1.7280701754385965,\n",
       "   'no_speech_prob': 0.07744191586971283},\n",
       "  {'id': 778,\n",
       "   'seek': 294286,\n",
       "   'start': 2965.86,\n",
       "   'end': 2970.86,\n",
       "   'text': ' The time, for the first sample, when we are predicting it to be cancerous, viral.',\n",
       "   'tokens': [51513,\n",
       "    383,\n",
       "    640,\n",
       "    11,\n",
       "    329,\n",
       "    262,\n",
       "    717,\n",
       "    6291,\n",
       "    11,\n",
       "    618,\n",
       "    356,\n",
       "    389,\n",
       "    25539,\n",
       "    340,\n",
       "    284,\n",
       "    307,\n",
       "    4890,\n",
       "    516,\n",
       "    11,\n",
       "    14416,\n",
       "    13,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.158450190226237,\n",
       "   'compression_ratio': 1.7280701754385965,\n",
       "   'no_speech_prob': 0.07744191586971283},\n",
       "  {'id': 779,\n",
       "   'seek': 297086,\n",
       "   'start': 2970.86,\n",
       "   'end': 2972.86,\n",
       "   'text': ' In ground truth, it is not cancerous.',\n",
       "   'tokens': [50363, 554, 2323, 3872, 11, 340, 318, 407, 4890, 516, 13, 50463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10702289853777204,\n",
       "   'compression_ratio': 1.8584474885844748,\n",
       "   'no_speech_prob': 0.028210928663611412},\n",
       "  {'id': 780,\n",
       "   'seek': 297086,\n",
       "   'start': 2972.86,\n",
       "   'end': 2976.86,\n",
       "   'text': ' And the other time we are getting it wrong is when we are predicting it to be not cancerous.',\n",
       "   'tokens': [50463,\n",
       "    843,\n",
       "    262,\n",
       "    584,\n",
       "    640,\n",
       "    356,\n",
       "    389,\n",
       "    1972,\n",
       "    340,\n",
       "    2642,\n",
       "    318,\n",
       "    618,\n",
       "    356,\n",
       "    389,\n",
       "    25539,\n",
       "    340,\n",
       "    284,\n",
       "    307,\n",
       "    407,\n",
       "    4890,\n",
       "    516,\n",
       "    13,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10702289853777204,\n",
       "   'compression_ratio': 1.8584474885844748,\n",
       "   'no_speech_prob': 0.028210928663611412},\n",
       "  {'id': 781,\n",
       "   'seek': 297086,\n",
       "   'start': 2976.86,\n",
       "   'end': 2980.86,\n",
       "   'text': ' And the ground truth says it is cancerous, which is the last sample.',\n",
       "   'tokens': [50663,\n",
       "    843,\n",
       "    262,\n",
       "    2323,\n",
       "    3872,\n",
       "    1139,\n",
       "    340,\n",
       "    318,\n",
       "    4890,\n",
       "    516,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    262,\n",
       "    938,\n",
       "    6291,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10702289853777204,\n",
       "   'compression_ratio': 1.8584474885844748,\n",
       "   'no_speech_prob': 0.028210928663611412},\n",
       "  {'id': 782,\n",
       "   'seek': 297086,\n",
       "   'start': 2980.86,\n",
       "   'end': 2982.86,\n",
       "   'text': ' The accuracy is 98 times.',\n",
       "   'tokens': [50863, 383, 9922, 318, 9661, 1661, 13, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10702289853777204,\n",
       "   'compression_ratio': 1.8584474885844748,\n",
       "   'no_speech_prob': 0.028210928663611412},\n",
       "  {'id': 783,\n",
       "   'seek': 297086,\n",
       "   'start': 2982.86,\n",
       "   'end': 2984.86,\n",
       "   'text': \" You've correctly identified it over the hundred times.\",\n",
       "   'tokens': [50963,\n",
       "    921,\n",
       "    1053,\n",
       "    9380,\n",
       "    5174,\n",
       "    340,\n",
       "    625,\n",
       "    262,\n",
       "    3470,\n",
       "    1661,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10702289853777204,\n",
       "   'compression_ratio': 1.8584474885844748,\n",
       "   'no_speech_prob': 0.028210928663611412},\n",
       "  {'id': 784,\n",
       "   'seek': 297086,\n",
       "   'start': 2984.86,\n",
       "   'end': 2987.86,\n",
       "   'text': \" Now, let's look at the recall.\",\n",
       "   'tokens': [51063, 2735, 11, 1309, 338, 804, 379, 262, 10014, 13, 51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10702289853777204,\n",
       "   'compression_ratio': 1.8584474885844748,\n",
       "   'no_speech_prob': 0.028210928663611412},\n",
       "  {'id': 785,\n",
       "   'seek': 297086,\n",
       "   'start': 2987.86,\n",
       "   'end': 2993.86,\n",
       "   'text': ' Out of the times, the ground truth was true, which is the hundred sample.',\n",
       "   'tokens': [51213,\n",
       "    3806,\n",
       "    286,\n",
       "    262,\n",
       "    1661,\n",
       "    11,\n",
       "    262,\n",
       "    2323,\n",
       "    3872,\n",
       "    373,\n",
       "    2081,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    262,\n",
       "    3470,\n",
       "    6291,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10702289853777204,\n",
       "   'compression_ratio': 1.8584474885844748,\n",
       "   'no_speech_prob': 0.028210928663611412},\n",
       "  {'id': 786,\n",
       "   'seek': 297086,\n",
       "   'start': 2993.86,\n",
       "   'end': 2995.86,\n",
       "   'text': ' Only a single sample.',\n",
       "   'tokens': [51513, 5514, 257, 2060, 6291, 13, 51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10702289853777204,\n",
       "   'compression_ratio': 1.8584474885844748,\n",
       "   'no_speech_prob': 0.028210928663611412},\n",
       "  {'id': 787,\n",
       "   'seek': 299586,\n",
       "   'start': 2995.86,\n",
       "   'end': 3001.86,\n",
       "   'text': ' Do we predict it to be cancerous in our prediction system?',\n",
       "   'tokens': [50363,\n",
       "    2141,\n",
       "    356,\n",
       "    4331,\n",
       "    340,\n",
       "    284,\n",
       "    307,\n",
       "    4890,\n",
       "    516,\n",
       "    287,\n",
       "    674,\n",
       "    17724,\n",
       "    1080,\n",
       "    30,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10785090063036103,\n",
       "   'compression_ratio': 1.78125,\n",
       "   'no_speech_prob': 0.11367809772491455},\n",
       "  {'id': 788,\n",
       "   'seek': 299586,\n",
       "   'start': 3001.86,\n",
       "   'end': 3002.86,\n",
       "   'text': ' No.',\n",
       "   'tokens': [50663, 1400, 13, 50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10785090063036103,\n",
       "   'compression_ratio': 1.78125,\n",
       "   'no_speech_prob': 0.11367809772491455},\n",
       "  {'id': 789,\n",
       "   'seek': 299586,\n",
       "   'start': 3002.86,\n",
       "   'end': 3009.86,\n",
       "   'text': ' So, out of one time where it was actually cancerous, we are not able to recall that prediction correctly.',\n",
       "   'tokens': [50713,\n",
       "    1406,\n",
       "    11,\n",
       "    503,\n",
       "    286,\n",
       "    530,\n",
       "    640,\n",
       "    810,\n",
       "    340,\n",
       "    373,\n",
       "    1682,\n",
       "    4890,\n",
       "    516,\n",
       "    11,\n",
       "    356,\n",
       "    389,\n",
       "    407,\n",
       "    1498,\n",
       "    284,\n",
       "    10014,\n",
       "    326,\n",
       "    17724,\n",
       "    9380,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10785090063036103,\n",
       "   'compression_ratio': 1.78125,\n",
       "   'no_speech_prob': 0.11367809772491455},\n",
       "  {'id': 790,\n",
       "   'seek': 299586,\n",
       "   'start': 3009.86,\n",
       "   'end': 3012.86,\n",
       "   'text': ' Thus, the recall is 0 or 1, which is 0.',\n",
       "   'tokens': [51063,\n",
       "    6660,\n",
       "    11,\n",
       "    262,\n",
       "    10014,\n",
       "    318,\n",
       "    657,\n",
       "    393,\n",
       "    352,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    657,\n",
       "    13,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10785090063036103,\n",
       "   'compression_ratio': 1.78125,\n",
       "   'no_speech_prob': 0.11367809772491455},\n",
       "  {'id': 791,\n",
       "   'seek': 299586,\n",
       "   'start': 3012.86,\n",
       "   'end': 3015.86,\n",
       "   'text': \" Let's look at the precision now.\",\n",
       "   'tokens': [51213, 3914, 338, 804, 379, 262, 15440, 783, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10785090063036103,\n",
       "   'compression_ratio': 1.78125,\n",
       "   'no_speech_prob': 0.11367809772491455},\n",
       "  {'id': 792,\n",
       "   'seek': 299586,\n",
       "   'start': 3015.86,\n",
       "   'end': 3023.86,\n",
       "   'text': ' Out of the one time, which we are predicting, the tissue to be cancerous, was it actually cancerous?',\n",
       "   'tokens': [51363,\n",
       "    3806,\n",
       "    286,\n",
       "    262,\n",
       "    530,\n",
       "    640,\n",
       "    11,\n",
       "    543,\n",
       "    356,\n",
       "    389,\n",
       "    25539,\n",
       "    11,\n",
       "    262,\n",
       "    10712,\n",
       "    284,\n",
       "    307,\n",
       "    4890,\n",
       "    516,\n",
       "    11,\n",
       "    373,\n",
       "    340,\n",
       "    1682,\n",
       "    4890,\n",
       "    516,\n",
       "    30,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10785090063036103,\n",
       "   'compression_ratio': 1.78125,\n",
       "   'no_speech_prob': 0.11367809772491455},\n",
       "  {'id': 793,\n",
       "   'seek': 302386,\n",
       "   'start': 3023.86,\n",
       "   'end': 3024.86,\n",
       "   'text': ' No.',\n",
       "   'tokens': [50363, 1400, 13, 50413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.05829902795644907,\n",
       "   'compression_ratio': 1.8627450980392157,\n",
       "   'no_speech_prob': 0.10029488801956177},\n",
       "  {'id': 794,\n",
       "   'seek': 302386,\n",
       "   'start': 3024.86,\n",
       "   'end': 3025.86,\n",
       "   'text': ' In the ground truth, it was not cancerous.',\n",
       "   'tokens': [50413,\n",
       "    554,\n",
       "    262,\n",
       "    2323,\n",
       "    3872,\n",
       "    11,\n",
       "    340,\n",
       "    373,\n",
       "    407,\n",
       "    4890,\n",
       "    516,\n",
       "    13,\n",
       "    50463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.05829902795644907,\n",
       "   'compression_ratio': 1.8627450980392157,\n",
       "   'no_speech_prob': 0.10029488801956177},\n",
       "  {'id': 795,\n",
       "   'seek': 302386,\n",
       "   'start': 3025.86,\n",
       "   'end': 3029.86,\n",
       "   'text': ' Thus, the precision is 0 or 1, which is 0.',\n",
       "   'tokens': [50463,\n",
       "    6660,\n",
       "    11,\n",
       "    262,\n",
       "    15440,\n",
       "    318,\n",
       "    657,\n",
       "    393,\n",
       "    352,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    657,\n",
       "    13,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.05829902795644907,\n",
       "   'compression_ratio': 1.8627450980392157,\n",
       "   'no_speech_prob': 0.10029488801956177},\n",
       "  {'id': 796,\n",
       "   'seek': 302386,\n",
       "   'start': 3029.86,\n",
       "   'end': 3038.86,\n",
       "   'text': ' There is another way to look at the previous example, which is known as confusion matrix.',\n",
       "   'tokens': [50663,\n",
       "    1318,\n",
       "    318,\n",
       "    1194,\n",
       "    835,\n",
       "    284,\n",
       "    804,\n",
       "    379,\n",
       "    262,\n",
       "    2180,\n",
       "    1672,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    1900,\n",
       "    355,\n",
       "    10802,\n",
       "    17593,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.05829902795644907,\n",
       "   'compression_ratio': 1.8627450980392157,\n",
       "   'no_speech_prob': 0.10029488801956177},\n",
       "  {'id': 797,\n",
       "   'seek': 302386,\n",
       "   'start': 3038.86,\n",
       "   'end': 3041.86,\n",
       "   'text': ' We have four entries in this confusion matrix.',\n",
       "   'tokens': [51113, 775, 423, 1440, 12784, 287, 428, 10802, 17593, 13, 51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.05829902795644907,\n",
       "   'compression_ratio': 1.8627450980392157,\n",
       "   'no_speech_prob': 0.10029488801956177},\n",
       "  {'id': 798,\n",
       "   'seek': 302386,\n",
       "   'start': 3041.86,\n",
       "   'end': 3046.86,\n",
       "   'text': ' The ground truth could be either yes or no, which is cancerous or not cancerous.',\n",
       "   'tokens': [51263,\n",
       "    383,\n",
       "    2323,\n",
       "    3872,\n",
       "    714,\n",
       "    307,\n",
       "    2035,\n",
       "    3763,\n",
       "    393,\n",
       "    645,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    4890,\n",
       "    516,\n",
       "    393,\n",
       "    407,\n",
       "    4890,\n",
       "    516,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.05829902795644907,\n",
       "   'compression_ratio': 1.8627450980392157,\n",
       "   'no_speech_prob': 0.10029488801956177},\n",
       "  {'id': 799,\n",
       "   'seek': 302386,\n",
       "   'start': 3046.86,\n",
       "   'end': 3052.86,\n",
       "   'text': ' And similarly, we could predict to be either cancerous or not cancerous.',\n",
       "   'tokens': [51513,\n",
       "    843,\n",
       "    12470,\n",
       "    11,\n",
       "    356,\n",
       "    714,\n",
       "    4331,\n",
       "    284,\n",
       "    307,\n",
       "    2035,\n",
       "    4890,\n",
       "    516,\n",
       "    393,\n",
       "    407,\n",
       "    4890,\n",
       "    516,\n",
       "    13,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.05829902795644907,\n",
       "   'compression_ratio': 1.8627450980392157,\n",
       "   'no_speech_prob': 0.10029488801956177},\n",
       "  {'id': 800,\n",
       "   'seek': 305286,\n",
       "   'start': 3052.86,\n",
       "   'end': 3061.86,\n",
       "   'text': ' We saw previously that out of the 90, out of the hundred instances, 98 times when the',\n",
       "   'tokens': [50363,\n",
       "    775,\n",
       "    2497,\n",
       "    4271,\n",
       "    326,\n",
       "    503,\n",
       "    286,\n",
       "    262,\n",
       "    4101,\n",
       "    11,\n",
       "    503,\n",
       "    286,\n",
       "    262,\n",
       "    3470,\n",
       "    10245,\n",
       "    11,\n",
       "    9661,\n",
       "    1661,\n",
       "    618,\n",
       "    262,\n",
       "    50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10622745431879516,\n",
       "   'compression_ratio': 1.7524271844660195,\n",
       "   'no_speech_prob': 0.007757869549095631},\n",
       "  {'id': 801,\n",
       "   'seek': 305286,\n",
       "   'start': 3061.86,\n",
       "   'end': 3064.86,\n",
       "   'text': ' ground truth was not cancerous.',\n",
       "   'tokens': [50813, 2323, 3872, 373, 407, 4890, 516, 13, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10622745431879516,\n",
       "   'compression_ratio': 1.7524271844660195,\n",
       "   'no_speech_prob': 0.007757869549095631},\n",
       "  {'id': 802,\n",
       "   'seek': 305286,\n",
       "   'start': 3064.86,\n",
       "   'end': 3066.86,\n",
       "   'text': ' We were also able to predict it as not cancerous.',\n",
       "   'tokens': [50963,\n",
       "    775,\n",
       "    547,\n",
       "    635,\n",
       "    1498,\n",
       "    284,\n",
       "    4331,\n",
       "    340,\n",
       "    355,\n",
       "    407,\n",
       "    4890,\n",
       "    516,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10622745431879516,\n",
       "   'compression_ratio': 1.7524271844660195,\n",
       "   'no_speech_prob': 0.007757869549095631},\n",
       "  {'id': 803,\n",
       "   'seek': 305286,\n",
       "   'start': 3066.86,\n",
       "   'end': 3074.86,\n",
       "   'text': ' Thus, the entry corresponding to predicted equal to no and ground truth equal to no is 98.',\n",
       "   'tokens': [51063,\n",
       "    6660,\n",
       "    11,\n",
       "    262,\n",
       "    5726,\n",
       "    11188,\n",
       "    284,\n",
       "    11001,\n",
       "    4961,\n",
       "    284,\n",
       "    645,\n",
       "    290,\n",
       "    2323,\n",
       "    3872,\n",
       "    4961,\n",
       "    284,\n",
       "    645,\n",
       "    318,\n",
       "    9661,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10622745431879516,\n",
       "   'compression_ratio': 1.7524271844660195,\n",
       "   'no_speech_prob': 0.007757869549095631},\n",
       "  {'id': 804,\n",
       "   'seek': 305286,\n",
       "   'start': 3074.86,\n",
       "   'end': 3081.86,\n",
       "   'text': ' For one instance, if you look at the first sample, the prediction is yes, but the ground truth was no.',\n",
       "   'tokens': [51463,\n",
       "    1114,\n",
       "    530,\n",
       "    4554,\n",
       "    11,\n",
       "    611,\n",
       "    345,\n",
       "    804,\n",
       "    379,\n",
       "    262,\n",
       "    717,\n",
       "    6291,\n",
       "    11,\n",
       "    262,\n",
       "    17724,\n",
       "    318,\n",
       "    3763,\n",
       "    11,\n",
       "    475,\n",
       "    262,\n",
       "    2323,\n",
       "    3872,\n",
       "    373,\n",
       "    645,\n",
       "    13,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10622745431879516,\n",
       "   'compression_ratio': 1.7524271844660195,\n",
       "   'no_speech_prob': 0.007757869549095631},\n",
       "  {'id': 805,\n",
       "   'seek': 308186,\n",
       "   'start': 3081.86,\n",
       "   'end': 3088.86,\n",
       "   'text': ' So, the prediction is yes, the ground truth is no, which is the first row and the second column.',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    11,\n",
       "    262,\n",
       "    17724,\n",
       "    318,\n",
       "    3763,\n",
       "    11,\n",
       "    262,\n",
       "    2323,\n",
       "    3872,\n",
       "    318,\n",
       "    645,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    262,\n",
       "    717,\n",
       "    5752,\n",
       "    290,\n",
       "    262,\n",
       "    1218,\n",
       "    5721,\n",
       "    13,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10222222431596503,\n",
       "   'compression_ratio': 2.1946308724832213,\n",
       "   'no_speech_prob': 0.025587180629372597},\n",
       "  {'id': 806,\n",
       "   'seek': 308186,\n",
       "   'start': 3088.86,\n",
       "   'end': 3095.86,\n",
       "   'text': ' And then if we go back, we thought there was one sample where the ground truth was yes, but the prediction was no.',\n",
       "   'tokens': [50713,\n",
       "    843,\n",
       "    788,\n",
       "    611,\n",
       "    356,\n",
       "    467,\n",
       "    736,\n",
       "    11,\n",
       "    356,\n",
       "    1807,\n",
       "    612,\n",
       "    373,\n",
       "    530,\n",
       "    6291,\n",
       "    810,\n",
       "    262,\n",
       "    2323,\n",
       "    3872,\n",
       "    373,\n",
       "    3763,\n",
       "    11,\n",
       "    475,\n",
       "    262,\n",
       "    17724,\n",
       "    373,\n",
       "    645,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10222222431596503,\n",
       "   'compression_ratio': 2.1946308724832213,\n",
       "   'no_speech_prob': 0.025587180629372597},\n",
       "  {'id': 807,\n",
       "   'seek': 308186,\n",
       "   'start': 3095.86,\n",
       "   'end': 3102.86,\n",
       "   'text': ' So, one sample where the ground truth was yes, the prediction was no, which is the first column and the second row.',\n",
       "   'tokens': [51063,\n",
       "    1406,\n",
       "    11,\n",
       "    530,\n",
       "    6291,\n",
       "    810,\n",
       "    262,\n",
       "    2323,\n",
       "    3872,\n",
       "    373,\n",
       "    3763,\n",
       "    11,\n",
       "    262,\n",
       "    17724,\n",
       "    373,\n",
       "    645,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    262,\n",
       "    717,\n",
       "    5721,\n",
       "    290,\n",
       "    262,\n",
       "    1218,\n",
       "    5752,\n",
       "    13,\n",
       "    51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10222222431596503,\n",
       "   'compression_ratio': 2.1946308724832213,\n",
       "   'no_speech_prob': 0.025587180629372597},\n",
       "  {'id': 808,\n",
       "   'seek': 310286,\n",
       "   'start': 3103.86,\n",
       "   'end': 3111.86,\n",
       "   'text': ' Now, can you think about precision and recall in terms of these quantities or in terms of the confusion matrix?',\n",
       "   'tokens': [50413,\n",
       "    2735,\n",
       "    11,\n",
       "    460,\n",
       "    345,\n",
       "    892,\n",
       "    546,\n",
       "    15440,\n",
       "    290,\n",
       "    10014,\n",
       "    287,\n",
       "    2846,\n",
       "    286,\n",
       "    777,\n",
       "    17794,\n",
       "    393,\n",
       "    287,\n",
       "    2846,\n",
       "    286,\n",
       "    262,\n",
       "    10802,\n",
       "    17593,\n",
       "    30,\n",
       "    50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09142710660633288,\n",
       "   'compression_ratio': 1.7210526315789474,\n",
       "   'no_speech_prob': 0.08646957576274872},\n",
       "  {'id': 809,\n",
       "   'seek': 310286,\n",
       "   'start': 3111.86,\n",
       "   'end': 3117.86,\n",
       "   'text': ' But before we do that, let us make the confusion matrix more generalizable.',\n",
       "   'tokens': [50813,\n",
       "    887,\n",
       "    878,\n",
       "    356,\n",
       "    466,\n",
       "    326,\n",
       "    11,\n",
       "    1309,\n",
       "    514,\n",
       "    787,\n",
       "    262,\n",
       "    10802,\n",
       "    17593,\n",
       "    517,\n",
       "    2276,\n",
       "    13821,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09142710660633288,\n",
       "   'compression_ratio': 1.7210526315789474,\n",
       "   'no_speech_prob': 0.08646957576274872},\n",
       "  {'id': 810,\n",
       "   'seek': 310286,\n",
       "   'start': 3117.86,\n",
       "   'end': 3121.86,\n",
       "   'text': ' So, we now have four quantities.',\n",
       "   'tokens': [51113, 1406, 11, 356, 783, 423, 1440, 17794, 13, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09142710660633288,\n",
       "   'compression_ratio': 1.7210526315789474,\n",
       "   'no_speech_prob': 0.08646957576274872},\n",
       "  {'id': 811,\n",
       "   'seek': 310286,\n",
       "   'start': 3121.86,\n",
       "   'end': 3127.86,\n",
       "   'text': ' We have four numbers which are written as true positive, false positive, false negative and true negative.',\n",
       "   'tokens': [51313,\n",
       "    775,\n",
       "    423,\n",
       "    1440,\n",
       "    3146,\n",
       "    543,\n",
       "    389,\n",
       "    3194,\n",
       "    355,\n",
       "    2081,\n",
       "    3967,\n",
       "    11,\n",
       "    3991,\n",
       "    3967,\n",
       "    11,\n",
       "    3991,\n",
       "    4633,\n",
       "    290,\n",
       "    2081,\n",
       "    4633,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09142710660633288,\n",
       "   'compression_ratio': 1.7210526315789474,\n",
       "   'no_speech_prob': 0.08646957576274872},\n",
       "  {'id': 812,\n",
       "   'seek': 312786,\n",
       "   'start': 3127.86,\n",
       "   'end': 3132.86,\n",
       "   'text': ' Let us try and understand how do we remember these four names.',\n",
       "   'tokens': [50363,\n",
       "    3914,\n",
       "    514,\n",
       "    1949,\n",
       "    290,\n",
       "    1833,\n",
       "    703,\n",
       "    466,\n",
       "    356,\n",
       "    3505,\n",
       "    777,\n",
       "    1440,\n",
       "    3891,\n",
       "    13,\n",
       "    50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10999074796350991,\n",
       "   'compression_ratio': 1.907514450867052,\n",
       "   'no_speech_prob': 0.03987037017941475},\n",
       "  {'id': 813,\n",
       "   'seek': 312786,\n",
       "   'start': 3132.86,\n",
       "   'end': 3134.86,\n",
       "   'text': ' Let us look at the first true positive.',\n",
       "   'tokens': [50613, 3914, 514, 804, 379, 262, 717, 2081, 3967, 13, 50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10999074796350991,\n",
       "   'compression_ratio': 1.907514450867052,\n",
       "   'no_speech_prob': 0.03987037017941475},\n",
       "  {'id': 814,\n",
       "   'seek': 312786,\n",
       "   'start': 3134.86,\n",
       "   'end': 3141.86,\n",
       "   'text': ' The ground truth was positive and we are predicting it to be true, we are truly predicting it to be positive.',\n",
       "   'tokens': [50713,\n",
       "    383,\n",
       "    2323,\n",
       "    3872,\n",
       "    373,\n",
       "    3967,\n",
       "    290,\n",
       "    356,\n",
       "    389,\n",
       "    25539,\n",
       "    340,\n",
       "    284,\n",
       "    307,\n",
       "    2081,\n",
       "    11,\n",
       "    356,\n",
       "    389,\n",
       "    4988,\n",
       "    25539,\n",
       "    340,\n",
       "    284,\n",
       "    307,\n",
       "    3967,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10999074796350991,\n",
       "   'compression_ratio': 1.907514450867052,\n",
       "   'no_speech_prob': 0.03987037017941475},\n",
       "  {'id': 815,\n",
       "   'seek': 312786,\n",
       "   'start': 3141.86,\n",
       "   'end': 3145.86,\n",
       "   'text': ' Thus, it is truly predicted as positive, that is true positive.',\n",
       "   'tokens': [51063,\n",
       "    6660,\n",
       "    11,\n",
       "    340,\n",
       "    318,\n",
       "    4988,\n",
       "    11001,\n",
       "    355,\n",
       "    3967,\n",
       "    11,\n",
       "    326,\n",
       "    318,\n",
       "    2081,\n",
       "    3967,\n",
       "    13,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10999074796350991,\n",
       "   'compression_ratio': 1.907514450867052,\n",
       "   'no_speech_prob': 0.03987037017941475},\n",
       "  {'id': 816,\n",
       "   'seek': 312786,\n",
       "   'start': 3145.86,\n",
       "   'end': 3150.86,\n",
       "   'text': ' The first one in the second column is false positive.',\n",
       "   'tokens': [51263,\n",
       "    383,\n",
       "    717,\n",
       "    530,\n",
       "    287,\n",
       "    262,\n",
       "    1218,\n",
       "    5721,\n",
       "    318,\n",
       "    3991,\n",
       "    3967,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10999074796350991,\n",
       "   'compression_ratio': 1.907514450867052,\n",
       "   'no_speech_prob': 0.03987037017941475},\n",
       "  {'id': 817,\n",
       "   'seek': 315086,\n",
       "   'start': 3150.86,\n",
       "   'end': 3159.86,\n",
       "   'text': ' So, the ground truth was not positive, but we are falsely predicting it to be positive, thus false positive.',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    11,\n",
       "    262,\n",
       "    2323,\n",
       "    3872,\n",
       "    373,\n",
       "    407,\n",
       "    3967,\n",
       "    11,\n",
       "    475,\n",
       "    356,\n",
       "    389,\n",
       "    24566,\n",
       "    25539,\n",
       "    340,\n",
       "    284,\n",
       "    307,\n",
       "    3967,\n",
       "    11,\n",
       "    4145,\n",
       "    3991,\n",
       "    3967,\n",
       "    13,\n",
       "    50813],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.13403365255772381,\n",
       "   'compression_ratio': 2.3741935483870966,\n",
       "   'no_speech_prob': 0.11423098295927048},\n",
       "  {'id': 818,\n",
       "   'seek': 315086,\n",
       "   'start': 3159.86,\n",
       "   'end': 3162.86,\n",
       "   'text': ' The third element is false negative.',\n",
       "   'tokens': [50813, 383, 2368, 5002, 318, 3991, 4633, 13, 50963],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.13403365255772381,\n",
       "   'compression_ratio': 2.3741935483870966,\n",
       "   'no_speech_prob': 0.11423098295927048},\n",
       "  {'id': 819,\n",
       "   'seek': 315086,\n",
       "   'start': 3162.86,\n",
       "   'end': 3169.86,\n",
       "   'text': ' The ground truth was yes or positive, but we are falsely predicting it to be negative.',\n",
       "   'tokens': [50963,\n",
       "    383,\n",
       "    2323,\n",
       "    3872,\n",
       "    373,\n",
       "    3763,\n",
       "    393,\n",
       "    3967,\n",
       "    11,\n",
       "    475,\n",
       "    356,\n",
       "    389,\n",
       "    24566,\n",
       "    25539,\n",
       "    340,\n",
       "    284,\n",
       "    307,\n",
       "    4633,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.13403365255772381,\n",
       "   'compression_ratio': 2.3741935483870966,\n",
       "   'no_speech_prob': 0.11423098295927048},\n",
       "  {'id': 820,\n",
       "   'seek': 315086,\n",
       "   'start': 3169.86,\n",
       "   'end': 3177.86,\n",
       "   'text': ' So, it is a false negative and the last entry is a true negative, the ground truth was a negative and the prediction was also negative.',\n",
       "   'tokens': [51313,\n",
       "    1406,\n",
       "    11,\n",
       "    340,\n",
       "    318,\n",
       "    257,\n",
       "    3991,\n",
       "    4633,\n",
       "    290,\n",
       "    262,\n",
       "    938,\n",
       "    5726,\n",
       "    318,\n",
       "    257,\n",
       "    2081,\n",
       "    4633,\n",
       "    11,\n",
       "    262,\n",
       "    2323,\n",
       "    3872,\n",
       "    373,\n",
       "    257,\n",
       "    4633,\n",
       "    290,\n",
       "    262,\n",
       "    17724,\n",
       "    373,\n",
       "    635,\n",
       "    4633,\n",
       "    13,\n",
       "    51713],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.13403365255772381,\n",
       "   'compression_ratio': 2.3741935483870966,\n",
       "   'no_speech_prob': 0.11423098295927048},\n",
       "  {'id': 821,\n",
       "   'seek': 317786,\n",
       "   'start': 3177.86,\n",
       "   'end': 3182.86,\n",
       "   'text': ' So, we are truly predicting it to be negative.',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    11,\n",
       "    356,\n",
       "    389,\n",
       "    4988,\n",
       "    25539,\n",
       "    340,\n",
       "    284,\n",
       "    307,\n",
       "    4633,\n",
       "    13,\n",
       "    50613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1162100571852464,\n",
       "   'compression_ratio': 1.6482412060301508,\n",
       "   'no_speech_prob': 0.05405137315392494},\n",
       "  {'id': 822,\n",
       "   'seek': 317786,\n",
       "   'start': 3182.86,\n",
       "   'end': 3194.86,\n",
       "   'text': ' Now, let us come back to the definitions of recall and precision and try to write them in terms of the four quantities from the confusion matrix that we have just seen.',\n",
       "   'tokens': [50613,\n",
       "    2735,\n",
       "    11,\n",
       "    1309,\n",
       "    514,\n",
       "    1282,\n",
       "    736,\n",
       "    284,\n",
       "    262,\n",
       "    17336,\n",
       "    286,\n",
       "    10014,\n",
       "    290,\n",
       "    15440,\n",
       "    290,\n",
       "    1949,\n",
       "    284,\n",
       "    3551,\n",
       "    606,\n",
       "    287,\n",
       "    2846,\n",
       "    286,\n",
       "    262,\n",
       "    1440,\n",
       "    17794,\n",
       "    422,\n",
       "    262,\n",
       "    10802,\n",
       "    17593,\n",
       "    326,\n",
       "    356,\n",
       "    423,\n",
       "    655,\n",
       "    1775,\n",
       "    13,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1162100571852464,\n",
       "   'compression_ratio': 1.6482412060301508,\n",
       "   'no_speech_prob': 0.05405137315392494},\n",
       "  {'id': 823,\n",
       "   'seek': 317786,\n",
       "   'start': 3194.86,\n",
       "   'end': 3203.86,\n",
       "   'text': ' So, when we talk about precision, we spoke about how correct we are when we predict it to be the positive class.',\n",
       "   'tokens': [51213,\n",
       "    1406,\n",
       "    11,\n",
       "    618,\n",
       "    356,\n",
       "    1561,\n",
       "    546,\n",
       "    15440,\n",
       "    11,\n",
       "    356,\n",
       "    5158,\n",
       "    546,\n",
       "    703,\n",
       "    3376,\n",
       "    356,\n",
       "    389,\n",
       "    618,\n",
       "    356,\n",
       "    4331,\n",
       "    340,\n",
       "    284,\n",
       "    307,\n",
       "    262,\n",
       "    3967,\n",
       "    1398,\n",
       "    13,\n",
       "    51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1162100571852464,\n",
       "   'compression_ratio': 1.6482412060301508,\n",
       "   'no_speech_prob': 0.05405137315392494},\n",
       "  {'id': 824,\n",
       "   'seek': 320386,\n",
       "   'start': 3203.86,\n",
       "   'end': 3211.86,\n",
       "   'text': ' So, we say yes in this case, out of the total number of times we predicted it to yes, how accurate we were.',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    11,\n",
       "    356,\n",
       "    910,\n",
       "    3763,\n",
       "    287,\n",
       "    428,\n",
       "    1339,\n",
       "    11,\n",
       "    503,\n",
       "    286,\n",
       "    262,\n",
       "    2472,\n",
       "    1271,\n",
       "    286,\n",
       "    1661,\n",
       "    356,\n",
       "    11001,\n",
       "    340,\n",
       "    284,\n",
       "    3763,\n",
       "    11,\n",
       "    703,\n",
       "    7187,\n",
       "    356,\n",
       "    547,\n",
       "    13,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.16727912425994873,\n",
       "   'compression_ratio': 1.8985507246376812,\n",
       "   'no_speech_prob': 0.34880682826042175},\n",
       "  {'id': 825,\n",
       "   'seek': 320386,\n",
       "   'start': 3211.86,\n",
       "   'end': 3216.86,\n",
       "   'text': ' So, the first row corresponds to the total number of times we predicting it to yes.',\n",
       "   'tokens': [50763,\n",
       "    1406,\n",
       "    11,\n",
       "    262,\n",
       "    717,\n",
       "    5752,\n",
       "    24866,\n",
       "    284,\n",
       "    262,\n",
       "    2472,\n",
       "    1271,\n",
       "    286,\n",
       "    1661,\n",
       "    356,\n",
       "    25539,\n",
       "    340,\n",
       "    284,\n",
       "    3763,\n",
       "    13,\n",
       "    51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.16727912425994873,\n",
       "   'compression_ratio': 1.8985507246376812,\n",
       "   'no_speech_prob': 0.34880682826042175},\n",
       "  {'id': 826,\n",
       "   'seek': 320386,\n",
       "   'start': 3216.86,\n",
       "   'end': 3220.86,\n",
       "   'text': ' This becomes a denominator which is true positive plus false positive.',\n",
       "   'tokens': [51013,\n",
       "    770,\n",
       "    4329,\n",
       "    257,\n",
       "    31457,\n",
       "    1352,\n",
       "    543,\n",
       "    318,\n",
       "    2081,\n",
       "    3967,\n",
       "    5556,\n",
       "    3991,\n",
       "    3967,\n",
       "    13,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.16727912425994873,\n",
       "   'compression_ratio': 1.8985507246376812,\n",
       "   'no_speech_prob': 0.34880682826042175},\n",
       "  {'id': 827,\n",
       "   'seek': 320386,\n",
       "   'start': 3220.86,\n",
       "   'end': 3229.86,\n",
       "   'text': ' And the portion where we correct is the true positive, where we were predicting it to be positive or yes, when it is actually yes.',\n",
       "   'tokens': [51213,\n",
       "    843,\n",
       "    262,\n",
       "    6903,\n",
       "    810,\n",
       "    356,\n",
       "    3376,\n",
       "    318,\n",
       "    262,\n",
       "    2081,\n",
       "    3967,\n",
       "    11,\n",
       "    810,\n",
       "    356,\n",
       "    547,\n",
       "    25539,\n",
       "    340,\n",
       "    284,\n",
       "    307,\n",
       "    3967,\n",
       "    393,\n",
       "    3763,\n",
       "    11,\n",
       "    618,\n",
       "    340,\n",
       "    318,\n",
       "    1682,\n",
       "    3763,\n",
       "    13,\n",
       "    51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.16727912425994873,\n",
       "   'compression_ratio': 1.8985507246376812,\n",
       "   'no_speech_prob': 0.34880682826042175},\n",
       "  {'id': 828,\n",
       "   'seek': 322986,\n",
       "   'start': 3229.86,\n",
       "   'end': 3232.86,\n",
       "   'text': ' Thus, the numerator becomes true positive.',\n",
       "   'tokens': [50363, 6660, 11, 262, 5470, 1352, 4329, 2081, 3967, 13, 50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.07739903270334438,\n",
       "   'compression_ratio': 1.6529411764705881,\n",
       "   'no_speech_prob': 0.06200122460722923},\n",
       "  {'id': 829,\n",
       "   'seek': 322986,\n",
       "   'start': 3232.86,\n",
       "   'end': 3239.86,\n",
       "   'text': ' Thus, the precision is given by true positive over true positive plus false positive.',\n",
       "   'tokens': [50513,\n",
       "    6660,\n",
       "    11,\n",
       "    262,\n",
       "    15440,\n",
       "    318,\n",
       "    1813,\n",
       "    416,\n",
       "    2081,\n",
       "    3967,\n",
       "    625,\n",
       "    2081,\n",
       "    3967,\n",
       "    5556,\n",
       "    3991,\n",
       "    3967,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.07739903270334438,\n",
       "   'compression_ratio': 1.6529411764705881,\n",
       "   'no_speech_prob': 0.06200122460722923},\n",
       "  {'id': 830,\n",
       "   'seek': 322986,\n",
       "   'start': 3239.86,\n",
       "   'end': 3243.86,\n",
       "   'text': ' Similarly, let us think about recall.',\n",
       "   'tokens': [50863, 15298, 11, 1309, 514, 892, 546, 10014, 13, 51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.07739903270334438,\n",
       "   'compression_ratio': 1.6529411764705881,\n",
       "   'no_speech_prob': 0.06200122460722923},\n",
       "  {'id': 831,\n",
       "   'seek': 322986,\n",
       "   'start': 3243.86,\n",
       "   'end': 3253.86,\n",
       "   'text': ' For recall, we said that out of the instances which were true in the ground truth, how many are we able to recall.',\n",
       "   'tokens': [51063,\n",
       "    1114,\n",
       "    10014,\n",
       "    11,\n",
       "    356,\n",
       "    531,\n",
       "    326,\n",
       "    503,\n",
       "    286,\n",
       "    262,\n",
       "    10245,\n",
       "    543,\n",
       "    547,\n",
       "    2081,\n",
       "    287,\n",
       "    262,\n",
       "    2323,\n",
       "    3872,\n",
       "    11,\n",
       "    703,\n",
       "    867,\n",
       "    389,\n",
       "    356,\n",
       "    1498,\n",
       "    284,\n",
       "    10014,\n",
       "    13,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.07739903270334438,\n",
       "   'compression_ratio': 1.6529411764705881,\n",
       "   'no_speech_prob': 0.06200122460722923},\n",
       "  {'id': 832,\n",
       "   'seek': 325386,\n",
       "   'start': 3253.86,\n",
       "   'end': 3265.86,\n",
       "   'text': ' So, thus, the instances which were true in the ground truth becomes a denominator which is the first column of this matrix which corresponds to true positive plus false negative.',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    11,\n",
       "    4145,\n",
       "    11,\n",
       "    262,\n",
       "    10245,\n",
       "    543,\n",
       "    547,\n",
       "    2081,\n",
       "    287,\n",
       "    262,\n",
       "    2323,\n",
       "    3872,\n",
       "    4329,\n",
       "    257,\n",
       "    31457,\n",
       "    1352,\n",
       "    543,\n",
       "    318,\n",
       "    262,\n",
       "    717,\n",
       "    5721,\n",
       "    286,\n",
       "    428,\n",
       "    17593,\n",
       "    543,\n",
       "    24866,\n",
       "    284,\n",
       "    2081,\n",
       "    3967,\n",
       "    5556,\n",
       "    3991,\n",
       "    4633,\n",
       "    13,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.08857638322854344,\n",
       "   'compression_ratio': 1.9842105263157894,\n",
       "   'no_speech_prob': 0.11039761453866959},\n",
       "  {'id': 833,\n",
       "   'seek': 325386,\n",
       "   'start': 3265.86,\n",
       "   'end': 3273.86,\n",
       "   'text': ' And the fraction which is identified correctly is the true positive or what we are able to recall is the true positive.',\n",
       "   'tokens': [50963,\n",
       "    843,\n",
       "    262,\n",
       "    13390,\n",
       "    543,\n",
       "    318,\n",
       "    5174,\n",
       "    9380,\n",
       "    318,\n",
       "    262,\n",
       "    2081,\n",
       "    3967,\n",
       "    393,\n",
       "    644,\n",
       "    356,\n",
       "    389,\n",
       "    1498,\n",
       "    284,\n",
       "    10014,\n",
       "    318,\n",
       "    262,\n",
       "    2081,\n",
       "    3967,\n",
       "    13,\n",
       "    51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.08857638322854344,\n",
       "   'compression_ratio': 1.9842105263157894,\n",
       "   'no_speech_prob': 0.11039761453866959},\n",
       "  {'id': 834,\n",
       "   'seek': 325386,\n",
       "   'start': 3273.86,\n",
       "   'end': 3281.86,\n",
       "   'text': ' Thus, the recall becomes true positive over true positive plus false negative.',\n",
       "   'tokens': [51363,\n",
       "    6660,\n",
       "    11,\n",
       "    262,\n",
       "    10014,\n",
       "    4329,\n",
       "    2081,\n",
       "    3967,\n",
       "    625,\n",
       "    2081,\n",
       "    3967,\n",
       "    5556,\n",
       "    3991,\n",
       "    4633,\n",
       "    13,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.08857638322854344,\n",
       "   'compression_ratio': 1.9842105263157894,\n",
       "   'no_speech_prob': 0.11039761453866959},\n",
       "  {'id': 835,\n",
       "   'seek': 328186,\n",
       "   'start': 3281.86,\n",
       "   'end': 3288.86,\n",
       "   'text': ' We have another metric called the F score which combines the precision and recall in the following ways.',\n",
       "   'tokens': [50363,\n",
       "    775,\n",
       "    423,\n",
       "    1194,\n",
       "    18663,\n",
       "    1444,\n",
       "    262,\n",
       "    376,\n",
       "    4776,\n",
       "    543,\n",
       "    21001,\n",
       "    262,\n",
       "    15440,\n",
       "    290,\n",
       "    10014,\n",
       "    287,\n",
       "    262,\n",
       "    1708,\n",
       "    2842,\n",
       "    13,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14024219228260554,\n",
       "   'compression_ratio': 1.7197802197802199,\n",
       "   'no_speech_prob': 0.031014004722237587},\n",
       "  {'id': 836,\n",
       "   'seek': 328186,\n",
       "   'start': 3288.86,\n",
       "   'end': 3296.86,\n",
       "   'text': ' So, the definition is given by the formula is given by twice precision times recall divided by precision plus recall.',\n",
       "   'tokens': [50713,\n",
       "    1406,\n",
       "    11,\n",
       "    262,\n",
       "    6770,\n",
       "    318,\n",
       "    1813,\n",
       "    416,\n",
       "    262,\n",
       "    10451,\n",
       "    318,\n",
       "    1813,\n",
       "    416,\n",
       "    5403,\n",
       "    15440,\n",
       "    1661,\n",
       "    10014,\n",
       "    9086,\n",
       "    416,\n",
       "    15440,\n",
       "    5556,\n",
       "    10014,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14024219228260554,\n",
       "   'compression_ratio': 1.7197802197802199,\n",
       "   'no_speech_prob': 0.031014004722237587},\n",
       "  {'id': 837,\n",
       "   'seek': 328186,\n",
       "   'start': 3296.86,\n",
       "   'end': 3301.86,\n",
       "   'text': ' It is sometimes useful to give a single number instead of giving a precision and a recall.',\n",
       "   'tokens': [51113,\n",
       "    632,\n",
       "    318,\n",
       "    3360,\n",
       "    4465,\n",
       "    284,\n",
       "    1577,\n",
       "    257,\n",
       "    2060,\n",
       "    1271,\n",
       "    2427,\n",
       "    286,\n",
       "    3501,\n",
       "    257,\n",
       "    15440,\n",
       "    290,\n",
       "    257,\n",
       "    10014,\n",
       "    13,\n",
       "    51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14024219228260554,\n",
       "   'compression_ratio': 1.7197802197802199,\n",
       "   'no_speech_prob': 0.031014004722237587},\n",
       "  {'id': 838,\n",
       "   'seek': 330186,\n",
       "   'start': 3302.86,\n",
       "   'end': 3307.86,\n",
       "   'text': \" There is another interesting metric called Matthew's correlation coefficient.\",\n",
       "   'tokens': [50413,\n",
       "    1318,\n",
       "    318,\n",
       "    1194,\n",
       "    3499,\n",
       "    18663,\n",
       "    1444,\n",
       "    9308,\n",
       "    338,\n",
       "    16096,\n",
       "    35381,\n",
       "    13,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.11724775487726385,\n",
       "   'compression_ratio': 1.528205128205128,\n",
       "   'no_speech_prob': 0.052487149834632874},\n",
       "  {'id': 839,\n",
       "   'seek': 330186,\n",
       "   'start': 3307.86,\n",
       "   'end': 3312.86,\n",
       "   'text': ' The formula looks fairly complicated at this point of time if you see.',\n",
       "   'tokens': [50663,\n",
       "    383,\n",
       "    10451,\n",
       "    3073,\n",
       "    6547,\n",
       "    8253,\n",
       "    379,\n",
       "    428,\n",
       "    966,\n",
       "    286,\n",
       "    640,\n",
       "    611,\n",
       "    345,\n",
       "    766,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.11724775487726385,\n",
       "   'compression_ratio': 1.528205128205128,\n",
       "   'no_speech_prob': 0.052487149834632874},\n",
       "  {'id': 840,\n",
       "   'seek': 330186,\n",
       "   'start': 3312.86,\n",
       "   'end': 3318.86,\n",
       "   'text': ' But there is one particular reason why this coefficient is very useful.',\n",
       "   'tokens': [50913,\n",
       "    887,\n",
       "    612,\n",
       "    318,\n",
       "    530,\n",
       "    1948,\n",
       "    1738,\n",
       "    1521,\n",
       "    428,\n",
       "    35381,\n",
       "    318,\n",
       "    845,\n",
       "    4465,\n",
       "    13,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.11724775487726385,\n",
       "   'compression_ratio': 1.528205128205128,\n",
       "   'no_speech_prob': 0.052487149834632874},\n",
       "  {'id': 841,\n",
       "   'seek': 330186,\n",
       "   'start': 3318.86,\n",
       "   'end': 3324.86,\n",
       "   'text': ' And to see that specific reason, let us try to work out a simple example now.',\n",
       "   'tokens': [51213,\n",
       "    843,\n",
       "    284,\n",
       "    766,\n",
       "    326,\n",
       "    2176,\n",
       "    1738,\n",
       "    11,\n",
       "    1309,\n",
       "    514,\n",
       "    1949,\n",
       "    284,\n",
       "    670,\n",
       "    503,\n",
       "    257,\n",
       "    2829,\n",
       "    1672,\n",
       "    783,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.11724775487726385,\n",
       "   'compression_ratio': 1.528205128205128,\n",
       "   'no_speech_prob': 0.052487149834632874},\n",
       "  {'id': 842,\n",
       "   'seek': 332486,\n",
       "   'start': 3325.86,\n",
       "   'end': 3334.86,\n",
       "   'text': ' For the data that you have given below where the ground truth positive and predicted positive is the largest number 90.',\n",
       "   'tokens': [50413,\n",
       "    1114,\n",
       "    262,\n",
       "    1366,\n",
       "    326,\n",
       "    345,\n",
       "    423,\n",
       "    1813,\n",
       "    2174,\n",
       "    810,\n",
       "    262,\n",
       "    2323,\n",
       "    3872,\n",
       "    3967,\n",
       "    290,\n",
       "    11001,\n",
       "    3967,\n",
       "    318,\n",
       "    262,\n",
       "    4387,\n",
       "    1271,\n",
       "    4101,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.13991230328877766,\n",
       "   'compression_ratio': 1.5164835164835164,\n",
       "   'no_speech_prob': 0.07798037678003311},\n",
       "  {'id': 843,\n",
       "   'seek': 332486,\n",
       "   'start': 3334.86,\n",
       "   'end': 3339.86,\n",
       "   'text': ' And the other three entries are also in the field in the matrix and fusion matrix.',\n",
       "   'tokens': [50863,\n",
       "    843,\n",
       "    262,\n",
       "    584,\n",
       "    1115,\n",
       "    12784,\n",
       "    389,\n",
       "    635,\n",
       "    287,\n",
       "    262,\n",
       "    2214,\n",
       "    287,\n",
       "    262,\n",
       "    17593,\n",
       "    290,\n",
       "    21748,\n",
       "    17593,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.13991230328877766,\n",
       "   'compression_ratio': 1.5164835164835164,\n",
       "   'no_speech_prob': 0.07798037678003311},\n",
       "  {'id': 844,\n",
       "   'seek': 332486,\n",
       "   'start': 3339.86,\n",
       "   'end': 3343.86,\n",
       "   'text': \" Can you calculate the precision recall F score and Matthew's coefficient?\",\n",
       "   'tokens': [51113,\n",
       "    1680,\n",
       "    345,\n",
       "    15284,\n",
       "    262,\n",
       "    15440,\n",
       "    10014,\n",
       "    376,\n",
       "    4776,\n",
       "    290,\n",
       "    9308,\n",
       "    338,\n",
       "    35381,\n",
       "    30,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.13991230328877766,\n",
       "   'compression_ratio': 1.5164835164835164,\n",
       "   'no_speech_prob': 0.07798037678003311},\n",
       "  {'id': 845,\n",
       "   'seek': 334386,\n",
       "   'start': 3344.86,\n",
       "   'end': 3349.86,\n",
       "   'text': ' Okay, let us talk about precision for now.',\n",
       "   'tokens': [50413,\n",
       "    16805,\n",
       "    11,\n",
       "    1309,\n",
       "    514,\n",
       "    1561,\n",
       "    546,\n",
       "    15440,\n",
       "    329,\n",
       "    783,\n",
       "    13,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.15994813068803534,\n",
       "   'compression_ratio': 1.6328502415458936,\n",
       "   'no_speech_prob': 0.08298610150814056},\n",
       "  {'id': 846,\n",
       "   'seek': 334386,\n",
       "   'start': 3349.86,\n",
       "   'end': 3354.86,\n",
       "   'text': ' The precision is out of the times you are predicting it to be positive how correct you are.',\n",
       "   'tokens': [50663,\n",
       "    383,\n",
       "    15440,\n",
       "    318,\n",
       "    503,\n",
       "    286,\n",
       "    262,\n",
       "    1661,\n",
       "    345,\n",
       "    389,\n",
       "    25539,\n",
       "    340,\n",
       "    284,\n",
       "    307,\n",
       "    3967,\n",
       "    703,\n",
       "    3376,\n",
       "    345,\n",
       "    389,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.15994813068803534,\n",
       "   'compression_ratio': 1.6328502415458936,\n",
       "   'no_speech_prob': 0.08298610150814056},\n",
       "  {'id': 847,\n",
       "   'seek': 334386,\n",
       "   'start': 3354.86,\n",
       "   'end': 3360.86,\n",
       "   'text': ' For that we look at the row corresponding to predicted positive that becomes a denominator.',\n",
       "   'tokens': [50913,\n",
       "    1114,\n",
       "    326,\n",
       "    356,\n",
       "    804,\n",
       "    379,\n",
       "    262,\n",
       "    5752,\n",
       "    11188,\n",
       "    284,\n",
       "    11001,\n",
       "    3967,\n",
       "    326,\n",
       "    4329,\n",
       "    257,\n",
       "    31457,\n",
       "    1352,\n",
       "    13,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.15994813068803534,\n",
       "   'compression_ratio': 1.6328502415458936,\n",
       "   'no_speech_prob': 0.08298610150814056},\n",
       "  {'id': 848,\n",
       "   'seek': 334386,\n",
       "   'start': 3360.86,\n",
       "   'end': 3364.86,\n",
       "   'text': ' Thus the total entries are 90 plus 4 which is 94.',\n",
       "   'tokens': [51213,\n",
       "    6660,\n",
       "    262,\n",
       "    2472,\n",
       "    12784,\n",
       "    389,\n",
       "    4101,\n",
       "    5556,\n",
       "    604,\n",
       "    543,\n",
       "    318,\n",
       "    10048,\n",
       "    13,\n",
       "    51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.15994813068803534,\n",
       "   'compression_ratio': 1.6328502415458936,\n",
       "   'no_speech_prob': 0.08298610150814056},\n",
       "  {'id': 849,\n",
       "   'seek': 334386,\n",
       "   'start': 3364.86,\n",
       "   'end': 3368.86,\n",
       "   'text': ' And how many of them are we correctly identifying that is 90.',\n",
       "   'tokens': [51413,\n",
       "    843,\n",
       "    703,\n",
       "    867,\n",
       "    286,\n",
       "    606,\n",
       "    389,\n",
       "    356,\n",
       "    9380,\n",
       "    13720,\n",
       "    326,\n",
       "    318,\n",
       "    4101,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.15994813068803534,\n",
       "   'compression_ratio': 1.6328502415458936,\n",
       "   'no_speech_prob': 0.08298610150814056},\n",
       "  {'id': 850,\n",
       "   'seek': 336886,\n",
       "   'start': 3369.86,\n",
       "   'end': 3372.86,\n",
       "   'text': ' Thus precision becomes 90 over 94.',\n",
       "   'tokens': [50413, 6660, 15440, 4329, 4101, 625, 10048, 13, 50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.13769317626953126,\n",
       "   'compression_ratio': 1.5698324022346368,\n",
       "   'no_speech_prob': 0.08146023750305176},\n",
       "  {'id': 851,\n",
       "   'seek': 336886,\n",
       "   'start': 3374.86,\n",
       "   'end': 3383.86,\n",
       "   'text': ' Similarly, if you look for recall out of the entries which were positive in the ground truth that becomes a first column.',\n",
       "   'tokens': [50663,\n",
       "    15298,\n",
       "    11,\n",
       "    611,\n",
       "    345,\n",
       "    804,\n",
       "    329,\n",
       "    10014,\n",
       "    503,\n",
       "    286,\n",
       "    262,\n",
       "    12784,\n",
       "    543,\n",
       "    547,\n",
       "    3967,\n",
       "    287,\n",
       "    262,\n",
       "    2323,\n",
       "    3872,\n",
       "    326,\n",
       "    4329,\n",
       "    257,\n",
       "    717,\n",
       "    5721,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.13769317626953126,\n",
       "   'compression_ratio': 1.5698324022346368,\n",
       "   'no_speech_prob': 0.08146023750305176},\n",
       "  {'id': 852,\n",
       "   'seek': 336886,\n",
       "   'start': 3383.86,\n",
       "   'end': 3386.86,\n",
       "   'text': ' That is 90 plus 1 which is 91 entries.',\n",
       "   'tokens': [51113,\n",
       "    1320,\n",
       "    318,\n",
       "    4101,\n",
       "    5556,\n",
       "    352,\n",
       "    543,\n",
       "    318,\n",
       "    10495,\n",
       "    12784,\n",
       "    13,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.13769317626953126,\n",
       "   'compression_ratio': 1.5698324022346368,\n",
       "   'no_speech_prob': 0.08146023750305176},\n",
       "  {'id': 853,\n",
       "   'seek': 336886,\n",
       "   'start': 3386.86,\n",
       "   'end': 3388.86,\n",
       "   'text': ' How many are we able to recall correctly?',\n",
       "   'tokens': [51263, 1374, 867, 389, 356, 1498, 284, 10014, 9380, 30, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.13769317626953126,\n",
       "   'compression_ratio': 1.5698324022346368,\n",
       "   'no_speech_prob': 0.08146023750305176},\n",
       "  {'id': 854,\n",
       "   'seek': 336886,\n",
       "   'start': 3388.86,\n",
       "   'end': 3390.86,\n",
       "   'text': ' That is 90.',\n",
       "   'tokens': [51363, 1320, 318, 4101, 13, 51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.13769317626953126,\n",
       "   'compression_ratio': 1.5698324022346368,\n",
       "   'no_speech_prob': 0.08146023750305176},\n",
       "  {'id': 855,\n",
       "   'seek': 336886,\n",
       "   'start': 3390.86,\n",
       "   'end': 3393.86,\n",
       "   'text': ' Thus recall becomes 90 over 91.',\n",
       "   'tokens': [51463, 6660, 10014, 4329, 4101, 625, 10495, 13, 51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.13769317626953126,\n",
       "   'compression_ratio': 1.5698324022346368,\n",
       "   'no_speech_prob': 0.08146023750305176},\n",
       "  {'id': 856,\n",
       "   'seek': 339386,\n",
       "   'start': 3394.86,\n",
       "   'end': 3400.86,\n",
       "   'text': ' And we can calculate the F score by twice precision times recall divided by precision plus recall.',\n",
       "   'tokens': [50413,\n",
       "    843,\n",
       "    356,\n",
       "    460,\n",
       "    15284,\n",
       "    262,\n",
       "    376,\n",
       "    4776,\n",
       "    416,\n",
       "    5403,\n",
       "    15440,\n",
       "    1661,\n",
       "    10014,\n",
       "    9086,\n",
       "    416,\n",
       "    15440,\n",
       "    5556,\n",
       "    10014,\n",
       "    13,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.13716328281095658,\n",
       "   'compression_ratio': 1.6893617021276597,\n",
       "   'no_speech_prob': 0.06337115913629532},\n",
       "  {'id': 857,\n",
       "   'seek': 339386,\n",
       "   'start': 3400.86,\n",
       "   'end': 3407.86,\n",
       "   'text': ' Now all of these numbers are giving an indication that we have done a very good job by identification or prediction.',\n",
       "   'tokens': [50713,\n",
       "    2735,\n",
       "    477,\n",
       "    286,\n",
       "    777,\n",
       "    3146,\n",
       "    389,\n",
       "    3501,\n",
       "    281,\n",
       "    12955,\n",
       "    326,\n",
       "    356,\n",
       "    423,\n",
       "    1760,\n",
       "    257,\n",
       "    845,\n",
       "    922,\n",
       "    1693,\n",
       "    416,\n",
       "    11795,\n",
       "    393,\n",
       "    17724,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.13716328281095658,\n",
       "   'compression_ratio': 1.6893617021276597,\n",
       "   'no_speech_prob': 0.06337115913629532},\n",
       "  {'id': 858,\n",
       "   'seek': 339386,\n",
       "   'start': 3407.86,\n",
       "   'end': 3410.86,\n",
       "   'text': ' But does this seem to be a problem?',\n",
       "   'tokens': [51063, 887, 857, 428, 1283, 284, 307, 257, 1917, 30, 51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.13716328281095658,\n",
       "   'compression_ratio': 1.6893617021276597,\n",
       "   'no_speech_prob': 0.06337115913629532},\n",
       "  {'id': 859,\n",
       "   'seek': 339386,\n",
       "   'start': 3412.86,\n",
       "   'end': 3422.86,\n",
       "   'text': ' Yes, so the problem is that this was a very very easy problem for classification because most of the instances were positive in the ground truth.',\n",
       "   'tokens': [51313,\n",
       "    3363,\n",
       "    11,\n",
       "    523,\n",
       "    262,\n",
       "    1917,\n",
       "    318,\n",
       "    326,\n",
       "    428,\n",
       "    373,\n",
       "    257,\n",
       "    845,\n",
       "    845,\n",
       "    2562,\n",
       "    1917,\n",
       "    329,\n",
       "    17923,\n",
       "    780,\n",
       "    749,\n",
       "    286,\n",
       "    262,\n",
       "    10245,\n",
       "    547,\n",
       "    3967,\n",
       "    287,\n",
       "    262,\n",
       "    2323,\n",
       "    3872,\n",
       "    13,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.13716328281095658,\n",
       "   'compression_ratio': 1.6893617021276597,\n",
       "   'no_speech_prob': 0.06337115913629532},\n",
       "  {'id': 860,\n",
       "   'seek': 342286,\n",
       "   'start': 3423.86,\n",
       "   'end': 3430.86,\n",
       "   'text': ' So if you predicted everything to be positive you will have a fairly high precision and recall and accuracy and F score.',\n",
       "   'tokens': [50413,\n",
       "    1406,\n",
       "    611,\n",
       "    345,\n",
       "    11001,\n",
       "    2279,\n",
       "    284,\n",
       "    307,\n",
       "    3967,\n",
       "    345,\n",
       "    481,\n",
       "    423,\n",
       "    257,\n",
       "    6547,\n",
       "    1029,\n",
       "    15440,\n",
       "    290,\n",
       "    10014,\n",
       "    290,\n",
       "    9922,\n",
       "    290,\n",
       "    376,\n",
       "    4776,\n",
       "    13,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1407561759426169,\n",
       "   'compression_ratio': 1.5740740740740742,\n",
       "   'no_speech_prob': 0.009578376077115536},\n",
       "  {'id': 861,\n",
       "   'seek': 342286,\n",
       "   'start': 3430.86,\n",
       "   'end': 3434.86,\n",
       "   'text': \" But the Matthew's coefficient comes out to be fairly low.\",\n",
       "   'tokens': [50763,\n",
       "    887,\n",
       "    262,\n",
       "    9308,\n",
       "    338,\n",
       "    35381,\n",
       "    2058,\n",
       "    503,\n",
       "    284,\n",
       "    307,\n",
       "    6547,\n",
       "    1877,\n",
       "    13,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1407561759426169,\n",
       "   'compression_ratio': 1.5740740740740742,\n",
       "   'no_speech_prob': 0.009578376077115536},\n",
       "  {'id': 862,\n",
       "   'seek': 342286,\n",
       "   'start': 3434.86,\n",
       "   'end': 3444.86,\n",
       "   'text': ' What this is telling us is that you are not doing a substantially good job identifying or predicting in such a case because the problem itself was fairly simple.',\n",
       "   'tokens': [50963,\n",
       "    1867,\n",
       "    428,\n",
       "    318,\n",
       "    5149,\n",
       "    514,\n",
       "    318,\n",
       "    326,\n",
       "    345,\n",
       "    389,\n",
       "    407,\n",
       "    1804,\n",
       "    257,\n",
       "    13788,\n",
       "    922,\n",
       "    1693,\n",
       "    13720,\n",
       "    393,\n",
       "    25539,\n",
       "    287,\n",
       "    884,\n",
       "    257,\n",
       "    1339,\n",
       "    780,\n",
       "    262,\n",
       "    1917,\n",
       "    2346,\n",
       "    373,\n",
       "    6547,\n",
       "    2829,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1407561759426169,\n",
       "   'compression_ratio': 1.5740740740740742,\n",
       "   'no_speech_prob': 0.009578376077115536},\n",
       "  {'id': 863,\n",
       "   'seek': 344486,\n",
       "   'start': 3444.86,\n",
       "   'end': 3459.86,\n",
       "   'text': ' So this is where we need to take all the metrics and all the results with the salt of grain because it is important to look at how easy or difficult it was when you could have predicted the most occurring class.',\n",
       "   'tokens': [50363,\n",
       "    1406,\n",
       "    428,\n",
       "    318,\n",
       "    810,\n",
       "    356,\n",
       "    761,\n",
       "    284,\n",
       "    1011,\n",
       "    477,\n",
       "    262,\n",
       "    20731,\n",
       "    290,\n",
       "    477,\n",
       "    262,\n",
       "    2482,\n",
       "    351,\n",
       "    262,\n",
       "    8268,\n",
       "    286,\n",
       "    13020,\n",
       "    780,\n",
       "    340,\n",
       "    318,\n",
       "    1593,\n",
       "    284,\n",
       "    804,\n",
       "    379,\n",
       "    703,\n",
       "    2562,\n",
       "    393,\n",
       "    2408,\n",
       "    340,\n",
       "    373,\n",
       "    618,\n",
       "    345,\n",
       "    714,\n",
       "    423,\n",
       "    11001,\n",
       "    262,\n",
       "    749,\n",
       "    14963,\n",
       "    1398,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.16267418354115587,\n",
       "   'compression_ratio': 1.4551724137931035,\n",
       "   'no_speech_prob': 0.11197616159915924},\n",
       "  {'id': 864,\n",
       "   'seek': 345986,\n",
       "   'start': 3460.86,\n",
       "   'end': 3467.86,\n",
       "   'text': ' I, ground truth, has a vector of grain number and the prediction will also be a vector of grain number.',\n",
       "   'tokens': [50413,\n",
       "    314,\n",
       "    11,\n",
       "    2323,\n",
       "    3872,\n",
       "    11,\n",
       "    468,\n",
       "    257,\n",
       "    15879,\n",
       "    286,\n",
       "    13020,\n",
       "    1271,\n",
       "    290,\n",
       "    262,\n",
       "    17724,\n",
       "    481,\n",
       "    635,\n",
       "    307,\n",
       "    257,\n",
       "    15879,\n",
       "    286,\n",
       "    13020,\n",
       "    1271,\n",
       "    13,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5161785670689174,\n",
       "   'compression_ratio': 1.6198830409356726,\n",
       "   'no_speech_prob': 0.6234908699989319},\n",
       "  {'id': 865,\n",
       "   'seek': 345986,\n",
       "   'start': 3467.86,\n",
       "   'end': 3468.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50763, 6498, 30, 50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5161785670689174,\n",
       "   'compression_ratio': 1.6198830409356726,\n",
       "   'no_speech_prob': 0.6234908699989319},\n",
       "  {'id': 866,\n",
       "   'seek': 345986,\n",
       "   'start': 3468.86,\n",
       "   'end': 3472.86,\n",
       "   'text': ' We first met with a look at the mean squared error.',\n",
       "   'tokens': [50813,\n",
       "    775,\n",
       "    717,\n",
       "    1138,\n",
       "    351,\n",
       "    257,\n",
       "    804,\n",
       "    379,\n",
       "    262,\n",
       "    1612,\n",
       "    44345,\n",
       "    4049,\n",
       "    13,\n",
       "    51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5161785670689174,\n",
       "   'compression_ratio': 1.6198830409356726,\n",
       "   'no_speech_prob': 0.6234908699989319},\n",
       "  {'id': 867,\n",
       "   'seek': 345986,\n",
       "   'start': 3472.86,\n",
       "   'end': 3478.86,\n",
       "   'text': ' The way to remember this is to compose the three terms mean squared error and then the good and the reverse value.',\n",
       "   'tokens': [51013,\n",
       "    383,\n",
       "    835,\n",
       "    284,\n",
       "    3505,\n",
       "    428,\n",
       "    318,\n",
       "    284,\n",
       "    36664,\n",
       "    262,\n",
       "    1115,\n",
       "    2846,\n",
       "    1612,\n",
       "    44345,\n",
       "    4049,\n",
       "    290,\n",
       "    788,\n",
       "    262,\n",
       "    922,\n",
       "    290,\n",
       "    262,\n",
       "    9575,\n",
       "    1988,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5161785670689174,\n",
       "   'compression_ratio': 1.6198830409356726,\n",
       "   'no_speech_prob': 0.6234908699989319},\n",
       "  {'id': 868,\n",
       "   'seek': 347886,\n",
       "   'start': 3479.86,\n",
       "   'end': 3486.86,\n",
       "   'text': ' You first compute the error which is y i hat minus y i. Right?',\n",
       "   'tokens': [50413,\n",
       "    921,\n",
       "    717,\n",
       "    24061,\n",
       "    262,\n",
       "    4049,\n",
       "    543,\n",
       "    318,\n",
       "    331,\n",
       "    1312,\n",
       "    6877,\n",
       "    20208,\n",
       "    331,\n",
       "    1312,\n",
       "    13,\n",
       "    6498,\n",
       "    30,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5336177907091506,\n",
       "   'compression_ratio': 1.3700787401574803,\n",
       "   'no_speech_prob': 0.3702652156352997},\n",
       "  {'id': 869,\n",
       "   'seek': 347886,\n",
       "   'start': 3486.86,\n",
       "   'end': 3489.86,\n",
       "   'text': ' Predicted minus ground for the i-e example.',\n",
       "   'tokens': [50763,\n",
       "    14322,\n",
       "    5722,\n",
       "    20208,\n",
       "    2323,\n",
       "    329,\n",
       "    262,\n",
       "    1312,\n",
       "    12,\n",
       "    68,\n",
       "    1672,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5336177907091506,\n",
       "   'compression_ratio': 1.3700787401574803,\n",
       "   'no_speech_prob': 0.3702652156352997},\n",
       "  {'id': 870,\n",
       "   'seek': 347886,\n",
       "   'start': 3489.86,\n",
       "   'end': 3494.86,\n",
       "   'text': ' You have computed the error and also shown the corresponding error.',\n",
       "   'tokens': [50913,\n",
       "    921,\n",
       "    423,\n",
       "    29231,\n",
       "    262,\n",
       "    4049,\n",
       "    290,\n",
       "    635,\n",
       "    3402,\n",
       "    262,\n",
       "    11188,\n",
       "    4049,\n",
       "    13,\n",
       "    51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5336177907091506,\n",
       "   'compression_ratio': 1.3700787401574803,\n",
       "   'no_speech_prob': 0.3702652156352997},\n",
       "  {'id': 871,\n",
       "   'seek': 349486,\n",
       "   'start': 3494.86,\n",
       "   'end': 3502.86,\n",
       "   'text': ' And see the different colors now.',\n",
       "   'tokens': [50363, 843, 766, 262, 1180, 7577, 783, 13, 50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32790097882670743,\n",
       "   'compression_ratio': 1.740506329113924,\n",
       "   'no_speech_prob': 0.6218307614326477},\n",
       "  {'id': 872,\n",
       "   'seek': 349486,\n",
       "   'start': 3502.86,\n",
       "   'end': 3508.86,\n",
       "   'text': ' So y i minus y, y i minus y i is the error term.',\n",
       "   'tokens': [50763,\n",
       "    1406,\n",
       "    331,\n",
       "    1312,\n",
       "    20208,\n",
       "    331,\n",
       "    11,\n",
       "    331,\n",
       "    1312,\n",
       "    20208,\n",
       "    331,\n",
       "    1312,\n",
       "    318,\n",
       "    262,\n",
       "    4049,\n",
       "    3381,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32790097882670743,\n",
       "   'compression_ratio': 1.740506329113924,\n",
       "   'no_speech_prob': 0.6218307614326477},\n",
       "  {'id': 873,\n",
       "   'seek': 349486,\n",
       "   'start': 3508.86,\n",
       "   'end': 3510.86,\n",
       "   'text': ' Then you have a squared term.',\n",
       "   'tokens': [51063, 3244, 345, 423, 257, 44345, 3381, 13, 51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32790097882670743,\n",
       "   'compression_ratio': 1.740506329113924,\n",
       "   'no_speech_prob': 0.6218307614326477},\n",
       "  {'id': 874,\n",
       "   'seek': 349486,\n",
       "   'start': 3510.86,\n",
       "   'end': 3513.86,\n",
       "   'text': ' So y i minus y i hat minus y i.',\n",
       "   'tokens': [51163,\n",
       "    1406,\n",
       "    331,\n",
       "    1312,\n",
       "    20208,\n",
       "    331,\n",
       "    1312,\n",
       "    6877,\n",
       "    20208,\n",
       "    331,\n",
       "    1312,\n",
       "    13,\n",
       "    51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32790097882670743,\n",
       "   'compression_ratio': 1.740506329113924,\n",
       "   'no_speech_prob': 0.6218307614326477},\n",
       "  {'id': 875,\n",
       "   'seek': 349486,\n",
       "   'start': 3513.86,\n",
       "   'end': 3515.86,\n",
       "   'text': ' For example, you squared the error.',\n",
       "   'tokens': [51313, 1114, 1672, 11, 345, 44345, 262, 4049, 13, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32790097882670743,\n",
       "   'compression_ratio': 1.740506329113924,\n",
       "   'no_speech_prob': 0.6218307614326477},\n",
       "  {'id': 876,\n",
       "   'seek': 349486,\n",
       "   'start': 3515.86,\n",
       "   'end': 3516.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51413, 6498, 30, 51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32790097882670743,\n",
       "   'compression_ratio': 1.740506329113924,\n",
       "   'no_speech_prob': 0.6218307614326477},\n",
       "  {'id': 877,\n",
       "   'seek': 349486,\n",
       "   'start': 3516.86,\n",
       "   'end': 3518.86,\n",
       "   'text': ' And then you find it is the mean over it.',\n",
       "   'tokens': [51463,\n",
       "    843,\n",
       "    788,\n",
       "    345,\n",
       "    1064,\n",
       "    340,\n",
       "    318,\n",
       "    262,\n",
       "    1612,\n",
       "    625,\n",
       "    340,\n",
       "    13,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32790097882670743,\n",
       "   'compression_ratio': 1.740506329113924,\n",
       "   'no_speech_prob': 0.6218307614326477},\n",
       "  {'id': 878,\n",
       "   'seek': 349486,\n",
       "   'start': 3518.86,\n",
       "   'end': 3520.86,\n",
       "   'text': ' Which is the mean over the end sample.',\n",
       "   'tokens': [51563, 9022, 318, 262, 1612, 625, 262, 886, 6291, 13, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32790097882670743,\n",
       "   'compression_ratio': 1.740506329113924,\n",
       "   'no_speech_prob': 0.6218307614326477},\n",
       "  {'id': 879,\n",
       "   'seek': 349486,\n",
       "   'start': 3520.86,\n",
       "   'end': 3521.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51663, 6498, 30, 51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32790097882670743,\n",
       "   'compression_ratio': 1.740506329113924,\n",
       "   'no_speech_prob': 0.6218307614326477},\n",
       "  {'id': 880,\n",
       "   'seek': 352186,\n",
       "   'start': 3521.86,\n",
       "   'end': 3522.86,\n",
       "   'text': ' Means squared error.',\n",
       "   'tokens': [50363, 28453, 44345, 4049, 13, 50413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3860047016668757,\n",
       "   'compression_ratio': 1.7972350230414746,\n",
       "   'no_speech_prob': 0.26574739813804626},\n",
       "  {'id': 881,\n",
       "   'seek': 352186,\n",
       "   'start': 3522.86,\n",
       "   'end': 3525.86,\n",
       "   'text': ' First the error squared is 18 mean.',\n",
       "   'tokens': [50413, 3274, 262, 4049, 44345, 318, 1248, 1612, 13, 50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3860047016668757,\n",
       "   'compression_ratio': 1.7972350230414746,\n",
       "   'no_speech_prob': 0.26574739813804626},\n",
       "  {'id': 882,\n",
       "   'seek': 352186,\n",
       "   'start': 3525.86,\n",
       "   'end': 3530.86,\n",
       "   'text': ' And a term is generally then used in the root of the root means squared error.',\n",
       "   'tokens': [50563,\n",
       "    843,\n",
       "    257,\n",
       "    3381,\n",
       "    318,\n",
       "    4143,\n",
       "    788,\n",
       "    973,\n",
       "    287,\n",
       "    262,\n",
       "    6808,\n",
       "    286,\n",
       "    262,\n",
       "    6808,\n",
       "    1724,\n",
       "    44345,\n",
       "    4049,\n",
       "    13,\n",
       "    50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3860047016668757,\n",
       "   'compression_ratio': 1.7972350230414746,\n",
       "   'no_speech_prob': 0.26574739813804626},\n",
       "  {'id': 883,\n",
       "   'seek': 352186,\n",
       "   'start': 3530.86,\n",
       "   'end': 3533.86,\n",
       "   'text': ' Which is the root of the mean squared error.',\n",
       "   'tokens': [50813,\n",
       "    9022,\n",
       "    318,\n",
       "    262,\n",
       "    6808,\n",
       "    286,\n",
       "    262,\n",
       "    1612,\n",
       "    44345,\n",
       "    4049,\n",
       "    13,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3860047016668757,\n",
       "   'compression_ratio': 1.7972350230414746,\n",
       "   'no_speech_prob': 0.26574739813804626},\n",
       "  {'id': 884,\n",
       "   'seek': 352186,\n",
       "   'start': 3533.86,\n",
       "   'end': 3534.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [50963, 6498, 30, 51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3860047016668757,\n",
       "   'compression_ratio': 1.7972350230414746,\n",
       "   'no_speech_prob': 0.26574739813804626},\n",
       "  {'id': 885,\n",
       "   'seek': 352186,\n",
       "   'start': 3534.86,\n",
       "   'end': 3539.86,\n",
       "   'text': ' There are other many similar method called the mean absolute error.',\n",
       "   'tokens': [51013,\n",
       "    1318,\n",
       "    389,\n",
       "    584,\n",
       "    867,\n",
       "    2092,\n",
       "    2446,\n",
       "    1444,\n",
       "    262,\n",
       "    1612,\n",
       "    4112,\n",
       "    4049,\n",
       "    13,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3860047016668757,\n",
       "   'compression_ratio': 1.7972350230414746,\n",
       "   'no_speech_prob': 0.26574739813804626},\n",
       "  {'id': 886,\n",
       "   'seek': 352186,\n",
       "   'start': 3539.86,\n",
       "   'end': 3541.86,\n",
       "   'text': ' Again, it starts with the inside.',\n",
       "   'tokens': [51263, 6521, 11, 340, 4940, 351, 262, 2641, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3860047016668757,\n",
       "   'compression_ratio': 1.7972350230414746,\n",
       "   'no_speech_prob': 0.26574739813804626},\n",
       "  {'id': 887,\n",
       "   'seek': 352186,\n",
       "   'start': 3541.86,\n",
       "   'end': 3544.86,\n",
       "   'text': ' You first calculate the error y i hat and y i.',\n",
       "   'tokens': [51363,\n",
       "    921,\n",
       "    717,\n",
       "    15284,\n",
       "    262,\n",
       "    4049,\n",
       "    331,\n",
       "    1312,\n",
       "    6877,\n",
       "    290,\n",
       "    331,\n",
       "    1312,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3860047016668757,\n",
       "   'compression_ratio': 1.7972350230414746,\n",
       "   'no_speech_prob': 0.26574739813804626},\n",
       "  {'id': 888,\n",
       "   'seek': 352186,\n",
       "   'start': 3544.86,\n",
       "   'end': 3547.86,\n",
       "   'text': ' If the absolute value is a good, then they do.',\n",
       "   'tokens': [51513,\n",
       "    1002,\n",
       "    262,\n",
       "    4112,\n",
       "    1988,\n",
       "    318,\n",
       "    257,\n",
       "    922,\n",
       "    11,\n",
       "    788,\n",
       "    484,\n",
       "    466,\n",
       "    13,\n",
       "    51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3860047016668757,\n",
       "   'compression_ratio': 1.7972350230414746,\n",
       "   'no_speech_prob': 0.26574739813804626},\n",
       "  {'id': 889,\n",
       "   'seek': 352186,\n",
       "   'start': 3547.86,\n",
       "   'end': 3548.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51663, 6498, 30, 51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3860047016668757,\n",
       "   'compression_ratio': 1.7972350230414746,\n",
       "   'no_speech_prob': 0.26574739813804626},\n",
       "  {'id': 890,\n",
       "   'seek': 354886,\n",
       "   'start': 3548.86,\n",
       "   'end': 3551.86,\n",
       "   'text': ' We can also come with a method called the mean error.',\n",
       "   'tokens': [50363,\n",
       "    775,\n",
       "    460,\n",
       "    635,\n",
       "    1282,\n",
       "    351,\n",
       "    257,\n",
       "    2446,\n",
       "    1444,\n",
       "    262,\n",
       "    1612,\n",
       "    4049,\n",
       "    13,\n",
       "    50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47041314886521923,\n",
       "   'compression_ratio': 1.7272727272727273,\n",
       "   'no_speech_prob': 0.28200966119766235},\n",
       "  {'id': 891,\n",
       "   'seek': 354886,\n",
       "   'start': 3551.86,\n",
       "   'end': 3554.86,\n",
       "   'text': ' Which is first of the error and 18 mean.',\n",
       "   'tokens': [50513,\n",
       "    9022,\n",
       "    318,\n",
       "    717,\n",
       "    286,\n",
       "    262,\n",
       "    4049,\n",
       "    290,\n",
       "    1248,\n",
       "    1612,\n",
       "    13,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47041314886521923,\n",
       "   'compression_ratio': 1.7272727272727273,\n",
       "   'no_speech_prob': 0.28200966119766235},\n",
       "  {'id': 892,\n",
       "   'seek': 354886,\n",
       "   'start': 3554.86,\n",
       "   'end': 3556.86,\n",
       "   'text': ' Why is that a part right?',\n",
       "   'tokens': [50663, 4162, 318, 326, 257, 636, 826, 30, 50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47041314886521923,\n",
       "   'compression_ratio': 1.7272727272727273,\n",
       "   'no_speech_prob': 0.28200966119766235},\n",
       "  {'id': 893,\n",
       "   'seek': 354886,\n",
       "   'start': 3556.86,\n",
       "   'end': 3557.86,\n",
       "   'text': ' Use it as a metric.',\n",
       "   'tokens': [50763, 5765, 340, 355, 257, 18663, 13, 50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47041314886521923,\n",
       "   'compression_ratio': 1.7272727272727273,\n",
       "   'no_speech_prob': 0.28200966119766235},\n",
       "  {'id': 894,\n",
       "   'seek': 354886,\n",
       "   'start': 3557.86,\n",
       "   'end': 3559.86,\n",
       "   'text': ' Yeah, we can get the error.',\n",
       "   'tokens': [50813, 9425, 11, 356, 460, 651, 262, 4049, 13, 50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47041314886521923,\n",
       "   'compression_ratio': 1.7272727272727273,\n",
       "   'no_speech_prob': 0.28200966119766235},\n",
       "  {'id': 895,\n",
       "   'seek': 354886,\n",
       "   'start': 3559.86,\n",
       "   'end': 3560.86,\n",
       "   'text': ' Then we cancel each other out.',\n",
       "   'tokens': [50913, 3244, 356, 14241, 1123, 584, 503, 13, 50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47041314886521923,\n",
       "   'compression_ratio': 1.7272727272727273,\n",
       "   'no_speech_prob': 0.28200966119766235},\n",
       "  {'id': 896,\n",
       "   'seek': 354886,\n",
       "   'start': 3560.86,\n",
       "   'end': 3566.86,\n",
       "   'text': ' If you could have a prediction imagine the number of 0 0 0 0 0.',\n",
       "   'tokens': [50963,\n",
       "    1002,\n",
       "    345,\n",
       "    714,\n",
       "    423,\n",
       "    257,\n",
       "    17724,\n",
       "    5967,\n",
       "    262,\n",
       "    1271,\n",
       "    286,\n",
       "    657,\n",
       "    657,\n",
       "    657,\n",
       "    657,\n",
       "    657,\n",
       "    13,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47041314886521923,\n",
       "   'compression_ratio': 1.7272727272727273,\n",
       "   'no_speech_prob': 0.28200966119766235},\n",
       "  {'id': 897,\n",
       "   'seek': 354886,\n",
       "   'start': 3566.86,\n",
       "   'end': 3568.86,\n",
       "   'text': ' Or you have a code in terms of all 0.',\n",
       "   'tokens': [51263,\n",
       "    1471,\n",
       "    345,\n",
       "    423,\n",
       "    257,\n",
       "    2438,\n",
       "    287,\n",
       "    2846,\n",
       "    286,\n",
       "    477,\n",
       "    657,\n",
       "    13,\n",
       "    51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47041314886521923,\n",
       "   'compression_ratio': 1.7272727272727273,\n",
       "   'no_speech_prob': 0.28200966119766235},\n",
       "  {'id': 898,\n",
       "   'seek': 354886,\n",
       "   'start': 3568.86,\n",
       "   'end': 3571.86,\n",
       "   'text': ' And I have predicted as plus and minus and plus and minus.',\n",
       "   'tokens': [51363,\n",
       "    843,\n",
       "    314,\n",
       "    423,\n",
       "    11001,\n",
       "    355,\n",
       "    5556,\n",
       "    290,\n",
       "    20208,\n",
       "    290,\n",
       "    5556,\n",
       "    290,\n",
       "    20208,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47041314886521923,\n",
       "   'compression_ratio': 1.7272727272727273,\n",
       "   'no_speech_prob': 0.28200966119766235},\n",
       "  {'id': 899,\n",
       "   'seek': 354886,\n",
       "   'start': 3571.86,\n",
       "   'end': 3573.86,\n",
       "   'text': ' What is the mean error in the space?',\n",
       "   'tokens': [51513, 1867, 318, 262, 1612, 4049, 287, 262, 2272, 30, 51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47041314886521923,\n",
       "   'compression_ratio': 1.7272727272727273,\n",
       "   'no_speech_prob': 0.28200966119766235},\n",
       "  {'id': 900,\n",
       "   'seek': 354886,\n",
       "   'start': 3573.86,\n",
       "   'end': 3576.86,\n",
       "   'text': ' It means error is 0.',\n",
       "   'tokens': [51613, 632, 1724, 4049, 318, 657, 13, 51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47041314886521923,\n",
       "   'compression_ratio': 1.7272727272727273,\n",
       "   'no_speech_prob': 0.28200966119766235},\n",
       "  {'id': 901,\n",
       "   'seek': 357686,\n",
       "   'start': 3576.86,\n",
       "   'end': 3579.86,\n",
       "   'text': ' What is the mean absolute error?',\n",
       "   'tokens': [50363, 1867, 318, 262, 1612, 4112, 4049, 30, 50513],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.48167906657303916,\n",
       "   'compression_ratio': 2.011627906976744,\n",
       "   'no_speech_prob': 0.18587757647037506},\n",
       "  {'id': 902,\n",
       "   'seek': 357686,\n",
       "   'start': 3579.86,\n",
       "   'end': 3580.86,\n",
       "   'text': ' What is the mean?',\n",
       "   'tokens': [50513, 1867, 318, 262, 1612, 30, 50563],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.48167906657303916,\n",
       "   'compression_ratio': 2.011627906976744,\n",
       "   'no_speech_prob': 0.18587757647037506},\n",
       "  {'id': 903,\n",
       "   'seek': 357686,\n",
       "   'start': 3580.86,\n",
       "   'end': 3581.86,\n",
       "   'text': ' What is the mean?',\n",
       "   'tokens': [50563, 1867, 318, 262, 1612, 30, 50613],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.48167906657303916,\n",
       "   'compression_ratio': 2.011627906976744,\n",
       "   'no_speech_prob': 0.18587757647037506},\n",
       "  {'id': 904,\n",
       "   'seek': 357686,\n",
       "   'start': 3581.86,\n",
       "   'end': 3582.86,\n",
       "   'text': ' What is the mean absolute error?',\n",
       "   'tokens': [50613, 1867, 318, 262, 1612, 4112, 4049, 30, 50663],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.48167906657303916,\n",
       "   'compression_ratio': 2.011627906976744,\n",
       "   'no_speech_prob': 0.18587757647037506},\n",
       "  {'id': 905,\n",
       "   'seek': 357686,\n",
       "   'start': 3582.86,\n",
       "   'end': 3586.86,\n",
       "   'text': ' Yeah, I will see you to know what is the mean error.',\n",
       "   'tokens': [50663,\n",
       "    9425,\n",
       "    11,\n",
       "    314,\n",
       "    481,\n",
       "    766,\n",
       "    345,\n",
       "    284,\n",
       "    760,\n",
       "    644,\n",
       "    318,\n",
       "    262,\n",
       "    1612,\n",
       "    4049,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.48167906657303916,\n",
       "   'compression_ratio': 2.011627906976744,\n",
       "   'no_speech_prob': 0.18587757647037506},\n",
       "  {'id': 906,\n",
       "   'seek': 357686,\n",
       "   'start': 3586.86,\n",
       "   'end': 3589.86,\n",
       "   'text': ' So this is why it is also what it is known what is the metrics.',\n",
       "   'tokens': [50863,\n",
       "    1406,\n",
       "    428,\n",
       "    318,\n",
       "    1521,\n",
       "    340,\n",
       "    318,\n",
       "    635,\n",
       "    644,\n",
       "    340,\n",
       "    318,\n",
       "    1900,\n",
       "    644,\n",
       "    318,\n",
       "    262,\n",
       "    20731,\n",
       "    13,\n",
       "    51013],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.48167906657303916,\n",
       "   'compression_ratio': 2.011627906976744,\n",
       "   'no_speech_prob': 0.18587757647037506},\n",
       "  {'id': 907,\n",
       "   'seek': 357686,\n",
       "   'start': 3589.86,\n",
       "   'end': 3593.86,\n",
       "   'text': ' You are trying to optimize them.',\n",
       "   'tokens': [51013, 921, 389, 2111, 284, 27183, 606, 13, 51213],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.48167906657303916,\n",
       "   'compression_ratio': 2.011627906976744,\n",
       "   'no_speech_prob': 0.18587757647037506},\n",
       "  {'id': 908,\n",
       "   'seek': 357686,\n",
       "   'start': 3593.86,\n",
       "   'end': 3601.86,\n",
       "   'text': ' And you know why you might want to use mean squared error or mean absolute error times.',\n",
       "   'tokens': [51213,\n",
       "    843,\n",
       "    345,\n",
       "    760,\n",
       "    1521,\n",
       "    345,\n",
       "    1244,\n",
       "    765,\n",
       "    284,\n",
       "    779,\n",
       "    1612,\n",
       "    44345,\n",
       "    4049,\n",
       "    393,\n",
       "    1612,\n",
       "    4112,\n",
       "    4049,\n",
       "    1661,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.48167906657303916,\n",
       "   'compression_ratio': 2.011627906976744,\n",
       "   'no_speech_prob': 0.18587757647037506},\n",
       "  {'id': 909,\n",
       "   'seek': 357686,\n",
       "   'start': 3601.86,\n",
       "   'end': 3602.86,\n",
       "   'text': ' Right?',\n",
       "   'tokens': [51613, 6498, 30, 51663],\n",
       "   'temperature': 0.2,\n",
       "   'avg_logprob': -0.48167906657303916,\n",
       "   'compression_ratio': 2.011627906976744,\n",
       "   'no_speech_prob': 0.18587757647037506},\n",
       "  {'id': 910,\n",
       "   'seek': 360286,\n",
       "   'start': 3603.86,\n",
       "   'end': 3606.86,\n",
       "   'text': ' There is something more to do with.',\n",
       "   'tokens': [50413, 1318, 318, 1223, 517, 284, 466, 351, 13, 50563],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.7601106063179348,\n",
       "   'compression_ratio': 1.627659574468085,\n",
       "   'no_speech_prob': 0.5507836937904358},\n",
       "  {'id': 911,\n",
       "   'seek': 360286,\n",
       "   'start': 3606.86,\n",
       "   'end': 3608.86,\n",
       "   'text': ' Sorry.',\n",
       "   'tokens': [50563, 19061, 13, 50663],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.7601106063179348,\n",
       "   'compression_ratio': 1.627659574468085,\n",
       "   'no_speech_prob': 0.5507836937904358},\n",
       "  {'id': 912,\n",
       "   'seek': 360286,\n",
       "   'start': 3608.86,\n",
       "   'end': 3610.86,\n",
       "   'text': ' Maybe not.',\n",
       "   'tokens': [50663, 6674, 407, 13, 50763],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.7601106063179348,\n",
       "   'compression_ratio': 1.627659574468085,\n",
       "   'no_speech_prob': 0.5507836937904358},\n",
       "  {'id': 913,\n",
       "   'seek': 360286,\n",
       "   'start': 3610.86,\n",
       "   'end': 3612.86,\n",
       "   'text': ' Okay, something even bigger than that.',\n",
       "   'tokens': [50763, 16805, 11, 1223, 772, 5749, 621, 326, 13, 50863],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.7601106063179348,\n",
       "   'compression_ratio': 1.627659574468085,\n",
       "   'no_speech_prob': 0.5507836937904358},\n",
       "  {'id': 914,\n",
       "   'seek': 360286,\n",
       "   'start': 3612.86,\n",
       "   'end': 3617.86,\n",
       "   'text': ' Can you just write out the mean and then write out the mean and then write it.',\n",
       "   'tokens': [50863,\n",
       "    1680,\n",
       "    345,\n",
       "    655,\n",
       "    3551,\n",
       "    503,\n",
       "    262,\n",
       "    1612,\n",
       "    290,\n",
       "    788,\n",
       "    3551,\n",
       "    503,\n",
       "    262,\n",
       "    1612,\n",
       "    290,\n",
       "    788,\n",
       "    3551,\n",
       "    340,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.7601106063179348,\n",
       "   'compression_ratio': 1.627659574468085,\n",
       "   'no_speech_prob': 0.5507836937904358},\n",
       "  {'id': 915,\n",
       "   'seek': 360286,\n",
       "   'start': 3617.86,\n",
       "   'end': 3621.86,\n",
       "   'text': ' Okay, can you tell me how does the error may see?',\n",
       "   'tokens': [51113,\n",
       "    16805,\n",
       "    11,\n",
       "    460,\n",
       "    345,\n",
       "    1560,\n",
       "    502,\n",
       "    703,\n",
       "    857,\n",
       "    262,\n",
       "    4049,\n",
       "    743,\n",
       "    766,\n",
       "    30,\n",
       "    51313],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.7601106063179348,\n",
       "   'compression_ratio': 1.627659574468085,\n",
       "   'no_speech_prob': 0.5507836937904358},\n",
       "  {'id': 916,\n",
       "   'seek': 360286,\n",
       "   'start': 3621.86,\n",
       "   'end': 3628.86,\n",
       "   'text': ' So if y i hat is very far away from y i which is going to produce more error.',\n",
       "   'tokens': [51313,\n",
       "    1406,\n",
       "    611,\n",
       "    331,\n",
       "    1312,\n",
       "    6877,\n",
       "    318,\n",
       "    845,\n",
       "    1290,\n",
       "    1497,\n",
       "    422,\n",
       "    331,\n",
       "    1312,\n",
       "    543,\n",
       "    318,\n",
       "    1016,\n",
       "    284,\n",
       "    4439,\n",
       "    517,\n",
       "    4049,\n",
       "    13,\n",
       "    51663],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.7601106063179348,\n",
       "   'compression_ratio': 1.627659574468085,\n",
       "   'no_speech_prob': 0.5507836937904358},\n",
       "  {'id': 917,\n",
       "   'seek': 360286,\n",
       "   'start': 3628.86,\n",
       "   'end': 3629.86,\n",
       "   'text': ' Right.',\n",
       "   'tokens': [51663, 6498, 13, 51713],\n",
       "   'temperature': 0.4,\n",
       "   'avg_logprob': -0.7601106063179348,\n",
       "   'compression_ratio': 1.627659574468085,\n",
       "   'no_speech_prob': 0.5507836937904358},\n",
       "  {'id': 918,\n",
       "   'seek': 362986,\n",
       "   'start': 3630.86,\n",
       "   'end': 3639.86,\n",
       "   'text': ' So can you say that squared errors tend to penalize bad predictions much more than the regular.',\n",
       "   'tokens': [50413,\n",
       "    1406,\n",
       "    460,\n",
       "    345,\n",
       "    910,\n",
       "    326,\n",
       "    44345,\n",
       "    8563,\n",
       "    4327,\n",
       "    284,\n",
       "    23634,\n",
       "    1096,\n",
       "    2089,\n",
       "    16277,\n",
       "    881,\n",
       "    517,\n",
       "    621,\n",
       "    262,\n",
       "    3218,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2983153931638028,\n",
       "   'compression_ratio': 1.3424657534246576,\n",
       "   'no_speech_prob': 0.07320936024188995},\n",
       "  {'id': 919,\n",
       "   'seek': 362986,\n",
       "   'start': 3646.86,\n",
       "   'end': 3651.86,\n",
       "   'text': \" Now let's quickly get into the first algorithm for today.\",\n",
       "   'tokens': [51213,\n",
       "    2735,\n",
       "    1309,\n",
       "    338,\n",
       "    2952,\n",
       "    651,\n",
       "    656,\n",
       "    262,\n",
       "    717,\n",
       "    11862,\n",
       "    329,\n",
       "    1909,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2983153931638028,\n",
       "   'compression_ratio': 1.3424657534246576,\n",
       "   'no_speech_prob': 0.07320936024188995},\n",
       "  {'id': 920,\n",
       "   'seek': 362986,\n",
       "   'start': 3651.86,\n",
       "   'end': 3655.86,\n",
       "   'text': ' We are going to talk about decision trees.',\n",
       "   'tokens': [51463, 775, 389, 1016, 284, 1561, 546, 2551, 7150, 13, 51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2983153931638028,\n",
       "   'compression_ratio': 1.3424657534246576,\n",
       "   'no_speech_prob': 0.07320936024188995},\n",
       "  {'id': 921,\n",
       "   'seek': 365986,\n",
       "   'start': 3660.86,\n",
       "   'end': 3667.86,\n",
       "   'text': ' We are getting now solving a classification problem using our first algorithm for decision trees.',\n",
       "   'tokens': [50413,\n",
       "    775,\n",
       "    389,\n",
       "    1972,\n",
       "    783,\n",
       "    18120,\n",
       "    257,\n",
       "    17923,\n",
       "    1917,\n",
       "    1262,\n",
       "    674,\n",
       "    717,\n",
       "    11862,\n",
       "    329,\n",
       "    2551,\n",
       "    7150,\n",
       "    13,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5365080247845566,\n",
       "   'compression_ratio': 1.6591760299625469,\n",
       "   'no_speech_prob': 0.04381432384252548},\n",
       "  {'id': 922,\n",
       "   'seek': 365986,\n",
       "   'start': 3667.86,\n",
       "   'end': 3673.86,\n",
       "   'text': ' So we have some training data where we have different days from D1 to D4E.',\n",
       "   'tokens': [50763,\n",
       "    1406,\n",
       "    356,\n",
       "    423,\n",
       "    617,\n",
       "    3047,\n",
       "    1366,\n",
       "    810,\n",
       "    356,\n",
       "    423,\n",
       "    1180,\n",
       "    1528,\n",
       "    422,\n",
       "    360,\n",
       "    16,\n",
       "    284,\n",
       "    360,\n",
       "    19,\n",
       "    36,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5365080247845566,\n",
       "   'compression_ratio': 1.6591760299625469,\n",
       "   'no_speech_prob': 0.04381432384252548},\n",
       "  {'id': 923,\n",
       "   'seek': 365986,\n",
       "   'start': 3673.86,\n",
       "   'end': 3676.86,\n",
       "   'text': ' Should the day be included at an accurate error path?',\n",
       "   'tokens': [51063,\n",
       "    10358,\n",
       "    262,\n",
       "    1110,\n",
       "    307,\n",
       "    3017,\n",
       "    379,\n",
       "    281,\n",
       "    7187,\n",
       "    4049,\n",
       "    3108,\n",
       "    30,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5365080247845566,\n",
       "   'compression_ratio': 1.6591760299625469,\n",
       "   'no_speech_prob': 0.04381432384252548},\n",
       "  {'id': 924,\n",
       "   'seek': 365986,\n",
       "   'start': 3676.86,\n",
       "   'end': 3679.86,\n",
       "   'text': ' That is the new assignment from the one that we have now.',\n",
       "   'tokens': [51213,\n",
       "    1320,\n",
       "    318,\n",
       "    262,\n",
       "    649,\n",
       "    16237,\n",
       "    422,\n",
       "    262,\n",
       "    530,\n",
       "    326,\n",
       "    356,\n",
       "    423,\n",
       "    783,\n",
       "    13,\n",
       "    51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5365080247845566,\n",
       "   'compression_ratio': 1.6591760299625469,\n",
       "   'no_speech_prob': 0.04381432384252548},\n",
       "  {'id': 925,\n",
       "   'seek': 365986,\n",
       "   'start': 3679.86,\n",
       "   'end': 3683.86,\n",
       "   'text': ' We have the algorithm that is funny and we want to talk a separate generation of a quad,',\n",
       "   'tokens': [51363,\n",
       "    775,\n",
       "    423,\n",
       "    262,\n",
       "    11862,\n",
       "    326,\n",
       "    318,\n",
       "    8258,\n",
       "    290,\n",
       "    356,\n",
       "    765,\n",
       "    284,\n",
       "    1561,\n",
       "    257,\n",
       "    4553,\n",
       "    5270,\n",
       "    286,\n",
       "    257,\n",
       "    15094,\n",
       "    11,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5365080247845566,\n",
       "   'compression_ratio': 1.6591760299625469,\n",
       "   'no_speech_prob': 0.04381432384252548},\n",
       "  {'id': 926,\n",
       "   'seek': 365986,\n",
       "   'start': 3683.86,\n",
       "   'end': 3685.86,\n",
       "   'text': ' a quad, a quad, a humidity and a wind.',\n",
       "   'tokens': [51563,\n",
       "    257,\n",
       "    15094,\n",
       "    11,\n",
       "    257,\n",
       "    15094,\n",
       "    11,\n",
       "    257,\n",
       "    27716,\n",
       "    290,\n",
       "    257,\n",
       "    2344,\n",
       "    13,\n",
       "    51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5365080247845566,\n",
       "   'compression_ratio': 1.6591760299625469,\n",
       "   'no_speech_prob': 0.04381432384252548},\n",
       "  {'id': 927,\n",
       "   'seek': 365986,\n",
       "   'start': 3685.86,\n",
       "   'end': 3687.86,\n",
       "   'text': ' And whether or not we play it.',\n",
       "   'tokens': [51663, 843, 1771, 393, 407, 356, 711, 340, 13, 51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5365080247845566,\n",
       "   'compression_ratio': 1.6591760299625469,\n",
       "   'no_speech_prob': 0.04381432384252548},\n",
       "  {'id': 928,\n",
       "   'seek': 368786,\n",
       "   'start': 3688.86,\n",
       "   'end': 3695.86,\n",
       "   'text': ' So now you try and predict whether I should or learn a function between data and some of the attributes of the function.',\n",
       "   'tokens': [50413,\n",
       "    1406,\n",
       "    783,\n",
       "    345,\n",
       "    1949,\n",
       "    290,\n",
       "    4331,\n",
       "    1771,\n",
       "    314,\n",
       "    815,\n",
       "    393,\n",
       "    2193,\n",
       "    257,\n",
       "    2163,\n",
       "    1022,\n",
       "    1366,\n",
       "    290,\n",
       "    617,\n",
       "    286,\n",
       "    262,\n",
       "    12608,\n",
       "    286,\n",
       "    262,\n",
       "    2163,\n",
       "    13,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5819258213043212,\n",
       "   'compression_ratio': 1.79,\n",
       "   'no_speech_prob': 0.08373139053583145},\n",
       "  {'id': 929,\n",
       "   'seek': 368786,\n",
       "   'start': 3698.86,\n",
       "   'end': 3704.86,\n",
       "   'text': ' These are actually different in the computer, the four way attributes and the output variable.',\n",
       "   'tokens': [50913,\n",
       "    2312,\n",
       "    389,\n",
       "    1682,\n",
       "    1180,\n",
       "    287,\n",
       "    262,\n",
       "    3644,\n",
       "    11,\n",
       "    262,\n",
       "    1440,\n",
       "    835,\n",
       "    12608,\n",
       "    290,\n",
       "    262,\n",
       "    5072,\n",
       "    7885,\n",
       "    13,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5819258213043212,\n",
       "   'compression_ratio': 1.79,\n",
       "   'no_speech_prob': 0.08373139053583145},\n",
       "  {'id': 930,\n",
       "   'seek': 368786,\n",
       "   'start': 3704.86,\n",
       "   'end': 3709.86,\n",
       "   'text': ' And this is practice equation because the output variable of the function is just clear.',\n",
       "   'tokens': [51213,\n",
       "    843,\n",
       "    428,\n",
       "    318,\n",
       "    3357,\n",
       "    16022,\n",
       "    780,\n",
       "    262,\n",
       "    5072,\n",
       "    7885,\n",
       "    286,\n",
       "    262,\n",
       "    2163,\n",
       "    318,\n",
       "    655,\n",
       "    1598,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5819258213043212,\n",
       "   'compression_ratio': 1.79,\n",
       "   'no_speech_prob': 0.08373139053583145},\n",
       "  {'id': 931,\n",
       "   'seek': 368786,\n",
       "   'start': 3709.86,\n",
       "   'end': 3711.86,\n",
       "   'text': ' In this case it is only in the guess of the function.',\n",
       "   'tokens': [51463,\n",
       "    554,\n",
       "    428,\n",
       "    1339,\n",
       "    340,\n",
       "    318,\n",
       "    691,\n",
       "    287,\n",
       "    262,\n",
       "    4724,\n",
       "    286,\n",
       "    262,\n",
       "    2163,\n",
       "    13,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5819258213043212,\n",
       "   'compression_ratio': 1.79,\n",
       "   'no_speech_prob': 0.08373139053583145},\n",
       "  {'id': 932,\n",
       "   'seek': 371186,\n",
       "   'start': 3712.86,\n",
       "   'end': 3718.86,\n",
       "   'text': ' And because I have also used decision trees to follow regression here.',\n",
       "   'tokens': [50413,\n",
       "    843,\n",
       "    780,\n",
       "    314,\n",
       "    423,\n",
       "    635,\n",
       "    973,\n",
       "    2551,\n",
       "    7150,\n",
       "    284,\n",
       "    1061,\n",
       "    20683,\n",
       "    994,\n",
       "    13,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4419206561464252,\n",
       "   'compression_ratio': 1.6081632653061224,\n",
       "   'no_speech_prob': 0.18520329892635345},\n",
       "  {'id': 933,\n",
       "   'seek': 371186,\n",
       "   'start': 3718.86,\n",
       "   'end': 3723.86,\n",
       "   'text': ' Where we try to predict the house price given the square point of the data.',\n",
       "   'tokens': [50713,\n",
       "    6350,\n",
       "    356,\n",
       "    1949,\n",
       "    284,\n",
       "    4331,\n",
       "    262,\n",
       "    2156,\n",
       "    2756,\n",
       "    1813,\n",
       "    262,\n",
       "    6616,\n",
       "    966,\n",
       "    286,\n",
       "    262,\n",
       "    1366,\n",
       "    13,\n",
       "    50963],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4419206561464252,\n",
       "   'compression_ratio': 1.6081632653061224,\n",
       "   'no_speech_prob': 0.18520329892635345},\n",
       "  {'id': 934,\n",
       "   'seek': 371186,\n",
       "   'start': 3723.86,\n",
       "   'end': 3726.86,\n",
       "   'text': \" Let's get back to the example which we were discussing.\",\n",
       "   'tokens': [50963,\n",
       "    3914,\n",
       "    338,\n",
       "    651,\n",
       "    736,\n",
       "    284,\n",
       "    262,\n",
       "    1672,\n",
       "    543,\n",
       "    356,\n",
       "    547,\n",
       "    11142,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4419206561464252,\n",
       "   'compression_ratio': 1.6081632653061224,\n",
       "   'no_speech_prob': 0.18520329892635345},\n",
       "  {'id': 935,\n",
       "   'seek': 371186,\n",
       "   'start': 3726.86,\n",
       "   'end': 3731.86,\n",
       "   'text': ' I am not going to talk about this for now.',\n",
       "   'tokens': [51113,\n",
       "    314,\n",
       "    716,\n",
       "    407,\n",
       "    1016,\n",
       "    284,\n",
       "    1561,\n",
       "    546,\n",
       "    428,\n",
       "    329,\n",
       "    783,\n",
       "    13,\n",
       "    51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4419206561464252,\n",
       "   'compression_ratio': 1.6081632653061224,\n",
       "   'no_speech_prob': 0.18520329892635345},\n",
       "  {'id': 936,\n",
       "   'seek': 371186,\n",
       "   'start': 3731.86,\n",
       "   'end': 3735.86,\n",
       "   'text': ' So one of the reasons why I am about to put a decision tree is started to be.',\n",
       "   'tokens': [51363,\n",
       "    1406,\n",
       "    530,\n",
       "    286,\n",
       "    262,\n",
       "    3840,\n",
       "    1521,\n",
       "    314,\n",
       "    716,\n",
       "    546,\n",
       "    284,\n",
       "    1234,\n",
       "    257,\n",
       "    2551,\n",
       "    5509,\n",
       "    318,\n",
       "    2067,\n",
       "    284,\n",
       "    307,\n",
       "    13,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4419206561464252,\n",
       "   'compression_ratio': 1.6081632653061224,\n",
       "   'no_speech_prob': 0.18520329892635345},\n",
       "  {'id': 937,\n",
       "   'seek': 371186,\n",
       "   'start': 3735.86,\n",
       "   'end': 3740.86,\n",
       "   'text': ' Remember last time we put a something like over and test our captures.',\n",
       "   'tokens': [51563,\n",
       "    11436,\n",
       "    938,\n",
       "    640,\n",
       "    356,\n",
       "    1234,\n",
       "    257,\n",
       "    1223,\n",
       "    588,\n",
       "    625,\n",
       "    290,\n",
       "    1332,\n",
       "    674,\n",
       "    23007,\n",
       "    13,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4419206561464252,\n",
       "   'compression_ratio': 1.6081632653061224,\n",
       "   'no_speech_prob': 0.18520329892635345},\n",
       "  {'id': 938,\n",
       "   'seek': 374086,\n",
       "   'start': 3741.86,\n",
       "   'end': 3744.86,\n",
       "   'text': ' Imagine if we are very very complicated machine learning algorithms.',\n",
       "   'tokens': [50413,\n",
       "    18450,\n",
       "    611,\n",
       "    356,\n",
       "    389,\n",
       "    845,\n",
       "    845,\n",
       "    8253,\n",
       "    4572,\n",
       "    4673,\n",
       "    16113,\n",
       "    13,\n",
       "    50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44840938568115235,\n",
       "   'compression_ratio': 1.7347826086956522,\n",
       "   'no_speech_prob': 0.010034156031906605},\n",
       "  {'id': 939,\n",
       "   'seek': 374086,\n",
       "   'start': 3744.86,\n",
       "   'end': 3747.86,\n",
       "   'text': ' That says some new retro technical models.',\n",
       "   'tokens': [50563, 1320, 1139, 617, 649, 12175, 6276, 4981, 13, 50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44840938568115235,\n",
       "   'compression_ratio': 1.7347826086956522,\n",
       "   'no_speech_prob': 0.010034156031906605},\n",
       "  {'id': 940,\n",
       "   'seek': 374086,\n",
       "   'start': 3747.86,\n",
       "   'end': 3751.86,\n",
       "   'text': ' There is often a very, there is often a case of very hard to do,',\n",
       "   'tokens': [50713,\n",
       "    1318,\n",
       "    318,\n",
       "    1690,\n",
       "    257,\n",
       "    845,\n",
       "    11,\n",
       "    612,\n",
       "    318,\n",
       "    1690,\n",
       "    257,\n",
       "    1339,\n",
       "    286,\n",
       "    845,\n",
       "    1327,\n",
       "    284,\n",
       "    466,\n",
       "    11,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44840938568115235,\n",
       "   'compression_ratio': 1.7347826086956522,\n",
       "   'no_speech_prob': 0.010034156031906605},\n",
       "  {'id': 941,\n",
       "   'seek': 374086,\n",
       "   'start': 3751.86,\n",
       "   'end': 3753.86,\n",
       "   'text': ' readjustratively for these models.',\n",
       "   'tokens': [50913, 1100, 3137, 81, 9404, 329, 777, 4981, 13, 51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44840938568115235,\n",
       "   'compression_ratio': 1.7347826086956522,\n",
       "   'no_speech_prob': 0.010034156031906605},\n",
       "  {'id': 942,\n",
       "   'seek': 374086,\n",
       "   'start': 3754.86,\n",
       "   'end': 3757.86,\n",
       "   'text': ' It is not really to understand what the model is done.',\n",
       "   'tokens': [51063,\n",
       "    632,\n",
       "    318,\n",
       "    407,\n",
       "    1107,\n",
       "    284,\n",
       "    1833,\n",
       "    644,\n",
       "    262,\n",
       "    2746,\n",
       "    318,\n",
       "    1760,\n",
       "    13,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44840938568115235,\n",
       "   'compression_ratio': 1.7347826086956522,\n",
       "   'no_speech_prob': 0.010034156031906605},\n",
       "  {'id': 943,\n",
       "   'seek': 374086,\n",
       "   'start': 3757.86,\n",
       "   'end': 3764.86,\n",
       "   'text': ' But the ship trees being one of the very simple models are very very suited for such cases.',\n",
       "   'tokens': [51213,\n",
       "    887,\n",
       "    262,\n",
       "    4074,\n",
       "    7150,\n",
       "    852,\n",
       "    530,\n",
       "    286,\n",
       "    262,\n",
       "    845,\n",
       "    2829,\n",
       "    4981,\n",
       "    389,\n",
       "    845,\n",
       "    845,\n",
       "    16662,\n",
       "    329,\n",
       "    884,\n",
       "    2663,\n",
       "    13,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44840938568115235,\n",
       "   'compression_ratio': 1.7347826086956522,\n",
       "   'no_speech_prob': 0.010034156031906605},\n",
       "  {'id': 944,\n",
       "   'seek': 374086,\n",
       "   'start': 3764.86,\n",
       "   'end': 3767.86,\n",
       "   'text': ' Where you want the model to be educated.',\n",
       "   'tokens': [51563, 6350, 345, 765, 262, 2746, 284, 307, 15657, 13, 51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44840938568115235,\n",
       "   'compression_ratio': 1.7347826086956522,\n",
       "   'no_speech_prob': 0.010034156031906605},\n",
       "  {'id': 945,\n",
       "   'seek': 376786,\n",
       "   'start': 3768.86,\n",
       "   'end': 3770.86,\n",
       "   'text': ' Now imagine if we go to a doctor.',\n",
       "   'tokens': [50413, 2735, 5967, 611, 356, 467, 284, 257, 6253, 13, 50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4924798378577599,\n",
       "   'compression_ratio': 1.685589519650655,\n",
       "   'no_speech_prob': 0.020548345521092415},\n",
       "  {'id': 946,\n",
       "   'seek': 376786,\n",
       "   'start': 3770.86,\n",
       "   'end': 3773.86,\n",
       "   'text': ' We want to build an application.',\n",
       "   'tokens': [50513, 775, 765, 284, 1382, 281, 3586, 13, 50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4924798378577599,\n",
       "   'compression_ratio': 1.685589519650655,\n",
       "   'no_speech_prob': 0.020548345521092415},\n",
       "  {'id': 947,\n",
       "   'seek': 376786,\n",
       "   'start': 3773.86,\n",
       "   'end': 3774.86,\n",
       "   'text': ' We want to build a machine learning that says,',\n",
       "   'tokens': [50663,\n",
       "    775,\n",
       "    765,\n",
       "    284,\n",
       "    1382,\n",
       "    257,\n",
       "    4572,\n",
       "    4673,\n",
       "    326,\n",
       "    1139,\n",
       "    11,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4924798378577599,\n",
       "   'compression_ratio': 1.685589519650655,\n",
       "   'no_speech_prob': 0.020548345521092415},\n",
       "  {'id': 948,\n",
       "   'seek': 376786,\n",
       "   'start': 3774.86,\n",
       "   'end': 3777.86,\n",
       "   'text': ' it adds a screening application for an author.',\n",
       "   'tokens': [50713, 340, 6673, 257, 14135, 3586, 329, 281, 1772, 13, 50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4924798378577599,\n",
       "   'compression_ratio': 1.685589519650655,\n",
       "   'no_speech_prob': 0.020548345521092415},\n",
       "  {'id': 949,\n",
       "   'seek': 376786,\n",
       "   'start': 3777.86,\n",
       "   'end': 3784.86,\n",
       "   'text': ' When the doctor tries that, I will find it is ignored and relo and some phalency maps.',\n",
       "   'tokens': [50863,\n",
       "    1649,\n",
       "    262,\n",
       "    6253,\n",
       "    8404,\n",
       "    326,\n",
       "    11,\n",
       "    314,\n",
       "    481,\n",
       "    1064,\n",
       "    340,\n",
       "    318,\n",
       "    9514,\n",
       "    290,\n",
       "    823,\n",
       "    78,\n",
       "    290,\n",
       "    617,\n",
       "    872,\n",
       "    282,\n",
       "    1387,\n",
       "    8739,\n",
       "    13,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4924798378577599,\n",
       "   'compression_ratio': 1.685589519650655,\n",
       "   'no_speech_prob': 0.020548345521092415},\n",
       "  {'id': 950,\n",
       "   'seek': 376786,\n",
       "   'start': 3784.86,\n",
       "   'end': 3789.86,\n",
       "   'text': ' And I have done some attention and 20 other technical terms in the event it works.',\n",
       "   'tokens': [51213,\n",
       "    843,\n",
       "    314,\n",
       "    423,\n",
       "    1760,\n",
       "    617,\n",
       "    3241,\n",
       "    290,\n",
       "    1160,\n",
       "    584,\n",
       "    6276,\n",
       "    2846,\n",
       "    287,\n",
       "    262,\n",
       "    1785,\n",
       "    340,\n",
       "    2499,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4924798378577599,\n",
       "   'compression_ratio': 1.685589519650655,\n",
       "   'no_speech_prob': 0.020548345521092415},\n",
       "  {'id': 951,\n",
       "   'seek': 376786,\n",
       "   'start': 3789.86,\n",
       "   'end': 3792.86,\n",
       "   'text': ' Or they will say that I have some of this set of rules.',\n",
       "   'tokens': [51463,\n",
       "    1471,\n",
       "    484,\n",
       "    481,\n",
       "    910,\n",
       "    326,\n",
       "    314,\n",
       "    423,\n",
       "    617,\n",
       "    286,\n",
       "    428,\n",
       "    900,\n",
       "    286,\n",
       "    3173,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4924798378577599,\n",
       "   'compression_ratio': 1.685589519650655,\n",
       "   'no_speech_prob': 0.020548345521092415},\n",
       "  {'id': 952,\n",
       "   'seek': 379286,\n",
       "   'start': 3792.86,\n",
       "   'end': 3798.86,\n",
       "   'text': ' If the patient has, you know, decaying cell function and the patient has some swelling etc.',\n",
       "   'tokens': [50363,\n",
       "    1002,\n",
       "    262,\n",
       "    5827,\n",
       "    468,\n",
       "    11,\n",
       "    345,\n",
       "    760,\n",
       "    11,\n",
       "    49240,\n",
       "    2685,\n",
       "    2163,\n",
       "    290,\n",
       "    262,\n",
       "    5827,\n",
       "    468,\n",
       "    617,\n",
       "    29844,\n",
       "    3503,\n",
       "    13,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4578658870009125,\n",
       "   'compression_ratio': 1.7234848484848484,\n",
       "   'no_speech_prob': 0.08432692289352417},\n",
       "  {'id': 953,\n",
       "   'seek': 379286,\n",
       "   'start': 3798.86,\n",
       "   'end': 3800.86,\n",
       "   'text': ' Then the patient is like you have to ask them.',\n",
       "   'tokens': [50663,\n",
       "    3244,\n",
       "    262,\n",
       "    5827,\n",
       "    318,\n",
       "    588,\n",
       "    345,\n",
       "    423,\n",
       "    284,\n",
       "    1265,\n",
       "    606,\n",
       "    13,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4578658870009125,\n",
       "   'compression_ratio': 1.7234848484848484,\n",
       "   'no_speech_prob': 0.08432692289352417},\n",
       "  {'id': 954,\n",
       "   'seek': 379286,\n",
       "   'start': 3800.86,\n",
       "   'end': 3802.86,\n",
       "   'text': ' Which of them do you think is doctorability?',\n",
       "   'tokens': [50763,\n",
       "    9022,\n",
       "    286,\n",
       "    606,\n",
       "    466,\n",
       "    345,\n",
       "    892,\n",
       "    318,\n",
       "    6253,\n",
       "    1799,\n",
       "    30,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4578658870009125,\n",
       "   'compression_ratio': 1.7234848484848484,\n",
       "   'no_speech_prob': 0.08432692289352417},\n",
       "  {'id': 955,\n",
       "   'seek': 379286,\n",
       "   'start': 3802.86,\n",
       "   'end': 3805.86,\n",
       "   'text': ' There is a couple of shared models.',\n",
       "   'tokens': [50863, 1318, 318, 257, 3155, 286, 4888, 4981, 13, 51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4578658870009125,\n",
       "   'compression_ratio': 1.7234848484848484,\n",
       "   'no_speech_prob': 0.08432692289352417},\n",
       "  {'id': 956,\n",
       "   'seek': 379286,\n",
       "   'start': 3805.86,\n",
       "   'end': 3807.86,\n",
       "   'text': ' Obviously it is a certain model.',\n",
       "   'tokens': [51013, 16263, 340, 318, 257, 1728, 2746, 13, 51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4578658870009125,\n",
       "   'compression_ratio': 1.7234848484848484,\n",
       "   'no_speech_prob': 0.08432692289352417},\n",
       "  {'id': 957,\n",
       "   'seek': 379286,\n",
       "   'start': 3807.86,\n",
       "   'end': 3808.86,\n",
       "   'text': ' Because that is more interpretive.',\n",
       "   'tokens': [51113, 4362, 326, 318, 517, 6179, 425, 13, 51163],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4578658870009125,\n",
       "   'compression_ratio': 1.7234848484848484,\n",
       "   'no_speech_prob': 0.08432692289352417},\n",
       "  {'id': 958,\n",
       "   'seek': 379286,\n",
       "   'start': 3808.86,\n",
       "   'end': 3811.86,\n",
       "   'text': ' This is also about many of our things.',\n",
       "   'tokens': [51163, 770, 318, 635, 546, 867, 286, 674, 1243, 13, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4578658870009125,\n",
       "   'compression_ratio': 1.7234848484848484,\n",
       "   'no_speech_prob': 0.08432692289352417},\n",
       "  {'id': 959,\n",
       "   'seek': 379286,\n",
       "   'start': 3811.86,\n",
       "   'end': 3816.86,\n",
       "   'text': ' If we go back to this example and if you think in your life,',\n",
       "   'tokens': [51313,\n",
       "    1002,\n",
       "    356,\n",
       "    467,\n",
       "    736,\n",
       "    284,\n",
       "    428,\n",
       "    1672,\n",
       "    290,\n",
       "    611,\n",
       "    345,\n",
       "    892,\n",
       "    287,\n",
       "    534,\n",
       "    1204,\n",
       "    11,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4578658870009125,\n",
       "   'compression_ratio': 1.7234848484848484,\n",
       "   'no_speech_prob': 0.08432692289352417},\n",
       "  {'id': 960,\n",
       "   'seek': 379286,\n",
       "   'start': 3816.86,\n",
       "   'end': 3820.86,\n",
       "   'text': ' if you were to play it as what is this set of values that you play?',\n",
       "   'tokens': [51563,\n",
       "    611,\n",
       "    345,\n",
       "    547,\n",
       "    284,\n",
       "    711,\n",
       "    340,\n",
       "    355,\n",
       "    644,\n",
       "    318,\n",
       "    428,\n",
       "    900,\n",
       "    286,\n",
       "    3815,\n",
       "    326,\n",
       "    345,\n",
       "    711,\n",
       "    30,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4578658870009125,\n",
       "   'compression_ratio': 1.7234848484848484,\n",
       "   'no_speech_prob': 0.08432692289352417},\n",
       "  {'id': 961,\n",
       "   'seek': 382286,\n",
       "   'start': 3822.86,\n",
       "   'end': 3824.86,\n",
       "   'text': ' One parameter is just not written as a code.',\n",
       "   'tokens': [50363,\n",
       "    1881,\n",
       "    11507,\n",
       "    318,\n",
       "    655,\n",
       "    407,\n",
       "    3194,\n",
       "    355,\n",
       "    257,\n",
       "    2438,\n",
       "    13,\n",
       "    50463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.379568120484711,\n",
       "   'compression_ratio': 1.73,\n",
       "   'no_speech_prob': 0.22699272632598877},\n",
       "  {'id': 962,\n",
       "   'seek': 382286,\n",
       "   'start': 3824.86,\n",
       "   'end': 3826.86,\n",
       "   'text': ' They will get someone to play with.',\n",
       "   'tokens': [50463, 1119, 481, 651, 2130, 284, 711, 351, 13, 50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.379568120484711,\n",
       "   'compression_ratio': 1.73,\n",
       "   'no_speech_prob': 0.22699272632598877},\n",
       "  {'id': 963,\n",
       "   'seek': 382286,\n",
       "   'start': 3826.86,\n",
       "   'end': 3828.86,\n",
       "   'text': ' They cannot play with them.',\n",
       "   'tokens': [50563, 1119, 2314, 711, 351, 606, 13, 50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.379568120484711,\n",
       "   'compression_ratio': 1.73,\n",
       "   'no_speech_prob': 0.22699272632598877},\n",
       "  {'id': 964,\n",
       "   'seek': 382286,\n",
       "   'start': 3828.86,\n",
       "   'end': 3832.86,\n",
       "   'text': ' But then of course you will not want to play with this very hot.',\n",
       "   'tokens': [50663,\n",
       "    887,\n",
       "    788,\n",
       "    286,\n",
       "    1781,\n",
       "    345,\n",
       "    481,\n",
       "    407,\n",
       "    765,\n",
       "    284,\n",
       "    711,\n",
       "    351,\n",
       "    428,\n",
       "    845,\n",
       "    3024,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.379568120484711,\n",
       "   'compression_ratio': 1.73,\n",
       "   'no_speech_prob': 0.22699272632598877},\n",
       "  {'id': 965,\n",
       "   'seek': 382286,\n",
       "   'start': 3832.86,\n",
       "   'end': 3836.86,\n",
       "   'text': ' You will not want to play with it very human.',\n",
       "   'tokens': [50863,\n",
       "    921,\n",
       "    481,\n",
       "    407,\n",
       "    765,\n",
       "    284,\n",
       "    711,\n",
       "    351,\n",
       "    340,\n",
       "    845,\n",
       "    1692,\n",
       "    13,\n",
       "    51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.379568120484711,\n",
       "   'compression_ratio': 1.73,\n",
       "   'no_speech_prob': 0.22699272632598877},\n",
       "  {'id': 966,\n",
       "   'seek': 382286,\n",
       "   'start': 3836.86,\n",
       "   'end': 3840.86,\n",
       "   'text': ' Looking at this, playing it up for a specific example.',\n",
       "   'tokens': [51063,\n",
       "    15616,\n",
       "    379,\n",
       "    428,\n",
       "    11,\n",
       "    2712,\n",
       "    340,\n",
       "    510,\n",
       "    329,\n",
       "    257,\n",
       "    2176,\n",
       "    1672,\n",
       "    13,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.379568120484711,\n",
       "   'compression_ratio': 1.73,\n",
       "   'no_speech_prob': 0.22699272632598877},\n",
       "  {'id': 967,\n",
       "   'seek': 382286,\n",
       "   'start': 3840.86,\n",
       "   'end': 3845.86,\n",
       "   'text': ' Can you tell me some of the times you will definitely play an operator.',\n",
       "   'tokens': [51263,\n",
       "    1680,\n",
       "    345,\n",
       "    1560,\n",
       "    502,\n",
       "    617,\n",
       "    286,\n",
       "    262,\n",
       "    1661,\n",
       "    345,\n",
       "    481,\n",
       "    4753,\n",
       "    711,\n",
       "    281,\n",
       "    10088,\n",
       "    13,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.379568120484711,\n",
       "   'compression_ratio': 1.73,\n",
       "   'no_speech_prob': 0.22699272632598877},\n",
       "  {'id': 968,\n",
       "   'seek': 384586,\n",
       "   'start': 3845.86,\n",
       "   'end': 3852.86,\n",
       "   'text': ' As an operator, the overcast has always been.',\n",
       "   'tokens': [50363,\n",
       "    1081,\n",
       "    281,\n",
       "    10088,\n",
       "    11,\n",
       "    262,\n",
       "    625,\n",
       "    2701,\n",
       "    468,\n",
       "    1464,\n",
       "    587,\n",
       "    13,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2695228175113076,\n",
       "   'compression_ratio': 1.615,\n",
       "   'no_speech_prob': 0.30024224519729614},\n",
       "  {'id': 969,\n",
       "   'seek': 384586,\n",
       "   'start': 3852.86,\n",
       "   'end': 3854.86,\n",
       "   'text': ' I mean tell you something like that.',\n",
       "   'tokens': [50713, 314, 1612, 1560, 345, 1223, 588, 326, 13, 50813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2695228175113076,\n",
       "   'compression_ratio': 1.615,\n",
       "   'no_speech_prob': 0.30024224519729614},\n",
       "  {'id': 970,\n",
       "   'seek': 384586,\n",
       "   'start': 3854.86,\n",
       "   'end': 3862.86,\n",
       "   'text': ' Okay, in fact, when it is overcast you see you are not here always playing.',\n",
       "   'tokens': [50813,\n",
       "    16805,\n",
       "    11,\n",
       "    287,\n",
       "    1109,\n",
       "    11,\n",
       "    618,\n",
       "    340,\n",
       "    318,\n",
       "    625,\n",
       "    2701,\n",
       "    345,\n",
       "    766,\n",
       "    345,\n",
       "    389,\n",
       "    407,\n",
       "    994,\n",
       "    1464,\n",
       "    2712,\n",
       "    13,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2695228175113076,\n",
       "   'compression_ratio': 1.615,\n",
       "   'no_speech_prob': 0.30024224519729614},\n",
       "  {'id': 971,\n",
       "   'seek': 384586,\n",
       "   'start': 3862.86,\n",
       "   'end': 3865.86,\n",
       "   'text': ' Just look at these specific rules.',\n",
       "   'tokens': [51213, 2329, 804, 379, 777, 2176, 3173, 13, 51363],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2695228175113076,\n",
       "   'compression_ratio': 1.615,\n",
       "   'no_speech_prob': 0.30024224519729614},\n",
       "  {'id': 972,\n",
       "   'seek': 384586,\n",
       "   'start': 3865.86,\n",
       "   'end': 3868.86,\n",
       "   'text': ' So can you come up with these simple kind of rules?',\n",
       "   'tokens': [51363,\n",
       "    1406,\n",
       "    460,\n",
       "    345,\n",
       "    1282,\n",
       "    510,\n",
       "    351,\n",
       "    777,\n",
       "    2829,\n",
       "    1611,\n",
       "    286,\n",
       "    3173,\n",
       "    30,\n",
       "    51513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2695228175113076,\n",
       "   'compression_ratio': 1.615,\n",
       "   'no_speech_prob': 0.30024224519729614},\n",
       "  {'id': 973,\n",
       "   'seek': 384586,\n",
       "   'start': 3868.86,\n",
       "   'end': 3870.86,\n",
       "   'text': ' If it is overcast, I will definitely play.',\n",
       "   'tokens': [51513,\n",
       "    1002,\n",
       "    340,\n",
       "    318,\n",
       "    625,\n",
       "    2701,\n",
       "    11,\n",
       "    314,\n",
       "    481,\n",
       "    4753,\n",
       "    711,\n",
       "    13,\n",
       "    51613],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2695228175113076,\n",
       "   'compression_ratio': 1.615,\n",
       "   'no_speech_prob': 0.30024224519729614},\n",
       "  {'id': 974,\n",
       "   'seek': 384586,\n",
       "   'start': 3870.86,\n",
       "   'end': 3873.86,\n",
       "   'text': ' If it is not overcast, it is semi.',\n",
       "   'tokens': [51613,\n",
       "    1002,\n",
       "    340,\n",
       "    318,\n",
       "    407,\n",
       "    625,\n",
       "    2701,\n",
       "    11,\n",
       "    340,\n",
       "    318,\n",
       "    10663,\n",
       "    13,\n",
       "    51763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2695228175113076,\n",
       "   'compression_ratio': 1.615,\n",
       "   'no_speech_prob': 0.30024224519729614},\n",
       "  {'id': 975,\n",
       "   'seek': 387386,\n",
       "   'start': 3873.86,\n",
       "   'end': 3877.86,\n",
       "   'text': ' Let us say that the temperature is mild and added also.',\n",
       "   'tokens': [50363,\n",
       "    3914,\n",
       "    514,\n",
       "    910,\n",
       "    326,\n",
       "    262,\n",
       "    5951,\n",
       "    318,\n",
       "    11607,\n",
       "    290,\n",
       "    2087,\n",
       "    635,\n",
       "    13,\n",
       "    50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44870388146602747,\n",
       "   'compression_ratio': 1.7772511848341233,\n",
       "   'no_speech_prob': 0.017426971346139908},\n",
       "  {'id': 976,\n",
       "   'seek': 387386,\n",
       "   'start': 3877.86,\n",
       "   'end': 3881.86,\n",
       "   'text': ' This is how we find to play it as a structure.',\n",
       "   'tokens': [50563,\n",
       "    770,\n",
       "    318,\n",
       "    703,\n",
       "    356,\n",
       "    1064,\n",
       "    284,\n",
       "    711,\n",
       "    340,\n",
       "    355,\n",
       "    257,\n",
       "    4645,\n",
       "    13,\n",
       "    50763],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44870388146602747,\n",
       "   'compression_ratio': 1.7772511848341233,\n",
       "   'no_speech_prob': 0.017426971346139908},\n",
       "  {'id': 977,\n",
       "   'seek': 387386,\n",
       "   'start': 3881.86,\n",
       "   'end': 3884.86,\n",
       "   'text': ' This is the output of the decision tree.',\n",
       "   'tokens': [50763, 770, 318, 262, 5072, 286, 262, 2551, 5509, 13, 50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44870388146602747,\n",
       "   'compression_ratio': 1.7772511848341233,\n",
       "   'no_speech_prob': 0.017426971346139908},\n",
       "  {'id': 978,\n",
       "   'seek': 387386,\n",
       "   'start': 3884.86,\n",
       "   'end': 3890.86,\n",
       "   'text': ' This is what we hope to learn from a machine learning algorithm called the decision tree.',\n",
       "   'tokens': [50913,\n",
       "    770,\n",
       "    318,\n",
       "    644,\n",
       "    356,\n",
       "    2911,\n",
       "    284,\n",
       "    2193,\n",
       "    422,\n",
       "    257,\n",
       "    4572,\n",
       "    4673,\n",
       "    11862,\n",
       "    1444,\n",
       "    262,\n",
       "    2551,\n",
       "    5509,\n",
       "    13,\n",
       "    51213],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44870388146602747,\n",
       "   'compression_ratio': 1.7772511848341233,\n",
       "   'no_speech_prob': 0.017426971346139908},\n",
       "  {'id': 979,\n",
       "   'seek': 387386,\n",
       "   'start': 3890.86,\n",
       "   'end': 3892.86,\n",
       "   'text': ' This is our tree.',\n",
       "   'tokens': [51213, 770, 318, 674, 5509, 13, 51313],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44870388146602747,\n",
       "   'compression_ratio': 1.7772511848341233,\n",
       "   'no_speech_prob': 0.017426971346139908},\n",
       "  {'id': 980,\n",
       "   'seek': 387386,\n",
       "   'start': 3892.86,\n",
       "   'end': 3894.86,\n",
       "   'text': ' You can see you have some rules.',\n",
       "   'tokens': [51313, 921, 460, 766, 345, 423, 617, 3173, 13, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44870388146602747,\n",
       "   'compression_ratio': 1.7772511848341233,\n",
       "   'no_speech_prob': 0.017426971346139908},\n",
       "  {'id': 981,\n",
       "   'seek': 387386,\n",
       "   'start': 3894.86,\n",
       "   'end': 3897.86,\n",
       "   'text': ' You have some branches and you have some leaves.',\n",
       "   'tokens': [51413,\n",
       "    921,\n",
       "    423,\n",
       "    617,\n",
       "    13737,\n",
       "    290,\n",
       "    345,\n",
       "    423,\n",
       "    617,\n",
       "    5667,\n",
       "    13,\n",
       "    51563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44870388146602747,\n",
       "   'compression_ratio': 1.7772511848341233,\n",
       "   'no_speech_prob': 0.017426971346139908},\n",
       "  {'id': 982,\n",
       "   'seek': 387386,\n",
       "   'start': 3897.86,\n",
       "   'end': 3900.86,\n",
       "   'text': ' These are also telling what is different.',\n",
       "   'tokens': [51563, 2312, 389, 635, 5149, 644, 318, 1180, 13, 51713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44870388146602747,\n",
       "   'compression_ratio': 1.7772511848341233,\n",
       "   'no_speech_prob': 0.017426971346139908},\n",
       "  {'id': 983,\n",
       "   'seek': 390086,\n",
       "   'start': 3900.86,\n",
       "   'end': 3902.86,\n",
       "   'text': ' I have to be sorry previously.',\n",
       "   'tokens': [50363, 314, 423, 284, 307, 7926, 4271, 13, 50463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.45687353951590404,\n",
       "   'compression_ratio': 1.8232323232323233,\n",
       "   'no_speech_prob': 0.09780457615852356},\n",
       "  {'id': 984,\n",
       "   'seek': 390086,\n",
       "   'start': 3902.86,\n",
       "   'end': 3906.86,\n",
       "   'text': ' If it is overcast, Glauvitz, Labor.',\n",
       "   'tokens': [50463,\n",
       "    1002,\n",
       "    340,\n",
       "    318,\n",
       "    625,\n",
       "    2701,\n",
       "    11,\n",
       "    2671,\n",
       "    559,\n",
       "    85,\n",
       "    4224,\n",
       "    11,\n",
       "    7882,\n",
       "    13,\n",
       "    50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.45687353951590404,\n",
       "   'compression_ratio': 1.8232323232323233,\n",
       "   'no_speech_prob': 0.09780457615852356},\n",
       "  {'id': 985,\n",
       "   'seek': 390086,\n",
       "   'start': 3906.86,\n",
       "   'end': 3910.86,\n",
       "   'text': ' If it is, if the outlook is overcast, you play it in it.',\n",
       "   'tokens': [50663,\n",
       "    1002,\n",
       "    340,\n",
       "    318,\n",
       "    11,\n",
       "    611,\n",
       "    262,\n",
       "    19360,\n",
       "    318,\n",
       "    625,\n",
       "    2701,\n",
       "    11,\n",
       "    345,\n",
       "    711,\n",
       "    340,\n",
       "    287,\n",
       "    340,\n",
       "    13,\n",
       "    50863],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.45687353951590404,\n",
       "   'compression_ratio': 1.8232323232323233,\n",
       "   'no_speech_prob': 0.09780457615852356},\n",
       "  {'id': 986,\n",
       "   'seek': 390086,\n",
       "   'start': 3910.86,\n",
       "   'end': 3915.86,\n",
       "   'text': ' But if the outlook is semi and the humidity is lower, it is still playing.',\n",
       "   'tokens': [50863,\n",
       "    887,\n",
       "    611,\n",
       "    262,\n",
       "    19360,\n",
       "    318,\n",
       "    10663,\n",
       "    290,\n",
       "    262,\n",
       "    27716,\n",
       "    318,\n",
       "    2793,\n",
       "    11,\n",
       "    340,\n",
       "    318,\n",
       "    991,\n",
       "    2712,\n",
       "    13,\n",
       "    51113],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.45687353951590404,\n",
       "   'compression_ratio': 1.8232323232323233,\n",
       "   'no_speech_prob': 0.09780457615852356},\n",
       "  {'id': 987,\n",
       "   'seek': 390086,\n",
       "   'start': 3915.86,\n",
       "   'end': 3922.86,\n",
       "   'text': ' It is only when the humidity is high and the outlook is sunny, I will not only play.',\n",
       "   'tokens': [51113,\n",
       "    632,\n",
       "    318,\n",
       "    691,\n",
       "    618,\n",
       "    262,\n",
       "    27716,\n",
       "    318,\n",
       "    1029,\n",
       "    290,\n",
       "    262,\n",
       "    19360,\n",
       "    318,\n",
       "    27737,\n",
       "    11,\n",
       "    314,\n",
       "    481,\n",
       "    407,\n",
       "    691,\n",
       "    711,\n",
       "    13,\n",
       "    51463],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.45687353951590404,\n",
       "   'compression_ratio': 1.8232323232323233,\n",
       "   'no_speech_prob': 0.09780457615852356},\n",
       "  {'id': 988,\n",
       "   'seek': 390086,\n",
       "   'start': 3922.86,\n",
       "   'end': 3926.86,\n",
       "   'text': ' Similarly if the outlook is raining, but the wind is really I can still play.',\n",
       "   'tokens': [51463,\n",
       "    15298,\n",
       "    611,\n",
       "    262,\n",
       "    19360,\n",
       "    318,\n",
       "    43079,\n",
       "    11,\n",
       "    475,\n",
       "    262,\n",
       "    2344,\n",
       "    318,\n",
       "    1107,\n",
       "    314,\n",
       "    460,\n",
       "    991,\n",
       "    711,\n",
       "    13,\n",
       "    51663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.45687353951590404,\n",
       "   'compression_ratio': 1.8232323232323233,\n",
       "   'no_speech_prob': 0.09780457615852356},\n",
       "  {'id': 989,\n",
       "   'seek': 392686,\n",
       "   'start': 3926.86,\n",
       "   'end': 3930.86,\n",
       "   'text': ' But if the wind is strong, maybe I will not be able to play.',\n",
       "   'tokens': [50363,\n",
       "    887,\n",
       "    611,\n",
       "    262,\n",
       "    2344,\n",
       "    318,\n",
       "    1913,\n",
       "    11,\n",
       "    3863,\n",
       "    314,\n",
       "    481,\n",
       "    407,\n",
       "    307,\n",
       "    1498,\n",
       "    284,\n",
       "    711,\n",
       "    13,\n",
       "    50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.29962395562065974,\n",
       "   'compression_ratio': 1.559090909090909,\n",
       "   'no_speech_prob': 0.165657639503479},\n",
       "  {'id': 990,\n",
       "   'seek': 392686,\n",
       "   'start': 3930.86,\n",
       "   'end': 3932.86,\n",
       "   'text': ' Or this is a specific example.',\n",
       "   'tokens': [50563, 1471, 428, 318, 257, 2176, 1672, 13, 50663],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.29962395562065974,\n",
       "   'compression_ratio': 1.559090909090909,\n",
       "   'no_speech_prob': 0.165657639503479},\n",
       "  {'id': 991,\n",
       "   'seek': 392686,\n",
       "   'start': 3932.86,\n",
       "   'end': 3937.86,\n",
       "   'text': ' This is what we hope to learn using a algorithm.',\n",
       "   'tokens': [50663,\n",
       "    770,\n",
       "    318,\n",
       "    644,\n",
       "    356,\n",
       "    2911,\n",
       "    284,\n",
       "    2193,\n",
       "    1262,\n",
       "    257,\n",
       "    11862,\n",
       "    13,\n",
       "    50913],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.29962395562065974,\n",
       "   'compression_ratio': 1.559090909090909,\n",
       "   'no_speech_prob': 0.165657639503479},\n",
       "  {'id': 992,\n",
       "   'seek': 392686,\n",
       "   'start': 3937.86,\n",
       "   'end': 3940.86,\n",
       "   'text': ' We have data.',\n",
       "   'tokens': [50913, 775, 423, 1366, 13, 51063],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.29962395562065974,\n",
       "   'compression_ratio': 1.559090909090909,\n",
       "   'no_speech_prob': 0.165657639503479},\n",
       "  {'id': 993,\n",
       "   'seek': 392686,\n",
       "   'start': 3940.86,\n",
       "   'end': 3944.86,\n",
       "   'text': ' We have some performance images, what the accuracy figures and results are.',\n",
       "   'tokens': [51063,\n",
       "    775,\n",
       "    423,\n",
       "    617,\n",
       "    2854,\n",
       "    4263,\n",
       "    11,\n",
       "    644,\n",
       "    262,\n",
       "    9922,\n",
       "    5538,\n",
       "    290,\n",
       "    2482,\n",
       "    389,\n",
       "    13,\n",
       "    51263],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.29962395562065974,\n",
       "   'compression_ratio': 1.559090909090909,\n",
       "   'no_speech_prob': 0.165657639503479},\n",
       "  {'id': 994,\n",
       "   'seek': 392686,\n",
       "   'start': 3944.86,\n",
       "   'end': 3947.86,\n",
       "   'text': ' And we have experience coming from this data.',\n",
       "   'tokens': [51263, 843, 356, 423, 1998, 2406, 422, 428, 1366, 13, 51413],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.29962395562065974,\n",
       "   'compression_ratio': 1.559090909090909,\n",
       "   'no_speech_prob': 0.165657639503479},\n",
       "  {'id': 995,\n",
       "   'seek': 392686,\n",
       "   'start': 3950.86,\n",
       "   'end': 3955.86,\n",
       "   'text': ' Interestingly, what is an optimum decision tree that we can learn?',\n",
       "   'tokens': [51563,\n",
       "    25044,\n",
       "    11,\n",
       "    644,\n",
       "    318,\n",
       "    281,\n",
       "    39475,\n",
       "    2551,\n",
       "    5509,\n",
       "    326,\n",
       "    356,\n",
       "    460,\n",
       "    2193,\n",
       "    30,\n",
       "    51813],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.29962395562065974,\n",
       "   'compression_ratio': 1.559090909090909,\n",
       "   'no_speech_prob': 0.165657639503479},\n",
       "  {'id': 996,\n",
       "   'seek': 395586,\n",
       "   'start': 3955.86,\n",
       "   'end': 3958.86,\n",
       "   'text': ' What is the optimum tree that we can learn?',\n",
       "   'tokens': [50363,\n",
       "    1867,\n",
       "    318,\n",
       "    262,\n",
       "    39475,\n",
       "    5509,\n",
       "    326,\n",
       "    356,\n",
       "    460,\n",
       "    2193,\n",
       "    30,\n",
       "    50513],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.46809438331839964,\n",
       "   'compression_ratio': 1.7303921568627452,\n",
       "   'no_speech_prob': 0.04118362069129944},\n",
       "  {'id': 997,\n",
       "   'seek': 395586,\n",
       "   'start': 3958.86,\n",
       "   'end': 3959.86,\n",
       "   'text': ' We have learned one such tree.',\n",
       "   'tokens': [50513, 775, 423, 4499, 530, 884, 5509, 13, 50563],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.46809438331839964,\n",
       "   'compression_ratio': 1.7303921568627452,\n",
       "   'no_speech_prob': 0.04118362069129944},\n",
       "  {'id': 998,\n",
       "   'seek': 395586,\n",
       "   'start': 3959.86,\n",
       "   'end': 3962.86,\n",
       "   'text': ' Could you have learned many such trees?',\n",
       "   'tokens': [50563, 10347, 345, 423, 4499, 867, 884, 7150, 30, 50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.46809438331839964,\n",
       "   'compression_ratio': 1.7303921568627452,\n",
       "   'no_speech_prob': 0.04118362069129944},\n",
       "  {'id': 999,\n",
       "   'seek': 395586,\n",
       "   'start': 3962.86,\n",
       "   'end': 3968.86,\n",
       "   'text': ' Could you have learned tree where the environment appears, the environment appears below?',\n",
       "   'tokens': [50713,\n",
       "    10347,\n",
       "    345,\n",
       "    423,\n",
       "    4499,\n",
       "    5509,\n",
       "    810,\n",
       "    262,\n",
       "    2858,\n",
       "    3568,\n",
       "    11,\n",
       "    262,\n",
       "    2858,\n",
       "    3568,\n",
       "    2174,\n",
       "    30,\n",
       "    51013],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.46809438331839964,\n",
       "   'compression_ratio': 1.7303921568627452,\n",
       "   'no_speech_prob': 0.04118362069129944},\n",
       "  ...],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b106d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_srt_from_transcription(transcription_objects, srt_file_path):\n",
    "    with open(srt_file_path, 'w') as srt_file:\n",
    "        index = 1  # SRT format starts with index 1\n",
    "\n",
    "        for entry in transcription_objects['segments']:\n",
    "            start_time = entry['start']\n",
    "            end_time = entry['end']\n",
    "            text = entry['text']\n",
    "\n",
    "            # Convert time to SRT format\n",
    "            start_time_str = format_time(start_time)\n",
    "            end_time_str = format_time(end_time)\n",
    "\n",
    "            # Write entry to SRT file\n",
    "            srt_file.write(f\"{index}\\n\")\n",
    "            srt_file.write(f\"{start_time_str} --> {end_time_str}\\n\")\n",
    "            srt_file.write(f\"{text}\\n\\n\")\n",
    "\n",
    "            index += 1\n",
    "\n",
    "def format_time(time_seconds):\n",
    "    minutes, seconds = divmod(time_seconds, 60)\n",
    "    hours, minutes = divmod(minutes, 60)\n",
    "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0dd53e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_srt_from_transcription(transcription, \"audio/CuBzyh4Xmvk.srt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b592eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "00:00:00,000 --> 00:00:05,000\n",
      " Please look at the code mentioned above and please sign up on the Google Cloud.\n",
      "\n",
      "2\n",
      "00:00:05,000 --> 00:00:08,000\n",
      " We've already started making some announcements.\n",
      "\n",
      "3\n",
      "00:00:08,000 --> 00:00:14,000\n"
     ]
    }
   ],
   "source": [
    "!head audio/CuBzyh4Xmvk.srt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac12faae",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33a7946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import getpass\n",
    "\n",
    "# Get OpenAI API key from the user without displaying it\n",
    "openai.api_key = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "921c0a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38339cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(transcription_text):\n",
    "    client = OpenAI(api_key=openai.api_key)\n",
    "\n",
    "    prompt = f\"Summarize the following transcription:\\n\\n{transcription_text}\\n\\nSummary:\"\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "\n",
    "    summary = chat_completion['choices'][0]['message']['content'].strip()\n",
    "    return summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
